{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3e5adf",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4953d96",
   "metadata": {},
   "source": [
    "Dataset in use: https://susanqq.github.io/UTKFace/\n",
    "\n",
    "*In-the-wild Faces is used and part-2 is selected for train, part-3 is selected for test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c12cb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e2d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'utk_train_cropped'\n",
    "val_dir = 'utk_test_cropped'\n",
    "input_size = (224, 224)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82175af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2050487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom dataset\n",
    "class GenderDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.filenames = os.listdir(directory)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.filenames[idx]\n",
    "        img_path = os.path.join(self.directory, img_name)\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        gender_label = int(img_name.split('_')[1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, gender_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "856e3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65fe7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': GenderDataset(directory=train_dir, transform=transform['train']),\n",
    "    'val': GenderDataset(directory=val_dir, transform=transform['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829ef977",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "811269e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GenderClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.bn1(nn.ReLU()(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(nn.ReLU()(self.conv2(x))))\n",
    "        x = self.pool(self.bn3(nn.ReLU()(self.conv3(x))))\n",
    "        x = x.view(-1, 64 * 28 * 28)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae5811eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenderClassifier()\n",
    "\n",
    "model.to(device)\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71b1931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [1/131], Loss: 0.6969\n",
      "Epoch [1/10], Phase: train, Batch: [2/131], Loss: 0.7787\n",
      "Epoch [1/10], Phase: train, Batch: [3/131], Loss: 2.4413\n",
      "Epoch [1/10], Phase: train, Batch: [4/131], Loss: 1.5349\n",
      "Epoch [1/10], Phase: train, Batch: [5/131], Loss: 0.7847\n",
      "Epoch [1/10], Phase: train, Batch: [6/131], Loss: 0.7700\n",
      "Epoch [1/10], Phase: train, Batch: [7/131], Loss: 0.5812\n",
      "Epoch [1/10], Phase: train, Batch: [8/131], Loss: 0.5352\n",
      "Epoch [1/10], Phase: train, Batch: [9/131], Loss: 0.4807\n",
      "Epoch [1/10], Phase: train, Batch: [10/131], Loss: 0.7715\n",
      "Epoch [1/10], Phase: train, Batch: [11/131], Loss: 0.7143\n",
      "Epoch [1/10], Phase: train, Batch: [12/131], Loss: 0.4150\n",
      "Epoch [1/10], Phase: train, Batch: [13/131], Loss: 0.6522\n",
      "Epoch [1/10], Phase: train, Batch: [14/131], Loss: 0.6573\n",
      "Epoch [1/10], Phase: train, Batch: [15/131], Loss: 0.6687\n",
      "Epoch [1/10], Phase: train, Batch: [16/131], Loss: 0.5777\n",
      "Epoch [1/10], Phase: train, Batch: [17/131], Loss: 0.4174\n",
      "Epoch [1/10], Phase: train, Batch: [18/131], Loss: 0.8005\n",
      "Epoch [1/10], Phase: train, Batch: [19/131], Loss: 0.5192\n",
      "Epoch [1/10], Phase: train, Batch: [20/131], Loss: 0.5754\n",
      "Epoch [1/10], Phase: train, Batch: [21/131], Loss: 0.5668\n",
      "Epoch [1/10], Phase: train, Batch: [22/131], Loss: 0.5613\n",
      "Epoch [1/10], Phase: train, Batch: [23/131], Loss: 0.4697\n",
      "Epoch [1/10], Phase: train, Batch: [24/131], Loss: 0.3493\n",
      "Epoch [1/10], Phase: train, Batch: [25/131], Loss: 0.4367\n",
      "Epoch [1/10], Phase: train, Batch: [26/131], Loss: 0.7181\n",
      "Epoch [1/10], Phase: train, Batch: [27/131], Loss: 0.4141\n",
      "Epoch [1/10], Phase: train, Batch: [28/131], Loss: 0.5754\n",
      "Epoch [1/10], Phase: train, Batch: [29/131], Loss: 0.4300\n",
      "Epoch [1/10], Phase: train, Batch: [30/131], Loss: 0.5232\n",
      "Epoch [1/10], Phase: train, Batch: [31/131], Loss: 0.4671\n",
      "Epoch [1/10], Phase: train, Batch: [32/131], Loss: 0.4855\n",
      "Epoch [1/10], Phase: train, Batch: [33/131], Loss: 0.5390\n",
      "Epoch [1/10], Phase: train, Batch: [34/131], Loss: 0.4825\n",
      "Epoch [1/10], Phase: train, Batch: [35/131], Loss: 0.5783\n",
      "Epoch [1/10], Phase: train, Batch: [36/131], Loss: 0.5178\n",
      "Epoch [1/10], Phase: train, Batch: [37/131], Loss: 0.4557\n",
      "Epoch [1/10], Phase: train, Batch: [38/131], Loss: 0.5631\n",
      "Epoch [1/10], Phase: train, Batch: [39/131], Loss: 0.5054\n",
      "Epoch [1/10], Phase: train, Batch: [40/131], Loss: 0.3540\n",
      "Epoch [1/10], Phase: train, Batch: [41/131], Loss: 0.4511\n",
      "Epoch [1/10], Phase: train, Batch: [42/131], Loss: 0.6189\n",
      "Epoch [1/10], Phase: train, Batch: [43/131], Loss: 0.3983\n",
      "Epoch [1/10], Phase: train, Batch: [44/131], Loss: 0.5258\n",
      "Epoch [1/10], Phase: train, Batch: [45/131], Loss: 0.3329\n",
      "Epoch [1/10], Phase: train, Batch: [46/131], Loss: 0.5246\n",
      "Epoch [1/10], Phase: train, Batch: [47/131], Loss: 0.6185\n",
      "Epoch [1/10], Phase: train, Batch: [48/131], Loss: 0.4152\n",
      "Epoch [1/10], Phase: train, Batch: [49/131], Loss: 0.3214\n",
      "Epoch [1/10], Phase: train, Batch: [50/131], Loss: 0.5659\n",
      "Epoch [1/10], Phase: train, Batch: [51/131], Loss: 0.5530\n",
      "Epoch [1/10], Phase: train, Batch: [52/131], Loss: 0.2554\n",
      "Epoch [1/10], Phase: train, Batch: [53/131], Loss: 0.4327\n",
      "Epoch [1/10], Phase: train, Batch: [54/131], Loss: 0.5250\n",
      "Epoch [1/10], Phase: train, Batch: [55/131], Loss: 0.4682\n",
      "Epoch [1/10], Phase: train, Batch: [56/131], Loss: 0.5712\n",
      "Epoch [1/10], Phase: train, Batch: [57/131], Loss: 0.4957\n",
      "Epoch [1/10], Phase: train, Batch: [58/131], Loss: 0.3561\n",
      "Epoch [1/10], Phase: train, Batch: [59/131], Loss: 0.5426\n",
      "Epoch [1/10], Phase: train, Batch: [60/131], Loss: 0.2158\n",
      "Epoch [1/10], Phase: train, Batch: [61/131], Loss: 0.4867\n",
      "Epoch [1/10], Phase: train, Batch: [62/131], Loss: 0.3706\n",
      "Epoch [1/10], Phase: train, Batch: [63/131], Loss: 0.4648\n",
      "Epoch [1/10], Phase: train, Batch: [64/131], Loss: 0.4018\n",
      "Epoch [1/10], Phase: train, Batch: [65/131], Loss: 0.4860\n",
      "Epoch [1/10], Phase: train, Batch: [66/131], Loss: 0.4031\n",
      "Epoch [1/10], Phase: train, Batch: [67/131], Loss: 0.3551\n",
      "Epoch [1/10], Phase: train, Batch: [68/131], Loss: 0.3738\n",
      "Epoch [1/10], Phase: train, Batch: [69/131], Loss: 0.3150\n",
      "Epoch [1/10], Phase: train, Batch: [70/131], Loss: 0.3866\n",
      "Epoch [1/10], Phase: train, Batch: [71/131], Loss: 0.4257\n",
      "Epoch [1/10], Phase: train, Batch: [72/131], Loss: 0.2964\n",
      "Epoch [1/10], Phase: train, Batch: [73/131], Loss: 0.4302\n",
      "Epoch [1/10], Phase: train, Batch: [74/131], Loss: 0.3418\n",
      "Epoch [1/10], Phase: train, Batch: [75/131], Loss: 0.2860\n",
      "Epoch [1/10], Phase: train, Batch: [76/131], Loss: 0.3818\n",
      "Epoch [1/10], Phase: train, Batch: [77/131], Loss: 0.4737\n",
      "Epoch [1/10], Phase: train, Batch: [78/131], Loss: 0.2633\n",
      "Epoch [1/10], Phase: train, Batch: [79/131], Loss: 0.2933\n",
      "Epoch [1/10], Phase: train, Batch: [80/131], Loss: 0.3573\n",
      "Epoch [1/10], Phase: train, Batch: [81/131], Loss: 0.3829\n",
      "Epoch [1/10], Phase: train, Batch: [82/131], Loss: 0.3167\n",
      "Epoch [1/10], Phase: train, Batch: [83/131], Loss: 0.3726\n",
      "Epoch [1/10], Phase: train, Batch: [84/131], Loss: 0.4192\n",
      "Epoch [1/10], Phase: train, Batch: [85/131], Loss: 0.3925\n",
      "Epoch [1/10], Phase: train, Batch: [86/131], Loss: 0.6278\n",
      "Epoch [1/10], Phase: train, Batch: [87/131], Loss: 0.3795\n",
      "Epoch [1/10], Phase: train, Batch: [88/131], Loss: 0.3150\n",
      "Epoch [1/10], Phase: train, Batch: [89/131], Loss: 0.5507\n",
      "Epoch [1/10], Phase: train, Batch: [90/131], Loss: 0.5069\n",
      "Epoch [1/10], Phase: train, Batch: [91/131], Loss: 0.5046\n",
      "Epoch [1/10], Phase: train, Batch: [92/131], Loss: 0.3450\n",
      "Epoch [1/10], Phase: train, Batch: [93/131], Loss: 0.3716\n",
      "Epoch [1/10], Phase: train, Batch: [94/131], Loss: 0.3750\n",
      "Epoch [1/10], Phase: train, Batch: [95/131], Loss: 0.4429\n",
      "Epoch [1/10], Phase: train, Batch: [96/131], Loss: 0.3839\n",
      "Epoch [1/10], Phase: train, Batch: [97/131], Loss: 0.4297\n",
      "Epoch [1/10], Phase: train, Batch: [98/131], Loss: 0.3642\n",
      "Epoch [1/10], Phase: train, Batch: [99/131], Loss: 0.5771\n",
      "Epoch [1/10], Phase: train, Batch: [100/131], Loss: 0.3731\n",
      "Epoch [1/10], Phase: train, Batch: [101/131], Loss: 0.5045\n",
      "Epoch [1/10], Phase: train, Batch: [102/131], Loss: 0.4532\n",
      "Epoch [1/10], Phase: train, Batch: [103/131], Loss: 0.4773\n",
      "Epoch [1/10], Phase: train, Batch: [104/131], Loss: 0.3137\n",
      "Epoch [1/10], Phase: train, Batch: [105/131], Loss: 0.3885\n",
      "Epoch [1/10], Phase: train, Batch: [106/131], Loss: 0.4490\n",
      "Epoch [1/10], Phase: train, Batch: [107/131], Loss: 0.3574\n",
      "Epoch [1/10], Phase: train, Batch: [108/131], Loss: 0.2905\n",
      "Epoch [1/10], Phase: train, Batch: [109/131], Loss: 0.3407\n",
      "Epoch [1/10], Phase: train, Batch: [110/131], Loss: 0.3199\n",
      "Epoch [1/10], Phase: train, Batch: [111/131], Loss: 0.2911\n",
      "Epoch [1/10], Phase: train, Batch: [112/131], Loss: 0.4073\n",
      "Epoch [1/10], Phase: train, Batch: [113/131], Loss: 0.4299\n",
      "Epoch [1/10], Phase: train, Batch: [114/131], Loss: 0.3927\n",
      "Epoch [1/10], Phase: train, Batch: [115/131], Loss: 0.3038\n",
      "Epoch [1/10], Phase: train, Batch: [116/131], Loss: 0.2263\n",
      "Epoch [1/10], Phase: train, Batch: [117/131], Loss: 0.4057\n",
      "Epoch [1/10], Phase: train, Batch: [118/131], Loss: 0.4802\n",
      "Epoch [1/10], Phase: train, Batch: [119/131], Loss: 0.3064\n",
      "Epoch [1/10], Phase: train, Batch: [120/131], Loss: 0.3900\n",
      "Epoch [1/10], Phase: train, Batch: [121/131], Loss: 0.3551\n",
      "Epoch [1/10], Phase: train, Batch: [122/131], Loss: 0.3728\n",
      "Epoch [1/10], Phase: train, Batch: [123/131], Loss: 0.3843\n",
      "Epoch [1/10], Phase: train, Batch: [124/131], Loss: 0.2766\n",
      "Epoch [1/10], Phase: train, Batch: [125/131], Loss: 0.3728\n",
      "Epoch [1/10], Phase: train, Batch: [126/131], Loss: 0.3141\n",
      "Epoch [1/10], Phase: train, Batch: [127/131], Loss: 0.3490\n",
      "Epoch [1/10], Phase: train, Batch: [128/131], Loss: 0.4387\n",
      "Epoch [1/10], Phase: train, Batch: [129/131], Loss: 0.3110\n",
      "Epoch [1/10], Phase: train, Batch: [130/131], Loss: 0.3214\n",
      "Epoch [1/10], Phase: train, Batch: [131/131], Loss: 0.5434\n",
      "Epoch [1/10], Train Loss: 0.4740\n",
      "Epoch [2/10], Phase: train, Batch: [1/131], Loss: 0.2120\n",
      "Epoch [2/10], Phase: train, Batch: [2/131], Loss: 0.3148\n",
      "Epoch [2/10], Phase: train, Batch: [3/131], Loss: 0.2513\n",
      "Epoch [2/10], Phase: train, Batch: [4/131], Loss: 0.2466\n",
      "Epoch [2/10], Phase: train, Batch: [5/131], Loss: 0.4631\n",
      "Epoch [2/10], Phase: train, Batch: [6/131], Loss: 0.3524\n",
      "Epoch [2/10], Phase: train, Batch: [7/131], Loss: 0.4836\n",
      "Epoch [2/10], Phase: train, Batch: [8/131], Loss: 0.2158\n",
      "Epoch [2/10], Phase: train, Batch: [9/131], Loss: 0.2758\n",
      "Epoch [2/10], Phase: train, Batch: [10/131], Loss: 0.3009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [11/131], Loss: 0.3319\n",
      "Epoch [2/10], Phase: train, Batch: [12/131], Loss: 0.1976\n",
      "Epoch [2/10], Phase: train, Batch: [13/131], Loss: 0.3806\n",
      "Epoch [2/10], Phase: train, Batch: [14/131], Loss: 0.2330\n",
      "Epoch [2/10], Phase: train, Batch: [15/131], Loss: 0.1949\n",
      "Epoch [2/10], Phase: train, Batch: [16/131], Loss: 0.2578\n",
      "Epoch [2/10], Phase: train, Batch: [17/131], Loss: 0.2658\n",
      "Epoch [2/10], Phase: train, Batch: [18/131], Loss: 0.2367\n",
      "Epoch [2/10], Phase: train, Batch: [19/131], Loss: 0.3115\n",
      "Epoch [2/10], Phase: train, Batch: [20/131], Loss: 0.4667\n",
      "Epoch [2/10], Phase: train, Batch: [21/131], Loss: 0.2484\n",
      "Epoch [2/10], Phase: train, Batch: [22/131], Loss: 0.4620\n",
      "Epoch [2/10], Phase: train, Batch: [23/131], Loss: 0.1751\n",
      "Epoch [2/10], Phase: train, Batch: [24/131], Loss: 0.2071\n",
      "Epoch [2/10], Phase: train, Batch: [25/131], Loss: 0.2952\n",
      "Epoch [2/10], Phase: train, Batch: [26/131], Loss: 0.4027\n",
      "Epoch [2/10], Phase: train, Batch: [27/131], Loss: 0.3823\n",
      "Epoch [2/10], Phase: train, Batch: [28/131], Loss: 0.3614\n",
      "Epoch [2/10], Phase: train, Batch: [29/131], Loss: 0.2820\n",
      "Epoch [2/10], Phase: train, Batch: [30/131], Loss: 0.3512\n",
      "Epoch [2/10], Phase: train, Batch: [31/131], Loss: 0.2395\n",
      "Epoch [2/10], Phase: train, Batch: [32/131], Loss: 0.3538\n",
      "Epoch [2/10], Phase: train, Batch: [33/131], Loss: 0.2185\n",
      "Epoch [2/10], Phase: train, Batch: [34/131], Loss: 0.5547\n",
      "Epoch [2/10], Phase: train, Batch: [35/131], Loss: 0.3664\n",
      "Epoch [2/10], Phase: train, Batch: [36/131], Loss: 0.2122\n",
      "Epoch [2/10], Phase: train, Batch: [37/131], Loss: 0.1639\n",
      "Epoch [2/10], Phase: train, Batch: [38/131], Loss: 0.2212\n",
      "Epoch [2/10], Phase: train, Batch: [39/131], Loss: 0.4005\n",
      "Epoch [2/10], Phase: train, Batch: [40/131], Loss: 0.4543\n",
      "Epoch [2/10], Phase: train, Batch: [41/131], Loss: 0.4418\n",
      "Epoch [2/10], Phase: train, Batch: [42/131], Loss: 0.2248\n",
      "Epoch [2/10], Phase: train, Batch: [43/131], Loss: 0.3992\n",
      "Epoch [2/10], Phase: train, Batch: [44/131], Loss: 0.2458\n",
      "Epoch [2/10], Phase: train, Batch: [45/131], Loss: 0.3871\n",
      "Epoch [2/10], Phase: train, Batch: [46/131], Loss: 0.1914\n",
      "Epoch [2/10], Phase: train, Batch: [47/131], Loss: 0.2425\n",
      "Epoch [2/10], Phase: train, Batch: [48/131], Loss: 0.3141\n",
      "Epoch [2/10], Phase: train, Batch: [49/131], Loss: 0.2331\n",
      "Epoch [2/10], Phase: train, Batch: [50/131], Loss: 0.3779\n",
      "Epoch [2/10], Phase: train, Batch: [51/131], Loss: 0.3300\n",
      "Epoch [2/10], Phase: train, Batch: [52/131], Loss: 0.1853\n",
      "Epoch [2/10], Phase: train, Batch: [53/131], Loss: 0.2138\n",
      "Epoch [2/10], Phase: train, Batch: [54/131], Loss: 0.3402\n",
      "Epoch [2/10], Phase: train, Batch: [55/131], Loss: 0.2212\n",
      "Epoch [2/10], Phase: train, Batch: [56/131], Loss: 0.2768\n",
      "Epoch [2/10], Phase: train, Batch: [57/131], Loss: 0.2371\n",
      "Epoch [2/10], Phase: train, Batch: [58/131], Loss: 0.2406\n",
      "Epoch [2/10], Phase: train, Batch: [59/131], Loss: 0.3143\n",
      "Epoch [2/10], Phase: train, Batch: [60/131], Loss: 0.2164\n",
      "Epoch [2/10], Phase: train, Batch: [61/131], Loss: 0.2705\n",
      "Epoch [2/10], Phase: train, Batch: [62/131], Loss: 0.1340\n",
      "Epoch [2/10], Phase: train, Batch: [63/131], Loss: 0.3263\n",
      "Epoch [2/10], Phase: train, Batch: [64/131], Loss: 0.2435\n",
      "Epoch [2/10], Phase: train, Batch: [65/131], Loss: 0.2942\n",
      "Epoch [2/10], Phase: train, Batch: [66/131], Loss: 0.3316\n",
      "Epoch [2/10], Phase: train, Batch: [67/131], Loss: 0.2846\n",
      "Epoch [2/10], Phase: train, Batch: [68/131], Loss: 0.2008\n",
      "Epoch [2/10], Phase: train, Batch: [69/131], Loss: 0.3111\n",
      "Epoch [2/10], Phase: train, Batch: [70/131], Loss: 0.2115\n",
      "Epoch [2/10], Phase: train, Batch: [71/131], Loss: 0.3194\n",
      "Epoch [2/10], Phase: train, Batch: [72/131], Loss: 0.1280\n",
      "Epoch [2/10], Phase: train, Batch: [73/131], Loss: 0.3143\n",
      "Epoch [2/10], Phase: train, Batch: [74/131], Loss: 0.1562\n",
      "Epoch [2/10], Phase: train, Batch: [75/131], Loss: 0.4081\n",
      "Epoch [2/10], Phase: train, Batch: [76/131], Loss: 0.2799\n",
      "Epoch [2/10], Phase: train, Batch: [77/131], Loss: 0.2161\n",
      "Epoch [2/10], Phase: train, Batch: [78/131], Loss: 0.2941\n",
      "Epoch [2/10], Phase: train, Batch: [79/131], Loss: 0.2701\n",
      "Epoch [2/10], Phase: train, Batch: [80/131], Loss: 0.2571\n",
      "Epoch [2/10], Phase: train, Batch: [81/131], Loss: 0.2250\n",
      "Epoch [2/10], Phase: train, Batch: [82/131], Loss: 0.3581\n",
      "Epoch [2/10], Phase: train, Batch: [83/131], Loss: 0.1974\n",
      "Epoch [2/10], Phase: train, Batch: [84/131], Loss: 0.3109\n",
      "Epoch [2/10], Phase: train, Batch: [85/131], Loss: 0.2843\n",
      "Epoch [2/10], Phase: train, Batch: [86/131], Loss: 0.3514\n",
      "Epoch [2/10], Phase: train, Batch: [87/131], Loss: 0.4166\n",
      "Epoch [2/10], Phase: train, Batch: [88/131], Loss: 0.1943\n",
      "Epoch [2/10], Phase: train, Batch: [89/131], Loss: 0.1704\n",
      "Epoch [2/10], Phase: train, Batch: [90/131], Loss: 0.2846\n",
      "Epoch [2/10], Phase: train, Batch: [91/131], Loss: 0.3229\n",
      "Epoch [2/10], Phase: train, Batch: [92/131], Loss: 0.2899\n",
      "Epoch [2/10], Phase: train, Batch: [93/131], Loss: 0.1927\n",
      "Epoch [2/10], Phase: train, Batch: [94/131], Loss: 0.4329\n",
      "Epoch [2/10], Phase: train, Batch: [95/131], Loss: 0.4067\n",
      "Epoch [2/10], Phase: train, Batch: [96/131], Loss: 0.2582\n",
      "Epoch [2/10], Phase: train, Batch: [97/131], Loss: 0.3907\n",
      "Epoch [2/10], Phase: train, Batch: [98/131], Loss: 0.2093\n",
      "Epoch [2/10], Phase: train, Batch: [99/131], Loss: 0.2781\n",
      "Epoch [2/10], Phase: train, Batch: [100/131], Loss: 0.2114\n",
      "Epoch [2/10], Phase: train, Batch: [101/131], Loss: 0.2050\n",
      "Epoch [2/10], Phase: train, Batch: [102/131], Loss: 0.1891\n",
      "Epoch [2/10], Phase: train, Batch: [103/131], Loss: 0.2627\n",
      "Epoch [2/10], Phase: train, Batch: [104/131], Loss: 0.2552\n",
      "Epoch [2/10], Phase: train, Batch: [105/131], Loss: 0.3037\n",
      "Epoch [2/10], Phase: train, Batch: [106/131], Loss: 0.3086\n",
      "Epoch [2/10], Phase: train, Batch: [107/131], Loss: 0.1355\n",
      "Epoch [2/10], Phase: train, Batch: [108/131], Loss: 0.1250\n",
      "Epoch [2/10], Phase: train, Batch: [109/131], Loss: 0.2579\n",
      "Epoch [2/10], Phase: train, Batch: [110/131], Loss: 0.2297\n",
      "Epoch [2/10], Phase: train, Batch: [111/131], Loss: 0.1759\n",
      "Epoch [2/10], Phase: train, Batch: [112/131], Loss: 0.1501\n",
      "Epoch [2/10], Phase: train, Batch: [113/131], Loss: 0.2118\n",
      "Epoch [2/10], Phase: train, Batch: [114/131], Loss: 0.2611\n",
      "Epoch [2/10], Phase: train, Batch: [115/131], Loss: 0.1414\n",
      "Epoch [2/10], Phase: train, Batch: [116/131], Loss: 0.2176\n",
      "Epoch [2/10], Phase: train, Batch: [117/131], Loss: 0.2396\n",
      "Epoch [2/10], Phase: train, Batch: [118/131], Loss: 0.2744\n",
      "Epoch [2/10], Phase: train, Batch: [119/131], Loss: 0.2638\n",
      "Epoch [2/10], Phase: train, Batch: [120/131], Loss: 0.5186\n",
      "Epoch [2/10], Phase: train, Batch: [121/131], Loss: 0.4415\n",
      "Epoch [2/10], Phase: train, Batch: [122/131], Loss: 0.2560\n",
      "Epoch [2/10], Phase: train, Batch: [123/131], Loss: 0.3134\n",
      "Epoch [2/10], Phase: train, Batch: [124/131], Loss: 0.2572\n",
      "Epoch [2/10], Phase: train, Batch: [125/131], Loss: 0.1950\n",
      "Epoch [2/10], Phase: train, Batch: [126/131], Loss: 0.1647\n",
      "Epoch [2/10], Phase: train, Batch: [127/131], Loss: 0.3109\n",
      "Epoch [2/10], Phase: train, Batch: [128/131], Loss: 0.2496\n",
      "Epoch [2/10], Phase: train, Batch: [129/131], Loss: 0.3591\n",
      "Epoch [2/10], Phase: train, Batch: [130/131], Loss: 0.1962\n",
      "Epoch [2/10], Phase: train, Batch: [131/131], Loss: 0.0501\n",
      "Epoch [2/10], Train Loss: 0.2803\n",
      "Epoch [3/10], Phase: train, Batch: [1/131], Loss: 0.2501\n",
      "Epoch [3/10], Phase: train, Batch: [2/131], Loss: 0.3689\n",
      "Epoch [3/10], Phase: train, Batch: [3/131], Loss: 0.1802\n",
      "Epoch [3/10], Phase: train, Batch: [4/131], Loss: 0.3327\n",
      "Epoch [3/10], Phase: train, Batch: [5/131], Loss: 0.1607\n",
      "Epoch [3/10], Phase: train, Batch: [6/131], Loss: 0.3001\n",
      "Epoch [3/10], Phase: train, Batch: [7/131], Loss: 0.2102\n",
      "Epoch [3/10], Phase: train, Batch: [8/131], Loss: 0.2405\n",
      "Epoch [3/10], Phase: train, Batch: [9/131], Loss: 0.2567\n",
      "Epoch [3/10], Phase: train, Batch: [10/131], Loss: 0.2220\n",
      "Epoch [3/10], Phase: train, Batch: [11/131], Loss: 0.1588\n",
      "Epoch [3/10], Phase: train, Batch: [12/131], Loss: 0.3387\n",
      "Epoch [3/10], Phase: train, Batch: [13/131], Loss: 0.1295\n",
      "Epoch [3/10], Phase: train, Batch: [14/131], Loss: 0.1668\n",
      "Epoch [3/10], Phase: train, Batch: [15/131], Loss: 0.1204\n",
      "Epoch [3/10], Phase: train, Batch: [16/131], Loss: 0.2278\n",
      "Epoch [3/10], Phase: train, Batch: [17/131], Loss: 0.2077\n",
      "Epoch [3/10], Phase: train, Batch: [18/131], Loss: 0.2144\n",
      "Epoch [3/10], Phase: train, Batch: [19/131], Loss: 0.1770\n",
      "Epoch [3/10], Phase: train, Batch: [20/131], Loss: 0.2381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [21/131], Loss: 0.1904\n",
      "Epoch [3/10], Phase: train, Batch: [22/131], Loss: 0.1764\n",
      "Epoch [3/10], Phase: train, Batch: [23/131], Loss: 0.2768\n",
      "Epoch [3/10], Phase: train, Batch: [24/131], Loss: 0.0816\n",
      "Epoch [3/10], Phase: train, Batch: [25/131], Loss: 0.1498\n",
      "Epoch [3/10], Phase: train, Batch: [26/131], Loss: 0.2622\n",
      "Epoch [3/10], Phase: train, Batch: [27/131], Loss: 0.1551\n",
      "Epoch [3/10], Phase: train, Batch: [28/131], Loss: 0.2043\n",
      "Epoch [3/10], Phase: train, Batch: [29/131], Loss: 0.3405\n",
      "Epoch [3/10], Phase: train, Batch: [30/131], Loss: 0.2751\n",
      "Epoch [3/10], Phase: train, Batch: [31/131], Loss: 0.1485\n",
      "Epoch [3/10], Phase: train, Batch: [32/131], Loss: 0.1620\n",
      "Epoch [3/10], Phase: train, Batch: [33/131], Loss: 0.1327\n",
      "Epoch [3/10], Phase: train, Batch: [34/131], Loss: 0.1378\n",
      "Epoch [3/10], Phase: train, Batch: [35/131], Loss: 0.2082\n",
      "Epoch [3/10], Phase: train, Batch: [36/131], Loss: 0.2190\n",
      "Epoch [3/10], Phase: train, Batch: [37/131], Loss: 0.1473\n",
      "Epoch [3/10], Phase: train, Batch: [38/131], Loss: 0.0659\n",
      "Epoch [3/10], Phase: train, Batch: [39/131], Loss: 0.2082\n",
      "Epoch [3/10], Phase: train, Batch: [40/131], Loss: 0.1617\n",
      "Epoch [3/10], Phase: train, Batch: [41/131], Loss: 0.2347\n",
      "Epoch [3/10], Phase: train, Batch: [42/131], Loss: 0.2524\n",
      "Epoch [3/10], Phase: train, Batch: [43/131], Loss: 0.1917\n",
      "Epoch [3/10], Phase: train, Batch: [44/131], Loss: 0.2577\n",
      "Epoch [3/10], Phase: train, Batch: [45/131], Loss: 0.2313\n",
      "Epoch [3/10], Phase: train, Batch: [46/131], Loss: 0.3445\n",
      "Epoch [3/10], Phase: train, Batch: [47/131], Loss: 0.1741\n",
      "Epoch [3/10], Phase: train, Batch: [48/131], Loss: 0.1960\n",
      "Epoch [3/10], Phase: train, Batch: [49/131], Loss: 0.1332\n",
      "Epoch [3/10], Phase: train, Batch: [50/131], Loss: 0.2349\n",
      "Epoch [3/10], Phase: train, Batch: [51/131], Loss: 0.1004\n",
      "Epoch [3/10], Phase: train, Batch: [52/131], Loss: 0.2093\n",
      "Epoch [3/10], Phase: train, Batch: [53/131], Loss: 0.3378\n",
      "Epoch [3/10], Phase: train, Batch: [54/131], Loss: 0.2170\n",
      "Epoch [3/10], Phase: train, Batch: [55/131], Loss: 0.1428\n",
      "Epoch [3/10], Phase: train, Batch: [56/131], Loss: 0.1466\n",
      "Epoch [3/10], Phase: train, Batch: [57/131], Loss: 0.1206\n",
      "Epoch [3/10], Phase: train, Batch: [58/131], Loss: 0.0641\n",
      "Epoch [3/10], Phase: train, Batch: [59/131], Loss: 0.2283\n",
      "Epoch [3/10], Phase: train, Batch: [60/131], Loss: 0.1333\n",
      "Epoch [3/10], Phase: train, Batch: [61/131], Loss: 0.5014\n",
      "Epoch [3/10], Phase: train, Batch: [62/131], Loss: 0.0814\n",
      "Epoch [3/10], Phase: train, Batch: [63/131], Loss: 0.1868\n",
      "Epoch [3/10], Phase: train, Batch: [64/131], Loss: 0.2334\n",
      "Epoch [3/10], Phase: train, Batch: [65/131], Loss: 0.1270\n",
      "Epoch [3/10], Phase: train, Batch: [66/131], Loss: 0.1137\n",
      "Epoch [3/10], Phase: train, Batch: [67/131], Loss: 0.1402\n",
      "Epoch [3/10], Phase: train, Batch: [68/131], Loss: 0.3647\n",
      "Epoch [3/10], Phase: train, Batch: [69/131], Loss: 0.2665\n",
      "Epoch [3/10], Phase: train, Batch: [70/131], Loss: 0.1048\n",
      "Epoch [3/10], Phase: train, Batch: [71/131], Loss: 0.2553\n",
      "Epoch [3/10], Phase: train, Batch: [72/131], Loss: 0.1202\n",
      "Epoch [3/10], Phase: train, Batch: [73/131], Loss: 0.1021\n",
      "Epoch [3/10], Phase: train, Batch: [74/131], Loss: 0.1768\n",
      "Epoch [3/10], Phase: train, Batch: [75/131], Loss: 0.2615\n",
      "Epoch [3/10], Phase: train, Batch: [76/131], Loss: 0.1848\n",
      "Epoch [3/10], Phase: train, Batch: [77/131], Loss: 0.1402\n",
      "Epoch [3/10], Phase: train, Batch: [78/131], Loss: 0.2979\n",
      "Epoch [3/10], Phase: train, Batch: [79/131], Loss: 0.2327\n",
      "Epoch [3/10], Phase: train, Batch: [80/131], Loss: 0.2232\n",
      "Epoch [3/10], Phase: train, Batch: [81/131], Loss: 0.2682\n",
      "Epoch [3/10], Phase: train, Batch: [82/131], Loss: 0.1912\n",
      "Epoch [3/10], Phase: train, Batch: [83/131], Loss: 0.2382\n",
      "Epoch [3/10], Phase: train, Batch: [84/131], Loss: 0.2601\n",
      "Epoch [3/10], Phase: train, Batch: [85/131], Loss: 0.1905\n",
      "Epoch [3/10], Phase: train, Batch: [86/131], Loss: 0.1467\n",
      "Epoch [3/10], Phase: train, Batch: [87/131], Loss: 0.1637\n",
      "Epoch [3/10], Phase: train, Batch: [88/131], Loss: 0.1017\n",
      "Epoch [3/10], Phase: train, Batch: [89/131], Loss: 0.2726\n",
      "Epoch [3/10], Phase: train, Batch: [90/131], Loss: 0.1863\n",
      "Epoch [3/10], Phase: train, Batch: [91/131], Loss: 0.1782\n",
      "Epoch [3/10], Phase: train, Batch: [92/131], Loss: 0.2926\n",
      "Epoch [3/10], Phase: train, Batch: [93/131], Loss: 0.0706\n",
      "Epoch [3/10], Phase: train, Batch: [94/131], Loss: 0.2228\n",
      "Epoch [3/10], Phase: train, Batch: [95/131], Loss: 0.2695\n",
      "Epoch [3/10], Phase: train, Batch: [96/131], Loss: 0.1893\n",
      "Epoch [3/10], Phase: train, Batch: [97/131], Loss: 0.2439\n",
      "Epoch [3/10], Phase: train, Batch: [98/131], Loss: 0.0957\n",
      "Epoch [3/10], Phase: train, Batch: [99/131], Loss: 0.1967\n",
      "Epoch [3/10], Phase: train, Batch: [100/131], Loss: 0.1403\n",
      "Epoch [3/10], Phase: train, Batch: [101/131], Loss: 0.2897\n",
      "Epoch [3/10], Phase: train, Batch: [102/131], Loss: 0.2944\n",
      "Epoch [3/10], Phase: train, Batch: [103/131], Loss: 0.1467\n",
      "Epoch [3/10], Phase: train, Batch: [104/131], Loss: 0.1063\n",
      "Epoch [3/10], Phase: train, Batch: [105/131], Loss: 0.0767\n",
      "Epoch [3/10], Phase: train, Batch: [106/131], Loss: 0.2689\n",
      "Epoch [3/10], Phase: train, Batch: [107/131], Loss: 0.3833\n",
      "Epoch [3/10], Phase: train, Batch: [108/131], Loss: 0.2902\n",
      "Epoch [3/10], Phase: train, Batch: [109/131], Loss: 0.2334\n",
      "Epoch [3/10], Phase: train, Batch: [110/131], Loss: 0.2305\n",
      "Epoch [3/10], Phase: train, Batch: [111/131], Loss: 0.1284\n",
      "Epoch [3/10], Phase: train, Batch: [112/131], Loss: 0.2641\n",
      "Epoch [3/10], Phase: train, Batch: [113/131], Loss: 0.2491\n",
      "Epoch [3/10], Phase: train, Batch: [114/131], Loss: 0.1750\n",
      "Epoch [3/10], Phase: train, Batch: [115/131], Loss: 0.2081\n",
      "Epoch [3/10], Phase: train, Batch: [116/131], Loss: 0.3067\n",
      "Epoch [3/10], Phase: train, Batch: [117/131], Loss: 0.2032\n",
      "Epoch [3/10], Phase: train, Batch: [118/131], Loss: 0.3071\n",
      "Epoch [3/10], Phase: train, Batch: [119/131], Loss: 0.1082\n",
      "Epoch [3/10], Phase: train, Batch: [120/131], Loss: 0.0998\n",
      "Epoch [3/10], Phase: train, Batch: [121/131], Loss: 0.0949\n",
      "Epoch [3/10], Phase: train, Batch: [122/131], Loss: 0.2851\n",
      "Epoch [3/10], Phase: train, Batch: [123/131], Loss: 0.2334\n",
      "Epoch [3/10], Phase: train, Batch: [124/131], Loss: 0.1724\n",
      "Epoch [3/10], Phase: train, Batch: [125/131], Loss: 0.0940\n",
      "Epoch [3/10], Phase: train, Batch: [126/131], Loss: 0.1481\n",
      "Epoch [3/10], Phase: train, Batch: [127/131], Loss: 0.1487\n",
      "Epoch [3/10], Phase: train, Batch: [128/131], Loss: 0.2051\n",
      "Epoch [3/10], Phase: train, Batch: [129/131], Loss: 0.2667\n",
      "Epoch [3/10], Phase: train, Batch: [130/131], Loss: 0.0709\n",
      "Epoch [3/10], Phase: train, Batch: [131/131], Loss: 0.3213\n",
      "Epoch [3/10], Train Loss: 0.2023\n",
      "Epoch [4/10], Phase: train, Batch: [1/131], Loss: 0.1557\n",
      "Epoch [4/10], Phase: train, Batch: [2/131], Loss: 0.1438\n",
      "Epoch [4/10], Phase: train, Batch: [3/131], Loss: 0.1800\n",
      "Epoch [4/10], Phase: train, Batch: [4/131], Loss: 0.1304\n",
      "Epoch [4/10], Phase: train, Batch: [5/131], Loss: 0.1044\n",
      "Epoch [4/10], Phase: train, Batch: [6/131], Loss: 0.2184\n",
      "Epoch [4/10], Phase: train, Batch: [7/131], Loss: 0.0232\n",
      "Epoch [4/10], Phase: train, Batch: [8/131], Loss: 0.2000\n",
      "Epoch [4/10], Phase: train, Batch: [9/131], Loss: 0.1624\n",
      "Epoch [4/10], Phase: train, Batch: [10/131], Loss: 0.1107\n",
      "Epoch [4/10], Phase: train, Batch: [11/131], Loss: 0.1031\n",
      "Epoch [4/10], Phase: train, Batch: [12/131], Loss: 0.1948\n",
      "Epoch [4/10], Phase: train, Batch: [13/131], Loss: 0.1924\n",
      "Epoch [4/10], Phase: train, Batch: [14/131], Loss: 0.0952\n",
      "Epoch [4/10], Phase: train, Batch: [15/131], Loss: 0.0332\n",
      "Epoch [4/10], Phase: train, Batch: [16/131], Loss: 0.0758\n",
      "Epoch [4/10], Phase: train, Batch: [17/131], Loss: 0.1989\n",
      "Epoch [4/10], Phase: train, Batch: [18/131], Loss: 0.1349\n",
      "Epoch [4/10], Phase: train, Batch: [19/131], Loss: 0.1454\n",
      "Epoch [4/10], Phase: train, Batch: [20/131], Loss: 0.0963\n",
      "Epoch [4/10], Phase: train, Batch: [21/131], Loss: 0.0776\n",
      "Epoch [4/10], Phase: train, Batch: [22/131], Loss: 0.0352\n",
      "Epoch [4/10], Phase: train, Batch: [23/131], Loss: 0.2119\n",
      "Epoch [4/10], Phase: train, Batch: [24/131], Loss: 0.1397\n",
      "Epoch [4/10], Phase: train, Batch: [25/131], Loss: 0.1498\n",
      "Epoch [4/10], Phase: train, Batch: [26/131], Loss: 0.0420\n",
      "Epoch [4/10], Phase: train, Batch: [27/131], Loss: 0.1892\n",
      "Epoch [4/10], Phase: train, Batch: [28/131], Loss: 0.1842\n",
      "Epoch [4/10], Phase: train, Batch: [29/131], Loss: 0.1898\n",
      "Epoch [4/10], Phase: train, Batch: [30/131], Loss: 0.2277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [31/131], Loss: 0.1199\n",
      "Epoch [4/10], Phase: train, Batch: [32/131], Loss: 0.2708\n",
      "Epoch [4/10], Phase: train, Batch: [33/131], Loss: 0.1048\n",
      "Epoch [4/10], Phase: train, Batch: [34/131], Loss: 0.1510\n",
      "Epoch [4/10], Phase: train, Batch: [35/131], Loss: 0.0635\n",
      "Epoch [4/10], Phase: train, Batch: [36/131], Loss: 0.0652\n",
      "Epoch [4/10], Phase: train, Batch: [37/131], Loss: 0.1067\n",
      "Epoch [4/10], Phase: train, Batch: [38/131], Loss: 0.1777\n",
      "Epoch [4/10], Phase: train, Batch: [39/131], Loss: 0.1518\n",
      "Epoch [4/10], Phase: train, Batch: [40/131], Loss: 0.0863\n",
      "Epoch [4/10], Phase: train, Batch: [41/131], Loss: 0.1529\n",
      "Epoch [4/10], Phase: train, Batch: [42/131], Loss: 0.1697\n",
      "Epoch [4/10], Phase: train, Batch: [43/131], Loss: 0.1147\n",
      "Epoch [4/10], Phase: train, Batch: [44/131], Loss: 0.1294\n",
      "Epoch [4/10], Phase: train, Batch: [45/131], Loss: 0.1439\n",
      "Epoch [4/10], Phase: train, Batch: [46/131], Loss: 0.1349\n",
      "Epoch [4/10], Phase: train, Batch: [47/131], Loss: 0.1740\n",
      "Epoch [4/10], Phase: train, Batch: [48/131], Loss: 0.0616\n",
      "Epoch [4/10], Phase: train, Batch: [49/131], Loss: 0.1324\n",
      "Epoch [4/10], Phase: train, Batch: [50/131], Loss: 0.0540\n",
      "Epoch [4/10], Phase: train, Batch: [51/131], Loss: 0.0786\n",
      "Epoch [4/10], Phase: train, Batch: [52/131], Loss: 0.0482\n",
      "Epoch [4/10], Phase: train, Batch: [53/131], Loss: 0.1058\n",
      "Epoch [4/10], Phase: train, Batch: [54/131], Loss: 0.2443\n",
      "Epoch [4/10], Phase: train, Batch: [55/131], Loss: 0.0597\n",
      "Epoch [4/10], Phase: train, Batch: [56/131], Loss: 0.1092\n",
      "Epoch [4/10], Phase: train, Batch: [57/131], Loss: 0.1230\n",
      "Epoch [4/10], Phase: train, Batch: [58/131], Loss: 0.0671\n",
      "Epoch [4/10], Phase: train, Batch: [59/131], Loss: 0.1808\n",
      "Epoch [4/10], Phase: train, Batch: [60/131], Loss: 0.1564\n",
      "Epoch [4/10], Phase: train, Batch: [61/131], Loss: 0.1015\n",
      "Epoch [4/10], Phase: train, Batch: [62/131], Loss: 0.1401\n",
      "Epoch [4/10], Phase: train, Batch: [63/131], Loss: 0.0954\n",
      "Epoch [4/10], Phase: train, Batch: [64/131], Loss: 0.0644\n",
      "Epoch [4/10], Phase: train, Batch: [65/131], Loss: 0.1657\n",
      "Epoch [4/10], Phase: train, Batch: [66/131], Loss: 0.1894\n",
      "Epoch [4/10], Phase: train, Batch: [67/131], Loss: 0.3325\n",
      "Epoch [4/10], Phase: train, Batch: [68/131], Loss: 0.0653\n",
      "Epoch [4/10], Phase: train, Batch: [69/131], Loss: 0.1953\n",
      "Epoch [4/10], Phase: train, Batch: [70/131], Loss: 0.1161\n",
      "Epoch [4/10], Phase: train, Batch: [71/131], Loss: 0.1562\n",
      "Epoch [4/10], Phase: train, Batch: [72/131], Loss: 0.1624\n",
      "Epoch [4/10], Phase: train, Batch: [73/131], Loss: 0.2150\n",
      "Epoch [4/10], Phase: train, Batch: [74/131], Loss: 0.1052\n",
      "Epoch [4/10], Phase: train, Batch: [75/131], Loss: 0.0630\n",
      "Epoch [4/10], Phase: train, Batch: [76/131], Loss: 0.2037\n",
      "Epoch [4/10], Phase: train, Batch: [77/131], Loss: 0.1811\n",
      "Epoch [4/10], Phase: train, Batch: [78/131], Loss: 0.1118\n",
      "Epoch [4/10], Phase: train, Batch: [79/131], Loss: 0.1491\n",
      "Epoch [4/10], Phase: train, Batch: [80/131], Loss: 0.1313\n",
      "Epoch [4/10], Phase: train, Batch: [81/131], Loss: 0.1576\n",
      "Epoch [4/10], Phase: train, Batch: [82/131], Loss: 0.1726\n",
      "Epoch [4/10], Phase: train, Batch: [83/131], Loss: 0.1542\n",
      "Epoch [4/10], Phase: train, Batch: [84/131], Loss: 0.0866\n",
      "Epoch [4/10], Phase: train, Batch: [85/131], Loss: 0.1218\n",
      "Epoch [4/10], Phase: train, Batch: [86/131], Loss: 0.2116\n",
      "Epoch [4/10], Phase: train, Batch: [87/131], Loss: 0.0972\n",
      "Epoch [4/10], Phase: train, Batch: [88/131], Loss: 0.1581\n",
      "Epoch [4/10], Phase: train, Batch: [89/131], Loss: 0.0906\n",
      "Epoch [4/10], Phase: train, Batch: [90/131], Loss: 0.1339\n",
      "Epoch [4/10], Phase: train, Batch: [91/131], Loss: 0.0898\n",
      "Epoch [4/10], Phase: train, Batch: [92/131], Loss: 0.2694\n",
      "Epoch [4/10], Phase: train, Batch: [93/131], Loss: 0.1555\n",
      "Epoch [4/10], Phase: train, Batch: [94/131], Loss: 0.1424\n",
      "Epoch [4/10], Phase: train, Batch: [95/131], Loss: 0.1008\n",
      "Epoch [4/10], Phase: train, Batch: [96/131], Loss: 0.1482\n",
      "Epoch [4/10], Phase: train, Batch: [97/131], Loss: 0.0522\n",
      "Epoch [4/10], Phase: train, Batch: [98/131], Loss: 0.1480\n",
      "Epoch [4/10], Phase: train, Batch: [99/131], Loss: 0.0974\n",
      "Epoch [4/10], Phase: train, Batch: [100/131], Loss: 0.2097\n",
      "Epoch [4/10], Phase: train, Batch: [101/131], Loss: 0.2186\n",
      "Epoch [4/10], Phase: train, Batch: [102/131], Loss: 0.0683\n",
      "Epoch [4/10], Phase: train, Batch: [103/131], Loss: 0.1762\n",
      "Epoch [4/10], Phase: train, Batch: [104/131], Loss: 0.1350\n",
      "Epoch [4/10], Phase: train, Batch: [105/131], Loss: 0.0749\n",
      "Epoch [4/10], Phase: train, Batch: [106/131], Loss: 0.1129\n",
      "Epoch [4/10], Phase: train, Batch: [107/131], Loss: 0.1167\n",
      "Epoch [4/10], Phase: train, Batch: [108/131], Loss: 0.1109\n",
      "Epoch [4/10], Phase: train, Batch: [109/131], Loss: 0.1051\n",
      "Epoch [4/10], Phase: train, Batch: [110/131], Loss: 0.2109\n",
      "Epoch [4/10], Phase: train, Batch: [111/131], Loss: 0.0634\n",
      "Epoch [4/10], Phase: train, Batch: [112/131], Loss: 0.1015\n",
      "Epoch [4/10], Phase: train, Batch: [113/131], Loss: 0.1619\n",
      "Epoch [4/10], Phase: train, Batch: [114/131], Loss: 0.0778\n",
      "Epoch [4/10], Phase: train, Batch: [115/131], Loss: 0.0550\n",
      "Epoch [4/10], Phase: train, Batch: [116/131], Loss: 0.2854\n",
      "Epoch [4/10], Phase: train, Batch: [117/131], Loss: 0.1401\n",
      "Epoch [4/10], Phase: train, Batch: [118/131], Loss: 0.3626\n",
      "Epoch [4/10], Phase: train, Batch: [119/131], Loss: 0.1282\n",
      "Epoch [4/10], Phase: train, Batch: [120/131], Loss: 0.0423\n",
      "Epoch [4/10], Phase: train, Batch: [121/131], Loss: 0.0597\n",
      "Epoch [4/10], Phase: train, Batch: [122/131], Loss: 0.1192\n",
      "Epoch [4/10], Phase: train, Batch: [123/131], Loss: 0.1146\n",
      "Epoch [4/10], Phase: train, Batch: [124/131], Loss: 0.1945\n",
      "Epoch [4/10], Phase: train, Batch: [125/131], Loss: 0.0812\n",
      "Epoch [4/10], Phase: train, Batch: [126/131], Loss: 0.2574\n",
      "Epoch [4/10], Phase: train, Batch: [127/131], Loss: 0.1726\n",
      "Epoch [4/10], Phase: train, Batch: [128/131], Loss: 0.1634\n",
      "Epoch [4/10], Phase: train, Batch: [129/131], Loss: 0.2439\n",
      "Epoch [4/10], Phase: train, Batch: [130/131], Loss: 0.0803\n",
      "Epoch [4/10], Phase: train, Batch: [131/131], Loss: 0.0773\n",
      "Epoch [4/10], Train Loss: 0.1373\n",
      "Epoch [5/10], Phase: train, Batch: [1/131], Loss: 0.0798\n",
      "Epoch [5/10], Phase: train, Batch: [2/131], Loss: 0.0363\n",
      "Epoch [5/10], Phase: train, Batch: [3/131], Loss: 0.2008\n",
      "Epoch [5/10], Phase: train, Batch: [4/131], Loss: 0.1396\n",
      "Epoch [5/10], Phase: train, Batch: [5/131], Loss: 0.1280\n",
      "Epoch [5/10], Phase: train, Batch: [6/131], Loss: 0.0672\n",
      "Epoch [5/10], Phase: train, Batch: [7/131], Loss: 0.0663\n",
      "Epoch [5/10], Phase: train, Batch: [8/131], Loss: 0.0432\n",
      "Epoch [5/10], Phase: train, Batch: [9/131], Loss: 0.0688\n",
      "Epoch [5/10], Phase: train, Batch: [10/131], Loss: 0.0426\n",
      "Epoch [5/10], Phase: train, Batch: [11/131], Loss: 0.1033\n",
      "Epoch [5/10], Phase: train, Batch: [12/131], Loss: 0.0674\n",
      "Epoch [5/10], Phase: train, Batch: [13/131], Loss: 0.0833\n",
      "Epoch [5/10], Phase: train, Batch: [14/131], Loss: 0.1110\n",
      "Epoch [5/10], Phase: train, Batch: [15/131], Loss: 0.1523\n",
      "Epoch [5/10], Phase: train, Batch: [16/131], Loss: 0.1461\n",
      "Epoch [5/10], Phase: train, Batch: [17/131], Loss: 0.0669\n",
      "Epoch [5/10], Phase: train, Batch: [18/131], Loss: 0.0904\n",
      "Epoch [5/10], Phase: train, Batch: [19/131], Loss: 0.0772\n",
      "Epoch [5/10], Phase: train, Batch: [20/131], Loss: 0.0955\n",
      "Epoch [5/10], Phase: train, Batch: [21/131], Loss: 0.0546\n",
      "Epoch [5/10], Phase: train, Batch: [22/131], Loss: 0.1973\n",
      "Epoch [5/10], Phase: train, Batch: [23/131], Loss: 0.0771\n",
      "Epoch [5/10], Phase: train, Batch: [24/131], Loss: 0.0256\n",
      "Epoch [5/10], Phase: train, Batch: [25/131], Loss: 0.1584\n",
      "Epoch [5/10], Phase: train, Batch: [26/131], Loss: 0.0434\n",
      "Epoch [5/10], Phase: train, Batch: [27/131], Loss: 0.0376\n",
      "Epoch [5/10], Phase: train, Batch: [28/131], Loss: 0.0569\n",
      "Epoch [5/10], Phase: train, Batch: [29/131], Loss: 0.0767\n",
      "Epoch [5/10], Phase: train, Batch: [30/131], Loss: 0.0716\n",
      "Epoch [5/10], Phase: train, Batch: [31/131], Loss: 0.1071\n",
      "Epoch [5/10], Phase: train, Batch: [32/131], Loss: 0.0496\n",
      "Epoch [5/10], Phase: train, Batch: [33/131], Loss: 0.1305\n",
      "Epoch [5/10], Phase: train, Batch: [34/131], Loss: 0.0454\n",
      "Epoch [5/10], Phase: train, Batch: [35/131], Loss: 0.0744\n",
      "Epoch [5/10], Phase: train, Batch: [36/131], Loss: 0.0704\n",
      "Epoch [5/10], Phase: train, Batch: [37/131], Loss: 0.1245\n",
      "Epoch [5/10], Phase: train, Batch: [38/131], Loss: 0.2098\n",
      "Epoch [5/10], Phase: train, Batch: [39/131], Loss: 0.0321\n",
      "Epoch [5/10], Phase: train, Batch: [40/131], Loss: 0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [41/131], Loss: 0.0626\n",
      "Epoch [5/10], Phase: train, Batch: [42/131], Loss: 0.0681\n",
      "Epoch [5/10], Phase: train, Batch: [43/131], Loss: 0.1054\n",
      "Epoch [5/10], Phase: train, Batch: [44/131], Loss: 0.0440\n",
      "Epoch [5/10], Phase: train, Batch: [45/131], Loss: 0.0776\n",
      "Epoch [5/10], Phase: train, Batch: [46/131], Loss: 0.0613\n",
      "Epoch [5/10], Phase: train, Batch: [47/131], Loss: 0.0996\n",
      "Epoch [5/10], Phase: train, Batch: [48/131], Loss: 0.0707\n",
      "Epoch [5/10], Phase: train, Batch: [49/131], Loss: 0.0444\n",
      "Epoch [5/10], Phase: train, Batch: [50/131], Loss: 0.0457\n",
      "Epoch [5/10], Phase: train, Batch: [51/131], Loss: 0.0367\n",
      "Epoch [5/10], Phase: train, Batch: [52/131], Loss: 0.0178\n",
      "Epoch [5/10], Phase: train, Batch: [53/131], Loss: 0.0840\n",
      "Epoch [5/10], Phase: train, Batch: [54/131], Loss: 0.0463\n",
      "Epoch [5/10], Phase: train, Batch: [55/131], Loss: 0.0467\n",
      "Epoch [5/10], Phase: train, Batch: [56/131], Loss: 0.1398\n",
      "Epoch [5/10], Phase: train, Batch: [57/131], Loss: 0.1171\n",
      "Epoch [5/10], Phase: train, Batch: [58/131], Loss: 0.2139\n",
      "Epoch [5/10], Phase: train, Batch: [59/131], Loss: 0.0760\n",
      "Epoch [5/10], Phase: train, Batch: [60/131], Loss: 0.0901\n",
      "Epoch [5/10], Phase: train, Batch: [61/131], Loss: 0.0237\n",
      "Epoch [5/10], Phase: train, Batch: [62/131], Loss: 0.0946\n",
      "Epoch [5/10], Phase: train, Batch: [63/131], Loss: 0.0838\n",
      "Epoch [5/10], Phase: train, Batch: [64/131], Loss: 0.0476\n",
      "Epoch [5/10], Phase: train, Batch: [65/131], Loss: 0.0488\n",
      "Epoch [5/10], Phase: train, Batch: [66/131], Loss: 0.0590\n",
      "Epoch [5/10], Phase: train, Batch: [67/131], Loss: 0.0726\n",
      "Epoch [5/10], Phase: train, Batch: [68/131], Loss: 0.0667\n",
      "Epoch [5/10], Phase: train, Batch: [69/131], Loss: 0.0986\n",
      "Epoch [5/10], Phase: train, Batch: [70/131], Loss: 0.1543\n",
      "Epoch [5/10], Phase: train, Batch: [71/131], Loss: 0.0439\n",
      "Epoch [5/10], Phase: train, Batch: [72/131], Loss: 0.0737\n",
      "Epoch [5/10], Phase: train, Batch: [73/131], Loss: 0.1470\n",
      "Epoch [5/10], Phase: train, Batch: [74/131], Loss: 0.0388\n",
      "Epoch [5/10], Phase: train, Batch: [75/131], Loss: 0.1388\n",
      "Epoch [5/10], Phase: train, Batch: [76/131], Loss: 0.0873\n",
      "Epoch [5/10], Phase: train, Batch: [77/131], Loss: 0.0166\n",
      "Epoch [5/10], Phase: train, Batch: [78/131], Loss: 0.0720\n",
      "Epoch [5/10], Phase: train, Batch: [79/131], Loss: 0.0570\n",
      "Epoch [5/10], Phase: train, Batch: [80/131], Loss: 0.1217\n",
      "Epoch [5/10], Phase: train, Batch: [81/131], Loss: 0.0684\n",
      "Epoch [5/10], Phase: train, Batch: [82/131], Loss: 0.0201\n",
      "Epoch [5/10], Phase: train, Batch: [83/131], Loss: 0.0122\n",
      "Epoch [5/10], Phase: train, Batch: [84/131], Loss: 0.0826\n",
      "Epoch [5/10], Phase: train, Batch: [85/131], Loss: 0.0844\n",
      "Epoch [5/10], Phase: train, Batch: [86/131], Loss: 0.0199\n",
      "Epoch [5/10], Phase: train, Batch: [87/131], Loss: 0.0180\n",
      "Epoch [5/10], Phase: train, Batch: [88/131], Loss: 0.1055\n",
      "Epoch [5/10], Phase: train, Batch: [89/131], Loss: 0.0582\n",
      "Epoch [5/10], Phase: train, Batch: [90/131], Loss: 0.0486\n",
      "Epoch [5/10], Phase: train, Batch: [91/131], Loss: 0.2117\n",
      "Epoch [5/10], Phase: train, Batch: [92/131], Loss: 0.0710\n",
      "Epoch [5/10], Phase: train, Batch: [93/131], Loss: 0.2275\n",
      "Epoch [5/10], Phase: train, Batch: [94/131], Loss: 0.0780\n",
      "Epoch [5/10], Phase: train, Batch: [95/131], Loss: 0.1675\n",
      "Epoch [5/10], Phase: train, Batch: [96/131], Loss: 0.0416\n",
      "Epoch [5/10], Phase: train, Batch: [97/131], Loss: 0.0956\n",
      "Epoch [5/10], Phase: train, Batch: [98/131], Loss: 0.1412\n",
      "Epoch [5/10], Phase: train, Batch: [99/131], Loss: 0.0685\n",
      "Epoch [5/10], Phase: train, Batch: [100/131], Loss: 0.2226\n",
      "Epoch [5/10], Phase: train, Batch: [101/131], Loss: 0.0611\n",
      "Epoch [5/10], Phase: train, Batch: [102/131], Loss: 0.1521\n",
      "Epoch [5/10], Phase: train, Batch: [103/131], Loss: 0.0805\n",
      "Epoch [5/10], Phase: train, Batch: [104/131], Loss: 0.0982\n",
      "Epoch [5/10], Phase: train, Batch: [105/131], Loss: 0.0399\n",
      "Epoch [5/10], Phase: train, Batch: [106/131], Loss: 0.0707\n",
      "Epoch [5/10], Phase: train, Batch: [107/131], Loss: 0.1228\n",
      "Epoch [5/10], Phase: train, Batch: [108/131], Loss: 0.0642\n",
      "Epoch [5/10], Phase: train, Batch: [109/131], Loss: 0.0565\n",
      "Epoch [5/10], Phase: train, Batch: [110/131], Loss: 0.0195\n",
      "Epoch [5/10], Phase: train, Batch: [111/131], Loss: 0.1167\n",
      "Epoch [5/10], Phase: train, Batch: [112/131], Loss: 0.2015\n",
      "Epoch [5/10], Phase: train, Batch: [113/131], Loss: 0.1819\n",
      "Epoch [5/10], Phase: train, Batch: [114/131], Loss: 0.1217\n",
      "Epoch [5/10], Phase: train, Batch: [115/131], Loss: 0.0156\n",
      "Epoch [5/10], Phase: train, Batch: [116/131], Loss: 0.0918\n",
      "Epoch [5/10], Phase: train, Batch: [117/131], Loss: 0.0950\n",
      "Epoch [5/10], Phase: train, Batch: [118/131], Loss: 0.0940\n",
      "Epoch [5/10], Phase: train, Batch: [119/131], Loss: 0.0490\n",
      "Epoch [5/10], Phase: train, Batch: [120/131], Loss: 0.1790\n",
      "Epoch [5/10], Phase: train, Batch: [121/131], Loss: 0.1464\n",
      "Epoch [5/10], Phase: train, Batch: [122/131], Loss: 0.0817\n",
      "Epoch [5/10], Phase: train, Batch: [123/131], Loss: 0.0208\n",
      "Epoch [5/10], Phase: train, Batch: [124/131], Loss: 0.0137\n",
      "Epoch [5/10], Phase: train, Batch: [125/131], Loss: 0.0801\n",
      "Epoch [5/10], Phase: train, Batch: [126/131], Loss: 0.1355\n",
      "Epoch [5/10], Phase: train, Batch: [127/131], Loss: 0.1895\n",
      "Epoch [5/10], Phase: train, Batch: [128/131], Loss: 0.0839\n",
      "Epoch [5/10], Phase: train, Batch: [129/131], Loss: 0.1634\n",
      "Epoch [5/10], Phase: train, Batch: [130/131], Loss: 0.0479\n",
      "Epoch [5/10], Phase: train, Batch: [131/131], Loss: 0.0248\n",
      "Epoch [5/10], Train Loss: 0.0873\n",
      "Epoch [6/10], Phase: train, Batch: [1/131], Loss: 0.0753\n",
      "Epoch [6/10], Phase: train, Batch: [2/131], Loss: 0.0879\n",
      "Epoch [6/10], Phase: train, Batch: [3/131], Loss: 0.0886\n",
      "Epoch [6/10], Phase: train, Batch: [4/131], Loss: 0.0504\n",
      "Epoch [6/10], Phase: train, Batch: [5/131], Loss: 0.0892\n",
      "Epoch [6/10], Phase: train, Batch: [6/131], Loss: 0.0682\n",
      "Epoch [6/10], Phase: train, Batch: [7/131], Loss: 0.0927\n",
      "Epoch [6/10], Phase: train, Batch: [8/131], Loss: 0.0180\n",
      "Epoch [6/10], Phase: train, Batch: [9/131], Loss: 0.0408\n",
      "Epoch [6/10], Phase: train, Batch: [10/131], Loss: 0.1171\n",
      "Epoch [6/10], Phase: train, Batch: [11/131], Loss: 0.0273\n",
      "Epoch [6/10], Phase: train, Batch: [12/131], Loss: 0.0107\n",
      "Epoch [6/10], Phase: train, Batch: [13/131], Loss: 0.0825\n",
      "Epoch [6/10], Phase: train, Batch: [14/131], Loss: 0.0351\n",
      "Epoch [6/10], Phase: train, Batch: [15/131], Loss: 0.0757\n",
      "Epoch [6/10], Phase: train, Batch: [16/131], Loss: 0.0788\n",
      "Epoch [6/10], Phase: train, Batch: [17/131], Loss: 0.0258\n",
      "Epoch [6/10], Phase: train, Batch: [18/131], Loss: 0.0214\n",
      "Epoch [6/10], Phase: train, Batch: [19/131], Loss: 0.0483\n",
      "Epoch [6/10], Phase: train, Batch: [20/131], Loss: 0.0638\n",
      "Epoch [6/10], Phase: train, Batch: [21/131], Loss: 0.0359\n",
      "Epoch [6/10], Phase: train, Batch: [22/131], Loss: 0.0313\n",
      "Epoch [6/10], Phase: train, Batch: [23/131], Loss: 0.0653\n",
      "Epoch [6/10], Phase: train, Batch: [24/131], Loss: 0.0469\n",
      "Epoch [6/10], Phase: train, Batch: [25/131], Loss: 0.0328\n",
      "Epoch [6/10], Phase: train, Batch: [26/131], Loss: 0.0592\n",
      "Epoch [6/10], Phase: train, Batch: [27/131], Loss: 0.0710\n",
      "Epoch [6/10], Phase: train, Batch: [28/131], Loss: 0.1276\n",
      "Epoch [6/10], Phase: train, Batch: [29/131], Loss: 0.0084\n",
      "Epoch [6/10], Phase: train, Batch: [30/131], Loss: 0.0492\n",
      "Epoch [6/10], Phase: train, Batch: [31/131], Loss: 0.1341\n",
      "Epoch [6/10], Phase: train, Batch: [32/131], Loss: 0.0477\n",
      "Epoch [6/10], Phase: train, Batch: [33/131], Loss: 0.0232\n",
      "Epoch [6/10], Phase: train, Batch: [34/131], Loss: 0.0771\n",
      "Epoch [6/10], Phase: train, Batch: [35/131], Loss: 0.1757\n",
      "Epoch [6/10], Phase: train, Batch: [36/131], Loss: 0.1243\n",
      "Epoch [6/10], Phase: train, Batch: [37/131], Loss: 0.0154\n",
      "Epoch [6/10], Phase: train, Batch: [38/131], Loss: 0.0489\n",
      "Epoch [6/10], Phase: train, Batch: [39/131], Loss: 0.1322\n",
      "Epoch [6/10], Phase: train, Batch: [40/131], Loss: 0.0138\n",
      "Epoch [6/10], Phase: train, Batch: [41/131], Loss: 0.1176\n",
      "Epoch [6/10], Phase: train, Batch: [42/131], Loss: 0.0367\n",
      "Epoch [6/10], Phase: train, Batch: [43/131], Loss: 0.0529\n",
      "Epoch [6/10], Phase: train, Batch: [44/131], Loss: 0.0365\n",
      "Epoch [6/10], Phase: train, Batch: [45/131], Loss: 0.0387\n",
      "Epoch [6/10], Phase: train, Batch: [46/131], Loss: 0.0188\n",
      "Epoch [6/10], Phase: train, Batch: [47/131], Loss: 0.1656\n",
      "Epoch [6/10], Phase: train, Batch: [48/131], Loss: 0.1210\n",
      "Epoch [6/10], Phase: train, Batch: [49/131], Loss: 0.1350\n",
      "Epoch [6/10], Phase: train, Batch: [50/131], Loss: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Phase: train, Batch: [51/131], Loss: 0.0318\n",
      "Epoch [6/10], Phase: train, Batch: [52/131], Loss: 0.0461\n",
      "Epoch [6/10], Phase: train, Batch: [53/131], Loss: 0.0438\n",
      "Epoch [6/10], Phase: train, Batch: [54/131], Loss: 0.1375\n",
      "Epoch [6/10], Phase: train, Batch: [55/131], Loss: 0.0813\n",
      "Epoch [6/10], Phase: train, Batch: [56/131], Loss: 0.0693\n",
      "Epoch [6/10], Phase: train, Batch: [57/131], Loss: 0.1161\n",
      "Epoch [6/10], Phase: train, Batch: [58/131], Loss: 0.0238\n",
      "Epoch [6/10], Phase: train, Batch: [59/131], Loss: 0.1390\n",
      "Epoch [6/10], Phase: train, Batch: [60/131], Loss: 0.0052\n",
      "Epoch [6/10], Phase: train, Batch: [61/131], Loss: 0.0328\n",
      "Epoch [6/10], Phase: train, Batch: [62/131], Loss: 0.0449\n",
      "Epoch [6/10], Phase: train, Batch: [63/131], Loss: 0.0133\n",
      "Epoch [6/10], Phase: train, Batch: [64/131], Loss: 0.1055\n",
      "Epoch [6/10], Phase: train, Batch: [65/131], Loss: 0.0657\n",
      "Epoch [6/10], Phase: train, Batch: [66/131], Loss: 0.1237\n",
      "Epoch [6/10], Phase: train, Batch: [67/131], Loss: 0.0517\n",
      "Epoch [6/10], Phase: train, Batch: [68/131], Loss: 0.0350\n",
      "Epoch [6/10], Phase: train, Batch: [69/131], Loss: 0.1053\n",
      "Epoch [6/10], Phase: train, Batch: [70/131], Loss: 0.0549\n",
      "Epoch [6/10], Phase: train, Batch: [71/131], Loss: 0.0541\n",
      "Epoch [6/10], Phase: train, Batch: [72/131], Loss: 0.1367\n",
      "Epoch [6/10], Phase: train, Batch: [73/131], Loss: 0.0998\n",
      "Epoch [6/10], Phase: train, Batch: [74/131], Loss: 0.0799\n",
      "Epoch [6/10], Phase: train, Batch: [75/131], Loss: 0.0438\n",
      "Epoch [6/10], Phase: train, Batch: [76/131], Loss: 0.0271\n",
      "Epoch [6/10], Phase: train, Batch: [77/131], Loss: 0.1105\n",
      "Epoch [6/10], Phase: train, Batch: [78/131], Loss: 0.0580\n",
      "Epoch [6/10], Phase: train, Batch: [79/131], Loss: 0.0388\n",
      "Epoch [6/10], Phase: train, Batch: [80/131], Loss: 0.0318\n",
      "Epoch [6/10], Phase: train, Batch: [81/131], Loss: 0.0555\n",
      "Epoch [6/10], Phase: train, Batch: [82/131], Loss: 0.0191\n",
      "Epoch [6/10], Phase: train, Batch: [83/131], Loss: 0.0262\n",
      "Epoch [6/10], Phase: train, Batch: [84/131], Loss: 0.1091\n",
      "Epoch [6/10], Phase: train, Batch: [85/131], Loss: 0.0219\n",
      "Epoch [6/10], Phase: train, Batch: [86/131], Loss: 0.0629\n",
      "Epoch [6/10], Phase: train, Batch: [87/131], Loss: 0.0226\n",
      "Epoch [6/10], Phase: train, Batch: [88/131], Loss: 0.1417\n",
      "Epoch [6/10], Phase: train, Batch: [89/131], Loss: 0.0846\n",
      "Epoch [6/10], Phase: train, Batch: [90/131], Loss: 0.0896\n",
      "Epoch [6/10], Phase: train, Batch: [91/131], Loss: 0.0584\n",
      "Epoch [6/10], Phase: train, Batch: [92/131], Loss: 0.0482\n",
      "Epoch [6/10], Phase: train, Batch: [93/131], Loss: 0.0334\n",
      "Epoch [6/10], Phase: train, Batch: [94/131], Loss: 0.0864\n",
      "Epoch [6/10], Phase: train, Batch: [95/131], Loss: 0.1301\n",
      "Epoch [6/10], Phase: train, Batch: [96/131], Loss: 0.1296\n",
      "Epoch [6/10], Phase: train, Batch: [97/131], Loss: 0.0603\n",
      "Epoch [6/10], Phase: train, Batch: [98/131], Loss: 0.0638\n",
      "Epoch [6/10], Phase: train, Batch: [99/131], Loss: 0.0444\n",
      "Epoch [6/10], Phase: train, Batch: [100/131], Loss: 0.0807\n",
      "Epoch [6/10], Phase: train, Batch: [101/131], Loss: 0.0374\n",
      "Epoch [6/10], Phase: train, Batch: [102/131], Loss: 0.0626\n",
      "Epoch [6/10], Phase: train, Batch: [103/131], Loss: 0.0432\n",
      "Epoch [6/10], Phase: train, Batch: [104/131], Loss: 0.0486\n",
      "Epoch [6/10], Phase: train, Batch: [105/131], Loss: 0.0484\n",
      "Epoch [6/10], Phase: train, Batch: [106/131], Loss: 0.1549\n",
      "Epoch [6/10], Phase: train, Batch: [107/131], Loss: 0.0338\n",
      "Epoch [6/10], Phase: train, Batch: [108/131], Loss: 0.0444\n",
      "Epoch [6/10], Phase: train, Batch: [109/131], Loss: 0.0929\n",
      "Epoch [6/10], Phase: train, Batch: [110/131], Loss: 0.1589\n",
      "Epoch [6/10], Phase: train, Batch: [111/131], Loss: 0.0676\n",
      "Epoch [6/10], Phase: train, Batch: [112/131], Loss: 0.1166\n",
      "Epoch [6/10], Phase: train, Batch: [113/131], Loss: 0.0198\n",
      "Epoch [6/10], Phase: train, Batch: [114/131], Loss: 0.0295\n",
      "Epoch [6/10], Phase: train, Batch: [115/131], Loss: 0.0222\n",
      "Epoch [6/10], Phase: train, Batch: [116/131], Loss: 0.0736\n",
      "Epoch [6/10], Phase: train, Batch: [117/131], Loss: 0.0348\n",
      "Epoch [6/10], Phase: train, Batch: [118/131], Loss: 0.1379\n",
      "Epoch [6/10], Phase: train, Batch: [119/131], Loss: 0.0330\n",
      "Epoch [6/10], Phase: train, Batch: [120/131], Loss: 0.0131\n",
      "Epoch [6/10], Phase: train, Batch: [121/131], Loss: 0.0694\n",
      "Epoch [6/10], Phase: train, Batch: [122/131], Loss: 0.0750\n",
      "Epoch [6/10], Phase: train, Batch: [123/131], Loss: 0.0513\n",
      "Epoch [6/10], Phase: train, Batch: [124/131], Loss: 0.0550\n",
      "Epoch [6/10], Phase: train, Batch: [125/131], Loss: 0.0758\n",
      "Epoch [6/10], Phase: train, Batch: [126/131], Loss: 0.1158\n",
      "Epoch [6/10], Phase: train, Batch: [127/131], Loss: 0.0355\n",
      "Epoch [6/10], Phase: train, Batch: [128/131], Loss: 0.0463\n",
      "Epoch [6/10], Phase: train, Batch: [129/131], Loss: 0.0312\n",
      "Epoch [6/10], Phase: train, Batch: [130/131], Loss: 0.0450\n",
      "Epoch [6/10], Phase: train, Batch: [131/131], Loss: 0.6125\n",
      "Epoch [6/10], Train Loss: 0.0668\n",
      "Epoch [7/10], Phase: train, Batch: [1/131], Loss: 0.0204\n",
      "Epoch [7/10], Phase: train, Batch: [2/131], Loss: 0.0618\n",
      "Epoch [7/10], Phase: train, Batch: [3/131], Loss: 0.0523\n",
      "Epoch [7/10], Phase: train, Batch: [4/131], Loss: 0.0401\n",
      "Epoch [7/10], Phase: train, Batch: [5/131], Loss: 0.0438\n",
      "Epoch [7/10], Phase: train, Batch: [6/131], Loss: 0.0518\n",
      "Epoch [7/10], Phase: train, Batch: [7/131], Loss: 0.1373\n",
      "Epoch [7/10], Phase: train, Batch: [8/131], Loss: 0.1424\n",
      "Epoch [7/10], Phase: train, Batch: [9/131], Loss: 0.0207\n",
      "Epoch [7/10], Phase: train, Batch: [10/131], Loss: 0.0558\n",
      "Epoch [7/10], Phase: train, Batch: [11/131], Loss: 0.0178\n",
      "Epoch [7/10], Phase: train, Batch: [12/131], Loss: 0.0236\n",
      "Epoch [7/10], Phase: train, Batch: [13/131], Loss: 0.1095\n",
      "Epoch [7/10], Phase: train, Batch: [14/131], Loss: 0.0135\n",
      "Epoch [7/10], Phase: train, Batch: [15/131], Loss: 0.0806\n",
      "Epoch [7/10], Phase: train, Batch: [16/131], Loss: 0.0958\n",
      "Epoch [7/10], Phase: train, Batch: [17/131], Loss: 0.0201\n",
      "Epoch [7/10], Phase: train, Batch: [18/131], Loss: 0.0853\n",
      "Epoch [7/10], Phase: train, Batch: [19/131], Loss: 0.0741\n",
      "Epoch [7/10], Phase: train, Batch: [20/131], Loss: 0.1166\n",
      "Epoch [7/10], Phase: train, Batch: [21/131], Loss: 0.0287\n",
      "Epoch [7/10], Phase: train, Batch: [22/131], Loss: 0.0264\n",
      "Epoch [7/10], Phase: train, Batch: [23/131], Loss: 0.0317\n",
      "Epoch [7/10], Phase: train, Batch: [24/131], Loss: 0.0663\n",
      "Epoch [7/10], Phase: train, Batch: [25/131], Loss: 0.1242\n",
      "Epoch [7/10], Phase: train, Batch: [26/131], Loss: 0.0247\n",
      "Epoch [7/10], Phase: train, Batch: [27/131], Loss: 0.0200\n",
      "Epoch [7/10], Phase: train, Batch: [28/131], Loss: 0.0721\n",
      "Epoch [7/10], Phase: train, Batch: [29/131], Loss: 0.1329\n",
      "Epoch [7/10], Phase: train, Batch: [30/131], Loss: 0.0871\n",
      "Epoch [7/10], Phase: train, Batch: [31/131], Loss: 0.0220\n",
      "Epoch [7/10], Phase: train, Batch: [32/131], Loss: 0.0257\n",
      "Epoch [7/10], Phase: train, Batch: [33/131], Loss: 0.0139\n",
      "Epoch [7/10], Phase: train, Batch: [34/131], Loss: 0.0884\n",
      "Epoch [7/10], Phase: train, Batch: [35/131], Loss: 0.0130\n",
      "Epoch [7/10], Phase: train, Batch: [36/131], Loss: 0.1008\n",
      "Epoch [7/10], Phase: train, Batch: [37/131], Loss: 0.0748\n",
      "Epoch [7/10], Phase: train, Batch: [38/131], Loss: 0.0312\n",
      "Epoch [7/10], Phase: train, Batch: [39/131], Loss: 0.0447\n",
      "Epoch [7/10], Phase: train, Batch: [40/131], Loss: 0.0298\n",
      "Epoch [7/10], Phase: train, Batch: [41/131], Loss: 0.0047\n",
      "Epoch [7/10], Phase: train, Batch: [42/131], Loss: 0.0034\n",
      "Epoch [7/10], Phase: train, Batch: [43/131], Loss: 0.0645\n",
      "Epoch [7/10], Phase: train, Batch: [44/131], Loss: 0.0875\n",
      "Epoch [7/10], Phase: train, Batch: [45/131], Loss: 0.0336\n",
      "Epoch [7/10], Phase: train, Batch: [46/131], Loss: 0.0122\n",
      "Epoch [7/10], Phase: train, Batch: [47/131], Loss: 0.0311\n",
      "Epoch [7/10], Phase: train, Batch: [48/131], Loss: 0.0144\n",
      "Epoch [7/10], Phase: train, Batch: [49/131], Loss: 0.0449\n",
      "Epoch [7/10], Phase: train, Batch: [50/131], Loss: 0.0220\n",
      "Epoch [7/10], Phase: train, Batch: [51/131], Loss: 0.0154\n",
      "Epoch [7/10], Phase: train, Batch: [52/131], Loss: 0.0382\n",
      "Epoch [7/10], Phase: train, Batch: [53/131], Loss: 0.0093\n",
      "Epoch [7/10], Phase: train, Batch: [54/131], Loss: 0.0797\n",
      "Epoch [7/10], Phase: train, Batch: [55/131], Loss: 0.0396\n",
      "Epoch [7/10], Phase: train, Batch: [56/131], Loss: 0.0430\n",
      "Epoch [7/10], Phase: train, Batch: [57/131], Loss: 0.0210\n",
      "Epoch [7/10], Phase: train, Batch: [58/131], Loss: 0.0663\n",
      "Epoch [7/10], Phase: train, Batch: [59/131], Loss: 0.0492\n",
      "Epoch [7/10], Phase: train, Batch: [60/131], Loss: 0.0900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Phase: train, Batch: [61/131], Loss: 0.1090\n",
      "Epoch [7/10], Phase: train, Batch: [62/131], Loss: 0.0440\n",
      "Epoch [7/10], Phase: train, Batch: [63/131], Loss: 0.0180\n",
      "Epoch [7/10], Phase: train, Batch: [64/131], Loss: 0.0100\n",
      "Epoch [7/10], Phase: train, Batch: [65/131], Loss: 0.0208\n",
      "Epoch [7/10], Phase: train, Batch: [66/131], Loss: 0.0445\n",
      "Epoch [7/10], Phase: train, Batch: [67/131], Loss: 0.1052\n",
      "Epoch [7/10], Phase: train, Batch: [68/131], Loss: 0.0557\n",
      "Epoch [7/10], Phase: train, Batch: [69/131], Loss: 0.0372\n",
      "Epoch [7/10], Phase: train, Batch: [70/131], Loss: 0.1267\n",
      "Epoch [7/10], Phase: train, Batch: [71/131], Loss: 0.0196\n",
      "Epoch [7/10], Phase: train, Batch: [72/131], Loss: 0.0628\n",
      "Epoch [7/10], Phase: train, Batch: [73/131], Loss: 0.1262\n",
      "Epoch [7/10], Phase: train, Batch: [74/131], Loss: 0.0206\n",
      "Epoch [7/10], Phase: train, Batch: [75/131], Loss: 0.0886\n",
      "Epoch [7/10], Phase: train, Batch: [76/131], Loss: 0.0140\n",
      "Epoch [7/10], Phase: train, Batch: [77/131], Loss: 0.0375\n",
      "Epoch [7/10], Phase: train, Batch: [78/131], Loss: 0.0254\n",
      "Epoch [7/10], Phase: train, Batch: [79/131], Loss: 0.2176\n",
      "Epoch [7/10], Phase: train, Batch: [80/131], Loss: 0.0388\n",
      "Epoch [7/10], Phase: train, Batch: [81/131], Loss: 0.0247\n",
      "Epoch [7/10], Phase: train, Batch: [82/131], Loss: 0.0863\n",
      "Epoch [7/10], Phase: train, Batch: [83/131], Loss: 0.0207\n",
      "Epoch [7/10], Phase: train, Batch: [84/131], Loss: 0.0337\n",
      "Epoch [7/10], Phase: train, Batch: [85/131], Loss: 0.0404\n",
      "Epoch [7/10], Phase: train, Batch: [86/131], Loss: 0.0701\n",
      "Epoch [7/10], Phase: train, Batch: [87/131], Loss: 0.0256\n",
      "Epoch [7/10], Phase: train, Batch: [88/131], Loss: 0.0530\n",
      "Epoch [7/10], Phase: train, Batch: [89/131], Loss: 0.0957\n",
      "Epoch [7/10], Phase: train, Batch: [90/131], Loss: 0.0099\n",
      "Epoch [7/10], Phase: train, Batch: [91/131], Loss: 0.0449\n",
      "Epoch [7/10], Phase: train, Batch: [92/131], Loss: 0.1121\n",
      "Epoch [7/10], Phase: train, Batch: [93/131], Loss: 0.0092\n",
      "Epoch [7/10], Phase: train, Batch: [94/131], Loss: 0.1879\n",
      "Epoch [7/10], Phase: train, Batch: [95/131], Loss: 0.0302\n",
      "Epoch [7/10], Phase: train, Batch: [96/131], Loss: 0.0505\n",
      "Epoch [7/10], Phase: train, Batch: [97/131], Loss: 0.1132\n",
      "Epoch [7/10], Phase: train, Batch: [98/131], Loss: 0.0127\n",
      "Epoch [7/10], Phase: train, Batch: [99/131], Loss: 0.0441\n",
      "Epoch [7/10], Phase: train, Batch: [100/131], Loss: 0.1663\n",
      "Epoch [7/10], Phase: train, Batch: [101/131], Loss: 0.0781\n",
      "Epoch [7/10], Phase: train, Batch: [102/131], Loss: 0.0678\n",
      "Epoch [7/10], Phase: train, Batch: [103/131], Loss: 0.0182\n",
      "Epoch [7/10], Phase: train, Batch: [104/131], Loss: 0.0109\n",
      "Epoch [7/10], Phase: train, Batch: [105/131], Loss: 0.1998\n",
      "Epoch [7/10], Phase: train, Batch: [106/131], Loss: 0.0265\n",
      "Epoch [7/10], Phase: train, Batch: [107/131], Loss: 0.0966\n",
      "Epoch [7/10], Phase: train, Batch: [108/131], Loss: 0.0451\n",
      "Epoch [7/10], Phase: train, Batch: [109/131], Loss: 0.0240\n",
      "Epoch [7/10], Phase: train, Batch: [110/131], Loss: 0.0381\n",
      "Epoch [7/10], Phase: train, Batch: [111/131], Loss: 0.0529\n",
      "Epoch [7/10], Phase: train, Batch: [112/131], Loss: 0.0472\n",
      "Epoch [7/10], Phase: train, Batch: [113/131], Loss: 0.1495\n",
      "Epoch [7/10], Phase: train, Batch: [114/131], Loss: 0.0197\n",
      "Epoch [7/10], Phase: train, Batch: [115/131], Loss: 0.0448\n",
      "Epoch [7/10], Phase: train, Batch: [116/131], Loss: 0.0379\n",
      "Epoch [7/10], Phase: train, Batch: [117/131], Loss: 0.0965\n",
      "Epoch [7/10], Phase: train, Batch: [118/131], Loss: 0.1102\n",
      "Epoch [7/10], Phase: train, Batch: [119/131], Loss: 0.0577\n",
      "Epoch [7/10], Phase: train, Batch: [120/131], Loss: 0.0094\n",
      "Epoch [7/10], Phase: train, Batch: [121/131], Loss: 0.0258\n",
      "Epoch [7/10], Phase: train, Batch: [122/131], Loss: 0.0252\n",
      "Epoch [7/10], Phase: train, Batch: [123/131], Loss: 0.0831\n",
      "Epoch [7/10], Phase: train, Batch: [124/131], Loss: 0.1000\n",
      "Epoch [7/10], Phase: train, Batch: [125/131], Loss: 0.1576\n",
      "Epoch [7/10], Phase: train, Batch: [126/131], Loss: 0.0948\n",
      "Epoch [7/10], Phase: train, Batch: [127/131], Loss: 0.0180\n",
      "Epoch [7/10], Phase: train, Batch: [128/131], Loss: 0.0341\n",
      "Epoch [7/10], Phase: train, Batch: [129/131], Loss: 0.0368\n",
      "Epoch [7/10], Phase: train, Batch: [130/131], Loss: 0.0822\n",
      "Epoch [7/10], Phase: train, Batch: [131/131], Loss: 0.0035\n",
      "Epoch [7/10], Train Loss: 0.0571\n",
      "Epoch [8/10], Phase: train, Batch: [1/131], Loss: 0.0056\n",
      "Epoch [8/10], Phase: train, Batch: [2/131], Loss: 0.0104\n",
      "Epoch [8/10], Phase: train, Batch: [3/131], Loss: 0.0246\n",
      "Epoch [8/10], Phase: train, Batch: [4/131], Loss: 0.0149\n",
      "Epoch [8/10], Phase: train, Batch: [5/131], Loss: 0.0498\n",
      "Epoch [8/10], Phase: train, Batch: [6/131], Loss: 0.0247\n",
      "Epoch [8/10], Phase: train, Batch: [7/131], Loss: 0.1895\n",
      "Epoch [8/10], Phase: train, Batch: [8/131], Loss: 0.0076\n",
      "Epoch [8/10], Phase: train, Batch: [9/131], Loss: 0.0099\n",
      "Epoch [8/10], Phase: train, Batch: [10/131], Loss: 0.0291\n",
      "Epoch [8/10], Phase: train, Batch: [11/131], Loss: 0.0346\n",
      "Epoch [8/10], Phase: train, Batch: [12/131], Loss: 0.0085\n",
      "Epoch [8/10], Phase: train, Batch: [13/131], Loss: 0.0823\n",
      "Epoch [8/10], Phase: train, Batch: [14/131], Loss: 0.0239\n",
      "Epoch [8/10], Phase: train, Batch: [15/131], Loss: 0.0356\n",
      "Epoch [8/10], Phase: train, Batch: [16/131], Loss: 0.0140\n",
      "Epoch [8/10], Phase: train, Batch: [17/131], Loss: 0.0329\n",
      "Epoch [8/10], Phase: train, Batch: [18/131], Loss: 0.0225\n",
      "Epoch [8/10], Phase: train, Batch: [19/131], Loss: 0.0133\n",
      "Epoch [8/10], Phase: train, Batch: [20/131], Loss: 0.0049\n",
      "Epoch [8/10], Phase: train, Batch: [21/131], Loss: 0.0275\n",
      "Epoch [8/10], Phase: train, Batch: [22/131], Loss: 0.1259\n",
      "Epoch [8/10], Phase: train, Batch: [23/131], Loss: 0.0856\n",
      "Epoch [8/10], Phase: train, Batch: [24/131], Loss: 0.0168\n",
      "Epoch [8/10], Phase: train, Batch: [25/131], Loss: 0.0384\n",
      "Epoch [8/10], Phase: train, Batch: [26/131], Loss: 0.0497\n",
      "Epoch [8/10], Phase: train, Batch: [27/131], Loss: 0.0152\n",
      "Epoch [8/10], Phase: train, Batch: [28/131], Loss: 0.0295\n",
      "Epoch [8/10], Phase: train, Batch: [29/131], Loss: 0.0717\n",
      "Epoch [8/10], Phase: train, Batch: [30/131], Loss: 0.0800\n",
      "Epoch [8/10], Phase: train, Batch: [31/131], Loss: 0.0069\n",
      "Epoch [8/10], Phase: train, Batch: [32/131], Loss: 0.0079\n",
      "Epoch [8/10], Phase: train, Batch: [33/131], Loss: 0.0233\n",
      "Epoch [8/10], Phase: train, Batch: [34/131], Loss: 0.0367\n",
      "Epoch [8/10], Phase: train, Batch: [35/131], Loss: 0.0218\n",
      "Epoch [8/10], Phase: train, Batch: [36/131], Loss: 0.0358\n",
      "Epoch [8/10], Phase: train, Batch: [37/131], Loss: 0.0282\n",
      "Epoch [8/10], Phase: train, Batch: [38/131], Loss: 0.0141\n",
      "Epoch [8/10], Phase: train, Batch: [39/131], Loss: 0.0061\n",
      "Epoch [8/10], Phase: train, Batch: [40/131], Loss: 0.1266\n",
      "Epoch [8/10], Phase: train, Batch: [41/131], Loss: 0.0324\n",
      "Epoch [8/10], Phase: train, Batch: [42/131], Loss: 0.0477\n",
      "Epoch [8/10], Phase: train, Batch: [43/131], Loss: 0.0130\n",
      "Epoch [8/10], Phase: train, Batch: [44/131], Loss: 0.0254\n",
      "Epoch [8/10], Phase: train, Batch: [45/131], Loss: 0.0312\n",
      "Epoch [8/10], Phase: train, Batch: [46/131], Loss: 0.0755\n",
      "Epoch [8/10], Phase: train, Batch: [47/131], Loss: 0.0901\n",
      "Epoch [8/10], Phase: train, Batch: [48/131], Loss: 0.0213\n",
      "Epoch [8/10], Phase: train, Batch: [49/131], Loss: 0.0087\n",
      "Epoch [8/10], Phase: train, Batch: [50/131], Loss: 0.0071\n",
      "Epoch [8/10], Phase: train, Batch: [51/131], Loss: 0.0156\n",
      "Epoch [8/10], Phase: train, Batch: [52/131], Loss: 0.0257\n",
      "Epoch [8/10], Phase: train, Batch: [53/131], Loss: 0.0329\n",
      "Epoch [8/10], Phase: train, Batch: [54/131], Loss: 0.0403\n",
      "Epoch [8/10], Phase: train, Batch: [55/131], Loss: 0.0766\n",
      "Epoch [8/10], Phase: train, Batch: [56/131], Loss: 0.1279\n",
      "Epoch [8/10], Phase: train, Batch: [57/131], Loss: 0.0600\n",
      "Epoch [8/10], Phase: train, Batch: [58/131], Loss: 0.0146\n",
      "Epoch [8/10], Phase: train, Batch: [59/131], Loss: 0.0092\n",
      "Epoch [8/10], Phase: train, Batch: [60/131], Loss: 0.1653\n",
      "Epoch [8/10], Phase: train, Batch: [61/131], Loss: 0.0745\n",
      "Epoch [8/10], Phase: train, Batch: [62/131], Loss: 0.0157\n",
      "Epoch [8/10], Phase: train, Batch: [63/131], Loss: 0.0432\n",
      "Epoch [8/10], Phase: train, Batch: [64/131], Loss: 0.0112\n",
      "Epoch [8/10], Phase: train, Batch: [65/131], Loss: 0.0402\n",
      "Epoch [8/10], Phase: train, Batch: [66/131], Loss: 0.2051\n",
      "Epoch [8/10], Phase: train, Batch: [67/131], Loss: 0.0179\n",
      "Epoch [8/10], Phase: train, Batch: [68/131], Loss: 0.1513\n",
      "Epoch [8/10], Phase: train, Batch: [69/131], Loss: 0.0228\n",
      "Epoch [8/10], Phase: train, Batch: [70/131], Loss: 0.0440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Phase: train, Batch: [71/131], Loss: 0.0154\n",
      "Epoch [8/10], Phase: train, Batch: [72/131], Loss: 0.0924\n",
      "Epoch [8/10], Phase: train, Batch: [73/131], Loss: 0.0202\n",
      "Epoch [8/10], Phase: train, Batch: [74/131], Loss: 0.0123\n",
      "Epoch [8/10], Phase: train, Batch: [75/131], Loss: 0.0742\n",
      "Epoch [8/10], Phase: train, Batch: [76/131], Loss: 0.0379\n",
      "Epoch [8/10], Phase: train, Batch: [77/131], Loss: 0.0416\n",
      "Epoch [8/10], Phase: train, Batch: [78/131], Loss: 0.0167\n",
      "Epoch [8/10], Phase: train, Batch: [79/131], Loss: 0.1240\n",
      "Epoch [8/10], Phase: train, Batch: [80/131], Loss: 0.0761\n",
      "Epoch [8/10], Phase: train, Batch: [81/131], Loss: 0.0730\n",
      "Epoch [8/10], Phase: train, Batch: [82/131], Loss: 0.0446\n",
      "Epoch [8/10], Phase: train, Batch: [83/131], Loss: 0.0342\n",
      "Epoch [8/10], Phase: train, Batch: [84/131], Loss: 0.0673\n",
      "Epoch [8/10], Phase: train, Batch: [85/131], Loss: 0.0455\n",
      "Epoch [8/10], Phase: train, Batch: [86/131], Loss: 0.0723\n",
      "Epoch [8/10], Phase: train, Batch: [87/131], Loss: 0.0771\n",
      "Epoch [8/10], Phase: train, Batch: [88/131], Loss: 0.1219\n",
      "Epoch [8/10], Phase: train, Batch: [89/131], Loss: 0.0184\n",
      "Epoch [8/10], Phase: train, Batch: [90/131], Loss: 0.0074\n",
      "Epoch [8/10], Phase: train, Batch: [91/131], Loss: 0.0388\n",
      "Epoch [8/10], Phase: train, Batch: [92/131], Loss: 0.0207\n",
      "Epoch [8/10], Phase: train, Batch: [93/131], Loss: 0.0512\n",
      "Epoch [8/10], Phase: train, Batch: [94/131], Loss: 0.0557\n",
      "Epoch [8/10], Phase: train, Batch: [95/131], Loss: 0.0176\n",
      "Epoch [8/10], Phase: train, Batch: [96/131], Loss: 0.0961\n",
      "Epoch [8/10], Phase: train, Batch: [97/131], Loss: 0.1641\n",
      "Epoch [8/10], Phase: train, Batch: [98/131], Loss: 0.0334\n",
      "Epoch [8/10], Phase: train, Batch: [99/131], Loss: 0.0135\n",
      "Epoch [8/10], Phase: train, Batch: [100/131], Loss: 0.0270\n",
      "Epoch [8/10], Phase: train, Batch: [101/131], Loss: 0.0270\n",
      "Epoch [8/10], Phase: train, Batch: [102/131], Loss: 0.0191\n",
      "Epoch [8/10], Phase: train, Batch: [103/131], Loss: 0.0101\n",
      "Epoch [8/10], Phase: train, Batch: [104/131], Loss: 0.0092\n",
      "Epoch [8/10], Phase: train, Batch: [105/131], Loss: 0.0320\n",
      "Epoch [8/10], Phase: train, Batch: [106/131], Loss: 0.0128\n",
      "Epoch [8/10], Phase: train, Batch: [107/131], Loss: 0.0252\n",
      "Epoch [8/10], Phase: train, Batch: [108/131], Loss: 0.0127\n",
      "Epoch [8/10], Phase: train, Batch: [109/131], Loss: 0.0087\n",
      "Epoch [8/10], Phase: train, Batch: [110/131], Loss: 0.0220\n",
      "Epoch [8/10], Phase: train, Batch: [111/131], Loss: 0.1295\n",
      "Epoch [8/10], Phase: train, Batch: [112/131], Loss: 0.0454\n",
      "Epoch [8/10], Phase: train, Batch: [113/131], Loss: 0.0127\n",
      "Epoch [8/10], Phase: train, Batch: [114/131], Loss: 0.0507\n",
      "Epoch [8/10], Phase: train, Batch: [115/131], Loss: 0.0035\n",
      "Epoch [8/10], Phase: train, Batch: [116/131], Loss: 0.0715\n",
      "Epoch [8/10], Phase: train, Batch: [117/131], Loss: 0.0104\n",
      "Epoch [8/10], Phase: train, Batch: [118/131], Loss: 0.0362\n",
      "Epoch [8/10], Phase: train, Batch: [119/131], Loss: 0.0419\n",
      "Epoch [8/10], Phase: train, Batch: [120/131], Loss: 0.0753\n",
      "Epoch [8/10], Phase: train, Batch: [121/131], Loss: 0.0125\n",
      "Epoch [8/10], Phase: train, Batch: [122/131], Loss: 0.0069\n",
      "Epoch [8/10], Phase: train, Batch: [123/131], Loss: 0.0336\n",
      "Epoch [8/10], Phase: train, Batch: [124/131], Loss: 0.0730\n",
      "Epoch [8/10], Phase: train, Batch: [125/131], Loss: 0.0827\n",
      "Epoch [8/10], Phase: train, Batch: [126/131], Loss: 0.0324\n",
      "Epoch [8/10], Phase: train, Batch: [127/131], Loss: 0.0090\n",
      "Epoch [8/10], Phase: train, Batch: [128/131], Loss: 0.0188\n",
      "Epoch [8/10], Phase: train, Batch: [129/131], Loss: 0.0481\n",
      "Epoch [8/10], Phase: train, Batch: [130/131], Loss: 0.0756\n",
      "Epoch [8/10], Phase: train, Batch: [131/131], Loss: 0.0369\n",
      "Epoch [8/10], Train Loss: 0.0436\n",
      "Epoch [9/10], Phase: train, Batch: [1/131], Loss: 0.0530\n",
      "Epoch [9/10], Phase: train, Batch: [2/131], Loss: 0.0046\n",
      "Epoch [9/10], Phase: train, Batch: [3/131], Loss: 0.0145\n",
      "Epoch [9/10], Phase: train, Batch: [4/131], Loss: 0.0080\n",
      "Epoch [9/10], Phase: train, Batch: [5/131], Loss: 0.0076\n",
      "Epoch [9/10], Phase: train, Batch: [6/131], Loss: 0.0018\n",
      "Epoch [9/10], Phase: train, Batch: [7/131], Loss: 0.1403\n",
      "Epoch [9/10], Phase: train, Batch: [8/131], Loss: 0.0126\n",
      "Epoch [9/10], Phase: train, Batch: [9/131], Loss: 0.0483\n",
      "Epoch [9/10], Phase: train, Batch: [10/131], Loss: 0.0192\n",
      "Epoch [9/10], Phase: train, Batch: [11/131], Loss: 0.0081\n",
      "Epoch [9/10], Phase: train, Batch: [12/131], Loss: 0.0271\n",
      "Epoch [9/10], Phase: train, Batch: [13/131], Loss: 0.0034\n",
      "Epoch [9/10], Phase: train, Batch: [14/131], Loss: 0.0056\n",
      "Epoch [9/10], Phase: train, Batch: [15/131], Loss: 0.0444\n",
      "Epoch [9/10], Phase: train, Batch: [16/131], Loss: 0.0079\n",
      "Epoch [9/10], Phase: train, Batch: [17/131], Loss: 0.0157\n",
      "Epoch [9/10], Phase: train, Batch: [18/131], Loss: 0.0237\n",
      "Epoch [9/10], Phase: train, Batch: [19/131], Loss: 0.0028\n",
      "Epoch [9/10], Phase: train, Batch: [20/131], Loss: 0.0500\n",
      "Epoch [9/10], Phase: train, Batch: [21/131], Loss: 0.0080\n",
      "Epoch [9/10], Phase: train, Batch: [22/131], Loss: 0.0029\n",
      "Epoch [9/10], Phase: train, Batch: [23/131], Loss: 0.0044\n",
      "Epoch [9/10], Phase: train, Batch: [24/131], Loss: 0.0024\n",
      "Epoch [9/10], Phase: train, Batch: [25/131], Loss: 0.0418\n",
      "Epoch [9/10], Phase: train, Batch: [26/131], Loss: 0.0034\n",
      "Epoch [9/10], Phase: train, Batch: [27/131], Loss: 0.0061\n",
      "Epoch [9/10], Phase: train, Batch: [28/131], Loss: 0.0179\n",
      "Epoch [9/10], Phase: train, Batch: [29/131], Loss: 0.0341\n",
      "Epoch [9/10], Phase: train, Batch: [30/131], Loss: 0.0433\n",
      "Epoch [9/10], Phase: train, Batch: [31/131], Loss: 0.0089\n",
      "Epoch [9/10], Phase: train, Batch: [32/131], Loss: 0.0511\n",
      "Epoch [9/10], Phase: train, Batch: [33/131], Loss: 0.0064\n",
      "Epoch [9/10], Phase: train, Batch: [34/131], Loss: 0.1304\n",
      "Epoch [9/10], Phase: train, Batch: [35/131], Loss: 0.0160\n",
      "Epoch [9/10], Phase: train, Batch: [36/131], Loss: 0.0258\n",
      "Epoch [9/10], Phase: train, Batch: [37/131], Loss: 0.0386\n",
      "Epoch [9/10], Phase: train, Batch: [38/131], Loss: 0.0233\n",
      "Epoch [9/10], Phase: train, Batch: [39/131], Loss: 0.1909\n",
      "Epoch [9/10], Phase: train, Batch: [40/131], Loss: 0.0042\n",
      "Epoch [9/10], Phase: train, Batch: [41/131], Loss: 0.0069\n",
      "Epoch [9/10], Phase: train, Batch: [42/131], Loss: 0.0698\n",
      "Epoch [9/10], Phase: train, Batch: [43/131], Loss: 0.0030\n",
      "Epoch [9/10], Phase: train, Batch: [44/131], Loss: 0.0054\n",
      "Epoch [9/10], Phase: train, Batch: [45/131], Loss: 0.0044\n",
      "Epoch [9/10], Phase: train, Batch: [46/131], Loss: 0.0128\n",
      "Epoch [9/10], Phase: train, Batch: [47/131], Loss: 0.0804\n",
      "Epoch [9/10], Phase: train, Batch: [48/131], Loss: 0.0184\n",
      "Epoch [9/10], Phase: train, Batch: [49/131], Loss: 0.0019\n",
      "Epoch [9/10], Phase: train, Batch: [50/131], Loss: 0.0109\n",
      "Epoch [9/10], Phase: train, Batch: [51/131], Loss: 0.0050\n",
      "Epoch [9/10], Phase: train, Batch: [52/131], Loss: 0.0276\n",
      "Epoch [9/10], Phase: train, Batch: [53/131], Loss: 0.0328\n",
      "Epoch [9/10], Phase: train, Batch: [54/131], Loss: 0.0126\n",
      "Epoch [9/10], Phase: train, Batch: [55/131], Loss: 0.0176\n",
      "Epoch [9/10], Phase: train, Batch: [56/131], Loss: 0.0144\n",
      "Epoch [9/10], Phase: train, Batch: [57/131], Loss: 0.0136\n",
      "Epoch [9/10], Phase: train, Batch: [58/131], Loss: 0.0291\n",
      "Epoch [9/10], Phase: train, Batch: [59/131], Loss: 0.0116\n",
      "Epoch [9/10], Phase: train, Batch: [60/131], Loss: 0.0580\n",
      "Epoch [9/10], Phase: train, Batch: [61/131], Loss: 0.0389\n",
      "Epoch [9/10], Phase: train, Batch: [62/131], Loss: 0.0241\n",
      "Epoch [9/10], Phase: train, Batch: [63/131], Loss: 0.0010\n",
      "Epoch [9/10], Phase: train, Batch: [64/131], Loss: 0.0057\n",
      "Epoch [9/10], Phase: train, Batch: [65/131], Loss: 0.1108\n",
      "Epoch [9/10], Phase: train, Batch: [66/131], Loss: 0.0922\n",
      "Epoch [9/10], Phase: train, Batch: [67/131], Loss: 0.0051\n",
      "Epoch [9/10], Phase: train, Batch: [68/131], Loss: 0.0414\n",
      "Epoch [9/10], Phase: train, Batch: [69/131], Loss: 0.0125\n",
      "Epoch [9/10], Phase: train, Batch: [70/131], Loss: 0.0312\n",
      "Epoch [9/10], Phase: train, Batch: [71/131], Loss: 0.1153\n",
      "Epoch [9/10], Phase: train, Batch: [72/131], Loss: 0.0234\n",
      "Epoch [9/10], Phase: train, Batch: [73/131], Loss: 0.1471\n",
      "Epoch [9/10], Phase: train, Batch: [74/131], Loss: 0.1050\n",
      "Epoch [9/10], Phase: train, Batch: [75/131], Loss: 0.0303\n",
      "Epoch [9/10], Phase: train, Batch: [76/131], Loss: 0.0067\n",
      "Epoch [9/10], Phase: train, Batch: [77/131], Loss: 0.0100\n",
      "Epoch [9/10], Phase: train, Batch: [78/131], Loss: 0.0941\n",
      "Epoch [9/10], Phase: train, Batch: [79/131], Loss: 0.0091\n",
      "Epoch [9/10], Phase: train, Batch: [80/131], Loss: 0.0126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Phase: train, Batch: [81/131], Loss: 0.0740\n",
      "Epoch [9/10], Phase: train, Batch: [82/131], Loss: 0.0312\n",
      "Epoch [9/10], Phase: train, Batch: [83/131], Loss: 0.0089\n",
      "Epoch [9/10], Phase: train, Batch: [84/131], Loss: 0.0210\n",
      "Epoch [9/10], Phase: train, Batch: [85/131], Loss: 0.0404\n",
      "Epoch [9/10], Phase: train, Batch: [86/131], Loss: 0.0183\n",
      "Epoch [9/10], Phase: train, Batch: [87/131], Loss: 0.0274\n",
      "Epoch [9/10], Phase: train, Batch: [88/131], Loss: 0.0294\n",
      "Epoch [9/10], Phase: train, Batch: [89/131], Loss: 0.0391\n",
      "Epoch [9/10], Phase: train, Batch: [90/131], Loss: 0.0474\n",
      "Epoch [9/10], Phase: train, Batch: [91/131], Loss: 0.1189\n",
      "Epoch [9/10], Phase: train, Batch: [92/131], Loss: 0.0047\n",
      "Epoch [9/10], Phase: train, Batch: [93/131], Loss: 0.0067\n",
      "Epoch [9/10], Phase: train, Batch: [94/131], Loss: 0.0053\n",
      "Epoch [9/10], Phase: train, Batch: [95/131], Loss: 0.0104\n",
      "Epoch [9/10], Phase: train, Batch: [96/131], Loss: 0.0826\n",
      "Epoch [9/10], Phase: train, Batch: [97/131], Loss: 0.0619\n",
      "Epoch [9/10], Phase: train, Batch: [98/131], Loss: 0.0545\n",
      "Epoch [9/10], Phase: train, Batch: [99/131], Loss: 0.0023\n",
      "Epoch [9/10], Phase: train, Batch: [100/131], Loss: 0.0068\n",
      "Epoch [9/10], Phase: train, Batch: [101/131], Loss: 0.3031\n",
      "Epoch [9/10], Phase: train, Batch: [102/131], Loss: 0.0828\n",
      "Epoch [9/10], Phase: train, Batch: [103/131], Loss: 0.0020\n",
      "Epoch [9/10], Phase: train, Batch: [104/131], Loss: 0.0374\n",
      "Epoch [9/10], Phase: train, Batch: [105/131], Loss: 0.0098\n",
      "Epoch [9/10], Phase: train, Batch: [106/131], Loss: 0.0698\n",
      "Epoch [9/10], Phase: train, Batch: [107/131], Loss: 0.0398\n",
      "Epoch [9/10], Phase: train, Batch: [108/131], Loss: 0.0191\n",
      "Epoch [9/10], Phase: train, Batch: [109/131], Loss: 0.0151\n",
      "Epoch [9/10], Phase: train, Batch: [110/131], Loss: 0.0278\n",
      "Epoch [9/10], Phase: train, Batch: [111/131], Loss: 0.0108\n",
      "Epoch [9/10], Phase: train, Batch: [112/131], Loss: 0.0063\n",
      "Epoch [9/10], Phase: train, Batch: [113/131], Loss: 0.0030\n",
      "Epoch [9/10], Phase: train, Batch: [114/131], Loss: 0.0055\n",
      "Epoch [9/10], Phase: train, Batch: [115/131], Loss: 0.1381\n",
      "Epoch [9/10], Phase: train, Batch: [116/131], Loss: 0.1166\n",
      "Epoch [9/10], Phase: train, Batch: [117/131], Loss: 0.0460\n",
      "Epoch [9/10], Phase: train, Batch: [118/131], Loss: 0.0239\n",
      "Epoch [9/10], Phase: train, Batch: [119/131], Loss: 0.0961\n",
      "Epoch [9/10], Phase: train, Batch: [120/131], Loss: 0.0352\n",
      "Epoch [9/10], Phase: train, Batch: [121/131], Loss: 0.0196\n",
      "Epoch [9/10], Phase: train, Batch: [122/131], Loss: 0.0439\n",
      "Epoch [9/10], Phase: train, Batch: [123/131], Loss: 0.0364\n",
      "Epoch [9/10], Phase: train, Batch: [124/131], Loss: 0.0207\n",
      "Epoch [9/10], Phase: train, Batch: [125/131], Loss: 0.0528\n",
      "Epoch [9/10], Phase: train, Batch: [126/131], Loss: 0.0080\n",
      "Epoch [9/10], Phase: train, Batch: [127/131], Loss: 0.0203\n",
      "Epoch [9/10], Phase: train, Batch: [128/131], Loss: 0.0176\n",
      "Epoch [9/10], Phase: train, Batch: [129/131], Loss: 0.0092\n",
      "Epoch [9/10], Phase: train, Batch: [130/131], Loss: 0.0331\n",
      "Epoch [9/10], Phase: train, Batch: [131/131], Loss: 0.0151\n",
      "Epoch [9/10], Train Loss: 0.0350\n",
      "Epoch [10/10], Phase: train, Batch: [1/131], Loss: 0.0028\n",
      "Epoch [10/10], Phase: train, Batch: [2/131], Loss: 0.0186\n",
      "Epoch [10/10], Phase: train, Batch: [3/131], Loss: 0.0373\n",
      "Epoch [10/10], Phase: train, Batch: [4/131], Loss: 0.0011\n",
      "Epoch [10/10], Phase: train, Batch: [5/131], Loss: 0.0019\n",
      "Epoch [10/10], Phase: train, Batch: [6/131], Loss: 0.0057\n",
      "Epoch [10/10], Phase: train, Batch: [7/131], Loss: 0.0147\n",
      "Epoch [10/10], Phase: train, Batch: [8/131], Loss: 0.0023\n",
      "Epoch [10/10], Phase: train, Batch: [9/131], Loss: 0.0031\n",
      "Epoch [10/10], Phase: train, Batch: [10/131], Loss: 0.0026\n",
      "Epoch [10/10], Phase: train, Batch: [11/131], Loss: 0.0174\n",
      "Epoch [10/10], Phase: train, Batch: [12/131], Loss: 0.0327\n",
      "Epoch [10/10], Phase: train, Batch: [13/131], Loss: 0.0010\n",
      "Epoch [10/10], Phase: train, Batch: [14/131], Loss: 0.0060\n",
      "Epoch [10/10], Phase: train, Batch: [15/131], Loss: 0.0079\n",
      "Epoch [10/10], Phase: train, Batch: [16/131], Loss: 0.0045\n",
      "Epoch [10/10], Phase: train, Batch: [17/131], Loss: 0.0086\n",
      "Epoch [10/10], Phase: train, Batch: [18/131], Loss: 0.0190\n",
      "Epoch [10/10], Phase: train, Batch: [19/131], Loss: 0.0124\n",
      "Epoch [10/10], Phase: train, Batch: [20/131], Loss: 0.0008\n",
      "Epoch [10/10], Phase: train, Batch: [21/131], Loss: 0.0216\n",
      "Epoch [10/10], Phase: train, Batch: [22/131], Loss: 0.0103\n",
      "Epoch [10/10], Phase: train, Batch: [23/131], Loss: 0.0018\n",
      "Epoch [10/10], Phase: train, Batch: [24/131], Loss: 0.0066\n",
      "Epoch [10/10], Phase: train, Batch: [25/131], Loss: 0.0191\n",
      "Epoch [10/10], Phase: train, Batch: [26/131], Loss: 0.0062\n",
      "Epoch [10/10], Phase: train, Batch: [27/131], Loss: 0.0067\n",
      "Epoch [10/10], Phase: train, Batch: [28/131], Loss: 0.0248\n",
      "Epoch [10/10], Phase: train, Batch: [29/131], Loss: 0.0440\n",
      "Epoch [10/10], Phase: train, Batch: [30/131], Loss: 0.0034\n",
      "Epoch [10/10], Phase: train, Batch: [31/131], Loss: 0.0203\n",
      "Epoch [10/10], Phase: train, Batch: [32/131], Loss: 0.0017\n",
      "Epoch [10/10], Phase: train, Batch: [33/131], Loss: 0.0037\n",
      "Epoch [10/10], Phase: train, Batch: [34/131], Loss: 0.0054\n",
      "Epoch [10/10], Phase: train, Batch: [35/131], Loss: 0.0018\n",
      "Epoch [10/10], Phase: train, Batch: [36/131], Loss: 0.0250\n",
      "Epoch [10/10], Phase: train, Batch: [37/131], Loss: 0.0248\n",
      "Epoch [10/10], Phase: train, Batch: [38/131], Loss: 0.0064\n",
      "Epoch [10/10], Phase: train, Batch: [39/131], Loss: 0.0055\n",
      "Epoch [10/10], Phase: train, Batch: [40/131], Loss: 0.0125\n",
      "Epoch [10/10], Phase: train, Batch: [41/131], Loss: 0.0019\n",
      "Epoch [10/10], Phase: train, Batch: [42/131], Loss: 0.0071\n",
      "Epoch [10/10], Phase: train, Batch: [43/131], Loss: 0.0077\n",
      "Epoch [10/10], Phase: train, Batch: [44/131], Loss: 0.0030\n",
      "Epoch [10/10], Phase: train, Batch: [45/131], Loss: 0.0077\n",
      "Epoch [10/10], Phase: train, Batch: [46/131], Loss: 0.0060\n",
      "Epoch [10/10], Phase: train, Batch: [47/131], Loss: 0.0018\n",
      "Epoch [10/10], Phase: train, Batch: [48/131], Loss: 0.0138\n",
      "Epoch [10/10], Phase: train, Batch: [49/131], Loss: 0.0011\n",
      "Epoch [10/10], Phase: train, Batch: [50/131], Loss: 0.0011\n",
      "Epoch [10/10], Phase: train, Batch: [51/131], Loss: 0.0026\n",
      "Epoch [10/10], Phase: train, Batch: [52/131], Loss: 0.0425\n",
      "Epoch [10/10], Phase: train, Batch: [53/131], Loss: 0.0004\n",
      "Epoch [10/10], Phase: train, Batch: [54/131], Loss: 0.0096\n",
      "Epoch [10/10], Phase: train, Batch: [55/131], Loss: 0.0020\n",
      "Epoch [10/10], Phase: train, Batch: [56/131], Loss: 0.0443\n",
      "Epoch [10/10], Phase: train, Batch: [57/131], Loss: 0.0059\n",
      "Epoch [10/10], Phase: train, Batch: [58/131], Loss: 0.0069\n",
      "Epoch [10/10], Phase: train, Batch: [59/131], Loss: 0.0061\n",
      "Epoch [10/10], Phase: train, Batch: [60/131], Loss: 0.0964\n",
      "Epoch [10/10], Phase: train, Batch: [61/131], Loss: 0.0351\n",
      "Epoch [10/10], Phase: train, Batch: [62/131], Loss: 0.0088\n",
      "Epoch [10/10], Phase: train, Batch: [63/131], Loss: 0.0222\n",
      "Epoch [10/10], Phase: train, Batch: [64/131], Loss: 0.0593\n",
      "Epoch [10/10], Phase: train, Batch: [65/131], Loss: 0.0369\n",
      "Epoch [10/10], Phase: train, Batch: [66/131], Loss: 0.0068\n",
      "Epoch [10/10], Phase: train, Batch: [67/131], Loss: 0.0341\n",
      "Epoch [10/10], Phase: train, Batch: [68/131], Loss: 0.0133\n",
      "Epoch [10/10], Phase: train, Batch: [69/131], Loss: 0.0062\n",
      "Epoch [10/10], Phase: train, Batch: [70/131], Loss: 0.0264\n",
      "Epoch [10/10], Phase: train, Batch: [71/131], Loss: 0.0063\n",
      "Epoch [10/10], Phase: train, Batch: [72/131], Loss: 0.0047\n",
      "Epoch [10/10], Phase: train, Batch: [73/131], Loss: 0.0705\n",
      "Epoch [10/10], Phase: train, Batch: [74/131], Loss: 0.0164\n",
      "Epoch [10/10], Phase: train, Batch: [75/131], Loss: 0.0082\n",
      "Epoch [10/10], Phase: train, Batch: [76/131], Loss: 0.0009\n",
      "Epoch [10/10], Phase: train, Batch: [77/131], Loss: 0.0414\n",
      "Epoch [10/10], Phase: train, Batch: [78/131], Loss: 0.0230\n",
      "Epoch [10/10], Phase: train, Batch: [79/131], Loss: 0.0017\n",
      "Epoch [10/10], Phase: train, Batch: [80/131], Loss: 0.0145\n",
      "Epoch [10/10], Phase: train, Batch: [81/131], Loss: 0.0025\n",
      "Epoch [10/10], Phase: train, Batch: [82/131], Loss: 0.0014\n",
      "Epoch [10/10], Phase: train, Batch: [83/131], Loss: 0.0863\n",
      "Epoch [10/10], Phase: train, Batch: [84/131], Loss: 0.0605\n",
      "Epoch [10/10], Phase: train, Batch: [85/131], Loss: 0.0140\n",
      "Epoch [10/10], Phase: train, Batch: [86/131], Loss: 0.0215\n",
      "Epoch [10/10], Phase: train, Batch: [87/131], Loss: 0.0044\n",
      "Epoch [10/10], Phase: train, Batch: [88/131], Loss: 0.1108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Phase: train, Batch: [89/131], Loss: 0.0787\n",
      "Epoch [10/10], Phase: train, Batch: [90/131], Loss: 0.0233\n",
      "Epoch [10/10], Phase: train, Batch: [91/131], Loss: 0.0164\n",
      "Epoch [10/10], Phase: train, Batch: [92/131], Loss: 0.0026\n",
      "Epoch [10/10], Phase: train, Batch: [93/131], Loss: 0.0164\n",
      "Epoch [10/10], Phase: train, Batch: [94/131], Loss: 0.0373\n",
      "Epoch [10/10], Phase: train, Batch: [95/131], Loss: 0.0028\n",
      "Epoch [10/10], Phase: train, Batch: [96/131], Loss: 0.0599\n",
      "Epoch [10/10], Phase: train, Batch: [97/131], Loss: 0.1363\n",
      "Epoch [10/10], Phase: train, Batch: [98/131], Loss: 0.0294\n",
      "Epoch [10/10], Phase: train, Batch: [99/131], Loss: 0.0482\n",
      "Epoch [10/10], Phase: train, Batch: [100/131], Loss: 0.0048\n",
      "Epoch [10/10], Phase: train, Batch: [101/131], Loss: 0.0887\n",
      "Epoch [10/10], Phase: train, Batch: [102/131], Loss: 0.0003\n",
      "Epoch [10/10], Phase: train, Batch: [103/131], Loss: 0.0016\n",
      "Epoch [10/10], Phase: train, Batch: [104/131], Loss: 0.0435\n",
      "Epoch [10/10], Phase: train, Batch: [105/131], Loss: 0.0010\n",
      "Epoch [10/10], Phase: train, Batch: [106/131], Loss: 0.0014\n",
      "Epoch [10/10], Phase: train, Batch: [107/131], Loss: 0.1313\n",
      "Epoch [10/10], Phase: train, Batch: [108/131], Loss: 0.0095\n",
      "Epoch [10/10], Phase: train, Batch: [109/131], Loss: 0.0013\n",
      "Epoch [10/10], Phase: train, Batch: [110/131], Loss: 0.0677\n",
      "Epoch [10/10], Phase: train, Batch: [111/131], Loss: 0.0119\n",
      "Epoch [10/10], Phase: train, Batch: [112/131], Loss: 0.0044\n",
      "Epoch [10/10], Phase: train, Batch: [113/131], Loss: 0.0067\n",
      "Epoch [10/10], Phase: train, Batch: [114/131], Loss: 0.0404\n",
      "Epoch [10/10], Phase: train, Batch: [115/131], Loss: 0.0378\n",
      "Epoch [10/10], Phase: train, Batch: [116/131], Loss: 0.0042\n",
      "Epoch [10/10], Phase: train, Batch: [117/131], Loss: 0.0068\n",
      "Epoch [10/10], Phase: train, Batch: [118/131], Loss: 0.0885\n",
      "Epoch [10/10], Phase: train, Batch: [119/131], Loss: 0.9589\n",
      "Epoch [10/10], Phase: train, Batch: [120/131], Loss: 0.0351\n",
      "Epoch [10/10], Phase: train, Batch: [121/131], Loss: 0.0120\n",
      "Epoch [10/10], Phase: train, Batch: [122/131], Loss: 0.0248\n",
      "Epoch [10/10], Phase: train, Batch: [123/131], Loss: 0.0058\n",
      "Epoch [10/10], Phase: train, Batch: [124/131], Loss: 0.0067\n",
      "Epoch [10/10], Phase: train, Batch: [125/131], Loss: 0.0122\n",
      "Epoch [10/10], Phase: train, Batch: [126/131], Loss: 0.0759\n",
      "Epoch [10/10], Phase: train, Batch: [127/131], Loss: 0.0110\n",
      "Epoch [10/10], Phase: train, Batch: [128/131], Loss: 0.0391\n",
      "Epoch [10/10], Phase: train, Batch: [129/131], Loss: 0.0605\n",
      "Epoch [10/10], Phase: train, Batch: [130/131], Loss: 0.0203\n",
      "Epoch [10/10], Phase: train, Batch: [131/131], Loss: 0.1889\n",
      "Epoch [10/10], Train Loss: 0.0289\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloaders['train']):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculate accuracy for this batch\n",
    "        predicted = torch.round(outputs)\n",
    "        correct_predictions += torch.sum(predicted == labels.view_as(predicted)).item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Phase: train, Batch: [{batch_idx+1}/{len(dataloaders[\"train\"])}], Loss: {batch_loss:.4f}, Accuracy: {correct_predictions/total_predictions:.4f}')\n",
    "\n",
    "    epoch_loss = running_loss / dataset_sizes['train']\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38845765",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs >= 0.5).squeeze().long()\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93bda1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['male', 'female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d41ef2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1871  105]\n",
      " [ 152  626]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "classification_rep = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7856ea11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.92      0.95      0.94      1976\n",
      "      female       0.86      0.80      0.83       778\n",
      "\n",
      "    accuracy                           0.91      2754\n",
      "   macro avg       0.89      0.88      0.88      2754\n",
      "weighted avg       0.91      0.91      0.91      2754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1092a02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = ['Male', 'Female'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed50a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'custom_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
