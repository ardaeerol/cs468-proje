{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f4d732",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e9571",
   "metadata": {},
   "source": [
    "Dataset in use: https://susanqq.github.io/UTKFace/\n",
    "\n",
    "*In-the-wild Faces is used and part-2 is selected for train, part-3 is selected for test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd73cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e126db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'utk_train_cropped'\n",
    "val_dir = 'utk_test_cropped'\n",
    "input_size = (224, 224)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f943e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da954c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom dataset\n",
    "class GenderDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.filenames = os.listdir(directory)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.filenames[idx]\n",
    "        img_path = os.path.join(self.directory, img_name)\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        gender_label = int(img_name.split('_')[1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, gender_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40cbd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d72704",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': GenderDataset(directory=train_dir, transform=transform['train']),\n",
    "    'val': GenderDataset(directory=val_dir, transform=transform['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d5c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad6fed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aerol\\env\\facenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aerol\\env\\facenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained VGG model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the fully connected layer\n",
    "num_features = model.classifier[6].in_features\n",
    "\n",
    "# Custom Classifier\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1), # Dropout is applied with probability 0.1 to prevent overfitting\n",
    "    nn.Linear(256, 2)  # Output is 2 dimensional (male and female)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29111350",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb2c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9505d4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [1/131], Loss: 0.7042\n",
      "Epoch [1/10], Phase: train, Batch: [2/131], Loss: 0.6268\n",
      "Epoch [1/10], Phase: train, Batch: [3/131], Loss: 0.5757\n",
      "Epoch [1/10], Phase: train, Batch: [4/131], Loss: 0.5765\n",
      "Epoch [1/10], Phase: train, Batch: [5/131], Loss: 0.4710\n",
      "Epoch [1/10], Phase: train, Batch: [6/131], Loss: 0.5111\n",
      "Epoch [1/10], Phase: train, Batch: [7/131], Loss: 0.5026\n",
      "Epoch [1/10], Phase: train, Batch: [8/131], Loss: 0.4738\n",
      "Epoch [1/10], Phase: train, Batch: [9/131], Loss: 0.3946\n",
      "Epoch [1/10], Phase: train, Batch: [10/131], Loss: 0.4191\n",
      "Epoch [1/10], Phase: train, Batch: [11/131], Loss: 0.4421\n",
      "Epoch [1/10], Phase: train, Batch: [12/131], Loss: 0.5176\n",
      "Epoch [1/10], Phase: train, Batch: [13/131], Loss: 0.4342\n",
      "Epoch [1/10], Phase: train, Batch: [14/131], Loss: 0.3848\n",
      "Epoch [1/10], Phase: train, Batch: [15/131], Loss: 0.3693\n",
      "Epoch [1/10], Phase: train, Batch: [16/131], Loss: 0.4911\n",
      "Epoch [1/10], Phase: train, Batch: [17/131], Loss: 0.3414\n",
      "Epoch [1/10], Phase: train, Batch: [18/131], Loss: 0.4411\n",
      "Epoch [1/10], Phase: train, Batch: [19/131], Loss: 0.4319\n",
      "Epoch [1/10], Phase: train, Batch: [20/131], Loss: 0.4038\n",
      "Epoch [1/10], Phase: train, Batch: [21/131], Loss: 0.4744\n",
      "Epoch [1/10], Phase: train, Batch: [22/131], Loss: 0.4588\n",
      "Epoch [1/10], Phase: train, Batch: [23/131], Loss: 0.5512\n",
      "Epoch [1/10], Phase: train, Batch: [24/131], Loss: 0.3623\n",
      "Epoch [1/10], Phase: train, Batch: [25/131], Loss: 0.4926\n",
      "Epoch [1/10], Phase: train, Batch: [26/131], Loss: 0.5218\n",
      "Epoch [1/10], Phase: train, Batch: [27/131], Loss: 0.4603\n",
      "Epoch [1/10], Phase: train, Batch: [28/131], Loss: 0.4057\n",
      "Epoch [1/10], Phase: train, Batch: [29/131], Loss: 0.4493\n",
      "Epoch [1/10], Phase: train, Batch: [30/131], Loss: 0.3653\n",
      "Epoch [1/10], Phase: train, Batch: [31/131], Loss: 0.3733\n",
      "Epoch [1/10], Phase: train, Batch: [32/131], Loss: 0.6355\n",
      "Epoch [1/10], Phase: train, Batch: [33/131], Loss: 0.3172\n",
      "Epoch [1/10], Phase: train, Batch: [34/131], Loss: 0.2880\n",
      "Epoch [1/10], Phase: train, Batch: [35/131], Loss: 0.4305\n",
      "Epoch [1/10], Phase: train, Batch: [36/131], Loss: 0.3928\n",
      "Epoch [1/10], Phase: train, Batch: [37/131], Loss: 0.4538\n",
      "Epoch [1/10], Phase: train, Batch: [38/131], Loss: 0.4442\n",
      "Epoch [1/10], Phase: train, Batch: [39/131], Loss: 0.5626\n",
      "Epoch [1/10], Phase: train, Batch: [40/131], Loss: 0.4159\n",
      "Epoch [1/10], Phase: train, Batch: [41/131], Loss: 0.3784\n",
      "Epoch [1/10], Phase: train, Batch: [42/131], Loss: 0.4933\n",
      "Epoch [1/10], Phase: train, Batch: [43/131], Loss: 0.3573\n",
      "Epoch [1/10], Phase: train, Batch: [44/131], Loss: 0.3714\n",
      "Epoch [1/10], Phase: train, Batch: [45/131], Loss: 0.5834\n",
      "Epoch [1/10], Phase: train, Batch: [46/131], Loss: 0.4589\n",
      "Epoch [1/10], Phase: train, Batch: [47/131], Loss: 0.4426\n",
      "Epoch [1/10], Phase: train, Batch: [48/131], Loss: 0.3805\n",
      "Epoch [1/10], Phase: train, Batch: [49/131], Loss: 0.4551\n",
      "Epoch [1/10], Phase: train, Batch: [50/131], Loss: 0.6171\n",
      "Epoch [1/10], Phase: train, Batch: [51/131], Loss: 0.4333\n",
      "Epoch [1/10], Phase: train, Batch: [52/131], Loss: 0.4540\n",
      "Epoch [1/10], Phase: train, Batch: [53/131], Loss: 0.3050\n",
      "Epoch [1/10], Phase: train, Batch: [54/131], Loss: 0.4332\n",
      "Epoch [1/10], Phase: train, Batch: [55/131], Loss: 0.4946\n",
      "Epoch [1/10], Phase: train, Batch: [56/131], Loss: 0.4378\n",
      "Epoch [1/10], Phase: train, Batch: [57/131], Loss: 0.4555\n",
      "Epoch [1/10], Phase: train, Batch: [58/131], Loss: 0.4462\n",
      "Epoch [1/10], Phase: train, Batch: [59/131], Loss: 0.3251\n",
      "Epoch [1/10], Phase: train, Batch: [60/131], Loss: 0.3237\n",
      "Epoch [1/10], Phase: train, Batch: [61/131], Loss: 0.3247\n",
      "Epoch [1/10], Phase: train, Batch: [62/131], Loss: 0.3960\n",
      "Epoch [1/10], Phase: train, Batch: [63/131], Loss: 0.2944\n",
      "Epoch [1/10], Phase: train, Batch: [64/131], Loss: 0.2933\n",
      "Epoch [1/10], Phase: train, Batch: [65/131], Loss: 0.3388\n",
      "Epoch [1/10], Phase: train, Batch: [66/131], Loss: 0.2733\n",
      "Epoch [1/10], Phase: train, Batch: [67/131], Loss: 0.3545\n",
      "Epoch [1/10], Phase: train, Batch: [68/131], Loss: 0.2861\n",
      "Epoch [1/10], Phase: train, Batch: [69/131], Loss: 0.4368\n",
      "Epoch [1/10], Phase: train, Batch: [70/131], Loss: 0.4489\n",
      "Epoch [1/10], Phase: train, Batch: [71/131], Loss: 0.4083\n",
      "Epoch [1/10], Phase: train, Batch: [72/131], Loss: 0.3500\n",
      "Epoch [1/10], Phase: train, Batch: [73/131], Loss: 0.3651\n",
      "Epoch [1/10], Phase: train, Batch: [74/131], Loss: 0.5728\n",
      "Epoch [1/10], Phase: train, Batch: [75/131], Loss: 0.6252\n",
      "Epoch [1/10], Phase: train, Batch: [76/131], Loss: 0.3834\n",
      "Epoch [1/10], Phase: train, Batch: [77/131], Loss: 0.6728\n",
      "Epoch [1/10], Phase: train, Batch: [78/131], Loss: 0.2593\n",
      "Epoch [1/10], Phase: train, Batch: [79/131], Loss: 0.3687\n",
      "Epoch [1/10], Phase: train, Batch: [80/131], Loss: 0.3258\n",
      "Epoch [1/10], Phase: train, Batch: [81/131], Loss: 0.3849\n",
      "Epoch [1/10], Phase: train, Batch: [82/131], Loss: 0.4059\n",
      "Epoch [1/10], Phase: train, Batch: [83/131], Loss: 0.4035\n",
      "Epoch [1/10], Phase: train, Batch: [84/131], Loss: 0.3599\n",
      "Epoch [1/10], Phase: train, Batch: [85/131], Loss: 0.4519\n",
      "Epoch [1/10], Phase: train, Batch: [86/131], Loss: 0.5466\n",
      "Epoch [1/10], Phase: train, Batch: [87/131], Loss: 0.4614\n",
      "Epoch [1/10], Phase: train, Batch: [88/131], Loss: 0.3242\n",
      "Epoch [1/10], Phase: train, Batch: [89/131], Loss: 0.4132\n",
      "Epoch [1/10], Phase: train, Batch: [90/131], Loss: 0.4966\n",
      "Epoch [1/10], Phase: train, Batch: [91/131], Loss: 0.5437\n",
      "Epoch [1/10], Phase: train, Batch: [92/131], Loss: 0.2449\n",
      "Epoch [1/10], Phase: train, Batch: [93/131], Loss: 0.4245\n",
      "Epoch [1/10], Phase: train, Batch: [94/131], Loss: 0.4652\n",
      "Epoch [1/10], Phase: train, Batch: [95/131], Loss: 0.4535\n",
      "Epoch [1/10], Phase: train, Batch: [96/131], Loss: 0.4661\n",
      "Epoch [1/10], Phase: train, Batch: [97/131], Loss: 0.5364\n",
      "Epoch [1/10], Phase: train, Batch: [98/131], Loss: 0.4433\n",
      "Epoch [1/10], Phase: train, Batch: [99/131], Loss: 0.5173\n",
      "Epoch [1/10], Phase: train, Batch: [100/131], Loss: 0.4325\n",
      "Epoch [1/10], Phase: train, Batch: [101/131], Loss: 0.3578\n",
      "Epoch [1/10], Phase: train, Batch: [102/131], Loss: 0.3957\n",
      "Epoch [1/10], Phase: train, Batch: [103/131], Loss: 0.3997\n",
      "Epoch [1/10], Phase: train, Batch: [104/131], Loss: 0.3496\n",
      "Epoch [1/10], Phase: train, Batch: [105/131], Loss: 0.3871\n",
      "Epoch [1/10], Phase: train, Batch: [106/131], Loss: 0.3094\n",
      "Epoch [1/10], Phase: train, Batch: [107/131], Loss: 0.3186\n",
      "Epoch [1/10], Phase: train, Batch: [108/131], Loss: 0.4509\n",
      "Epoch [1/10], Phase: train, Batch: [109/131], Loss: 0.5205\n",
      "Epoch [1/10], Phase: train, Batch: [110/131], Loss: 0.3975\n",
      "Epoch [1/10], Phase: train, Batch: [111/131], Loss: 0.4665\n",
      "Epoch [1/10], Phase: train, Batch: [112/131], Loss: 0.4218\n",
      "Epoch [1/10], Phase: train, Batch: [113/131], Loss: 0.3275\n",
      "Epoch [1/10], Phase: train, Batch: [114/131], Loss: 0.3624\n",
      "Epoch [1/10], Phase: train, Batch: [115/131], Loss: 0.4151\n",
      "Epoch [1/10], Phase: train, Batch: [116/131], Loss: 0.3310\n",
      "Epoch [1/10], Phase: train, Batch: [117/131], Loss: 0.3418\n",
      "Epoch [1/10], Phase: train, Batch: [118/131], Loss: 0.4643\n",
      "Epoch [1/10], Phase: train, Batch: [119/131], Loss: 0.3626\n",
      "Epoch [1/10], Phase: train, Batch: [120/131], Loss: 0.3955\n",
      "Epoch [1/10], Phase: train, Batch: [121/131], Loss: 0.4443\n",
      "Epoch [1/10], Phase: train, Batch: [122/131], Loss: 0.4106\n",
      "Epoch [1/10], Phase: train, Batch: [123/131], Loss: 0.3035\n",
      "Epoch [1/10], Phase: train, Batch: [124/131], Loss: 0.3611\n",
      "Epoch [1/10], Phase: train, Batch: [125/131], Loss: 0.3902\n",
      "Epoch [1/10], Phase: train, Batch: [126/131], Loss: 0.5438\n",
      "Epoch [1/10], Phase: train, Batch: [127/131], Loss: 0.3607\n",
      "Epoch [1/10], Phase: train, Batch: [128/131], Loss: 0.3060\n",
      "Epoch [1/10], Phase: train, Batch: [129/131], Loss: 0.3970\n",
      "Epoch [1/10], Phase: train, Batch: [130/131], Loss: 0.5183\n",
      "Epoch [1/10], Phase: train, Batch: [131/131], Loss: 0.5483\n",
      "Train Loss: 0.4262 Acc: 0.8077\n",
      "Epoch [2/10], Phase: train, Batch: [1/131], Loss: 0.4960\n",
      "Epoch [2/10], Phase: train, Batch: [2/131], Loss: 0.5060\n",
      "Epoch [2/10], Phase: train, Batch: [3/131], Loss: 0.3738\n",
      "Epoch [2/10], Phase: train, Batch: [4/131], Loss: 0.3796\n",
      "Epoch [2/10], Phase: train, Batch: [5/131], Loss: 0.5111\n",
      "Epoch [2/10], Phase: train, Batch: [6/131], Loss: 0.4154\n",
      "Epoch [2/10], Phase: train, Batch: [7/131], Loss: 0.2858\n",
      "Epoch [2/10], Phase: train, Batch: [8/131], Loss: 0.3694\n",
      "Epoch [2/10], Phase: train, Batch: [9/131], Loss: 0.5039\n",
      "Epoch [2/10], Phase: train, Batch: [10/131], Loss: 0.4642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [11/131], Loss: 0.3956\n",
      "Epoch [2/10], Phase: train, Batch: [12/131], Loss: 0.3979\n",
      "Epoch [2/10], Phase: train, Batch: [13/131], Loss: 0.3309\n",
      "Epoch [2/10], Phase: train, Batch: [14/131], Loss: 0.3939\n",
      "Epoch [2/10], Phase: train, Batch: [15/131], Loss: 0.3327\n",
      "Epoch [2/10], Phase: train, Batch: [16/131], Loss: 0.3111\n",
      "Epoch [2/10], Phase: train, Batch: [17/131], Loss: 0.4649\n",
      "Epoch [2/10], Phase: train, Batch: [18/131], Loss: 0.3346\n",
      "Epoch [2/10], Phase: train, Batch: [19/131], Loss: 0.4488\n",
      "Epoch [2/10], Phase: train, Batch: [20/131], Loss: 0.4201\n",
      "Epoch [2/10], Phase: train, Batch: [21/131], Loss: 0.3336\n",
      "Epoch [2/10], Phase: train, Batch: [22/131], Loss: 0.3413\n",
      "Epoch [2/10], Phase: train, Batch: [23/131], Loss: 0.3509\n",
      "Epoch [2/10], Phase: train, Batch: [24/131], Loss: 0.5534\n",
      "Epoch [2/10], Phase: train, Batch: [25/131], Loss: 0.4091\n",
      "Epoch [2/10], Phase: train, Batch: [26/131], Loss: 0.2571\n",
      "Epoch [2/10], Phase: train, Batch: [27/131], Loss: 0.5108\n",
      "Epoch [2/10], Phase: train, Batch: [28/131], Loss: 0.2811\n",
      "Epoch [2/10], Phase: train, Batch: [29/131], Loss: 0.3752\n",
      "Epoch [2/10], Phase: train, Batch: [30/131], Loss: 0.4131\n",
      "Epoch [2/10], Phase: train, Batch: [31/131], Loss: 0.4881\n",
      "Epoch [2/10], Phase: train, Batch: [32/131], Loss: 0.2769\n",
      "Epoch [2/10], Phase: train, Batch: [33/131], Loss: 0.3598\n",
      "Epoch [2/10], Phase: train, Batch: [34/131], Loss: 0.5142\n",
      "Epoch [2/10], Phase: train, Batch: [35/131], Loss: 0.5079\n",
      "Epoch [2/10], Phase: train, Batch: [36/131], Loss: 0.4308\n",
      "Epoch [2/10], Phase: train, Batch: [37/131], Loss: 0.4020\n",
      "Epoch [2/10], Phase: train, Batch: [38/131], Loss: 0.2912\n",
      "Epoch [2/10], Phase: train, Batch: [39/131], Loss: 0.3217\n",
      "Epoch [2/10], Phase: train, Batch: [40/131], Loss: 0.3959\n",
      "Epoch [2/10], Phase: train, Batch: [41/131], Loss: 0.3033\n",
      "Epoch [2/10], Phase: train, Batch: [42/131], Loss: 0.5593\n",
      "Epoch [2/10], Phase: train, Batch: [43/131], Loss: 0.4292\n",
      "Epoch [2/10], Phase: train, Batch: [44/131], Loss: 0.4988\n",
      "Epoch [2/10], Phase: train, Batch: [45/131], Loss: 0.3943\n",
      "Epoch [2/10], Phase: train, Batch: [46/131], Loss: 0.3903\n",
      "Epoch [2/10], Phase: train, Batch: [47/131], Loss: 0.4547\n",
      "Epoch [2/10], Phase: train, Batch: [48/131], Loss: 0.3831\n",
      "Epoch [2/10], Phase: train, Batch: [49/131], Loss: 0.3931\n",
      "Epoch [2/10], Phase: train, Batch: [50/131], Loss: 0.3607\n",
      "Epoch [2/10], Phase: train, Batch: [51/131], Loss: 0.3525\n",
      "Epoch [2/10], Phase: train, Batch: [52/131], Loss: 0.3723\n",
      "Epoch [2/10], Phase: train, Batch: [53/131], Loss: 0.3530\n",
      "Epoch [2/10], Phase: train, Batch: [54/131], Loss: 0.3714\n",
      "Epoch [2/10], Phase: train, Batch: [55/131], Loss: 0.2831\n",
      "Epoch [2/10], Phase: train, Batch: [56/131], Loss: 0.3678\n",
      "Epoch [2/10], Phase: train, Batch: [57/131], Loss: 0.3671\n",
      "Epoch [2/10], Phase: train, Batch: [58/131], Loss: 0.2969\n",
      "Epoch [2/10], Phase: train, Batch: [59/131], Loss: 0.4376\n",
      "Epoch [2/10], Phase: train, Batch: [60/131], Loss: 0.3101\n",
      "Epoch [2/10], Phase: train, Batch: [61/131], Loss: 0.3082\n",
      "Epoch [2/10], Phase: train, Batch: [62/131], Loss: 0.4854\n",
      "Epoch [2/10], Phase: train, Batch: [63/131], Loss: 0.3111\n",
      "Epoch [2/10], Phase: train, Batch: [64/131], Loss: 0.3304\n",
      "Epoch [2/10], Phase: train, Batch: [65/131], Loss: 0.4953\n",
      "Epoch [2/10], Phase: train, Batch: [66/131], Loss: 0.3885\n",
      "Epoch [2/10], Phase: train, Batch: [67/131], Loss: 0.3788\n",
      "Epoch [2/10], Phase: train, Batch: [68/131], Loss: 0.3251\n",
      "Epoch [2/10], Phase: train, Batch: [69/131], Loss: 0.4425\n",
      "Epoch [2/10], Phase: train, Batch: [70/131], Loss: 0.3634\n",
      "Epoch [2/10], Phase: train, Batch: [71/131], Loss: 0.3114\n",
      "Epoch [2/10], Phase: train, Batch: [72/131], Loss: 0.3427\n",
      "Epoch [2/10], Phase: train, Batch: [73/131], Loss: 0.3998\n",
      "Epoch [2/10], Phase: train, Batch: [74/131], Loss: 0.3617\n",
      "Epoch [2/10], Phase: train, Batch: [75/131], Loss: 0.3066\n",
      "Epoch [2/10], Phase: train, Batch: [76/131], Loss: 0.4092\n",
      "Epoch [2/10], Phase: train, Batch: [77/131], Loss: 0.2759\n",
      "Epoch [2/10], Phase: train, Batch: [78/131], Loss: 0.4078\n",
      "Epoch [2/10], Phase: train, Batch: [79/131], Loss: 0.4486\n",
      "Epoch [2/10], Phase: train, Batch: [80/131], Loss: 0.4820\n",
      "Epoch [2/10], Phase: train, Batch: [81/131], Loss: 0.3295\n",
      "Epoch [2/10], Phase: train, Batch: [82/131], Loss: 0.4030\n",
      "Epoch [2/10], Phase: train, Batch: [83/131], Loss: 0.3451\n",
      "Epoch [2/10], Phase: train, Batch: [84/131], Loss: 0.4623\n",
      "Epoch [2/10], Phase: train, Batch: [85/131], Loss: 0.3046\n",
      "Epoch [2/10], Phase: train, Batch: [86/131], Loss: 0.3466\n",
      "Epoch [2/10], Phase: train, Batch: [87/131], Loss: 0.3641\n",
      "Epoch [2/10], Phase: train, Batch: [88/131], Loss: 0.3693\n",
      "Epoch [2/10], Phase: train, Batch: [89/131], Loss: 0.4615\n",
      "Epoch [2/10], Phase: train, Batch: [90/131], Loss: 0.4231\n",
      "Epoch [2/10], Phase: train, Batch: [91/131], Loss: 0.3789\n",
      "Epoch [2/10], Phase: train, Batch: [92/131], Loss: 0.2973\n",
      "Epoch [2/10], Phase: train, Batch: [93/131], Loss: 0.3093\n",
      "Epoch [2/10], Phase: train, Batch: [94/131], Loss: 0.3886\n",
      "Epoch [2/10], Phase: train, Batch: [95/131], Loss: 0.3312\n",
      "Epoch [2/10], Phase: train, Batch: [96/131], Loss: 0.4658\n",
      "Epoch [2/10], Phase: train, Batch: [97/131], Loss: 0.3771\n",
      "Epoch [2/10], Phase: train, Batch: [98/131], Loss: 0.3929\n",
      "Epoch [2/10], Phase: train, Batch: [99/131], Loss: 0.2903\n",
      "Epoch [2/10], Phase: train, Batch: [100/131], Loss: 0.3869\n",
      "Epoch [2/10], Phase: train, Batch: [101/131], Loss: 0.3002\n",
      "Epoch [2/10], Phase: train, Batch: [102/131], Loss: 0.2844\n",
      "Epoch [2/10], Phase: train, Batch: [103/131], Loss: 0.5067\n",
      "Epoch [2/10], Phase: train, Batch: [104/131], Loss: 0.3867\n",
      "Epoch [2/10], Phase: train, Batch: [105/131], Loss: 0.3651\n",
      "Epoch [2/10], Phase: train, Batch: [106/131], Loss: 0.3513\n",
      "Epoch [2/10], Phase: train, Batch: [107/131], Loss: 0.4434\n",
      "Epoch [2/10], Phase: train, Batch: [108/131], Loss: 0.5867\n",
      "Epoch [2/10], Phase: train, Batch: [109/131], Loss: 0.4497\n",
      "Epoch [2/10], Phase: train, Batch: [110/131], Loss: 0.3261\n",
      "Epoch [2/10], Phase: train, Batch: [111/131], Loss: 0.4668\n",
      "Epoch [2/10], Phase: train, Batch: [112/131], Loss: 0.4538\n",
      "Epoch [2/10], Phase: train, Batch: [113/131], Loss: 0.3824\n",
      "Epoch [2/10], Phase: train, Batch: [114/131], Loss: 0.3433\n",
      "Epoch [2/10], Phase: train, Batch: [115/131], Loss: 0.4181\n",
      "Epoch [2/10], Phase: train, Batch: [116/131], Loss: 0.5616\n",
      "Epoch [2/10], Phase: train, Batch: [117/131], Loss: 0.2997\n",
      "Epoch [2/10], Phase: train, Batch: [118/131], Loss: 0.4139\n",
      "Epoch [2/10], Phase: train, Batch: [119/131], Loss: 0.4895\n",
      "Epoch [2/10], Phase: train, Batch: [120/131], Loss: 0.3464\n",
      "Epoch [2/10], Phase: train, Batch: [121/131], Loss: 0.3495\n",
      "Epoch [2/10], Phase: train, Batch: [122/131], Loss: 0.2854\n",
      "Epoch [2/10], Phase: train, Batch: [123/131], Loss: 0.3691\n",
      "Epoch [2/10], Phase: train, Batch: [124/131], Loss: 0.3106\n",
      "Epoch [2/10], Phase: train, Batch: [125/131], Loss: 0.3237\n",
      "Epoch [2/10], Phase: train, Batch: [126/131], Loss: 0.4868\n",
      "Epoch [2/10], Phase: train, Batch: [127/131], Loss: 0.3158\n",
      "Epoch [2/10], Phase: train, Batch: [128/131], Loss: 0.5247\n",
      "Epoch [2/10], Phase: train, Batch: [129/131], Loss: 0.3049\n",
      "Epoch [2/10], Phase: train, Batch: [130/131], Loss: 0.2956\n",
      "Epoch [2/10], Phase: train, Batch: [131/131], Loss: 0.6585\n",
      "Train Loss: 0.3879 Acc: 0.8278\n",
      "Epoch [3/10], Phase: train, Batch: [1/131], Loss: 0.3004\n",
      "Epoch [3/10], Phase: train, Batch: [2/131], Loss: 0.3732\n",
      "Epoch [3/10], Phase: train, Batch: [3/131], Loss: 0.4920\n",
      "Epoch [3/10], Phase: train, Batch: [4/131], Loss: 0.3662\n",
      "Epoch [3/10], Phase: train, Batch: [5/131], Loss: 0.3059\n",
      "Epoch [3/10], Phase: train, Batch: [6/131], Loss: 0.3544\n",
      "Epoch [3/10], Phase: train, Batch: [7/131], Loss: 0.4862\n",
      "Epoch [3/10], Phase: train, Batch: [8/131], Loss: 0.3814\n",
      "Epoch [3/10], Phase: train, Batch: [9/131], Loss: 0.4074\n",
      "Epoch [3/10], Phase: train, Batch: [10/131], Loss: 0.3058\n",
      "Epoch [3/10], Phase: train, Batch: [11/131], Loss: 0.3295\n",
      "Epoch [3/10], Phase: train, Batch: [12/131], Loss: 0.4811\n",
      "Epoch [3/10], Phase: train, Batch: [13/131], Loss: 0.3094\n",
      "Epoch [3/10], Phase: train, Batch: [14/131], Loss: 0.3465\n",
      "Epoch [3/10], Phase: train, Batch: [15/131], Loss: 0.4844\n",
      "Epoch [3/10], Phase: train, Batch: [16/131], Loss: 0.4086\n",
      "Epoch [3/10], Phase: train, Batch: [17/131], Loss: 0.4538\n",
      "Epoch [3/10], Phase: train, Batch: [18/131], Loss: 0.3373\n",
      "Epoch [3/10], Phase: train, Batch: [19/131], Loss: 0.4166\n",
      "Epoch [3/10], Phase: train, Batch: [20/131], Loss: 0.4079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [21/131], Loss: 0.3541\n",
      "Epoch [3/10], Phase: train, Batch: [22/131], Loss: 0.4500\n",
      "Epoch [3/10], Phase: train, Batch: [23/131], Loss: 0.4015\n",
      "Epoch [3/10], Phase: train, Batch: [24/131], Loss: 0.3382\n",
      "Epoch [3/10], Phase: train, Batch: [25/131], Loss: 0.3630\n",
      "Epoch [3/10], Phase: train, Batch: [26/131], Loss: 0.3364\n",
      "Epoch [3/10], Phase: train, Batch: [27/131], Loss: 0.3887\n",
      "Epoch [3/10], Phase: train, Batch: [28/131], Loss: 0.3357\n",
      "Epoch [3/10], Phase: train, Batch: [29/131], Loss: 0.4671\n",
      "Epoch [3/10], Phase: train, Batch: [30/131], Loss: 0.4699\n",
      "Epoch [3/10], Phase: train, Batch: [31/131], Loss: 0.3559\n",
      "Epoch [3/10], Phase: train, Batch: [32/131], Loss: 0.3939\n",
      "Epoch [3/10], Phase: train, Batch: [33/131], Loss: 0.4073\n",
      "Epoch [3/10], Phase: train, Batch: [34/131], Loss: 0.5591\n",
      "Epoch [3/10], Phase: train, Batch: [35/131], Loss: 0.2626\n",
      "Epoch [3/10], Phase: train, Batch: [36/131], Loss: 0.3597\n",
      "Epoch [3/10], Phase: train, Batch: [37/131], Loss: 0.3622\n",
      "Epoch [3/10], Phase: train, Batch: [38/131], Loss: 0.3725\n",
      "Epoch [3/10], Phase: train, Batch: [39/131], Loss: 0.4188\n",
      "Epoch [3/10], Phase: train, Batch: [40/131], Loss: 0.3530\n",
      "Epoch [3/10], Phase: train, Batch: [41/131], Loss: 0.3410\n",
      "Epoch [3/10], Phase: train, Batch: [42/131], Loss: 0.3257\n",
      "Epoch [3/10], Phase: train, Batch: [43/131], Loss: 0.2756\n",
      "Epoch [3/10], Phase: train, Batch: [44/131], Loss: 0.2293\n",
      "Epoch [3/10], Phase: train, Batch: [45/131], Loss: 0.2817\n",
      "Epoch [3/10], Phase: train, Batch: [46/131], Loss: 0.3565\n",
      "Epoch [3/10], Phase: train, Batch: [47/131], Loss: 0.3662\n",
      "Epoch [3/10], Phase: train, Batch: [48/131], Loss: 0.3015\n",
      "Epoch [3/10], Phase: train, Batch: [49/131], Loss: 0.5231\n",
      "Epoch [3/10], Phase: train, Batch: [50/131], Loss: 0.2914\n",
      "Epoch [3/10], Phase: train, Batch: [51/131], Loss: 0.3256\n",
      "Epoch [3/10], Phase: train, Batch: [52/131], Loss: 0.2268\n",
      "Epoch [3/10], Phase: train, Batch: [53/131], Loss: 0.3755\n",
      "Epoch [3/10], Phase: train, Batch: [54/131], Loss: 0.3893\n",
      "Epoch [3/10], Phase: train, Batch: [55/131], Loss: 0.5031\n",
      "Epoch [3/10], Phase: train, Batch: [56/131], Loss: 0.5424\n",
      "Epoch [3/10], Phase: train, Batch: [57/131], Loss: 0.2362\n",
      "Epoch [3/10], Phase: train, Batch: [58/131], Loss: 0.5322\n",
      "Epoch [3/10], Phase: train, Batch: [59/131], Loss: 0.2931\n",
      "Epoch [3/10], Phase: train, Batch: [60/131], Loss: 0.3278\n",
      "Epoch [3/10], Phase: train, Batch: [61/131], Loss: 0.3367\n",
      "Epoch [3/10], Phase: train, Batch: [62/131], Loss: 0.4416\n",
      "Epoch [3/10], Phase: train, Batch: [63/131], Loss: 0.4034\n",
      "Epoch [3/10], Phase: train, Batch: [64/131], Loss: 0.3132\n",
      "Epoch [3/10], Phase: train, Batch: [65/131], Loss: 0.3744\n",
      "Epoch [3/10], Phase: train, Batch: [66/131], Loss: 0.4252\n",
      "Epoch [3/10], Phase: train, Batch: [67/131], Loss: 0.5170\n",
      "Epoch [3/10], Phase: train, Batch: [68/131], Loss: 0.3301\n",
      "Epoch [3/10], Phase: train, Batch: [69/131], Loss: 0.4479\n",
      "Epoch [3/10], Phase: train, Batch: [70/131], Loss: 0.3563\n",
      "Epoch [3/10], Phase: train, Batch: [71/131], Loss: 0.3847\n",
      "Epoch [3/10], Phase: train, Batch: [72/131], Loss: 0.3238\n",
      "Epoch [3/10], Phase: train, Batch: [73/131], Loss: 0.3187\n",
      "Epoch [3/10], Phase: train, Batch: [74/131], Loss: 0.4622\n",
      "Epoch [3/10], Phase: train, Batch: [75/131], Loss: 0.3152\n",
      "Epoch [3/10], Phase: train, Batch: [76/131], Loss: 0.2565\n",
      "Epoch [3/10], Phase: train, Batch: [77/131], Loss: 0.3554\n",
      "Epoch [3/10], Phase: train, Batch: [78/131], Loss: 0.3382\n",
      "Epoch [3/10], Phase: train, Batch: [79/131], Loss: 0.3551\n",
      "Epoch [3/10], Phase: train, Batch: [80/131], Loss: 0.3763\n",
      "Epoch [3/10], Phase: train, Batch: [81/131], Loss: 0.3202\n",
      "Epoch [3/10], Phase: train, Batch: [82/131], Loss: 0.4495\n",
      "Epoch [3/10], Phase: train, Batch: [83/131], Loss: 0.2926\n",
      "Epoch [3/10], Phase: train, Batch: [84/131], Loss: 0.3596\n",
      "Epoch [3/10], Phase: train, Batch: [85/131], Loss: 0.3029\n",
      "Epoch [3/10], Phase: train, Batch: [86/131], Loss: 0.3783\n",
      "Epoch [3/10], Phase: train, Batch: [87/131], Loss: 0.5761\n",
      "Epoch [3/10], Phase: train, Batch: [88/131], Loss: 0.2537\n",
      "Epoch [3/10], Phase: train, Batch: [89/131], Loss: 0.4124\n",
      "Epoch [3/10], Phase: train, Batch: [90/131], Loss: 0.4475\n",
      "Epoch [3/10], Phase: train, Batch: [91/131], Loss: 0.4004\n",
      "Epoch [3/10], Phase: train, Batch: [92/131], Loss: 0.3803\n",
      "Epoch [3/10], Phase: train, Batch: [93/131], Loss: 0.3673\n",
      "Epoch [3/10], Phase: train, Batch: [94/131], Loss: 0.3712\n",
      "Epoch [3/10], Phase: train, Batch: [95/131], Loss: 0.4853\n",
      "Epoch [3/10], Phase: train, Batch: [96/131], Loss: 0.4285\n",
      "Epoch [3/10], Phase: train, Batch: [97/131], Loss: 0.4000\n",
      "Epoch [3/10], Phase: train, Batch: [98/131], Loss: 0.4917\n",
      "Epoch [3/10], Phase: train, Batch: [99/131], Loss: 0.4234\n",
      "Epoch [3/10], Phase: train, Batch: [100/131], Loss: 0.4149\n",
      "Epoch [3/10], Phase: train, Batch: [101/131], Loss: 0.3582\n",
      "Epoch [3/10], Phase: train, Batch: [102/131], Loss: 0.2518\n",
      "Epoch [3/10], Phase: train, Batch: [103/131], Loss: 0.5145\n",
      "Epoch [3/10], Phase: train, Batch: [104/131], Loss: 0.3008\n",
      "Epoch [3/10], Phase: train, Batch: [105/131], Loss: 0.3789\n",
      "Epoch [3/10], Phase: train, Batch: [106/131], Loss: 0.3842\n",
      "Epoch [3/10], Phase: train, Batch: [107/131], Loss: 0.4186\n",
      "Epoch [3/10], Phase: train, Batch: [108/131], Loss: 0.3395\n",
      "Epoch [3/10], Phase: train, Batch: [109/131], Loss: 0.4004\n",
      "Epoch [3/10], Phase: train, Batch: [110/131], Loss: 0.3347\n",
      "Epoch [3/10], Phase: train, Batch: [111/131], Loss: 0.4680\n",
      "Epoch [3/10], Phase: train, Batch: [112/131], Loss: 0.3873\n",
      "Epoch [3/10], Phase: train, Batch: [113/131], Loss: 0.4130\n",
      "Epoch [3/10], Phase: train, Batch: [114/131], Loss: 0.3501\n",
      "Epoch [3/10], Phase: train, Batch: [115/131], Loss: 0.3699\n",
      "Epoch [3/10], Phase: train, Batch: [116/131], Loss: 0.4324\n",
      "Epoch [3/10], Phase: train, Batch: [117/131], Loss: 0.4752\n",
      "Epoch [3/10], Phase: train, Batch: [118/131], Loss: 0.3463\n",
      "Epoch [3/10], Phase: train, Batch: [119/131], Loss: 0.3489\n",
      "Epoch [3/10], Phase: train, Batch: [120/131], Loss: 0.4811\n",
      "Epoch [3/10], Phase: train, Batch: [121/131], Loss: 0.2608\n",
      "Epoch [3/10], Phase: train, Batch: [122/131], Loss: 0.3301\n",
      "Epoch [3/10], Phase: train, Batch: [123/131], Loss: 0.3534\n",
      "Epoch [3/10], Phase: train, Batch: [124/131], Loss: 0.3858\n",
      "Epoch [3/10], Phase: train, Batch: [125/131], Loss: 0.4324\n",
      "Epoch [3/10], Phase: train, Batch: [126/131], Loss: 0.3457\n",
      "Epoch [3/10], Phase: train, Batch: [127/131], Loss: 0.3676\n",
      "Epoch [3/10], Phase: train, Batch: [128/131], Loss: 0.2926\n",
      "Epoch [3/10], Phase: train, Batch: [129/131], Loss: 0.3704\n",
      "Epoch [3/10], Phase: train, Batch: [130/131], Loss: 0.4875\n",
      "Epoch [3/10], Phase: train, Batch: [131/131], Loss: 0.2540\n",
      "Train Loss: 0.3791 Acc: 0.8357\n",
      "Epoch [4/10], Phase: train, Batch: [1/131], Loss: 0.3844\n",
      "Epoch [4/10], Phase: train, Batch: [2/131], Loss: 0.5058\n",
      "Epoch [4/10], Phase: train, Batch: [3/131], Loss: 0.4727\n",
      "Epoch [4/10], Phase: train, Batch: [4/131], Loss: 0.3322\n",
      "Epoch [4/10], Phase: train, Batch: [5/131], Loss: 0.4909\n",
      "Epoch [4/10], Phase: train, Batch: [6/131], Loss: 0.4310\n",
      "Epoch [4/10], Phase: train, Batch: [7/131], Loss: 0.4427\n",
      "Epoch [4/10], Phase: train, Batch: [8/131], Loss: 0.3921\n",
      "Epoch [4/10], Phase: train, Batch: [9/131], Loss: 0.3153\n",
      "Epoch [4/10], Phase: train, Batch: [10/131], Loss: 0.3071\n",
      "Epoch [4/10], Phase: train, Batch: [11/131], Loss: 0.3447\n",
      "Epoch [4/10], Phase: train, Batch: [12/131], Loss: 0.4429\n",
      "Epoch [4/10], Phase: train, Batch: [13/131], Loss: 0.3413\n",
      "Epoch [4/10], Phase: train, Batch: [14/131], Loss: 0.3200\n",
      "Epoch [4/10], Phase: train, Batch: [15/131], Loss: 0.5113\n",
      "Epoch [4/10], Phase: train, Batch: [16/131], Loss: 0.4287\n",
      "Epoch [4/10], Phase: train, Batch: [17/131], Loss: 0.3408\n",
      "Epoch [4/10], Phase: train, Batch: [18/131], Loss: 0.4361\n",
      "Epoch [4/10], Phase: train, Batch: [19/131], Loss: 0.3693\n",
      "Epoch [4/10], Phase: train, Batch: [20/131], Loss: 0.4368\n",
      "Epoch [4/10], Phase: train, Batch: [21/131], Loss: 0.3268\n",
      "Epoch [4/10], Phase: train, Batch: [22/131], Loss: 0.3502\n",
      "Epoch [4/10], Phase: train, Batch: [23/131], Loss: 0.3412\n",
      "Epoch [4/10], Phase: train, Batch: [24/131], Loss: 0.2975\n",
      "Epoch [4/10], Phase: train, Batch: [25/131], Loss: 0.3564\n",
      "Epoch [4/10], Phase: train, Batch: [26/131], Loss: 0.3271\n",
      "Epoch [4/10], Phase: train, Batch: [27/131], Loss: 0.3500\n",
      "Epoch [4/10], Phase: train, Batch: [28/131], Loss: 0.4099\n",
      "Epoch [4/10], Phase: train, Batch: [29/131], Loss: 0.3795\n",
      "Epoch [4/10], Phase: train, Batch: [30/131], Loss: 0.4781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [31/131], Loss: 0.5250\n",
      "Epoch [4/10], Phase: train, Batch: [32/131], Loss: 0.3448\n",
      "Epoch [4/10], Phase: train, Batch: [33/131], Loss: 0.3047\n",
      "Epoch [4/10], Phase: train, Batch: [34/131], Loss: 0.3005\n",
      "Epoch [4/10], Phase: train, Batch: [35/131], Loss: 0.3980\n",
      "Epoch [4/10], Phase: train, Batch: [36/131], Loss: 0.2945\n",
      "Epoch [4/10], Phase: train, Batch: [37/131], Loss: 0.3188\n",
      "Epoch [4/10], Phase: train, Batch: [38/131], Loss: 0.4259\n",
      "Epoch [4/10], Phase: train, Batch: [39/131], Loss: 0.2542\n",
      "Epoch [4/10], Phase: train, Batch: [40/131], Loss: 0.4133\n",
      "Epoch [4/10], Phase: train, Batch: [41/131], Loss: 0.4079\n",
      "Epoch [4/10], Phase: train, Batch: [42/131], Loss: 0.2607\n",
      "Epoch [4/10], Phase: train, Batch: [43/131], Loss: 0.3195\n",
      "Epoch [4/10], Phase: train, Batch: [44/131], Loss: 0.4082\n",
      "Epoch [4/10], Phase: train, Batch: [45/131], Loss: 0.4073\n",
      "Epoch [4/10], Phase: train, Batch: [46/131], Loss: 0.5292\n",
      "Epoch [4/10], Phase: train, Batch: [47/131], Loss: 0.4774\n",
      "Epoch [4/10], Phase: train, Batch: [48/131], Loss: 0.3340\n",
      "Epoch [4/10], Phase: train, Batch: [49/131], Loss: 0.3815\n",
      "Epoch [4/10], Phase: train, Batch: [50/131], Loss: 0.6681\n",
      "Epoch [4/10], Phase: train, Batch: [51/131], Loss: 0.4391\n",
      "Epoch [4/10], Phase: train, Batch: [52/131], Loss: 0.5439\n",
      "Epoch [4/10], Phase: train, Batch: [53/131], Loss: 0.3227\n",
      "Epoch [4/10], Phase: train, Batch: [54/131], Loss: 0.3332\n",
      "Epoch [4/10], Phase: train, Batch: [55/131], Loss: 0.5024\n",
      "Epoch [4/10], Phase: train, Batch: [56/131], Loss: 0.5314\n",
      "Epoch [4/10], Phase: train, Batch: [57/131], Loss: 0.2951\n",
      "Epoch [4/10], Phase: train, Batch: [58/131], Loss: 0.3399\n",
      "Epoch [4/10], Phase: train, Batch: [59/131], Loss: 0.4885\n",
      "Epoch [4/10], Phase: train, Batch: [60/131], Loss: 0.3367\n",
      "Epoch [4/10], Phase: train, Batch: [61/131], Loss: 0.3225\n",
      "Epoch [4/10], Phase: train, Batch: [62/131], Loss: 0.2805\n",
      "Epoch [4/10], Phase: train, Batch: [63/131], Loss: 0.3552\n",
      "Epoch [4/10], Phase: train, Batch: [64/131], Loss: 0.3379\n",
      "Epoch [4/10], Phase: train, Batch: [65/131], Loss: 0.4403\n",
      "Epoch [4/10], Phase: train, Batch: [66/131], Loss: 0.3210\n",
      "Epoch [4/10], Phase: train, Batch: [67/131], Loss: 0.4995\n",
      "Epoch [4/10], Phase: train, Batch: [68/131], Loss: 0.4515\n",
      "Epoch [4/10], Phase: train, Batch: [69/131], Loss: 0.3402\n",
      "Epoch [4/10], Phase: train, Batch: [70/131], Loss: 0.5106\n",
      "Epoch [4/10], Phase: train, Batch: [71/131], Loss: 0.4047\n",
      "Epoch [4/10], Phase: train, Batch: [72/131], Loss: 0.4446\n",
      "Epoch [4/10], Phase: train, Batch: [73/131], Loss: 0.4212\n",
      "Epoch [4/10], Phase: train, Batch: [74/131], Loss: 0.3477\n",
      "Epoch [4/10], Phase: train, Batch: [75/131], Loss: 0.3272\n",
      "Epoch [4/10], Phase: train, Batch: [76/131], Loss: 0.4379\n",
      "Epoch [4/10], Phase: train, Batch: [77/131], Loss: 0.4926\n",
      "Epoch [4/10], Phase: train, Batch: [78/131], Loss: 0.3105\n",
      "Epoch [4/10], Phase: train, Batch: [79/131], Loss: 0.4128\n",
      "Epoch [4/10], Phase: train, Batch: [80/131], Loss: 0.4198\n",
      "Epoch [4/10], Phase: train, Batch: [81/131], Loss: 0.3248\n",
      "Epoch [4/10], Phase: train, Batch: [82/131], Loss: 0.3572\n",
      "Epoch [4/10], Phase: train, Batch: [83/131], Loss: 0.2962\n",
      "Epoch [4/10], Phase: train, Batch: [84/131], Loss: 0.4419\n",
      "Epoch [4/10], Phase: train, Batch: [85/131], Loss: 0.3576\n",
      "Epoch [4/10], Phase: train, Batch: [86/131], Loss: 0.3078\n",
      "Epoch [4/10], Phase: train, Batch: [87/131], Loss: 0.2987\n",
      "Epoch [4/10], Phase: train, Batch: [88/131], Loss: 0.3463\n",
      "Epoch [4/10], Phase: train, Batch: [89/131], Loss: 0.4713\n",
      "Epoch [4/10], Phase: train, Batch: [90/131], Loss: 0.3857\n",
      "Epoch [4/10], Phase: train, Batch: [91/131], Loss: 0.2767\n",
      "Epoch [4/10], Phase: train, Batch: [92/131], Loss: 0.4570\n",
      "Epoch [4/10], Phase: train, Batch: [93/131], Loss: 0.3389\n",
      "Epoch [4/10], Phase: train, Batch: [94/131], Loss: 0.3375\n",
      "Epoch [4/10], Phase: train, Batch: [95/131], Loss: 0.2858\n",
      "Epoch [4/10], Phase: train, Batch: [96/131], Loss: 0.2582\n",
      "Epoch [4/10], Phase: train, Batch: [97/131], Loss: 0.2963\n",
      "Epoch [4/10], Phase: train, Batch: [98/131], Loss: 0.4349\n",
      "Epoch [4/10], Phase: train, Batch: [99/131], Loss: 0.2625\n",
      "Epoch [4/10], Phase: train, Batch: [100/131], Loss: 0.4217\n",
      "Epoch [4/10], Phase: train, Batch: [101/131], Loss: 0.3096\n",
      "Epoch [4/10], Phase: train, Batch: [102/131], Loss: 0.2563\n",
      "Epoch [4/10], Phase: train, Batch: [103/131], Loss: 0.4489\n",
      "Epoch [4/10], Phase: train, Batch: [104/131], Loss: 0.4114\n",
      "Epoch [4/10], Phase: train, Batch: [105/131], Loss: 0.3362\n",
      "Epoch [4/10], Phase: train, Batch: [106/131], Loss: 0.5125\n",
      "Epoch [4/10], Phase: train, Batch: [107/131], Loss: 0.4506\n",
      "Epoch [4/10], Phase: train, Batch: [108/131], Loss: 0.3574\n",
      "Epoch [4/10], Phase: train, Batch: [109/131], Loss: 0.3557\n",
      "Epoch [4/10], Phase: train, Batch: [110/131], Loss: 0.4229\n",
      "Epoch [4/10], Phase: train, Batch: [111/131], Loss: 0.3667\n",
      "Epoch [4/10], Phase: train, Batch: [112/131], Loss: 0.4538\n",
      "Epoch [4/10], Phase: train, Batch: [113/131], Loss: 0.5274\n",
      "Epoch [4/10], Phase: train, Batch: [114/131], Loss: 0.4040\n",
      "Epoch [4/10], Phase: train, Batch: [115/131], Loss: 0.5070\n",
      "Epoch [4/10], Phase: train, Batch: [116/131], Loss: 0.3453\n",
      "Epoch [4/10], Phase: train, Batch: [117/131], Loss: 0.4678\n",
      "Epoch [4/10], Phase: train, Batch: [118/131], Loss: 0.3410\n",
      "Epoch [4/10], Phase: train, Batch: [119/131], Loss: 0.4812\n",
      "Epoch [4/10], Phase: train, Batch: [120/131], Loss: 0.3395\n",
      "Epoch [4/10], Phase: train, Batch: [121/131], Loss: 0.4420\n",
      "Epoch [4/10], Phase: train, Batch: [122/131], Loss: 0.4840\n",
      "Epoch [4/10], Phase: train, Batch: [123/131], Loss: 0.3583\n",
      "Epoch [4/10], Phase: train, Batch: [124/131], Loss: 0.3576\n",
      "Epoch [4/10], Phase: train, Batch: [125/131], Loss: 0.3110\n",
      "Epoch [4/10], Phase: train, Batch: [126/131], Loss: 0.2691\n",
      "Epoch [4/10], Phase: train, Batch: [127/131], Loss: 0.3918\n",
      "Epoch [4/10], Phase: train, Batch: [128/131], Loss: 0.3459\n",
      "Epoch [4/10], Phase: train, Batch: [129/131], Loss: 0.4450\n",
      "Epoch [4/10], Phase: train, Batch: [130/131], Loss: 0.2888\n",
      "Epoch [4/10], Phase: train, Batch: [131/131], Loss: 0.4127\n",
      "Train Loss: 0.3861 Acc: 0.8285\n",
      "Epoch [5/10], Phase: train, Batch: [1/131], Loss: 0.3622\n",
      "Epoch [5/10], Phase: train, Batch: [2/131], Loss: 0.4640\n",
      "Epoch [5/10], Phase: train, Batch: [3/131], Loss: 0.4404\n",
      "Epoch [5/10], Phase: train, Batch: [4/131], Loss: 0.3118\n",
      "Epoch [5/10], Phase: train, Batch: [5/131], Loss: 0.4191\n",
      "Epoch [5/10], Phase: train, Batch: [6/131], Loss: 0.3292\n",
      "Epoch [5/10], Phase: train, Batch: [7/131], Loss: 0.4663\n",
      "Epoch [5/10], Phase: train, Batch: [8/131], Loss: 0.2799\n",
      "Epoch [5/10], Phase: train, Batch: [9/131], Loss: 0.4252\n",
      "Epoch [5/10], Phase: train, Batch: [10/131], Loss: 0.2631\n",
      "Epoch [5/10], Phase: train, Batch: [11/131], Loss: 0.5081\n",
      "Epoch [5/10], Phase: train, Batch: [12/131], Loss: 0.4980\n",
      "Epoch [5/10], Phase: train, Batch: [13/131], Loss: 0.3188\n",
      "Epoch [5/10], Phase: train, Batch: [14/131], Loss: 0.3051\n",
      "Epoch [5/10], Phase: train, Batch: [15/131], Loss: 0.3322\n",
      "Epoch [5/10], Phase: train, Batch: [16/131], Loss: 0.4433\n",
      "Epoch [5/10], Phase: train, Batch: [17/131], Loss: 0.4865\n",
      "Epoch [5/10], Phase: train, Batch: [18/131], Loss: 0.5384\n",
      "Epoch [5/10], Phase: train, Batch: [19/131], Loss: 0.4809\n",
      "Epoch [5/10], Phase: train, Batch: [20/131], Loss: 0.3800\n",
      "Epoch [5/10], Phase: train, Batch: [21/131], Loss: 0.3307\n",
      "Epoch [5/10], Phase: train, Batch: [22/131], Loss: 0.3836\n",
      "Epoch [5/10], Phase: train, Batch: [23/131], Loss: 0.3247\n",
      "Epoch [5/10], Phase: train, Batch: [24/131], Loss: 0.3523\n",
      "Epoch [5/10], Phase: train, Batch: [25/131], Loss: 0.3118\n",
      "Epoch [5/10], Phase: train, Batch: [26/131], Loss: 0.3101\n",
      "Epoch [5/10], Phase: train, Batch: [27/131], Loss: 0.2776\n",
      "Epoch [5/10], Phase: train, Batch: [28/131], Loss: 0.3785\n",
      "Epoch [5/10], Phase: train, Batch: [29/131], Loss: 0.3645\n",
      "Epoch [5/10], Phase: train, Batch: [30/131], Loss: 0.4050\n",
      "Epoch [5/10], Phase: train, Batch: [31/131], Loss: 0.3371\n",
      "Epoch [5/10], Phase: train, Batch: [32/131], Loss: 0.4159\n",
      "Epoch [5/10], Phase: train, Batch: [33/131], Loss: 0.2955\n",
      "Epoch [5/10], Phase: train, Batch: [34/131], Loss: 0.2490\n",
      "Epoch [5/10], Phase: train, Batch: [35/131], Loss: 0.4063\n",
      "Epoch [5/10], Phase: train, Batch: [36/131], Loss: 0.2135\n",
      "Epoch [5/10], Phase: train, Batch: [37/131], Loss: 0.4078\n",
      "Epoch [5/10], Phase: train, Batch: [38/131], Loss: 0.3837\n",
      "Epoch [5/10], Phase: train, Batch: [39/131], Loss: 0.2790\n",
      "Epoch [5/10], Phase: train, Batch: [40/131], Loss: 0.4413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [41/131], Loss: 0.3666\n",
      "Epoch [5/10], Phase: train, Batch: [42/131], Loss: 0.3461\n",
      "Epoch [5/10], Phase: train, Batch: [43/131], Loss: 0.4347\n",
      "Epoch [5/10], Phase: train, Batch: [44/131], Loss: 0.3195\n",
      "Epoch [5/10], Phase: train, Batch: [45/131], Loss: 0.3890\n",
      "Epoch [5/10], Phase: train, Batch: [46/131], Loss: 0.3738\n",
      "Epoch [5/10], Phase: train, Batch: [47/131], Loss: 0.5035\n",
      "Epoch [5/10], Phase: train, Batch: [48/131], Loss: 0.4714\n",
      "Epoch [5/10], Phase: train, Batch: [49/131], Loss: 0.3932\n",
      "Epoch [5/10], Phase: train, Batch: [50/131], Loss: 0.5349\n",
      "Epoch [5/10], Phase: train, Batch: [51/131], Loss: 0.4869\n",
      "Epoch [5/10], Phase: train, Batch: [52/131], Loss: 0.3771\n",
      "Epoch [5/10], Phase: train, Batch: [53/131], Loss: 0.2992\n",
      "Epoch [5/10], Phase: train, Batch: [54/131], Loss: 0.2201\n",
      "Epoch [5/10], Phase: train, Batch: [55/131], Loss: 0.3489\n",
      "Epoch [5/10], Phase: train, Batch: [56/131], Loss: 0.4412\n",
      "Epoch [5/10], Phase: train, Batch: [57/131], Loss: 0.3914\n",
      "Epoch [5/10], Phase: train, Batch: [58/131], Loss: 0.3340\n",
      "Epoch [5/10], Phase: train, Batch: [59/131], Loss: 0.3421\n",
      "Epoch [5/10], Phase: train, Batch: [60/131], Loss: 0.4257\n",
      "Epoch [5/10], Phase: train, Batch: [61/131], Loss: 0.3860\n",
      "Epoch [5/10], Phase: train, Batch: [62/131], Loss: 0.3224\n",
      "Epoch [5/10], Phase: train, Batch: [63/131], Loss: 0.4753\n",
      "Epoch [5/10], Phase: train, Batch: [64/131], Loss: 0.3922\n",
      "Epoch [5/10], Phase: train, Batch: [65/131], Loss: 0.3082\n",
      "Epoch [5/10], Phase: train, Batch: [66/131], Loss: 0.3894\n",
      "Epoch [5/10], Phase: train, Batch: [67/131], Loss: 0.3719\n",
      "Epoch [5/10], Phase: train, Batch: [68/131], Loss: 0.5136\n",
      "Epoch [5/10], Phase: train, Batch: [69/131], Loss: 0.3261\n",
      "Epoch [5/10], Phase: train, Batch: [70/131], Loss: 0.3048\n",
      "Epoch [5/10], Phase: train, Batch: [71/131], Loss: 0.4715\n",
      "Epoch [5/10], Phase: train, Batch: [72/131], Loss: 0.3672\n",
      "Epoch [5/10], Phase: train, Batch: [73/131], Loss: 0.2166\n",
      "Epoch [5/10], Phase: train, Batch: [74/131], Loss: 0.4362\n",
      "Epoch [5/10], Phase: train, Batch: [75/131], Loss: 0.4020\n",
      "Epoch [5/10], Phase: train, Batch: [76/131], Loss: 0.3947\n",
      "Epoch [5/10], Phase: train, Batch: [77/131], Loss: 0.3125\n",
      "Epoch [5/10], Phase: train, Batch: [78/131], Loss: 0.4264\n",
      "Epoch [5/10], Phase: train, Batch: [79/131], Loss: 0.3598\n",
      "Epoch [5/10], Phase: train, Batch: [80/131], Loss: 0.2845\n",
      "Epoch [5/10], Phase: train, Batch: [81/131], Loss: 0.3419\n",
      "Epoch [5/10], Phase: train, Batch: [82/131], Loss: 0.3850\n",
      "Epoch [5/10], Phase: train, Batch: [83/131], Loss: 0.3109\n",
      "Epoch [5/10], Phase: train, Batch: [84/131], Loss: 0.2874\n",
      "Epoch [5/10], Phase: train, Batch: [85/131], Loss: 0.3560\n",
      "Epoch [5/10], Phase: train, Batch: [86/131], Loss: 0.3038\n",
      "Epoch [5/10], Phase: train, Batch: [87/131], Loss: 0.3341\n",
      "Epoch [5/10], Phase: train, Batch: [88/131], Loss: 0.2585\n",
      "Epoch [5/10], Phase: train, Batch: [89/131], Loss: 0.4698\n",
      "Epoch [5/10], Phase: train, Batch: [90/131], Loss: 0.2461\n",
      "Epoch [5/10], Phase: train, Batch: [91/131], Loss: 0.2793\n",
      "Epoch [5/10], Phase: train, Batch: [92/131], Loss: 0.3085\n",
      "Epoch [5/10], Phase: train, Batch: [93/131], Loss: 0.4014\n",
      "Epoch [5/10], Phase: train, Batch: [94/131], Loss: 0.3277\n",
      "Epoch [5/10], Phase: train, Batch: [95/131], Loss: 0.2819\n",
      "Epoch [5/10], Phase: train, Batch: [96/131], Loss: 0.3256\n",
      "Epoch [5/10], Phase: train, Batch: [97/131], Loss: 0.4232\n",
      "Epoch [5/10], Phase: train, Batch: [98/131], Loss: 0.4423\n",
      "Epoch [5/10], Phase: train, Batch: [99/131], Loss: 0.3959\n",
      "Epoch [5/10], Phase: train, Batch: [100/131], Loss: 0.4277\n",
      "Epoch [5/10], Phase: train, Batch: [101/131], Loss: 0.3051\n",
      "Epoch [5/10], Phase: train, Batch: [102/131], Loss: 0.3921\n",
      "Epoch [5/10], Phase: train, Batch: [103/131], Loss: 0.3346\n",
      "Epoch [5/10], Phase: train, Batch: [104/131], Loss: 0.3800\n",
      "Epoch [5/10], Phase: train, Batch: [105/131], Loss: 0.4039\n",
      "Epoch [5/10], Phase: train, Batch: [106/131], Loss: 0.3706\n",
      "Epoch [5/10], Phase: train, Batch: [107/131], Loss: 0.3268\n",
      "Epoch [5/10], Phase: train, Batch: [108/131], Loss: 0.2748\n",
      "Epoch [5/10], Phase: train, Batch: [109/131], Loss: 0.4261\n",
      "Epoch [5/10], Phase: train, Batch: [110/131], Loss: 0.3877\n",
      "Epoch [5/10], Phase: train, Batch: [111/131], Loss: 0.2845\n",
      "Epoch [5/10], Phase: train, Batch: [112/131], Loss: 0.3654\n",
      "Epoch [5/10], Phase: train, Batch: [113/131], Loss: 0.3842\n",
      "Epoch [5/10], Phase: train, Batch: [114/131], Loss: 0.3748\n",
      "Epoch [5/10], Phase: train, Batch: [115/131], Loss: 0.3123\n",
      "Epoch [5/10], Phase: train, Batch: [116/131], Loss: 0.3906\n",
      "Epoch [5/10], Phase: train, Batch: [117/131], Loss: 0.3177\n",
      "Epoch [5/10], Phase: train, Batch: [118/131], Loss: 0.2826\n",
      "Epoch [5/10], Phase: train, Batch: [119/131], Loss: 0.3274\n",
      "Epoch [5/10], Phase: train, Batch: [120/131], Loss: 0.3728\n",
      "Epoch [5/10], Phase: train, Batch: [121/131], Loss: 0.4212\n",
      "Epoch [5/10], Phase: train, Batch: [122/131], Loss: 0.3575\n",
      "Epoch [5/10], Phase: train, Batch: [123/131], Loss: 0.4490\n",
      "Epoch [5/10], Phase: train, Batch: [124/131], Loss: 0.3617\n",
      "Epoch [5/10], Phase: train, Batch: [125/131], Loss: 0.4396\n",
      "Epoch [5/10], Phase: train, Batch: [126/131], Loss: 0.3379\n",
      "Epoch [5/10], Phase: train, Batch: [127/131], Loss: 0.4640\n",
      "Epoch [5/10], Phase: train, Batch: [128/131], Loss: 0.4515\n",
      "Epoch [5/10], Phase: train, Batch: [129/131], Loss: 0.3757\n",
      "Epoch [5/10], Phase: train, Batch: [130/131], Loss: 0.3084\n",
      "Epoch [5/10], Phase: train, Batch: [131/131], Loss: 0.1965\n",
      "Train Loss: 0.3695 Acc: 0.8387\n",
      "Epoch [6/10], Phase: train, Batch: [1/131], Loss: 0.3508\n",
      "Epoch [6/10], Phase: train, Batch: [2/131], Loss: 0.3157\n",
      "Epoch [6/10], Phase: train, Batch: [3/131], Loss: 0.3752\n",
      "Epoch [6/10], Phase: train, Batch: [4/131], Loss: 0.4693\n",
      "Epoch [6/10], Phase: train, Batch: [5/131], Loss: 0.3838\n",
      "Epoch [6/10], Phase: train, Batch: [6/131], Loss: 0.3442\n",
      "Epoch [6/10], Phase: train, Batch: [7/131], Loss: 0.3876\n",
      "Epoch [6/10], Phase: train, Batch: [8/131], Loss: 0.4018\n",
      "Epoch [6/10], Phase: train, Batch: [9/131], Loss: 0.3647\n",
      "Epoch [6/10], Phase: train, Batch: [10/131], Loss: 0.4981\n",
      "Epoch [6/10], Phase: train, Batch: [11/131], Loss: 0.3597\n",
      "Epoch [6/10], Phase: train, Batch: [12/131], Loss: 0.4687\n",
      "Epoch [6/10], Phase: train, Batch: [13/131], Loss: 0.4522\n",
      "Epoch [6/10], Phase: train, Batch: [14/131], Loss: 0.3588\n",
      "Epoch [6/10], Phase: train, Batch: [15/131], Loss: 0.2918\n",
      "Epoch [6/10], Phase: train, Batch: [16/131], Loss: 0.2566\n",
      "Epoch [6/10], Phase: train, Batch: [17/131], Loss: 0.4071\n",
      "Epoch [6/10], Phase: train, Batch: [18/131], Loss: 0.3162\n",
      "Epoch [6/10], Phase: train, Batch: [19/131], Loss: 0.2398\n",
      "Epoch [6/10], Phase: train, Batch: [20/131], Loss: 0.4112\n",
      "Epoch [6/10], Phase: train, Batch: [21/131], Loss: 0.3256\n",
      "Epoch [6/10], Phase: train, Batch: [22/131], Loss: 0.3236\n",
      "Epoch [6/10], Phase: train, Batch: [23/131], Loss: 0.3868\n",
      "Epoch [6/10], Phase: train, Batch: [24/131], Loss: 0.3902\n",
      "Epoch [6/10], Phase: train, Batch: [25/131], Loss: 0.3809\n",
      "Epoch [6/10], Phase: train, Batch: [26/131], Loss: 0.3682\n",
      "Epoch [6/10], Phase: train, Batch: [27/131], Loss: 0.4073\n",
      "Epoch [6/10], Phase: train, Batch: [28/131], Loss: 0.3610\n",
      "Epoch [6/10], Phase: train, Batch: [29/131], Loss: 0.3406\n",
      "Epoch [6/10], Phase: train, Batch: [30/131], Loss: 0.4531\n",
      "Epoch [6/10], Phase: train, Batch: [31/131], Loss: 0.4478\n",
      "Epoch [6/10], Phase: train, Batch: [32/131], Loss: 0.4029\n",
      "Epoch [6/10], Phase: train, Batch: [33/131], Loss: 0.2546\n",
      "Epoch [6/10], Phase: train, Batch: [34/131], Loss: 0.3340\n",
      "Epoch [6/10], Phase: train, Batch: [35/131], Loss: 0.3725\n",
      "Epoch [6/10], Phase: train, Batch: [36/131], Loss: 0.4643\n",
      "Epoch [6/10], Phase: train, Batch: [37/131], Loss: 0.3973\n",
      "Epoch [6/10], Phase: train, Batch: [38/131], Loss: 0.4831\n",
      "Epoch [6/10], Phase: train, Batch: [39/131], Loss: 0.3662\n",
      "Epoch [6/10], Phase: train, Batch: [40/131], Loss: 0.4383\n",
      "Epoch [6/10], Phase: train, Batch: [41/131], Loss: 0.3797\n",
      "Epoch [6/10], Phase: train, Batch: [42/131], Loss: 0.2949\n",
      "Epoch [6/10], Phase: train, Batch: [43/131], Loss: 0.2907\n",
      "Epoch [6/10], Phase: train, Batch: [44/131], Loss: 0.2306\n",
      "Epoch [6/10], Phase: train, Batch: [45/131], Loss: 0.3423\n",
      "Epoch [6/10], Phase: train, Batch: [46/131], Loss: 0.2714\n",
      "Epoch [6/10], Phase: train, Batch: [47/131], Loss: 0.4777\n",
      "Epoch [6/10], Phase: train, Batch: [48/131], Loss: 0.2822\n",
      "Epoch [6/10], Phase: train, Batch: [49/131], Loss: 0.2523\n",
      "Epoch [6/10], Phase: train, Batch: [50/131], Loss: 0.4980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Phase: train, Batch: [51/131], Loss: 0.3273\n",
      "Epoch [6/10], Phase: train, Batch: [52/131], Loss: 0.2940\n",
      "Epoch [6/10], Phase: train, Batch: [53/131], Loss: 0.2752\n",
      "Epoch [6/10], Phase: train, Batch: [54/131], Loss: 0.3738\n",
      "Epoch [6/10], Phase: train, Batch: [55/131], Loss: 0.4452\n",
      "Epoch [6/10], Phase: train, Batch: [56/131], Loss: 0.3192\n",
      "Epoch [6/10], Phase: train, Batch: [57/131], Loss: 0.4275\n",
      "Epoch [6/10], Phase: train, Batch: [58/131], Loss: 0.4578\n",
      "Epoch [6/10], Phase: train, Batch: [59/131], Loss: 0.2236\n",
      "Epoch [6/10], Phase: train, Batch: [60/131], Loss: 0.3861\n",
      "Epoch [6/10], Phase: train, Batch: [61/131], Loss: 0.2891\n",
      "Epoch [6/10], Phase: train, Batch: [62/131], Loss: 0.3415\n",
      "Epoch [6/10], Phase: train, Batch: [63/131], Loss: 0.3581\n",
      "Epoch [6/10], Phase: train, Batch: [64/131], Loss: 0.3699\n",
      "Epoch [6/10], Phase: train, Batch: [65/131], Loss: 0.3345\n",
      "Epoch [6/10], Phase: train, Batch: [66/131], Loss: 0.3791\n",
      "Epoch [6/10], Phase: train, Batch: [67/131], Loss: 0.3731\n",
      "Epoch [6/10], Phase: train, Batch: [68/131], Loss: 0.3513\n",
      "Epoch [6/10], Phase: train, Batch: [69/131], Loss: 0.2694\n",
      "Epoch [6/10], Phase: train, Batch: [70/131], Loss: 0.3442\n",
      "Epoch [6/10], Phase: train, Batch: [71/131], Loss: 0.4749\n",
      "Epoch [6/10], Phase: train, Batch: [72/131], Loss: 0.3236\n",
      "Epoch [6/10], Phase: train, Batch: [73/131], Loss: 0.3421\n",
      "Epoch [6/10], Phase: train, Batch: [74/131], Loss: 0.3583\n",
      "Epoch [6/10], Phase: train, Batch: [75/131], Loss: 0.3173\n",
      "Epoch [6/10], Phase: train, Batch: [76/131], Loss: 0.2598\n",
      "Epoch [6/10], Phase: train, Batch: [77/131], Loss: 0.4339\n",
      "Epoch [6/10], Phase: train, Batch: [78/131], Loss: 0.3377\n",
      "Epoch [6/10], Phase: train, Batch: [79/131], Loss: 0.3254\n",
      "Epoch [6/10], Phase: train, Batch: [80/131], Loss: 0.3980\n",
      "Epoch [6/10], Phase: train, Batch: [81/131], Loss: 0.3759\n",
      "Epoch [6/10], Phase: train, Batch: [82/131], Loss: 0.3433\n",
      "Epoch [6/10], Phase: train, Batch: [83/131], Loss: 0.3442\n",
      "Epoch [6/10], Phase: train, Batch: [84/131], Loss: 0.4023\n",
      "Epoch [6/10], Phase: train, Batch: [85/131], Loss: 0.4344\n",
      "Epoch [6/10], Phase: train, Batch: [86/131], Loss: 0.2889\n",
      "Epoch [6/10], Phase: train, Batch: [87/131], Loss: 0.3241\n",
      "Epoch [6/10], Phase: train, Batch: [88/131], Loss: 0.2694\n",
      "Epoch [6/10], Phase: train, Batch: [89/131], Loss: 0.2949\n",
      "Epoch [6/10], Phase: train, Batch: [90/131], Loss: 0.2844\n",
      "Epoch [6/10], Phase: train, Batch: [91/131], Loss: 0.3211\n",
      "Epoch [6/10], Phase: train, Batch: [92/131], Loss: 0.4891\n",
      "Epoch [6/10], Phase: train, Batch: [93/131], Loss: 0.2253\n",
      "Epoch [6/10], Phase: train, Batch: [94/131], Loss: 0.3135\n",
      "Epoch [6/10], Phase: train, Batch: [95/131], Loss: 0.3479\n",
      "Epoch [6/10], Phase: train, Batch: [96/131], Loss: 0.3908\n",
      "Epoch [6/10], Phase: train, Batch: [97/131], Loss: 0.3012\n",
      "Epoch [6/10], Phase: train, Batch: [98/131], Loss: 0.3388\n",
      "Epoch [6/10], Phase: train, Batch: [99/131], Loss: 0.2974\n",
      "Epoch [6/10], Phase: train, Batch: [100/131], Loss: 0.3104\n",
      "Epoch [6/10], Phase: train, Batch: [101/131], Loss: 0.3682\n",
      "Epoch [6/10], Phase: train, Batch: [102/131], Loss: 0.3359\n",
      "Epoch [6/10], Phase: train, Batch: [103/131], Loss: 0.3480\n",
      "Epoch [6/10], Phase: train, Batch: [104/131], Loss: 0.2816\n",
      "Epoch [6/10], Phase: train, Batch: [105/131], Loss: 0.2116\n",
      "Epoch [6/10], Phase: train, Batch: [106/131], Loss: 0.2993\n",
      "Epoch [6/10], Phase: train, Batch: [107/131], Loss: 0.3898\n",
      "Epoch [6/10], Phase: train, Batch: [108/131], Loss: 0.3380\n",
      "Epoch [6/10], Phase: train, Batch: [109/131], Loss: 0.3221\n",
      "Epoch [6/10], Phase: train, Batch: [110/131], Loss: 0.2850\n",
      "Epoch [6/10], Phase: train, Batch: [111/131], Loss: 0.3704\n",
      "Epoch [6/10], Phase: train, Batch: [112/131], Loss: 0.3339\n",
      "Epoch [6/10], Phase: train, Batch: [113/131], Loss: 0.4347\n",
      "Epoch [6/10], Phase: train, Batch: [114/131], Loss: 0.3473\n",
      "Epoch [6/10], Phase: train, Batch: [115/131], Loss: 0.2054\n",
      "Epoch [6/10], Phase: train, Batch: [116/131], Loss: 0.3288\n",
      "Epoch [6/10], Phase: train, Batch: [117/131], Loss: 0.3312\n",
      "Epoch [6/10], Phase: train, Batch: [118/131], Loss: 0.3701\n",
      "Epoch [6/10], Phase: train, Batch: [119/131], Loss: 0.3166\n",
      "Epoch [6/10], Phase: train, Batch: [120/131], Loss: 0.4633\n",
      "Epoch [6/10], Phase: train, Batch: [121/131], Loss: 0.3864\n",
      "Epoch [6/10], Phase: train, Batch: [122/131], Loss: 0.2987\n",
      "Epoch [6/10], Phase: train, Batch: [123/131], Loss: 0.2492\n",
      "Epoch [6/10], Phase: train, Batch: [124/131], Loss: 0.2330\n",
      "Epoch [6/10], Phase: train, Batch: [125/131], Loss: 0.3084\n",
      "Epoch [6/10], Phase: train, Batch: [126/131], Loss: 0.3196\n",
      "Epoch [6/10], Phase: train, Batch: [127/131], Loss: 0.3310\n",
      "Epoch [6/10], Phase: train, Batch: [128/131], Loss: 0.5435\n",
      "Epoch [6/10], Phase: train, Batch: [129/131], Loss: 0.4376\n",
      "Epoch [6/10], Phase: train, Batch: [130/131], Loss: 0.3194\n",
      "Epoch [6/10], Phase: train, Batch: [131/131], Loss: 0.5243\n",
      "Train Loss: 0.3525 Acc: 0.8475\n",
      "Epoch [7/10], Phase: train, Batch: [1/131], Loss: 0.2771\n",
      "Epoch [7/10], Phase: train, Batch: [2/131], Loss: 0.2776\n",
      "Epoch [7/10], Phase: train, Batch: [3/131], Loss: 0.3560\n",
      "Epoch [7/10], Phase: train, Batch: [4/131], Loss: 0.3197\n",
      "Epoch [7/10], Phase: train, Batch: [5/131], Loss: 0.4465\n",
      "Epoch [7/10], Phase: train, Batch: [6/131], Loss: 0.3865\n",
      "Epoch [7/10], Phase: train, Batch: [7/131], Loss: 0.3582\n",
      "Epoch [7/10], Phase: train, Batch: [8/131], Loss: 0.3107\n",
      "Epoch [7/10], Phase: train, Batch: [9/131], Loss: 0.3951\n",
      "Epoch [7/10], Phase: train, Batch: [10/131], Loss: 0.3037\n",
      "Epoch [7/10], Phase: train, Batch: [11/131], Loss: 0.4494\n",
      "Epoch [7/10], Phase: train, Batch: [12/131], Loss: 0.2386\n",
      "Epoch [7/10], Phase: train, Batch: [13/131], Loss: 0.2390\n",
      "Epoch [7/10], Phase: train, Batch: [14/131], Loss: 0.4408\n",
      "Epoch [7/10], Phase: train, Batch: [15/131], Loss: 0.3558\n",
      "Epoch [7/10], Phase: train, Batch: [16/131], Loss: 0.3131\n",
      "Epoch [7/10], Phase: train, Batch: [17/131], Loss: 0.3034\n",
      "Epoch [7/10], Phase: train, Batch: [18/131], Loss: 0.3159\n",
      "Epoch [7/10], Phase: train, Batch: [19/131], Loss: 0.3470\n",
      "Epoch [7/10], Phase: train, Batch: [20/131], Loss: 0.4526\n",
      "Epoch [7/10], Phase: train, Batch: [21/131], Loss: 0.3284\n",
      "Epoch [7/10], Phase: train, Batch: [22/131], Loss: 0.3365\n",
      "Epoch [7/10], Phase: train, Batch: [23/131], Loss: 0.3890\n",
      "Epoch [7/10], Phase: train, Batch: [24/131], Loss: 0.4141\n",
      "Epoch [7/10], Phase: train, Batch: [25/131], Loss: 0.3691\n",
      "Epoch [7/10], Phase: train, Batch: [26/131], Loss: 0.3977\n",
      "Epoch [7/10], Phase: train, Batch: [27/131], Loss: 0.3441\n",
      "Epoch [7/10], Phase: train, Batch: [28/131], Loss: 0.3167\n",
      "Epoch [7/10], Phase: train, Batch: [29/131], Loss: 0.3030\n",
      "Epoch [7/10], Phase: train, Batch: [30/131], Loss: 0.3919\n",
      "Epoch [7/10], Phase: train, Batch: [31/131], Loss: 0.3173\n",
      "Epoch [7/10], Phase: train, Batch: [32/131], Loss: 0.4155\n",
      "Epoch [7/10], Phase: train, Batch: [33/131], Loss: 0.3487\n",
      "Epoch [7/10], Phase: train, Batch: [34/131], Loss: 0.3598\n",
      "Epoch [7/10], Phase: train, Batch: [35/131], Loss: 0.2942\n",
      "Epoch [7/10], Phase: train, Batch: [36/131], Loss: 0.3405\n",
      "Epoch [7/10], Phase: train, Batch: [37/131], Loss: 0.2675\n",
      "Epoch [7/10], Phase: train, Batch: [38/131], Loss: 0.2829\n",
      "Epoch [7/10], Phase: train, Batch: [39/131], Loss: 0.3042\n",
      "Epoch [7/10], Phase: train, Batch: [40/131], Loss: 0.2839\n",
      "Epoch [7/10], Phase: train, Batch: [41/131], Loss: 0.3240\n",
      "Epoch [7/10], Phase: train, Batch: [42/131], Loss: 0.3558\n",
      "Epoch [7/10], Phase: train, Batch: [43/131], Loss: 0.4015\n",
      "Epoch [7/10], Phase: train, Batch: [44/131], Loss: 0.3482\n",
      "Epoch [7/10], Phase: train, Batch: [45/131], Loss: 0.4573\n",
      "Epoch [7/10], Phase: train, Batch: [46/131], Loss: 0.3602\n",
      "Epoch [7/10], Phase: train, Batch: [47/131], Loss: 0.3417\n",
      "Epoch [7/10], Phase: train, Batch: [48/131], Loss: 0.4074\n",
      "Epoch [7/10], Phase: train, Batch: [49/131], Loss: 0.3314\n",
      "Epoch [7/10], Phase: train, Batch: [50/131], Loss: 0.2801\n",
      "Epoch [7/10], Phase: train, Batch: [51/131], Loss: 0.3445\n",
      "Epoch [7/10], Phase: train, Batch: [52/131], Loss: 0.3854\n",
      "Epoch [7/10], Phase: train, Batch: [53/131], Loss: 0.4134\n",
      "Epoch [7/10], Phase: train, Batch: [54/131], Loss: 0.3745\n",
      "Epoch [7/10], Phase: train, Batch: [55/131], Loss: 0.2910\n",
      "Epoch [7/10], Phase: train, Batch: [56/131], Loss: 0.4214\n",
      "Epoch [7/10], Phase: train, Batch: [57/131], Loss: 0.3667\n",
      "Epoch [7/10], Phase: train, Batch: [58/131], Loss: 0.3335\n",
      "Epoch [7/10], Phase: train, Batch: [59/131], Loss: 0.2901\n",
      "Epoch [7/10], Phase: train, Batch: [60/131], Loss: 0.3197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Phase: train, Batch: [61/131], Loss: 0.2746\n",
      "Epoch [7/10], Phase: train, Batch: [62/131], Loss: 0.3414\n",
      "Epoch [7/10], Phase: train, Batch: [63/131], Loss: 0.4200\n",
      "Epoch [7/10], Phase: train, Batch: [64/131], Loss: 0.2799\n",
      "Epoch [7/10], Phase: train, Batch: [65/131], Loss: 0.2996\n",
      "Epoch [7/10], Phase: train, Batch: [66/131], Loss: 0.3655\n",
      "Epoch [7/10], Phase: train, Batch: [67/131], Loss: 0.2990\n",
      "Epoch [7/10], Phase: train, Batch: [68/131], Loss: 0.3647\n",
      "Epoch [7/10], Phase: train, Batch: [69/131], Loss: 0.3088\n",
      "Epoch [7/10], Phase: train, Batch: [70/131], Loss: 0.2124\n",
      "Epoch [7/10], Phase: train, Batch: [71/131], Loss: 0.3772\n",
      "Epoch [7/10], Phase: train, Batch: [72/131], Loss: 0.2875\n",
      "Epoch [7/10], Phase: train, Batch: [73/131], Loss: 0.3903\n",
      "Epoch [7/10], Phase: train, Batch: [74/131], Loss: 0.3005\n",
      "Epoch [7/10], Phase: train, Batch: [75/131], Loss: 0.2629\n",
      "Epoch [7/10], Phase: train, Batch: [76/131], Loss: 0.5335\n",
      "Epoch [7/10], Phase: train, Batch: [77/131], Loss: 0.3295\n",
      "Epoch [7/10], Phase: train, Batch: [78/131], Loss: 0.3798\n",
      "Epoch [7/10], Phase: train, Batch: [79/131], Loss: 0.3862\n",
      "Epoch [7/10], Phase: train, Batch: [80/131], Loss: 0.3734\n",
      "Epoch [7/10], Phase: train, Batch: [81/131], Loss: 0.3925\n",
      "Epoch [7/10], Phase: train, Batch: [82/131], Loss: 0.2498\n",
      "Epoch [7/10], Phase: train, Batch: [83/131], Loss: 0.2345\n",
      "Epoch [7/10], Phase: train, Batch: [84/131], Loss: 0.3717\n",
      "Epoch [7/10], Phase: train, Batch: [85/131], Loss: 0.4520\n",
      "Epoch [7/10], Phase: train, Batch: [86/131], Loss: 0.3785\n",
      "Epoch [7/10], Phase: train, Batch: [87/131], Loss: 0.3729\n",
      "Epoch [7/10], Phase: train, Batch: [88/131], Loss: 0.4063\n",
      "Epoch [7/10], Phase: train, Batch: [89/131], Loss: 0.4788\n",
      "Epoch [7/10], Phase: train, Batch: [90/131], Loss: 0.3561\n",
      "Epoch [7/10], Phase: train, Batch: [91/131], Loss: 0.3872\n",
      "Epoch [7/10], Phase: train, Batch: [92/131], Loss: 0.2438\n",
      "Epoch [7/10], Phase: train, Batch: [93/131], Loss: 0.3394\n",
      "Epoch [7/10], Phase: train, Batch: [94/131], Loss: 0.3301\n",
      "Epoch [7/10], Phase: train, Batch: [95/131], Loss: 0.3023\n",
      "Epoch [7/10], Phase: train, Batch: [96/131], Loss: 0.3234\n",
      "Epoch [7/10], Phase: train, Batch: [97/131], Loss: 0.2116\n",
      "Epoch [7/10], Phase: train, Batch: [98/131], Loss: 0.3701\n",
      "Epoch [7/10], Phase: train, Batch: [99/131], Loss: 0.3462\n",
      "Epoch [7/10], Phase: train, Batch: [100/131], Loss: 0.2632\n",
      "Epoch [7/10], Phase: train, Batch: [101/131], Loss: 0.3080\n",
      "Epoch [7/10], Phase: train, Batch: [102/131], Loss: 0.4030\n",
      "Epoch [7/10], Phase: train, Batch: [103/131], Loss: 0.3553\n",
      "Epoch [7/10], Phase: train, Batch: [104/131], Loss: 0.3245\n",
      "Epoch [7/10], Phase: train, Batch: [105/131], Loss: 0.4912\n",
      "Epoch [7/10], Phase: train, Batch: [106/131], Loss: 0.2677\n",
      "Epoch [7/10], Phase: train, Batch: [107/131], Loss: 0.5081\n",
      "Epoch [7/10], Phase: train, Batch: [108/131], Loss: 0.2542\n",
      "Epoch [7/10], Phase: train, Batch: [109/131], Loss: 0.3112\n",
      "Epoch [7/10], Phase: train, Batch: [110/131], Loss: 0.2759\n",
      "Epoch [7/10], Phase: train, Batch: [111/131], Loss: 0.3346\n",
      "Epoch [7/10], Phase: train, Batch: [112/131], Loss: 0.4578\n",
      "Epoch [7/10], Phase: train, Batch: [113/131], Loss: 0.2577\n",
      "Epoch [7/10], Phase: train, Batch: [114/131], Loss: 0.3001\n",
      "Epoch [7/10], Phase: train, Batch: [115/131], Loss: 0.3468\n",
      "Epoch [7/10], Phase: train, Batch: [116/131], Loss: 0.3453\n",
      "Epoch [7/10], Phase: train, Batch: [117/131], Loss: 0.3144\n",
      "Epoch [7/10], Phase: train, Batch: [118/131], Loss: 0.3736\n",
      "Epoch [7/10], Phase: train, Batch: [119/131], Loss: 0.3613\n",
      "Epoch [7/10], Phase: train, Batch: [120/131], Loss: 0.2783\n",
      "Epoch [7/10], Phase: train, Batch: [121/131], Loss: 0.2374\n",
      "Epoch [7/10], Phase: train, Batch: [122/131], Loss: 0.3936\n",
      "Epoch [7/10], Phase: train, Batch: [123/131], Loss: 0.4211\n",
      "Epoch [7/10], Phase: train, Batch: [124/131], Loss: 0.2337\n",
      "Epoch [7/10], Phase: train, Batch: [125/131], Loss: 0.4127\n",
      "Epoch [7/10], Phase: train, Batch: [126/131], Loss: 0.2879\n",
      "Epoch [7/10], Phase: train, Batch: [127/131], Loss: 0.2442\n",
      "Epoch [7/10], Phase: train, Batch: [128/131], Loss: 0.4275\n",
      "Epoch [7/10], Phase: train, Batch: [129/131], Loss: 0.3462\n",
      "Epoch [7/10], Phase: train, Batch: [130/131], Loss: 0.3159\n",
      "Epoch [7/10], Phase: train, Batch: [131/131], Loss: 0.2775\n",
      "Train Loss: 0.3432 Acc: 0.8546\n",
      "Epoch [8/10], Phase: train, Batch: [1/131], Loss: 0.3225\n",
      "Epoch [8/10], Phase: train, Batch: [2/131], Loss: 0.3008\n",
      "Epoch [8/10], Phase: train, Batch: [3/131], Loss: 0.4738\n",
      "Epoch [8/10], Phase: train, Batch: [4/131], Loss: 0.3785\n",
      "Epoch [8/10], Phase: train, Batch: [5/131], Loss: 0.2480\n",
      "Epoch [8/10], Phase: train, Batch: [6/131], Loss: 0.4271\n",
      "Epoch [8/10], Phase: train, Batch: [7/131], Loss: 0.4026\n",
      "Epoch [8/10], Phase: train, Batch: [8/131], Loss: 0.2135\n",
      "Epoch [8/10], Phase: train, Batch: [9/131], Loss: 0.2440\n",
      "Epoch [8/10], Phase: train, Batch: [10/131], Loss: 0.3768\n",
      "Epoch [8/10], Phase: train, Batch: [11/131], Loss: 0.3635\n",
      "Epoch [8/10], Phase: train, Batch: [12/131], Loss: 0.3092\n",
      "Epoch [8/10], Phase: train, Batch: [13/131], Loss: 0.4031\n",
      "Epoch [8/10], Phase: train, Batch: [14/131], Loss: 0.4061\n",
      "Epoch [8/10], Phase: train, Batch: [15/131], Loss: 0.4738\n",
      "Epoch [8/10], Phase: train, Batch: [16/131], Loss: 0.3474\n",
      "Epoch [8/10], Phase: train, Batch: [17/131], Loss: 0.4732\n",
      "Epoch [8/10], Phase: train, Batch: [18/131], Loss: 0.3780\n",
      "Epoch [8/10], Phase: train, Batch: [19/131], Loss: 0.5236\n",
      "Epoch [8/10], Phase: train, Batch: [20/131], Loss: 0.2691\n",
      "Epoch [8/10], Phase: train, Batch: [21/131], Loss: 0.2547\n",
      "Epoch [8/10], Phase: train, Batch: [22/131], Loss: 0.3364\n",
      "Epoch [8/10], Phase: train, Batch: [23/131], Loss: 0.2649\n",
      "Epoch [8/10], Phase: train, Batch: [24/131], Loss: 0.3088\n",
      "Epoch [8/10], Phase: train, Batch: [25/131], Loss: 0.3271\n",
      "Epoch [8/10], Phase: train, Batch: [26/131], Loss: 0.3971\n",
      "Epoch [8/10], Phase: train, Batch: [27/131], Loss: 0.5490\n",
      "Epoch [8/10], Phase: train, Batch: [28/131], Loss: 0.3582\n",
      "Epoch [8/10], Phase: train, Batch: [29/131], Loss: 0.2276\n",
      "Epoch [8/10], Phase: train, Batch: [30/131], Loss: 0.3984\n",
      "Epoch [8/10], Phase: train, Batch: [31/131], Loss: 0.2350\n",
      "Epoch [8/10], Phase: train, Batch: [32/131], Loss: 0.3058\n",
      "Epoch [8/10], Phase: train, Batch: [33/131], Loss: 0.3228\n",
      "Epoch [8/10], Phase: train, Batch: [34/131], Loss: 0.3012\n",
      "Epoch [8/10], Phase: train, Batch: [35/131], Loss: 0.3595\n",
      "Epoch [8/10], Phase: train, Batch: [36/131], Loss: 0.2744\n",
      "Epoch [8/10], Phase: train, Batch: [37/131], Loss: 0.1825\n",
      "Epoch [8/10], Phase: train, Batch: [38/131], Loss: 0.3581\n",
      "Epoch [8/10], Phase: train, Batch: [39/131], Loss: 0.2964\n",
      "Epoch [8/10], Phase: train, Batch: [40/131], Loss: 0.3886\n",
      "Epoch [8/10], Phase: train, Batch: [41/131], Loss: 0.3606\n",
      "Epoch [8/10], Phase: train, Batch: [42/131], Loss: 0.1739\n",
      "Epoch [8/10], Phase: train, Batch: [43/131], Loss: 0.5059\n",
      "Epoch [8/10], Phase: train, Batch: [44/131], Loss: 0.2724\n",
      "Epoch [8/10], Phase: train, Batch: [45/131], Loss: 0.3060\n",
      "Epoch [8/10], Phase: train, Batch: [46/131], Loss: 0.2795\n",
      "Epoch [8/10], Phase: train, Batch: [47/131], Loss: 0.3913\n",
      "Epoch [8/10], Phase: train, Batch: [48/131], Loss: 0.2387\n",
      "Epoch [8/10], Phase: train, Batch: [49/131], Loss: 0.4300\n",
      "Epoch [8/10], Phase: train, Batch: [50/131], Loss: 0.3728\n",
      "Epoch [8/10], Phase: train, Batch: [51/131], Loss: 0.3234\n",
      "Epoch [8/10], Phase: train, Batch: [52/131], Loss: 0.3303\n",
      "Epoch [8/10], Phase: train, Batch: [53/131], Loss: 0.3432\n",
      "Epoch [8/10], Phase: train, Batch: [54/131], Loss: 0.4663\n",
      "Epoch [8/10], Phase: train, Batch: [55/131], Loss: 0.2151\n",
      "Epoch [8/10], Phase: train, Batch: [56/131], Loss: 0.2327\n",
      "Epoch [8/10], Phase: train, Batch: [57/131], Loss: 0.2985\n",
      "Epoch [8/10], Phase: train, Batch: [58/131], Loss: 0.3155\n",
      "Epoch [8/10], Phase: train, Batch: [59/131], Loss: 0.2097\n",
      "Epoch [8/10], Phase: train, Batch: [60/131], Loss: 0.3765\n",
      "Epoch [8/10], Phase: train, Batch: [61/131], Loss: 0.3144\n",
      "Epoch [8/10], Phase: train, Batch: [62/131], Loss: 0.2765\n",
      "Epoch [8/10], Phase: train, Batch: [63/131], Loss: 0.3439\n",
      "Epoch [8/10], Phase: train, Batch: [64/131], Loss: 0.3132\n",
      "Epoch [8/10], Phase: train, Batch: [65/131], Loss: 0.3561\n",
      "Epoch [8/10], Phase: train, Batch: [66/131], Loss: 0.3084\n",
      "Epoch [8/10], Phase: train, Batch: [67/131], Loss: 0.3591\n",
      "Epoch [8/10], Phase: train, Batch: [68/131], Loss: 0.2910\n",
      "Epoch [8/10], Phase: train, Batch: [69/131], Loss: 0.3696\n",
      "Epoch [8/10], Phase: train, Batch: [70/131], Loss: 0.3369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Phase: train, Batch: [71/131], Loss: 0.3892\n",
      "Epoch [8/10], Phase: train, Batch: [72/131], Loss: 0.3516\n",
      "Epoch [8/10], Phase: train, Batch: [73/131], Loss: 0.3088\n",
      "Epoch [8/10], Phase: train, Batch: [74/131], Loss: 0.3911\n",
      "Epoch [8/10], Phase: train, Batch: [75/131], Loss: 0.2970\n",
      "Epoch [8/10], Phase: train, Batch: [76/131], Loss: 0.3595\n",
      "Epoch [8/10], Phase: train, Batch: [77/131], Loss: 0.2157\n",
      "Epoch [8/10], Phase: train, Batch: [78/131], Loss: 0.3265\n",
      "Epoch [8/10], Phase: train, Batch: [79/131], Loss: 0.3863\n",
      "Epoch [8/10], Phase: train, Batch: [80/131], Loss: 0.3547\n",
      "Epoch [8/10], Phase: train, Batch: [81/131], Loss: 0.3485\n",
      "Epoch [8/10], Phase: train, Batch: [82/131], Loss: 0.3745\n",
      "Epoch [8/10], Phase: train, Batch: [83/131], Loss: 0.3077\n",
      "Epoch [8/10], Phase: train, Batch: [84/131], Loss: 0.5059\n",
      "Epoch [8/10], Phase: train, Batch: [85/131], Loss: 0.3128\n",
      "Epoch [8/10], Phase: train, Batch: [86/131], Loss: 0.3206\n",
      "Epoch [8/10], Phase: train, Batch: [87/131], Loss: 0.3612\n",
      "Epoch [8/10], Phase: train, Batch: [88/131], Loss: 0.3420\n",
      "Epoch [8/10], Phase: train, Batch: [89/131], Loss: 0.3264\n",
      "Epoch [8/10], Phase: train, Batch: [90/131], Loss: 0.3587\n",
      "Epoch [8/10], Phase: train, Batch: [91/131], Loss: 0.3421\n",
      "Epoch [8/10], Phase: train, Batch: [92/131], Loss: 0.5646\n",
      "Epoch [8/10], Phase: train, Batch: [93/131], Loss: 0.4713\n",
      "Epoch [8/10], Phase: train, Batch: [94/131], Loss: 0.4822\n",
      "Epoch [8/10], Phase: train, Batch: [95/131], Loss: 0.4049\n",
      "Epoch [8/10], Phase: train, Batch: [96/131], Loss: 0.3262\n",
      "Epoch [8/10], Phase: train, Batch: [97/131], Loss: 0.3874\n",
      "Epoch [8/10], Phase: train, Batch: [98/131], Loss: 0.2999\n",
      "Epoch [8/10], Phase: train, Batch: [99/131], Loss: 0.2522\n",
      "Epoch [8/10], Phase: train, Batch: [100/131], Loss: 0.2885\n",
      "Epoch [8/10], Phase: train, Batch: [101/131], Loss: 0.2738\n",
      "Epoch [8/10], Phase: train, Batch: [102/131], Loss: 0.4803\n",
      "Epoch [8/10], Phase: train, Batch: [103/131], Loss: 0.3862\n",
      "Epoch [8/10], Phase: train, Batch: [104/131], Loss: 0.2364\n",
      "Epoch [8/10], Phase: train, Batch: [105/131], Loss: 0.3496\n",
      "Epoch [8/10], Phase: train, Batch: [106/131], Loss: 0.3871\n",
      "Epoch [8/10], Phase: train, Batch: [107/131], Loss: 0.2253\n",
      "Epoch [8/10], Phase: train, Batch: [108/131], Loss: 0.2938\n",
      "Epoch [8/10], Phase: train, Batch: [109/131], Loss: 0.3874\n",
      "Epoch [8/10], Phase: train, Batch: [110/131], Loss: 0.2597\n",
      "Epoch [8/10], Phase: train, Batch: [111/131], Loss: 0.3795\n",
      "Epoch [8/10], Phase: train, Batch: [112/131], Loss: 0.4550\n",
      "Epoch [8/10], Phase: train, Batch: [113/131], Loss: 0.3954\n",
      "Epoch [8/10], Phase: train, Batch: [114/131], Loss: 0.3184\n",
      "Epoch [8/10], Phase: train, Batch: [115/131], Loss: 0.3498\n",
      "Epoch [8/10], Phase: train, Batch: [116/131], Loss: 0.3809\n",
      "Epoch [8/10], Phase: train, Batch: [117/131], Loss: 0.4105\n",
      "Epoch [8/10], Phase: train, Batch: [118/131], Loss: 0.4423\n",
      "Epoch [8/10], Phase: train, Batch: [119/131], Loss: 0.3399\n",
      "Epoch [8/10], Phase: train, Batch: [120/131], Loss: 0.2990\n",
      "Epoch [8/10], Phase: train, Batch: [121/131], Loss: 0.4415\n",
      "Epoch [8/10], Phase: train, Batch: [122/131], Loss: 0.3370\n",
      "Epoch [8/10], Phase: train, Batch: [123/131], Loss: 0.4708\n",
      "Epoch [8/10], Phase: train, Batch: [124/131], Loss: 0.4369\n",
      "Epoch [8/10], Phase: train, Batch: [125/131], Loss: 0.4202\n",
      "Epoch [8/10], Phase: train, Batch: [126/131], Loss: 0.3518\n",
      "Epoch [8/10], Phase: train, Batch: [127/131], Loss: 0.4569\n",
      "Epoch [8/10], Phase: train, Batch: [128/131], Loss: 0.2720\n",
      "Epoch [8/10], Phase: train, Batch: [129/131], Loss: 0.3622\n",
      "Epoch [8/10], Phase: train, Batch: [130/131], Loss: 0.3857\n",
      "Epoch [8/10], Phase: train, Batch: [131/131], Loss: 0.3129\n",
      "Train Loss: 0.3479 Acc: 0.8480\n",
      "Epoch [9/10], Phase: train, Batch: [1/131], Loss: 0.3507\n",
      "Epoch [9/10], Phase: train, Batch: [2/131], Loss: 0.4270\n",
      "Epoch [9/10], Phase: train, Batch: [3/131], Loss: 0.3683\n",
      "Epoch [9/10], Phase: train, Batch: [4/131], Loss: 0.2521\n",
      "Epoch [9/10], Phase: train, Batch: [5/131], Loss: 0.4357\n",
      "Epoch [9/10], Phase: train, Batch: [6/131], Loss: 0.3399\n",
      "Epoch [9/10], Phase: train, Batch: [7/131], Loss: 0.4737\n",
      "Epoch [9/10], Phase: train, Batch: [8/131], Loss: 0.3392\n",
      "Epoch [9/10], Phase: train, Batch: [9/131], Loss: 0.3377\n",
      "Epoch [9/10], Phase: train, Batch: [10/131], Loss: 0.4015\n",
      "Epoch [9/10], Phase: train, Batch: [11/131], Loss: 0.3119\n",
      "Epoch [9/10], Phase: train, Batch: [12/131], Loss: 0.4976\n",
      "Epoch [9/10], Phase: train, Batch: [13/131], Loss: 0.3158\n",
      "Epoch [9/10], Phase: train, Batch: [14/131], Loss: 0.2792\n",
      "Epoch [9/10], Phase: train, Batch: [15/131], Loss: 0.3440\n",
      "Epoch [9/10], Phase: train, Batch: [16/131], Loss: 0.3484\n",
      "Epoch [9/10], Phase: train, Batch: [17/131], Loss: 0.2583\n",
      "Epoch [9/10], Phase: train, Batch: [18/131], Loss: 0.2275\n",
      "Epoch [9/10], Phase: train, Batch: [19/131], Loss: 0.2634\n",
      "Epoch [9/10], Phase: train, Batch: [20/131], Loss: 0.4508\n",
      "Epoch [9/10], Phase: train, Batch: [21/131], Loss: 0.3094\n",
      "Epoch [9/10], Phase: train, Batch: [22/131], Loss: 0.4383\n",
      "Epoch [9/10], Phase: train, Batch: [23/131], Loss: 0.4139\n",
      "Epoch [9/10], Phase: train, Batch: [24/131], Loss: 0.3619\n",
      "Epoch [9/10], Phase: train, Batch: [25/131], Loss: 0.4321\n",
      "Epoch [9/10], Phase: train, Batch: [26/131], Loss: 0.3356\n",
      "Epoch [9/10], Phase: train, Batch: [27/131], Loss: 0.3749\n",
      "Epoch [9/10], Phase: train, Batch: [28/131], Loss: 0.3488\n",
      "Epoch [9/10], Phase: train, Batch: [29/131], Loss: 0.3733\n",
      "Epoch [9/10], Phase: train, Batch: [30/131], Loss: 0.3436\n",
      "Epoch [9/10], Phase: train, Batch: [31/131], Loss: 0.3252\n",
      "Epoch [9/10], Phase: train, Batch: [32/131], Loss: 0.3048\n",
      "Epoch [9/10], Phase: train, Batch: [33/131], Loss: 0.3107\n",
      "Epoch [9/10], Phase: train, Batch: [34/131], Loss: 0.2457\n",
      "Epoch [9/10], Phase: train, Batch: [35/131], Loss: 0.4242\n",
      "Epoch [9/10], Phase: train, Batch: [36/131], Loss: 0.2688\n",
      "Epoch [9/10], Phase: train, Batch: [37/131], Loss: 0.2844\n",
      "Epoch [9/10], Phase: train, Batch: [38/131], Loss: 0.3068\n",
      "Epoch [9/10], Phase: train, Batch: [39/131], Loss: 0.3784\n",
      "Epoch [9/10], Phase: train, Batch: [40/131], Loss: 0.3227\n",
      "Epoch [9/10], Phase: train, Batch: [41/131], Loss: 0.3419\n",
      "Epoch [9/10], Phase: train, Batch: [42/131], Loss: 0.2583\n",
      "Epoch [9/10], Phase: train, Batch: [43/131], Loss: 0.4974\n",
      "Epoch [9/10], Phase: train, Batch: [44/131], Loss: 0.1905\n",
      "Epoch [9/10], Phase: train, Batch: [45/131], Loss: 0.2971\n",
      "Epoch [9/10], Phase: train, Batch: [46/131], Loss: 0.2361\n",
      "Epoch [9/10], Phase: train, Batch: [47/131], Loss: 0.3875\n",
      "Epoch [9/10], Phase: train, Batch: [48/131], Loss: 0.3313\n",
      "Epoch [9/10], Phase: train, Batch: [49/131], Loss: 0.3459\n",
      "Epoch [9/10], Phase: train, Batch: [50/131], Loss: 0.3954\n",
      "Epoch [9/10], Phase: train, Batch: [51/131], Loss: 0.2503\n",
      "Epoch [9/10], Phase: train, Batch: [52/131], Loss: 0.4326\n",
      "Epoch [9/10], Phase: train, Batch: [53/131], Loss: 0.3009\n",
      "Epoch [9/10], Phase: train, Batch: [54/131], Loss: 0.3903\n",
      "Epoch [9/10], Phase: train, Batch: [55/131], Loss: 0.2583\n",
      "Epoch [9/10], Phase: train, Batch: [56/131], Loss: 0.3292\n",
      "Epoch [9/10], Phase: train, Batch: [57/131], Loss: 0.3118\n",
      "Epoch [9/10], Phase: train, Batch: [58/131], Loss: 0.3808\n",
      "Epoch [9/10], Phase: train, Batch: [59/131], Loss: 0.5167\n",
      "Epoch [9/10], Phase: train, Batch: [60/131], Loss: 0.4101\n",
      "Epoch [9/10], Phase: train, Batch: [61/131], Loss: 0.3396\n",
      "Epoch [9/10], Phase: train, Batch: [62/131], Loss: 0.2919\n",
      "Epoch [9/10], Phase: train, Batch: [63/131], Loss: 0.2334\n",
      "Epoch [9/10], Phase: train, Batch: [64/131], Loss: 0.3212\n",
      "Epoch [9/10], Phase: train, Batch: [65/131], Loss: 0.4748\n",
      "Epoch [9/10], Phase: train, Batch: [66/131], Loss: 0.2833\n",
      "Epoch [9/10], Phase: train, Batch: [67/131], Loss: 0.3281\n",
      "Epoch [9/10], Phase: train, Batch: [68/131], Loss: 0.3332\n",
      "Epoch [9/10], Phase: train, Batch: [69/131], Loss: 0.3925\n",
      "Epoch [9/10], Phase: train, Batch: [70/131], Loss: 0.2950\n",
      "Epoch [9/10], Phase: train, Batch: [71/131], Loss: 0.3198\n",
      "Epoch [9/10], Phase: train, Batch: [72/131], Loss: 0.2932\n",
      "Epoch [9/10], Phase: train, Batch: [73/131], Loss: 0.3402\n",
      "Epoch [9/10], Phase: train, Batch: [74/131], Loss: 0.4136\n",
      "Epoch [9/10], Phase: train, Batch: [75/131], Loss: 0.3287\n",
      "Epoch [9/10], Phase: train, Batch: [76/131], Loss: 0.3621\n",
      "Epoch [9/10], Phase: train, Batch: [77/131], Loss: 0.3703\n",
      "Epoch [9/10], Phase: train, Batch: [78/131], Loss: 0.3461\n",
      "Epoch [9/10], Phase: train, Batch: [79/131], Loss: 0.2496\n",
      "Epoch [9/10], Phase: train, Batch: [80/131], Loss: 0.5022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Phase: train, Batch: [81/131], Loss: 0.3264\n",
      "Epoch [9/10], Phase: train, Batch: [82/131], Loss: 0.3964\n",
      "Epoch [9/10], Phase: train, Batch: [83/131], Loss: 0.2980\n",
      "Epoch [9/10], Phase: train, Batch: [84/131], Loss: 0.2778\n",
      "Epoch [9/10], Phase: train, Batch: [85/131], Loss: 0.2914\n",
      "Epoch [9/10], Phase: train, Batch: [86/131], Loss: 0.3579\n",
      "Epoch [9/10], Phase: train, Batch: [87/131], Loss: 0.3520\n",
      "Epoch [9/10], Phase: train, Batch: [88/131], Loss: 0.3766\n",
      "Epoch [9/10], Phase: train, Batch: [89/131], Loss: 0.2430\n",
      "Epoch [9/10], Phase: train, Batch: [90/131], Loss: 0.4132\n",
      "Epoch [9/10], Phase: train, Batch: [91/131], Loss: 0.3219\n",
      "Epoch [9/10], Phase: train, Batch: [92/131], Loss: 0.2807\n",
      "Epoch [9/10], Phase: train, Batch: [93/131], Loss: 0.3701\n",
      "Epoch [9/10], Phase: train, Batch: [94/131], Loss: 0.4148\n",
      "Epoch [9/10], Phase: train, Batch: [95/131], Loss: 0.2972\n",
      "Epoch [9/10], Phase: train, Batch: [96/131], Loss: 0.2571\n",
      "Epoch [9/10], Phase: train, Batch: [97/131], Loss: 0.4660\n",
      "Epoch [9/10], Phase: train, Batch: [98/131], Loss: 0.3866\n",
      "Epoch [9/10], Phase: train, Batch: [99/131], Loss: 0.3954\n",
      "Epoch [9/10], Phase: train, Batch: [100/131], Loss: 0.3908\n",
      "Epoch [9/10], Phase: train, Batch: [101/131], Loss: 0.3304\n",
      "Epoch [9/10], Phase: train, Batch: [102/131], Loss: 0.3568\n",
      "Epoch [9/10], Phase: train, Batch: [103/131], Loss: 0.2846\n",
      "Epoch [9/10], Phase: train, Batch: [104/131], Loss: 0.3370\n",
      "Epoch [9/10], Phase: train, Batch: [105/131], Loss: 0.4580\n",
      "Epoch [9/10], Phase: train, Batch: [106/131], Loss: 0.4316\n",
      "Epoch [9/10], Phase: train, Batch: [107/131], Loss: 0.3315\n",
      "Epoch [9/10], Phase: train, Batch: [108/131], Loss: 0.4131\n",
      "Epoch [9/10], Phase: train, Batch: [109/131], Loss: 0.3385\n",
      "Epoch [9/10], Phase: train, Batch: [110/131], Loss: 0.4038\n",
      "Epoch [9/10], Phase: train, Batch: [111/131], Loss: 0.3115\n",
      "Epoch [9/10], Phase: train, Batch: [112/131], Loss: 0.3097\n",
      "Epoch [9/10], Phase: train, Batch: [113/131], Loss: 0.3139\n",
      "Epoch [9/10], Phase: train, Batch: [114/131], Loss: 0.2800\n",
      "Epoch [9/10], Phase: train, Batch: [115/131], Loss: 0.3148\n",
      "Epoch [9/10], Phase: train, Batch: [116/131], Loss: 0.3544\n",
      "Epoch [9/10], Phase: train, Batch: [117/131], Loss: 0.3591\n",
      "Epoch [9/10], Phase: train, Batch: [118/131], Loss: 0.3393\n",
      "Epoch [9/10], Phase: train, Batch: [119/131], Loss: 0.3181\n",
      "Epoch [9/10], Phase: train, Batch: [120/131], Loss: 0.3846\n",
      "Epoch [9/10], Phase: train, Batch: [121/131], Loss: 0.4186\n",
      "Epoch [9/10], Phase: train, Batch: [122/131], Loss: 0.4709\n",
      "Epoch [9/10], Phase: train, Batch: [123/131], Loss: 0.2125\n",
      "Epoch [9/10], Phase: train, Batch: [124/131], Loss: 0.2963\n",
      "Epoch [9/10], Phase: train, Batch: [125/131], Loss: 0.3469\n",
      "Epoch [9/10], Phase: train, Batch: [126/131], Loss: 0.4755\n",
      "Epoch [9/10], Phase: train, Batch: [127/131], Loss: 0.4416\n",
      "Epoch [9/10], Phase: train, Batch: [128/131], Loss: 0.2500\n",
      "Epoch [9/10], Phase: train, Batch: [129/131], Loss: 0.3733\n",
      "Epoch [9/10], Phase: train, Batch: [130/131], Loss: 0.3361\n",
      "Epoch [9/10], Phase: train, Batch: [131/131], Loss: 0.3220\n",
      "Train Loss: 0.3470 Acc: 0.8498\n",
      "Epoch [10/10], Phase: train, Batch: [1/131], Loss: 0.2894\n",
      "Epoch [10/10], Phase: train, Batch: [2/131], Loss: 0.2984\n",
      "Epoch [10/10], Phase: train, Batch: [3/131], Loss: 0.2838\n",
      "Epoch [10/10], Phase: train, Batch: [4/131], Loss: 0.2502\n",
      "Epoch [10/10], Phase: train, Batch: [5/131], Loss: 0.3542\n",
      "Epoch [10/10], Phase: train, Batch: [6/131], Loss: 0.3055\n",
      "Epoch [10/10], Phase: train, Batch: [7/131], Loss: 0.3162\n",
      "Epoch [10/10], Phase: train, Batch: [8/131], Loss: 0.5188\n",
      "Epoch [10/10], Phase: train, Batch: [9/131], Loss: 0.3024\n",
      "Epoch [10/10], Phase: train, Batch: [10/131], Loss: 0.3079\n",
      "Epoch [10/10], Phase: train, Batch: [11/131], Loss: 0.3856\n",
      "Epoch [10/10], Phase: train, Batch: [12/131], Loss: 0.3364\n",
      "Epoch [10/10], Phase: train, Batch: [13/131], Loss: 0.3703\n",
      "Epoch [10/10], Phase: train, Batch: [14/131], Loss: 0.3082\n",
      "Epoch [10/10], Phase: train, Batch: [15/131], Loss: 0.5661\n",
      "Epoch [10/10], Phase: train, Batch: [16/131], Loss: 0.3381\n",
      "Epoch [10/10], Phase: train, Batch: [17/131], Loss: 0.4222\n",
      "Epoch [10/10], Phase: train, Batch: [18/131], Loss: 0.3234\n",
      "Epoch [10/10], Phase: train, Batch: [19/131], Loss: 0.4329\n",
      "Epoch [10/10], Phase: train, Batch: [20/131], Loss: 0.3606\n",
      "Epoch [10/10], Phase: train, Batch: [21/131], Loss: 0.3755\n",
      "Epoch [10/10], Phase: train, Batch: [22/131], Loss: 0.4544\n",
      "Epoch [10/10], Phase: train, Batch: [23/131], Loss: 0.3883\n",
      "Epoch [10/10], Phase: train, Batch: [24/131], Loss: 0.3567\n",
      "Epoch [10/10], Phase: train, Batch: [25/131], Loss: 0.2998\n",
      "Epoch [10/10], Phase: train, Batch: [26/131], Loss: 0.2835\n",
      "Epoch [10/10], Phase: train, Batch: [27/131], Loss: 0.4266\n",
      "Epoch [10/10], Phase: train, Batch: [28/131], Loss: 0.2899\n",
      "Epoch [10/10], Phase: train, Batch: [29/131], Loss: 0.3386\n",
      "Epoch [10/10], Phase: train, Batch: [30/131], Loss: 0.3505\n",
      "Epoch [10/10], Phase: train, Batch: [31/131], Loss: 0.3543\n",
      "Epoch [10/10], Phase: train, Batch: [32/131], Loss: 0.3111\n",
      "Epoch [10/10], Phase: train, Batch: [33/131], Loss: 0.2832\n",
      "Epoch [10/10], Phase: train, Batch: [34/131], Loss: 0.2778\n",
      "Epoch [10/10], Phase: train, Batch: [35/131], Loss: 0.4529\n",
      "Epoch [10/10], Phase: train, Batch: [36/131], Loss: 0.3326\n",
      "Epoch [10/10], Phase: train, Batch: [37/131], Loss: 0.3895\n",
      "Epoch [10/10], Phase: train, Batch: [38/131], Loss: 0.3211\n",
      "Epoch [10/10], Phase: train, Batch: [39/131], Loss: 0.4420\n",
      "Epoch [10/10], Phase: train, Batch: [40/131], Loss: 0.2801\n",
      "Epoch [10/10], Phase: train, Batch: [41/131], Loss: 0.4852\n",
      "Epoch [10/10], Phase: train, Batch: [42/131], Loss: 0.3314\n",
      "Epoch [10/10], Phase: train, Batch: [43/131], Loss: 0.3550\n",
      "Epoch [10/10], Phase: train, Batch: [44/131], Loss: 0.4405\n",
      "Epoch [10/10], Phase: train, Batch: [45/131], Loss: 0.3547\n",
      "Epoch [10/10], Phase: train, Batch: [46/131], Loss: 0.3765\n",
      "Epoch [10/10], Phase: train, Batch: [47/131], Loss: 0.3377\n",
      "Epoch [10/10], Phase: train, Batch: [48/131], Loss: 0.3472\n",
      "Epoch [10/10], Phase: train, Batch: [49/131], Loss: 0.3418\n",
      "Epoch [10/10], Phase: train, Batch: [50/131], Loss: 0.3411\n",
      "Epoch [10/10], Phase: train, Batch: [51/131], Loss: 0.3256\n",
      "Epoch [10/10], Phase: train, Batch: [52/131], Loss: 0.3610\n",
      "Epoch [10/10], Phase: train, Batch: [53/131], Loss: 0.4031\n",
      "Epoch [10/10], Phase: train, Batch: [54/131], Loss: 0.3049\n",
      "Epoch [10/10], Phase: train, Batch: [55/131], Loss: 0.3533\n",
      "Epoch [10/10], Phase: train, Batch: [56/131], Loss: 0.2239\n",
      "Epoch [10/10], Phase: train, Batch: [57/131], Loss: 0.3199\n",
      "Epoch [10/10], Phase: train, Batch: [58/131], Loss: 0.4147\n",
      "Epoch [10/10], Phase: train, Batch: [59/131], Loss: 0.3927\n",
      "Epoch [10/10], Phase: train, Batch: [60/131], Loss: 0.2050\n",
      "Epoch [10/10], Phase: train, Batch: [61/131], Loss: 0.3012\n",
      "Epoch [10/10], Phase: train, Batch: [62/131], Loss: 0.3026\n",
      "Epoch [10/10], Phase: train, Batch: [63/131], Loss: 0.3493\n",
      "Epoch [10/10], Phase: train, Batch: [64/131], Loss: 0.4403\n",
      "Epoch [10/10], Phase: train, Batch: [65/131], Loss: 0.3813\n",
      "Epoch [10/10], Phase: train, Batch: [66/131], Loss: 0.6016\n",
      "Epoch [10/10], Phase: train, Batch: [67/131], Loss: 0.3244\n",
      "Epoch [10/10], Phase: train, Batch: [68/131], Loss: 0.3222\n",
      "Epoch [10/10], Phase: train, Batch: [69/131], Loss: 0.2473\n",
      "Epoch [10/10], Phase: train, Batch: [70/131], Loss: 0.3795\n",
      "Epoch [10/10], Phase: train, Batch: [71/131], Loss: 0.3710\n",
      "Epoch [10/10], Phase: train, Batch: [72/131], Loss: 0.2743\n",
      "Epoch [10/10], Phase: train, Batch: [73/131], Loss: 0.4322\n",
      "Epoch [10/10], Phase: train, Batch: [74/131], Loss: 0.3637\n",
      "Epoch [10/10], Phase: train, Batch: [75/131], Loss: 0.3744\n",
      "Epoch [10/10], Phase: train, Batch: [76/131], Loss: 0.4141\n",
      "Epoch [10/10], Phase: train, Batch: [77/131], Loss: 0.3057\n",
      "Epoch [10/10], Phase: train, Batch: [78/131], Loss: 0.4002\n",
      "Epoch [10/10], Phase: train, Batch: [79/131], Loss: 0.3509\n",
      "Epoch [10/10], Phase: train, Batch: [80/131], Loss: 0.2578\n",
      "Epoch [10/10], Phase: train, Batch: [81/131], Loss: 0.2168\n",
      "Epoch [10/10], Phase: train, Batch: [82/131], Loss: 0.3271\n",
      "Epoch [10/10], Phase: train, Batch: [83/131], Loss: 0.4085\n",
      "Epoch [10/10], Phase: train, Batch: [84/131], Loss: 0.3079\n",
      "Epoch [10/10], Phase: train, Batch: [85/131], Loss: 0.2540\n",
      "Epoch [10/10], Phase: train, Batch: [86/131], Loss: 0.2757\n",
      "Epoch [10/10], Phase: train, Batch: [87/131], Loss: 0.2991\n",
      "Epoch [10/10], Phase: train, Batch: [88/131], Loss: 0.3249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Phase: train, Batch: [89/131], Loss: 0.3785\n",
      "Epoch [10/10], Phase: train, Batch: [90/131], Loss: 0.3649\n",
      "Epoch [10/10], Phase: train, Batch: [91/131], Loss: 0.3418\n",
      "Epoch [10/10], Phase: train, Batch: [92/131], Loss: 0.3593\n",
      "Epoch [10/10], Phase: train, Batch: [93/131], Loss: 0.2511\n",
      "Epoch [10/10], Phase: train, Batch: [94/131], Loss: 0.2729\n",
      "Epoch [10/10], Phase: train, Batch: [95/131], Loss: 0.4223\n",
      "Epoch [10/10], Phase: train, Batch: [96/131], Loss: 0.4042\n",
      "Epoch [10/10], Phase: train, Batch: [97/131], Loss: 0.2660\n",
      "Epoch [10/10], Phase: train, Batch: [98/131], Loss: 0.3131\n",
      "Epoch [10/10], Phase: train, Batch: [99/131], Loss: 0.3569\n",
      "Epoch [10/10], Phase: train, Batch: [100/131], Loss: 0.3378\n",
      "Epoch [10/10], Phase: train, Batch: [101/131], Loss: 0.3359\n",
      "Epoch [10/10], Phase: train, Batch: [102/131], Loss: 0.3679\n",
      "Epoch [10/10], Phase: train, Batch: [103/131], Loss: 0.3186\n",
      "Epoch [10/10], Phase: train, Batch: [104/131], Loss: 0.2805\n",
      "Epoch [10/10], Phase: train, Batch: [105/131], Loss: 0.3491\n",
      "Epoch [10/10], Phase: train, Batch: [106/131], Loss: 0.3811\n",
      "Epoch [10/10], Phase: train, Batch: [107/131], Loss: 0.3610\n",
      "Epoch [10/10], Phase: train, Batch: [108/131], Loss: 0.3453\n",
      "Epoch [10/10], Phase: train, Batch: [109/131], Loss: 0.2655\n",
      "Epoch [10/10], Phase: train, Batch: [110/131], Loss: 0.4078\n",
      "Epoch [10/10], Phase: train, Batch: [111/131], Loss: 0.3178\n",
      "Epoch [10/10], Phase: train, Batch: [112/131], Loss: 0.3633\n",
      "Epoch [10/10], Phase: train, Batch: [113/131], Loss: 0.4150\n",
      "Epoch [10/10], Phase: train, Batch: [114/131], Loss: 0.3534\n",
      "Epoch [10/10], Phase: train, Batch: [115/131], Loss: 0.5857\n",
      "Epoch [10/10], Phase: train, Batch: [116/131], Loss: 0.3874\n",
      "Epoch [10/10], Phase: train, Batch: [117/131], Loss: 0.3050\n",
      "Epoch [10/10], Phase: train, Batch: [118/131], Loss: 0.2198\n",
      "Epoch [10/10], Phase: train, Batch: [119/131], Loss: 0.3936\n",
      "Epoch [10/10], Phase: train, Batch: [120/131], Loss: 0.2931\n",
      "Epoch [10/10], Phase: train, Batch: [121/131], Loss: 0.3185\n",
      "Epoch [10/10], Phase: train, Batch: [122/131], Loss: 0.3314\n",
      "Epoch [10/10], Phase: train, Batch: [123/131], Loss: 0.3851\n",
      "Epoch [10/10], Phase: train, Batch: [124/131], Loss: 0.3552\n",
      "Epoch [10/10], Phase: train, Batch: [125/131], Loss: 0.2988\n",
      "Epoch [10/10], Phase: train, Batch: [126/131], Loss: 0.3295\n",
      "Epoch [10/10], Phase: train, Batch: [127/131], Loss: 0.2283\n",
      "Epoch [10/10], Phase: train, Batch: [128/131], Loss: 0.2966\n",
      "Epoch [10/10], Phase: train, Batch: [129/131], Loss: 0.2572\n",
      "Epoch [10/10], Phase: train, Batch: [130/131], Loss: 0.2667\n",
      "Epoch [10/10], Phase: train, Batch: [131/131], Loss: 0.2706\n",
      "Train Loss: 0.3451 Acc: 0.8543\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloaders['train']):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Phase: train, Batch: [{batch_idx+1}/{len(dataloaders[\"train\"])}], Loss: {batch_loss:.4f}')\n",
    "\n",
    "    epoch_loss = running_loss / dataset_sizes['train']\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
    "    scheduler.step()\n",
    "\n",
    "    print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff961a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Batch: [1/44], Loss: 0.4852\n",
      "Validation Batch: [2/44], Loss: 0.3934\n",
      "Validation Batch: [3/44], Loss: 0.2545\n",
      "Validation Batch: [4/44], Loss: 0.2638\n",
      "Validation Batch: [5/44], Loss: 0.2341\n",
      "Validation Batch: [6/44], Loss: 0.2497\n",
      "Validation Batch: [7/44], Loss: 0.2504\n",
      "Validation Batch: [8/44], Loss: 0.2941\n",
      "Validation Batch: [9/44], Loss: 0.2970\n",
      "Validation Batch: [10/44], Loss: 0.3511\n",
      "Validation Batch: [11/44], Loss: 0.1656\n",
      "Validation Batch: [12/44], Loss: 0.2178\n",
      "Validation Batch: [13/44], Loss: 0.3902\n",
      "Validation Batch: [14/44], Loss: 0.2930\n",
      "Validation Batch: [15/44], Loss: 0.4157\n",
      "Validation Batch: [16/44], Loss: 0.2052\n",
      "Validation Batch: [17/44], Loss: 0.1751\n",
      "Validation Batch: [18/44], Loss: 0.2930\n",
      "Validation Batch: [19/44], Loss: 0.2530\n",
      "Validation Batch: [20/44], Loss: 0.2962\n",
      "Validation Batch: [21/44], Loss: 0.2320\n",
      "Validation Batch: [22/44], Loss: 0.2634\n",
      "Validation Batch: [23/44], Loss: 0.2314\n",
      "Validation Batch: [24/44], Loss: 0.2393\n",
      "Validation Batch: [25/44], Loss: 0.2293\n",
      "Validation Batch: [26/44], Loss: 0.2799\n",
      "Validation Batch: [27/44], Loss: 0.2919\n",
      "Validation Batch: [28/44], Loss: 0.1738\n",
      "Validation Batch: [29/44], Loss: 0.3304\n",
      "Validation Batch: [30/44], Loss: 0.3218\n",
      "Validation Batch: [31/44], Loss: 0.1321\n",
      "Validation Batch: [32/44], Loss: 0.3064\n",
      "Validation Batch: [33/44], Loss: 0.1359\n",
      "Validation Batch: [34/44], Loss: 0.2352\n",
      "Validation Batch: [35/44], Loss: 0.1976\n",
      "Validation Batch: [36/44], Loss: 0.2139\n",
      "Validation Batch: [37/44], Loss: 0.3062\n",
      "Validation Batch: [38/44], Loss: 0.1546\n",
      "Validation Batch: [39/44], Loss: 0.4315\n",
      "Validation Batch: [40/44], Loss: 0.1391\n",
      "Validation Batch: [41/44], Loss: 0.2978\n",
      "Validation Batch: [42/44], Loss: 1.1195\n",
      "Validation Batch: [43/44], Loss: 1.9106\n",
      "Validation Batch: [44/44], Loss: 0.7557\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "\n",
    "for batch_idx, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    batch_loss = loss.item()\n",
    "    print(f'Validation Batch: [{batch_idx+1}/{len(dataloaders[\"val\"])}], Loss: {batch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebe1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['male', 'female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82828fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1857  119]\n",
      " [ 220  558]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "classification_rep = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "005aa571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.89      0.94      0.92      1976\n",
      "      female       0.82      0.72      0.77       778\n",
      "\n",
      "    accuracy                           0.88      2754\n",
      "   macro avg       0.86      0.83      0.84      2754\n",
      "weighted avg       0.87      0.88      0.87      2754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9319fbab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cm_display \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix \u001b[38;5;241m=\u001b[39m conf_matrix, display_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFemale\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m cm_display\u001b[38;5;241m.\u001b[39mplot()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = ['Male', 'Female'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1f04388",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'vgg_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
