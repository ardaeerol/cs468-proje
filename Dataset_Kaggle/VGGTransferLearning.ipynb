{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb3cc07",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network  - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe92c4b",
   "metadata": {},
   "source": [
    "Dataset in use: https://www.kaggle.com/datasets/cashutosh/gender-classification-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7bba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640d1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./dataset/Training\"\n",
    "val_dir = \"./dataset/Validation\"\n",
    "input_size = (224, 224)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba002f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec86a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4e21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(root=train_dir, transform=transform['train']),\n",
    "    'val': datasets.ImageFolder(root=val_dir, transform=transform['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf15b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f79de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aerol\\env\\facenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aerol\\env\\facenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze Layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Custom Classifier\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1), # Dropout is applied with probability 0.1 to prevent overfitting\n",
    "    nn.Linear(256, 2)  # Output is 2 dimensional (male and female)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.013) # Adam Optimizer\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7af19a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175d0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4811a6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Phase: train, Batch: [1/730], Loss: 0.7068\n",
      "Epoch [1/3], Phase: train, Batch: [2/730], Loss: 4.2294\n",
      "Epoch [1/3], Phase: train, Batch: [3/730], Loss: 9.2497\n",
      "Epoch [1/3], Phase: train, Batch: [4/730], Loss: 4.7356\n",
      "Epoch [1/3], Phase: train, Batch: [5/730], Loss: 0.6188\n",
      "Epoch [1/3], Phase: train, Batch: [6/730], Loss: 2.7425\n",
      "Epoch [1/3], Phase: train, Batch: [7/730], Loss: 2.9531\n",
      "Epoch [1/3], Phase: train, Batch: [8/730], Loss: 1.0421\n",
      "Epoch [1/3], Phase: train, Batch: [9/730], Loss: 0.5554\n",
      "Epoch [1/3], Phase: train, Batch: [10/730], Loss: 0.5963\n",
      "Epoch [1/3], Phase: train, Batch: [11/730], Loss: 0.4012\n",
      "Epoch [1/3], Phase: train, Batch: [12/730], Loss: 0.6129\n",
      "Epoch [1/3], Phase: train, Batch: [13/730], Loss: 0.4655\n",
      "Epoch [1/3], Phase: train, Batch: [14/730], Loss: 0.4602\n",
      "Epoch [1/3], Phase: train, Batch: [15/730], Loss: 0.3687\n",
      "Epoch [1/3], Phase: train, Batch: [16/730], Loss: 0.3149\n",
      "Epoch [1/3], Phase: train, Batch: [17/730], Loss: 0.2650\n",
      "Epoch [1/3], Phase: train, Batch: [18/730], Loss: 0.3385\n",
      "Epoch [1/3], Phase: train, Batch: [19/730], Loss: 0.4764\n",
      "Epoch [1/3], Phase: train, Batch: [20/730], Loss: 0.3089\n",
      "Epoch [1/3], Phase: train, Batch: [21/730], Loss: 0.6918\n",
      "Epoch [1/3], Phase: train, Batch: [22/730], Loss: 0.4811\n",
      "Epoch [1/3], Phase: train, Batch: [23/730], Loss: 0.4107\n",
      "Epoch [1/3], Phase: train, Batch: [24/730], Loss: 0.3313\n",
      "Epoch [1/3], Phase: train, Batch: [25/730], Loss: 0.4459\n",
      "Epoch [1/3], Phase: train, Batch: [26/730], Loss: 0.3245\n",
      "Epoch [1/3], Phase: train, Batch: [27/730], Loss: 0.3992\n",
      "Epoch [1/3], Phase: train, Batch: [28/730], Loss: 0.2904\n",
      "Epoch [1/3], Phase: train, Batch: [29/730], Loss: 0.3629\n",
      "Epoch [1/3], Phase: train, Batch: [30/730], Loss: 0.2979\n",
      "Epoch [1/3], Phase: train, Batch: [31/730], Loss: 0.3022\n",
      "Epoch [1/3], Phase: train, Batch: [32/730], Loss: 0.2440\n",
      "Epoch [1/3], Phase: train, Batch: [33/730], Loss: 0.3544\n",
      "Epoch [1/3], Phase: train, Batch: [34/730], Loss: 0.3389\n",
      "Epoch [1/3], Phase: train, Batch: [35/730], Loss: 0.3275\n",
      "Epoch [1/3], Phase: train, Batch: [36/730], Loss: 0.4077\n",
      "Epoch [1/3], Phase: train, Batch: [37/730], Loss: 0.2970\n",
      "Epoch [1/3], Phase: train, Batch: [38/730], Loss: 0.3543\n",
      "Epoch [1/3], Phase: train, Batch: [39/730], Loss: 0.4094\n",
      "Epoch [1/3], Phase: train, Batch: [40/730], Loss: 0.3704\n",
      "Epoch [1/3], Phase: train, Batch: [41/730], Loss: 0.1879\n",
      "Epoch [1/3], Phase: train, Batch: [42/730], Loss: 0.2416\n",
      "Epoch [1/3], Phase: train, Batch: [43/730], Loss: 0.4864\n",
      "Epoch [1/3], Phase: train, Batch: [44/730], Loss: 0.3485\n",
      "Epoch [1/3], Phase: train, Batch: [45/730], Loss: 0.3274\n",
      "Epoch [1/3], Phase: train, Batch: [46/730], Loss: 0.3794\n",
      "Epoch [1/3], Phase: train, Batch: [47/730], Loss: 0.2642\n",
      "Epoch [1/3], Phase: train, Batch: [48/730], Loss: 0.3082\n",
      "Epoch [1/3], Phase: train, Batch: [49/730], Loss: 0.3838\n",
      "Epoch [1/3], Phase: train, Batch: [50/730], Loss: 0.3165\n",
      "Epoch [1/3], Phase: train, Batch: [51/730], Loss: 0.3846\n",
      "Epoch [1/3], Phase: train, Batch: [52/730], Loss: 0.3263\n",
      "Epoch [1/3], Phase: train, Batch: [53/730], Loss: 0.1935\n",
      "Epoch [1/3], Phase: train, Batch: [54/730], Loss: 0.2359\n",
      "Epoch [1/3], Phase: train, Batch: [55/730], Loss: 0.3386\n",
      "Epoch [1/3], Phase: train, Batch: [56/730], Loss: 0.3395\n",
      "Epoch [1/3], Phase: train, Batch: [57/730], Loss: 0.3852\n",
      "Epoch [1/3], Phase: train, Batch: [58/730], Loss: 0.4819\n",
      "Epoch [1/3], Phase: train, Batch: [59/730], Loss: 0.3078\n",
      "Epoch [1/3], Phase: train, Batch: [60/730], Loss: 0.2808\n",
      "Epoch [1/3], Phase: train, Batch: [61/730], Loss: 0.4379\n",
      "Epoch [1/3], Phase: train, Batch: [62/730], Loss: 0.2922\n",
      "Epoch [1/3], Phase: train, Batch: [63/730], Loss: 0.2853\n",
      "Epoch [1/3], Phase: train, Batch: [64/730], Loss: 0.2456\n",
      "Epoch [1/3], Phase: train, Batch: [65/730], Loss: 0.4241\n",
      "Epoch [1/3], Phase: train, Batch: [66/730], Loss: 0.4544\n",
      "Epoch [1/3], Phase: train, Batch: [67/730], Loss: 0.4008\n",
      "Epoch [1/3], Phase: train, Batch: [68/730], Loss: 0.2729\n",
      "Epoch [1/3], Phase: train, Batch: [69/730], Loss: 0.4550\n",
      "Epoch [1/3], Phase: train, Batch: [70/730], Loss: 0.3981\n",
      "Epoch [1/3], Phase: train, Batch: [71/730], Loss: 0.2891\n",
      "Epoch [1/3], Phase: train, Batch: [72/730], Loss: 0.2674\n",
      "Epoch [1/3], Phase: train, Batch: [73/730], Loss: 0.3321\n",
      "Epoch [1/3], Phase: train, Batch: [74/730], Loss: 0.3994\n",
      "Epoch [1/3], Phase: train, Batch: [75/730], Loss: 0.2937\n",
      "Epoch [1/3], Phase: train, Batch: [76/730], Loss: 0.2912\n",
      "Epoch [1/3], Phase: train, Batch: [77/730], Loss: 0.3382\n",
      "Epoch [1/3], Phase: train, Batch: [78/730], Loss: 0.3758\n",
      "Epoch [1/3], Phase: train, Batch: [79/730], Loss: 0.3356\n",
      "Epoch [1/3], Phase: train, Batch: [80/730], Loss: 0.3056\n",
      "Epoch [1/3], Phase: train, Batch: [81/730], Loss: 0.2759\n",
      "Epoch [1/3], Phase: train, Batch: [82/730], Loss: 0.2153\n",
      "Epoch [1/3], Phase: train, Batch: [83/730], Loss: 0.4226\n",
      "Epoch [1/3], Phase: train, Batch: [84/730], Loss: 0.2693\n",
      "Epoch [1/3], Phase: train, Batch: [85/730], Loss: 0.2299\n",
      "Epoch [1/3], Phase: train, Batch: [86/730], Loss: 0.3038\n",
      "Epoch [1/3], Phase: train, Batch: [87/730], Loss: 0.3924\n",
      "Epoch [1/3], Phase: train, Batch: [88/730], Loss: 0.4085\n",
      "Epoch [1/3], Phase: train, Batch: [89/730], Loss: 0.2792\n",
      "Epoch [1/3], Phase: train, Batch: [90/730], Loss: 0.2953\n",
      "Epoch [1/3], Phase: train, Batch: [91/730], Loss: 0.2961\n",
      "Epoch [1/3], Phase: train, Batch: [92/730], Loss: 0.3314\n",
      "Epoch [1/3], Phase: train, Batch: [93/730], Loss: 0.3622\n",
      "Epoch [1/3], Phase: train, Batch: [94/730], Loss: 0.3106\n",
      "Epoch [1/3], Phase: train, Batch: [95/730], Loss: 0.3352\n",
      "Epoch [1/3], Phase: train, Batch: [96/730], Loss: 0.3851\n",
      "Epoch [1/3], Phase: train, Batch: [97/730], Loss: 0.3309\n",
      "Epoch [1/3], Phase: train, Batch: [98/730], Loss: 0.3547\n",
      "Epoch [1/3], Phase: train, Batch: [99/730], Loss: 0.2643\n",
      "Epoch [1/3], Phase: train, Batch: [100/730], Loss: 0.2981\n",
      "Epoch [1/3], Phase: train, Batch: [101/730], Loss: 0.4706\n",
      "Epoch [1/3], Phase: train, Batch: [102/730], Loss: 0.2807\n",
      "Epoch [1/3], Phase: train, Batch: [103/730], Loss: 0.3586\n",
      "Epoch [1/3], Phase: train, Batch: [104/730], Loss: 0.3192\n",
      "Epoch [1/3], Phase: train, Batch: [105/730], Loss: 0.3035\n",
      "Epoch [1/3], Phase: train, Batch: [106/730], Loss: 0.4036\n",
      "Epoch [1/3], Phase: train, Batch: [107/730], Loss: 0.3492\n",
      "Epoch [1/3], Phase: train, Batch: [108/730], Loss: 0.4095\n",
      "Epoch [1/3], Phase: train, Batch: [109/730], Loss: 0.3888\n",
      "Epoch [1/3], Phase: train, Batch: [110/730], Loss: 0.4452\n",
      "Epoch [1/3], Phase: train, Batch: [111/730], Loss: 0.2569\n",
      "Epoch [1/3], Phase: train, Batch: [112/730], Loss: 0.2610\n",
      "Epoch [1/3], Phase: train, Batch: [113/730], Loss: 0.3869\n",
      "Epoch [1/3], Phase: train, Batch: [114/730], Loss: 0.3431\n",
      "Epoch [1/3], Phase: train, Batch: [115/730], Loss: 0.3229\n",
      "Epoch [1/3], Phase: train, Batch: [116/730], Loss: 0.4867\n",
      "Epoch [1/3], Phase: train, Batch: [117/730], Loss: 0.3636\n",
      "Epoch [1/3], Phase: train, Batch: [118/730], Loss: 0.3301\n",
      "Epoch [1/3], Phase: train, Batch: [119/730], Loss: 0.2001\n",
      "Epoch [1/3], Phase: train, Batch: [120/730], Loss: 0.3572\n",
      "Epoch [1/3], Phase: train, Batch: [121/730], Loss: 0.3193\n",
      "Epoch [1/3], Phase: train, Batch: [122/730], Loss: 0.2796\n",
      "Epoch [1/3], Phase: train, Batch: [123/730], Loss: 0.1787\n",
      "Epoch [1/3], Phase: train, Batch: [124/730], Loss: 0.2406\n",
      "Epoch [1/3], Phase: train, Batch: [125/730], Loss: 0.2297\n",
      "Epoch [1/3], Phase: train, Batch: [126/730], Loss: 0.4173\n",
      "Epoch [1/3], Phase: train, Batch: [127/730], Loss: 0.1927\n",
      "Epoch [1/3], Phase: train, Batch: [128/730], Loss: 0.1597\n",
      "Epoch [1/3], Phase: train, Batch: [129/730], Loss: 0.2897\n",
      "Epoch [1/3], Phase: train, Batch: [130/730], Loss: 0.1786\n",
      "Epoch [1/3], Phase: train, Batch: [131/730], Loss: 0.4334\n",
      "Epoch [1/3], Phase: train, Batch: [132/730], Loss: 0.5360\n",
      "Epoch [1/3], Phase: train, Batch: [133/730], Loss: 0.2972\n",
      "Epoch [1/3], Phase: train, Batch: [134/730], Loss: 0.2366\n",
      "Epoch [1/3], Phase: train, Batch: [135/730], Loss: 0.2733\n",
      "Epoch [1/3], Phase: train, Batch: [136/730], Loss: 0.2601\n",
      "Epoch [1/3], Phase: train, Batch: [137/730], Loss: 0.4173\n",
      "Epoch [1/3], Phase: train, Batch: [138/730], Loss: 0.2929\n",
      "Epoch [1/3], Phase: train, Batch: [139/730], Loss: 0.3722\n",
      "Epoch [1/3], Phase: train, Batch: [140/730], Loss: 0.3623\n",
      "Epoch [1/3], Phase: train, Batch: [141/730], Loss: 0.3159\n",
      "Epoch [1/3], Phase: train, Batch: [142/730], Loss: 0.2612\n",
      "Epoch [1/3], Phase: train, Batch: [143/730], Loss: 0.2875\n",
      "Epoch [1/3], Phase: train, Batch: [144/730], Loss: 0.3854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Phase: train, Batch: [145/730], Loss: 0.3426\n",
      "Epoch [1/3], Phase: train, Batch: [146/730], Loss: 0.3488\n",
      "Epoch [1/3], Phase: train, Batch: [147/730], Loss: 0.4372\n",
      "Epoch [1/3], Phase: train, Batch: [148/730], Loss: 0.2193\n",
      "Epoch [1/3], Phase: train, Batch: [149/730], Loss: 0.3515\n",
      "Epoch [1/3], Phase: train, Batch: [150/730], Loss: 0.2693\n",
      "Epoch [1/3], Phase: train, Batch: [151/730], Loss: 0.3653\n",
      "Epoch [1/3], Phase: train, Batch: [152/730], Loss: 0.1947\n",
      "Epoch [1/3], Phase: train, Batch: [153/730], Loss: 0.2810\n",
      "Epoch [1/3], Phase: train, Batch: [154/730], Loss: 0.2406\n",
      "Epoch [1/3], Phase: train, Batch: [155/730], Loss: 0.2733\n",
      "Epoch [1/3], Phase: train, Batch: [156/730], Loss: 0.2209\n",
      "Epoch [1/3], Phase: train, Batch: [157/730], Loss: 0.3785\n",
      "Epoch [1/3], Phase: train, Batch: [158/730], Loss: 0.3904\n",
      "Epoch [1/3], Phase: train, Batch: [159/730], Loss: 0.4399\n",
      "Epoch [1/3], Phase: train, Batch: [160/730], Loss: 0.4562\n",
      "Epoch [1/3], Phase: train, Batch: [161/730], Loss: 0.3352\n",
      "Epoch [1/3], Phase: train, Batch: [162/730], Loss: 0.1952\n",
      "Epoch [1/3], Phase: train, Batch: [163/730], Loss: 0.4139\n",
      "Epoch [1/3], Phase: train, Batch: [164/730], Loss: 0.2630\n",
      "Epoch [1/3], Phase: train, Batch: [165/730], Loss: 0.4395\n",
      "Epoch [1/3], Phase: train, Batch: [166/730], Loss: 0.3185\n",
      "Epoch [1/3], Phase: train, Batch: [167/730], Loss: 0.2426\n",
      "Epoch [1/3], Phase: train, Batch: [168/730], Loss: 0.1898\n",
      "Epoch [1/3], Phase: train, Batch: [169/730], Loss: 0.3025\n",
      "Epoch [1/3], Phase: train, Batch: [170/730], Loss: 0.4021\n",
      "Epoch [1/3], Phase: train, Batch: [171/730], Loss: 0.4487\n",
      "Epoch [1/3], Phase: train, Batch: [172/730], Loss: 0.2476\n",
      "Epoch [1/3], Phase: train, Batch: [173/730], Loss: 0.2328\n",
      "Epoch [1/3], Phase: train, Batch: [174/730], Loss: 0.1814\n",
      "Epoch [1/3], Phase: train, Batch: [175/730], Loss: 0.2975\n",
      "Epoch [1/3], Phase: train, Batch: [176/730], Loss: 0.1738\n",
      "Epoch [1/3], Phase: train, Batch: [177/730], Loss: 0.2199\n",
      "Epoch [1/3], Phase: train, Batch: [178/730], Loss: 0.3059\n",
      "Epoch [1/3], Phase: train, Batch: [179/730], Loss: 0.3251\n",
      "Epoch [1/3], Phase: train, Batch: [180/730], Loss: 0.2745\n",
      "Epoch [1/3], Phase: train, Batch: [181/730], Loss: 0.3399\n",
      "Epoch [1/3], Phase: train, Batch: [182/730], Loss: 0.3804\n",
      "Epoch [1/3], Phase: train, Batch: [183/730], Loss: 0.1924\n",
      "Epoch [1/3], Phase: train, Batch: [184/730], Loss: 0.4524\n",
      "Epoch [1/3], Phase: train, Batch: [185/730], Loss: 0.3538\n",
      "Epoch [1/3], Phase: train, Batch: [186/730], Loss: 0.3561\n",
      "Epoch [1/3], Phase: train, Batch: [187/730], Loss: 0.3412\n",
      "Epoch [1/3], Phase: train, Batch: [188/730], Loss: 0.4451\n",
      "Epoch [1/3], Phase: train, Batch: [189/730], Loss: 0.2590\n",
      "Epoch [1/3], Phase: train, Batch: [190/730], Loss: 0.2944\n",
      "Epoch [1/3], Phase: train, Batch: [191/730], Loss: 0.2116\n",
      "Epoch [1/3], Phase: train, Batch: [192/730], Loss: 0.3254\n",
      "Epoch [1/3], Phase: train, Batch: [193/730], Loss: 0.4384\n",
      "Epoch [1/3], Phase: train, Batch: [194/730], Loss: 0.3904\n",
      "Epoch [1/3], Phase: train, Batch: [195/730], Loss: 0.2879\n",
      "Epoch [1/3], Phase: train, Batch: [196/730], Loss: 0.3298\n",
      "Epoch [1/3], Phase: train, Batch: [197/730], Loss: 0.3292\n",
      "Epoch [1/3], Phase: train, Batch: [198/730], Loss: 0.2192\n",
      "Epoch [1/3], Phase: train, Batch: [199/730], Loss: 0.3413\n",
      "Epoch [1/3], Phase: train, Batch: [200/730], Loss: 0.2530\n",
      "Epoch [1/3], Phase: train, Batch: [201/730], Loss: 0.4006\n",
      "Epoch [1/3], Phase: train, Batch: [202/730], Loss: 0.2243\n",
      "Epoch [1/3], Phase: train, Batch: [203/730], Loss: 0.1559\n",
      "Epoch [1/3], Phase: train, Batch: [204/730], Loss: 0.1288\n",
      "Epoch [1/3], Phase: train, Batch: [205/730], Loss: 0.2596\n",
      "Epoch [1/3], Phase: train, Batch: [206/730], Loss: 0.2770\n",
      "Epoch [1/3], Phase: train, Batch: [207/730], Loss: 0.1767\n",
      "Epoch [1/3], Phase: train, Batch: [208/730], Loss: 0.4071\n",
      "Epoch [1/3], Phase: train, Batch: [209/730], Loss: 0.1268\n",
      "Epoch [1/3], Phase: train, Batch: [210/730], Loss: 0.2259\n",
      "Epoch [1/3], Phase: train, Batch: [211/730], Loss: 0.3734\n",
      "Epoch [1/3], Phase: train, Batch: [212/730], Loss: 0.2349\n",
      "Epoch [1/3], Phase: train, Batch: [213/730], Loss: 0.2707\n",
      "Epoch [1/3], Phase: train, Batch: [214/730], Loss: 0.3883\n",
      "Epoch [1/3], Phase: train, Batch: [215/730], Loss: 0.3894\n",
      "Epoch [1/3], Phase: train, Batch: [216/730], Loss: 0.2341\n",
      "Epoch [1/3], Phase: train, Batch: [217/730], Loss: 0.3180\n",
      "Epoch [1/3], Phase: train, Batch: [218/730], Loss: 0.2988\n",
      "Epoch [1/3], Phase: train, Batch: [219/730], Loss: 0.3066\n",
      "Epoch [1/3], Phase: train, Batch: [220/730], Loss: 0.3239\n",
      "Epoch [1/3], Phase: train, Batch: [221/730], Loss: 0.2324\n",
      "Epoch [1/3], Phase: train, Batch: [222/730], Loss: 0.4034\n",
      "Epoch [1/3], Phase: train, Batch: [223/730], Loss: 0.3486\n",
      "Epoch [1/3], Phase: train, Batch: [224/730], Loss: 0.4523\n",
      "Epoch [1/3], Phase: train, Batch: [225/730], Loss: 0.2955\n",
      "Epoch [1/3], Phase: train, Batch: [226/730], Loss: 0.3510\n",
      "Epoch [1/3], Phase: train, Batch: [227/730], Loss: 0.2786\n",
      "Epoch [1/3], Phase: train, Batch: [228/730], Loss: 0.3417\n",
      "Epoch [1/3], Phase: train, Batch: [229/730], Loss: 0.2489\n",
      "Epoch [1/3], Phase: train, Batch: [230/730], Loss: 0.3501\n",
      "Epoch [1/3], Phase: train, Batch: [231/730], Loss: 0.2631\n",
      "Epoch [1/3], Phase: train, Batch: [232/730], Loss: 0.2869\n",
      "Epoch [1/3], Phase: train, Batch: [233/730], Loss: 0.3670\n",
      "Epoch [1/3], Phase: train, Batch: [234/730], Loss: 0.3160\n",
      "Epoch [1/3], Phase: train, Batch: [235/730], Loss: 0.3350\n",
      "Epoch [1/3], Phase: train, Batch: [236/730], Loss: 0.3452\n",
      "Epoch [1/3], Phase: train, Batch: [237/730], Loss: 0.2111\n",
      "Epoch [1/3], Phase: train, Batch: [238/730], Loss: 0.2580\n",
      "Epoch [1/3], Phase: train, Batch: [239/730], Loss: 0.2556\n",
      "Epoch [1/3], Phase: train, Batch: [240/730], Loss: 0.3560\n",
      "Epoch [1/3], Phase: train, Batch: [241/730], Loss: 0.3528\n",
      "Epoch [1/3], Phase: train, Batch: [242/730], Loss: 0.4027\n",
      "Epoch [1/3], Phase: train, Batch: [243/730], Loss: 0.3359\n",
      "Epoch [1/3], Phase: train, Batch: [244/730], Loss: 0.2428\n",
      "Epoch [1/3], Phase: train, Batch: [245/730], Loss: 0.2530\n",
      "Epoch [1/3], Phase: train, Batch: [246/730], Loss: 0.3808\n",
      "Epoch [1/3], Phase: train, Batch: [247/730], Loss: 0.2807\n",
      "Epoch [1/3], Phase: train, Batch: [248/730], Loss: 0.2628\n",
      "Epoch [1/3], Phase: train, Batch: [249/730], Loss: 0.5126\n",
      "Epoch [1/3], Phase: train, Batch: [250/730], Loss: 0.3637\n",
      "Epoch [1/3], Phase: train, Batch: [251/730], Loss: 0.3825\n",
      "Epoch [1/3], Phase: train, Batch: [252/730], Loss: 0.3196\n",
      "Epoch [1/3], Phase: train, Batch: [253/730], Loss: 0.2404\n",
      "Epoch [1/3], Phase: train, Batch: [254/730], Loss: 0.4071\n",
      "Epoch [1/3], Phase: train, Batch: [255/730], Loss: 0.3565\n",
      "Epoch [1/3], Phase: train, Batch: [256/730], Loss: 0.3968\n",
      "Epoch [1/3], Phase: train, Batch: [257/730], Loss: 0.3913\n",
      "Epoch [1/3], Phase: train, Batch: [258/730], Loss: 0.2696\n",
      "Epoch [1/3], Phase: train, Batch: [259/730], Loss: 0.2720\n",
      "Epoch [1/3], Phase: train, Batch: [260/730], Loss: 0.1973\n",
      "Epoch [1/3], Phase: train, Batch: [261/730], Loss: 0.3660\n",
      "Epoch [1/3], Phase: train, Batch: [262/730], Loss: 0.2446\n",
      "Epoch [1/3], Phase: train, Batch: [263/730], Loss: 0.3237\n",
      "Epoch [1/3], Phase: train, Batch: [264/730], Loss: 0.3780\n",
      "Epoch [1/3], Phase: train, Batch: [265/730], Loss: 0.2856\n",
      "Epoch [1/3], Phase: train, Batch: [266/730], Loss: 0.3026\n",
      "Epoch [1/3], Phase: train, Batch: [267/730], Loss: 0.4501\n",
      "Epoch [1/3], Phase: train, Batch: [268/730], Loss: 0.2643\n",
      "Epoch [1/3], Phase: train, Batch: [269/730], Loss: 0.3329\n",
      "Epoch [1/3], Phase: train, Batch: [270/730], Loss: 0.3529\n",
      "Epoch [1/3], Phase: train, Batch: [271/730], Loss: 0.2286\n",
      "Epoch [1/3], Phase: train, Batch: [272/730], Loss: 0.3199\n",
      "Epoch [1/3], Phase: train, Batch: [273/730], Loss: 0.3249\n",
      "Epoch [1/3], Phase: train, Batch: [274/730], Loss: 0.3157\n",
      "Epoch [1/3], Phase: train, Batch: [275/730], Loss: 0.4085\n",
      "Epoch [1/3], Phase: train, Batch: [276/730], Loss: 0.3295\n",
      "Epoch [1/3], Phase: train, Batch: [277/730], Loss: 0.3481\n",
      "Epoch [1/3], Phase: train, Batch: [278/730], Loss: 0.3331\n",
      "Epoch [1/3], Phase: train, Batch: [279/730], Loss: 0.2970\n",
      "Epoch [1/3], Phase: train, Batch: [280/730], Loss: 0.3842\n",
      "Epoch [1/3], Phase: train, Batch: [281/730], Loss: 0.3556\n",
      "Epoch [1/3], Phase: train, Batch: [282/730], Loss: 0.3232\n",
      "Epoch [1/3], Phase: train, Batch: [283/730], Loss: 0.3184\n",
      "Epoch [1/3], Phase: train, Batch: [284/730], Loss: 0.3508\n",
      "Epoch [1/3], Phase: train, Batch: [285/730], Loss: 0.3348\n",
      "Epoch [1/3], Phase: train, Batch: [286/730], Loss: 0.2584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Phase: train, Batch: [287/730], Loss: 0.2360\n",
      "Epoch [1/3], Phase: train, Batch: [288/730], Loss: 0.3738\n",
      "Epoch [1/3], Phase: train, Batch: [289/730], Loss: 0.3671\n",
      "Epoch [1/3], Phase: train, Batch: [290/730], Loss: 0.1933\n",
      "Epoch [1/3], Phase: train, Batch: [291/730], Loss: 0.2732\n",
      "Epoch [1/3], Phase: train, Batch: [292/730], Loss: 0.2816\n",
      "Epoch [1/3], Phase: train, Batch: [293/730], Loss: 0.3587\n",
      "Epoch [1/3], Phase: train, Batch: [294/730], Loss: 0.2055\n",
      "Epoch [1/3], Phase: train, Batch: [295/730], Loss: 0.3202\n",
      "Epoch [1/3], Phase: train, Batch: [296/730], Loss: 0.3437\n",
      "Epoch [1/3], Phase: train, Batch: [297/730], Loss: 0.3512\n",
      "Epoch [1/3], Phase: train, Batch: [298/730], Loss: 0.3548\n",
      "Epoch [1/3], Phase: train, Batch: [299/730], Loss: 0.4298\n",
      "Epoch [1/3], Phase: train, Batch: [300/730], Loss: 0.2174\n",
      "Epoch [1/3], Phase: train, Batch: [301/730], Loss: 0.1949\n",
      "Epoch [1/3], Phase: train, Batch: [302/730], Loss: 0.3315\n",
      "Epoch [1/3], Phase: train, Batch: [303/730], Loss: 0.5304\n",
      "Epoch [1/3], Phase: train, Batch: [304/730], Loss: 0.3200\n",
      "Epoch [1/3], Phase: train, Batch: [305/730], Loss: 0.2485\n",
      "Epoch [1/3], Phase: train, Batch: [306/730], Loss: 0.4087\n",
      "Epoch [1/3], Phase: train, Batch: [307/730], Loss: 0.3102\n",
      "Epoch [1/3], Phase: train, Batch: [308/730], Loss: 0.3343\n",
      "Epoch [1/3], Phase: train, Batch: [309/730], Loss: 0.3176\n",
      "Epoch [1/3], Phase: train, Batch: [310/730], Loss: 0.3177\n",
      "Epoch [1/3], Phase: train, Batch: [311/730], Loss: 0.3255\n",
      "Epoch [1/3], Phase: train, Batch: [312/730], Loss: 0.2614\n",
      "Epoch [1/3], Phase: train, Batch: [313/730], Loss: 0.3991\n",
      "Epoch [1/3], Phase: train, Batch: [314/730], Loss: 0.3224\n",
      "Epoch [1/3], Phase: train, Batch: [315/730], Loss: 0.2611\n",
      "Epoch [1/3], Phase: train, Batch: [316/730], Loss: 0.4142\n",
      "Epoch [1/3], Phase: train, Batch: [317/730], Loss: 0.2927\n",
      "Epoch [1/3], Phase: train, Batch: [318/730], Loss: 0.2083\n",
      "Epoch [1/3], Phase: train, Batch: [319/730], Loss: 0.2215\n",
      "Epoch [1/3], Phase: train, Batch: [320/730], Loss: 0.2113\n",
      "Epoch [1/3], Phase: train, Batch: [321/730], Loss: 0.2176\n",
      "Epoch [1/3], Phase: train, Batch: [322/730], Loss: 0.2168\n",
      "Epoch [1/3], Phase: train, Batch: [323/730], Loss: 0.1710\n",
      "Epoch [1/3], Phase: train, Batch: [324/730], Loss: 0.4415\n",
      "Epoch [1/3], Phase: train, Batch: [325/730], Loss: 0.4438\n",
      "Epoch [1/3], Phase: train, Batch: [326/730], Loss: 0.1425\n",
      "Epoch [1/3], Phase: train, Batch: [327/730], Loss: 0.3725\n",
      "Epoch [1/3], Phase: train, Batch: [328/730], Loss: 0.2047\n",
      "Epoch [1/3], Phase: train, Batch: [329/730], Loss: 0.3143\n",
      "Epoch [1/3], Phase: train, Batch: [330/730], Loss: 0.2572\n",
      "Epoch [1/3], Phase: train, Batch: [331/730], Loss: 0.2058\n",
      "Epoch [1/3], Phase: train, Batch: [332/730], Loss: 0.3328\n",
      "Epoch [1/3], Phase: train, Batch: [333/730], Loss: 0.2007\n",
      "Epoch [1/3], Phase: train, Batch: [334/730], Loss: 0.3600\n",
      "Epoch [1/3], Phase: train, Batch: [335/730], Loss: 0.3069\n",
      "Epoch [1/3], Phase: train, Batch: [336/730], Loss: 0.2803\n",
      "Epoch [1/3], Phase: train, Batch: [337/730], Loss: 0.2907\n",
      "Epoch [1/3], Phase: train, Batch: [338/730], Loss: 0.3212\n",
      "Epoch [1/3], Phase: train, Batch: [339/730], Loss: 0.2755\n",
      "Epoch [1/3], Phase: train, Batch: [340/730], Loss: 0.3554\n",
      "Epoch [1/3], Phase: train, Batch: [341/730], Loss: 0.2386\n",
      "Epoch [1/3], Phase: train, Batch: [342/730], Loss: 0.3515\n",
      "Epoch [1/3], Phase: train, Batch: [343/730], Loss: 0.4689\n",
      "Epoch [1/3], Phase: train, Batch: [344/730], Loss: 0.2636\n",
      "Epoch [1/3], Phase: train, Batch: [345/730], Loss: 0.2974\n",
      "Epoch [1/3], Phase: train, Batch: [346/730], Loss: 0.3546\n",
      "Epoch [1/3], Phase: train, Batch: [347/730], Loss: 0.2157\n",
      "Epoch [1/3], Phase: train, Batch: [348/730], Loss: 0.3322\n",
      "Epoch [1/3], Phase: train, Batch: [349/730], Loss: 0.2825\n",
      "Epoch [1/3], Phase: train, Batch: [350/730], Loss: 0.3983\n",
      "Epoch [1/3], Phase: train, Batch: [351/730], Loss: 0.4478\n",
      "Epoch [1/3], Phase: train, Batch: [352/730], Loss: 0.2836\n",
      "Epoch [1/3], Phase: train, Batch: [353/730], Loss: 0.4036\n",
      "Epoch [1/3], Phase: train, Batch: [354/730], Loss: 0.2692\n",
      "Epoch [1/3], Phase: train, Batch: [355/730], Loss: 0.1552\n",
      "Epoch [1/3], Phase: train, Batch: [356/730], Loss: 0.5636\n",
      "Epoch [1/3], Phase: train, Batch: [357/730], Loss: 0.2405\n",
      "Epoch [1/3], Phase: train, Batch: [358/730], Loss: 0.3888\n",
      "Epoch [1/3], Phase: train, Batch: [359/730], Loss: 0.3243\n",
      "Epoch [1/3], Phase: train, Batch: [360/730], Loss: 0.3608\n",
      "Epoch [1/3], Phase: train, Batch: [361/730], Loss: 0.2474\n",
      "Epoch [1/3], Phase: train, Batch: [362/730], Loss: 0.2808\n",
      "Epoch [1/3], Phase: train, Batch: [363/730], Loss: 0.4564\n",
      "Epoch [1/3], Phase: train, Batch: [364/730], Loss: 0.2926\n",
      "Epoch [1/3], Phase: train, Batch: [365/730], Loss: 0.3193\n",
      "Epoch [1/3], Phase: train, Batch: [366/730], Loss: 0.3516\n",
      "Epoch [1/3], Phase: train, Batch: [367/730], Loss: 0.2568\n",
      "Epoch [1/3], Phase: train, Batch: [368/730], Loss: 0.2262\n",
      "Epoch [1/3], Phase: train, Batch: [369/730], Loss: 0.3906\n",
      "Epoch [1/3], Phase: train, Batch: [370/730], Loss: 0.3966\n",
      "Epoch [1/3], Phase: train, Batch: [371/730], Loss: 0.3670\n",
      "Epoch [1/3], Phase: train, Batch: [372/730], Loss: 0.3111\n",
      "Epoch [1/3], Phase: train, Batch: [373/730], Loss: 0.2400\n",
      "Epoch [1/3], Phase: train, Batch: [374/730], Loss: 0.2958\n",
      "Epoch [1/3], Phase: train, Batch: [375/730], Loss: 0.2566\n",
      "Epoch [1/3], Phase: train, Batch: [376/730], Loss: 0.3400\n",
      "Epoch [1/3], Phase: train, Batch: [377/730], Loss: 0.4045\n",
      "Epoch [1/3], Phase: train, Batch: [378/730], Loss: 0.3912\n",
      "Epoch [1/3], Phase: train, Batch: [379/730], Loss: 0.2427\n",
      "Epoch [1/3], Phase: train, Batch: [380/730], Loss: 0.4250\n",
      "Epoch [1/3], Phase: train, Batch: [381/730], Loss: 0.1915\n",
      "Epoch [1/3], Phase: train, Batch: [382/730], Loss: 0.2365\n",
      "Epoch [1/3], Phase: train, Batch: [383/730], Loss: 0.3588\n",
      "Epoch [1/3], Phase: train, Batch: [384/730], Loss: 0.3847\n",
      "Epoch [1/3], Phase: train, Batch: [385/730], Loss: 0.2291\n",
      "Epoch [1/3], Phase: train, Batch: [386/730], Loss: 0.2905\n",
      "Epoch [1/3], Phase: train, Batch: [387/730], Loss: 0.3005\n",
      "Epoch [1/3], Phase: train, Batch: [388/730], Loss: 0.2422\n",
      "Epoch [1/3], Phase: train, Batch: [389/730], Loss: 0.3143\n",
      "Epoch [1/3], Phase: train, Batch: [390/730], Loss: 0.2764\n",
      "Epoch [1/3], Phase: train, Batch: [391/730], Loss: 0.3521\n",
      "Epoch [1/3], Phase: train, Batch: [392/730], Loss: 0.2507\n",
      "Epoch [1/3], Phase: train, Batch: [393/730], Loss: 0.3807\n",
      "Epoch [1/3], Phase: train, Batch: [394/730], Loss: 0.3493\n",
      "Epoch [1/3], Phase: train, Batch: [395/730], Loss: 0.2372\n",
      "Epoch [1/3], Phase: train, Batch: [396/730], Loss: 0.3942\n",
      "Epoch [1/3], Phase: train, Batch: [397/730], Loss: 0.1770\n",
      "Epoch [1/3], Phase: train, Batch: [398/730], Loss: 0.3081\n",
      "Epoch [1/3], Phase: train, Batch: [399/730], Loss: 0.3887\n",
      "Epoch [1/3], Phase: train, Batch: [400/730], Loss: 0.2952\n",
      "Epoch [1/3], Phase: train, Batch: [401/730], Loss: 0.3795\n",
      "Epoch [1/3], Phase: train, Batch: [402/730], Loss: 0.2970\n",
      "Epoch [1/3], Phase: train, Batch: [403/730], Loss: 0.3435\n",
      "Epoch [1/3], Phase: train, Batch: [404/730], Loss: 0.4318\n",
      "Epoch [1/3], Phase: train, Batch: [405/730], Loss: 0.3881\n",
      "Epoch [1/3], Phase: train, Batch: [406/730], Loss: 0.2395\n",
      "Epoch [1/3], Phase: train, Batch: [407/730], Loss: 0.3012\n",
      "Epoch [1/3], Phase: train, Batch: [408/730], Loss: 0.2915\n",
      "Epoch [1/3], Phase: train, Batch: [409/730], Loss: 0.3476\n",
      "Epoch [1/3], Phase: train, Batch: [410/730], Loss: 0.2866\n",
      "Epoch [1/3], Phase: train, Batch: [411/730], Loss: 0.2654\n",
      "Epoch [1/3], Phase: train, Batch: [412/730], Loss: 0.6059\n",
      "Epoch [1/3], Phase: train, Batch: [413/730], Loss: 0.2598\n",
      "Epoch [1/3], Phase: train, Batch: [414/730], Loss: 0.1956\n",
      "Epoch [1/3], Phase: train, Batch: [415/730], Loss: 0.2814\n",
      "Epoch [1/3], Phase: train, Batch: [416/730], Loss: 0.3373\n",
      "Epoch [1/3], Phase: train, Batch: [417/730], Loss: 0.3879\n",
      "Epoch [1/3], Phase: train, Batch: [418/730], Loss: 0.4210\n",
      "Epoch [1/3], Phase: train, Batch: [419/730], Loss: 0.4315\n",
      "Epoch [1/3], Phase: train, Batch: [420/730], Loss: 0.2712\n",
      "Epoch [1/3], Phase: train, Batch: [421/730], Loss: 0.2293\n",
      "Epoch [1/3], Phase: train, Batch: [422/730], Loss: 0.3674\n",
      "Epoch [1/3], Phase: train, Batch: [423/730], Loss: 0.2238\n",
      "Epoch [1/3], Phase: train, Batch: [424/730], Loss: 0.2037\n",
      "Epoch [1/3], Phase: train, Batch: [425/730], Loss: 0.3456\n",
      "Epoch [1/3], Phase: train, Batch: [426/730], Loss: 0.2761\n",
      "Epoch [1/3], Phase: train, Batch: [427/730], Loss: 0.4227\n",
      "Epoch [1/3], Phase: train, Batch: [428/730], Loss: 0.2376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Phase: train, Batch: [429/730], Loss: 0.1974\n",
      "Epoch [1/3], Phase: train, Batch: [430/730], Loss: 0.4713\n",
      "Epoch [1/3], Phase: train, Batch: [431/730], Loss: 0.3826\n",
      "Epoch [1/3], Phase: train, Batch: [432/730], Loss: 0.2681\n",
      "Epoch [1/3], Phase: train, Batch: [433/730], Loss: 0.2210\n",
      "Epoch [1/3], Phase: train, Batch: [434/730], Loss: 0.3239\n",
      "Epoch [1/3], Phase: train, Batch: [435/730], Loss: 0.2145\n",
      "Epoch [1/3], Phase: train, Batch: [436/730], Loss: 0.3090\n",
      "Epoch [1/3], Phase: train, Batch: [437/730], Loss: 0.2202\n",
      "Epoch [1/3], Phase: train, Batch: [438/730], Loss: 0.2026\n",
      "Epoch [1/3], Phase: train, Batch: [439/730], Loss: 0.1631\n",
      "Epoch [1/3], Phase: train, Batch: [440/730], Loss: 0.3645\n",
      "Epoch [1/3], Phase: train, Batch: [441/730], Loss: 0.2053\n",
      "Epoch [1/3], Phase: train, Batch: [442/730], Loss: 0.2177\n",
      "Epoch [1/3], Phase: train, Batch: [443/730], Loss: 0.2327\n",
      "Epoch [1/3], Phase: train, Batch: [444/730], Loss: 0.2082\n",
      "Epoch [1/3], Phase: train, Batch: [445/730], Loss: 0.3420\n",
      "Epoch [1/3], Phase: train, Batch: [446/730], Loss: 0.4163\n",
      "Epoch [1/3], Phase: train, Batch: [447/730], Loss: 0.4916\n",
      "Epoch [1/3], Phase: train, Batch: [448/730], Loss: 0.2861\n",
      "Epoch [1/3], Phase: train, Batch: [449/730], Loss: 0.2703\n",
      "Epoch [1/3], Phase: train, Batch: [450/730], Loss: 0.3121\n",
      "Epoch [1/3], Phase: train, Batch: [451/730], Loss: 0.2421\n",
      "Epoch [1/3], Phase: train, Batch: [452/730], Loss: 0.4195\n",
      "Epoch [1/3], Phase: train, Batch: [453/730], Loss: 0.4888\n",
      "Epoch [1/3], Phase: train, Batch: [454/730], Loss: 0.4000\n",
      "Epoch [1/3], Phase: train, Batch: [455/730], Loss: 0.3387\n",
      "Epoch [1/3], Phase: train, Batch: [456/730], Loss: 0.3688\n",
      "Epoch [1/3], Phase: train, Batch: [457/730], Loss: 0.3508\n",
      "Epoch [1/3], Phase: train, Batch: [458/730], Loss: 0.3074\n",
      "Epoch [1/3], Phase: train, Batch: [459/730], Loss: 0.3968\n",
      "Epoch [1/3], Phase: train, Batch: [460/730], Loss: 0.4048\n",
      "Epoch [1/3], Phase: train, Batch: [461/730], Loss: 0.4473\n",
      "Epoch [1/3], Phase: train, Batch: [462/730], Loss: 0.2734\n",
      "Epoch [1/3], Phase: train, Batch: [463/730], Loss: 0.4591\n",
      "Epoch [1/3], Phase: train, Batch: [464/730], Loss: 0.3003\n",
      "Epoch [1/3], Phase: train, Batch: [465/730], Loss: 0.3453\n",
      "Epoch [1/3], Phase: train, Batch: [466/730], Loss: 0.2767\n",
      "Epoch [1/3], Phase: train, Batch: [467/730], Loss: 0.3613\n",
      "Epoch [1/3], Phase: train, Batch: [468/730], Loss: 0.2900\n",
      "Epoch [1/3], Phase: train, Batch: [469/730], Loss: 0.3155\n",
      "Epoch [1/3], Phase: train, Batch: [470/730], Loss: 0.3800\n",
      "Epoch [1/3], Phase: train, Batch: [471/730], Loss: 0.3805\n",
      "Epoch [1/3], Phase: train, Batch: [472/730], Loss: 0.2949\n",
      "Epoch [1/3], Phase: train, Batch: [473/730], Loss: 0.1461\n",
      "Epoch [1/3], Phase: train, Batch: [474/730], Loss: 0.3934\n",
      "Epoch [1/3], Phase: train, Batch: [475/730], Loss: 0.2981\n",
      "Epoch [1/3], Phase: train, Batch: [476/730], Loss: 0.4285\n",
      "Epoch [1/3], Phase: train, Batch: [477/730], Loss: 0.2628\n",
      "Epoch [1/3], Phase: train, Batch: [478/730], Loss: 0.2912\n",
      "Epoch [1/3], Phase: train, Batch: [479/730], Loss: 0.3259\n",
      "Epoch [1/3], Phase: train, Batch: [480/730], Loss: 0.3003\n",
      "Epoch [1/3], Phase: train, Batch: [481/730], Loss: 0.3485\n",
      "Epoch [1/3], Phase: train, Batch: [482/730], Loss: 0.2064\n",
      "Epoch [1/3], Phase: train, Batch: [483/730], Loss: 0.2238\n",
      "Epoch [1/3], Phase: train, Batch: [484/730], Loss: 0.2832\n",
      "Epoch [1/3], Phase: train, Batch: [485/730], Loss: 0.2737\n",
      "Epoch [1/3], Phase: train, Batch: [486/730], Loss: 0.3522\n",
      "Epoch [1/3], Phase: train, Batch: [487/730], Loss: 0.2737\n",
      "Epoch [1/3], Phase: train, Batch: [488/730], Loss: 0.1658\n",
      "Epoch [1/3], Phase: train, Batch: [489/730], Loss: 0.3837\n",
      "Epoch [1/3], Phase: train, Batch: [490/730], Loss: 0.1855\n",
      "Epoch [1/3], Phase: train, Batch: [491/730], Loss: 0.2002\n",
      "Epoch [1/3], Phase: train, Batch: [492/730], Loss: 0.2225\n",
      "Epoch [1/3], Phase: train, Batch: [493/730], Loss: 0.4676\n",
      "Epoch [1/3], Phase: train, Batch: [494/730], Loss: 0.4547\n",
      "Epoch [1/3], Phase: train, Batch: [495/730], Loss: 0.3168\n",
      "Epoch [1/3], Phase: train, Batch: [496/730], Loss: 0.3633\n",
      "Epoch [1/3], Phase: train, Batch: [497/730], Loss: 0.2599\n",
      "Epoch [1/3], Phase: train, Batch: [498/730], Loss: 0.3908\n",
      "Epoch [1/3], Phase: train, Batch: [499/730], Loss: 0.4030\n",
      "Epoch [1/3], Phase: train, Batch: [500/730], Loss: 0.4170\n",
      "Epoch [1/3], Phase: train, Batch: [501/730], Loss: 0.3279\n",
      "Epoch [1/3], Phase: train, Batch: [502/730], Loss: 0.4156\n",
      "Epoch [1/3], Phase: train, Batch: [503/730], Loss: 0.3870\n",
      "Epoch [1/3], Phase: train, Batch: [504/730], Loss: 0.2490\n",
      "Epoch [1/3], Phase: train, Batch: [505/730], Loss: 0.2891\n",
      "Epoch [1/3], Phase: train, Batch: [506/730], Loss: 0.1747\n",
      "Epoch [1/3], Phase: train, Batch: [507/730], Loss: 0.3254\n",
      "Epoch [1/3], Phase: train, Batch: [508/730], Loss: 0.2704\n",
      "Epoch [1/3], Phase: train, Batch: [509/730], Loss: 0.2640\n",
      "Epoch [1/3], Phase: train, Batch: [510/730], Loss: 0.6250\n",
      "Epoch [1/3], Phase: train, Batch: [511/730], Loss: 0.4592\n",
      "Epoch [1/3], Phase: train, Batch: [512/730], Loss: 0.5255\n",
      "Epoch [1/3], Phase: train, Batch: [513/730], Loss: 0.3204\n",
      "Epoch [1/3], Phase: train, Batch: [514/730], Loss: 0.2911\n",
      "Epoch [1/3], Phase: train, Batch: [515/730], Loss: 0.2995\n",
      "Epoch [1/3], Phase: train, Batch: [516/730], Loss: 0.2441\n",
      "Epoch [1/3], Phase: train, Batch: [517/730], Loss: 0.2451\n",
      "Epoch [1/3], Phase: train, Batch: [518/730], Loss: 0.2479\n",
      "Epoch [1/3], Phase: train, Batch: [519/730], Loss: 0.2904\n",
      "Epoch [1/3], Phase: train, Batch: [520/730], Loss: 0.3182\n",
      "Epoch [1/3], Phase: train, Batch: [521/730], Loss: 0.2791\n",
      "Epoch [1/3], Phase: train, Batch: [522/730], Loss: 0.2164\n",
      "Epoch [1/3], Phase: train, Batch: [523/730], Loss: 0.1929\n",
      "Epoch [1/3], Phase: train, Batch: [524/730], Loss: 0.2872\n",
      "Epoch [1/3], Phase: train, Batch: [525/730], Loss: 0.2806\n",
      "Epoch [1/3], Phase: train, Batch: [526/730], Loss: 0.6753\n",
      "Epoch [1/3], Phase: train, Batch: [527/730], Loss: 0.3805\n",
      "Epoch [1/3], Phase: train, Batch: [528/730], Loss: 0.2589\n",
      "Epoch [1/3], Phase: train, Batch: [529/730], Loss: 0.2794\n",
      "Epoch [1/3], Phase: train, Batch: [530/730], Loss: 0.2178\n",
      "Epoch [1/3], Phase: train, Batch: [531/730], Loss: 0.3619\n",
      "Epoch [1/3], Phase: train, Batch: [532/730], Loss: 0.2767\n",
      "Epoch [1/3], Phase: train, Batch: [533/730], Loss: 0.4352\n",
      "Epoch [1/3], Phase: train, Batch: [534/730], Loss: 0.2548\n",
      "Epoch [1/3], Phase: train, Batch: [535/730], Loss: 0.3117\n",
      "Epoch [1/3], Phase: train, Batch: [536/730], Loss: 0.2423\n",
      "Epoch [1/3], Phase: train, Batch: [537/730], Loss: 0.2283\n",
      "Epoch [1/3], Phase: train, Batch: [538/730], Loss: 0.1811\n",
      "Epoch [1/3], Phase: train, Batch: [539/730], Loss: 0.1765\n",
      "Epoch [1/3], Phase: train, Batch: [540/730], Loss: 0.2951\n",
      "Epoch [1/3], Phase: train, Batch: [541/730], Loss: 0.2820\n",
      "Epoch [1/3], Phase: train, Batch: [542/730], Loss: 0.2722\n",
      "Epoch [1/3], Phase: train, Batch: [543/730], Loss: 0.1952\n",
      "Epoch [1/3], Phase: train, Batch: [544/730], Loss: 0.2996\n",
      "Epoch [1/3], Phase: train, Batch: [545/730], Loss: 0.2411\n",
      "Epoch [1/3], Phase: train, Batch: [546/730], Loss: 0.2747\n",
      "Epoch [1/3], Phase: train, Batch: [547/730], Loss: 0.2002\n",
      "Epoch [1/3], Phase: train, Batch: [548/730], Loss: 0.4813\n",
      "Epoch [1/3], Phase: train, Batch: [549/730], Loss: 0.2542\n",
      "Epoch [1/3], Phase: train, Batch: [550/730], Loss: 0.3270\n",
      "Epoch [1/3], Phase: train, Batch: [551/730], Loss: 0.3801\n",
      "Epoch [1/3], Phase: train, Batch: [552/730], Loss: 0.3002\n",
      "Epoch [1/3], Phase: train, Batch: [553/730], Loss: 0.4573\n",
      "Epoch [1/3], Phase: train, Batch: [554/730], Loss: 0.2269\n",
      "Epoch [1/3], Phase: train, Batch: [555/730], Loss: 0.3556\n",
      "Epoch [1/3], Phase: train, Batch: [556/730], Loss: 0.3035\n",
      "Epoch [1/3], Phase: train, Batch: [557/730], Loss: 0.3237\n",
      "Epoch [1/3], Phase: train, Batch: [558/730], Loss: 0.3385\n",
      "Epoch [1/3], Phase: train, Batch: [559/730], Loss: 0.3127\n",
      "Epoch [1/3], Phase: train, Batch: [560/730], Loss: 0.2679\n",
      "Epoch [1/3], Phase: train, Batch: [561/730], Loss: 0.2133\n",
      "Epoch [1/3], Phase: train, Batch: [562/730], Loss: 0.2191\n",
      "Epoch [1/3], Phase: train, Batch: [563/730], Loss: 0.3705\n",
      "Epoch [1/3], Phase: train, Batch: [564/730], Loss: 0.2759\n",
      "Epoch [1/3], Phase: train, Batch: [565/730], Loss: 0.0914\n",
      "Epoch [1/3], Phase: train, Batch: [566/730], Loss: 0.3699\n",
      "Epoch [1/3], Phase: train, Batch: [567/730], Loss: 0.4939\n",
      "Epoch [1/3], Phase: train, Batch: [568/730], Loss: 0.3872\n",
      "Epoch [1/3], Phase: train, Batch: [569/730], Loss: 0.3600\n",
      "Epoch [1/3], Phase: train, Batch: [570/730], Loss: 0.2519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Phase: train, Batch: [571/730], Loss: 0.2906\n",
      "Epoch [1/3], Phase: train, Batch: [572/730], Loss: 0.1608\n",
      "Epoch [1/3], Phase: train, Batch: [573/730], Loss: 0.2599\n",
      "Epoch [1/3], Phase: train, Batch: [574/730], Loss: 0.2150\n",
      "Epoch [1/3], Phase: train, Batch: [575/730], Loss: 0.4375\n",
      "Epoch [1/3], Phase: train, Batch: [576/730], Loss: 0.4886\n",
      "Epoch [1/3], Phase: train, Batch: [577/730], Loss: 0.4639\n",
      "Epoch [1/3], Phase: train, Batch: [578/730], Loss: 0.3467\n",
      "Epoch [1/3], Phase: train, Batch: [579/730], Loss: 0.4104\n",
      "Epoch [1/3], Phase: train, Batch: [580/730], Loss: 0.2552\n",
      "Epoch [1/3], Phase: train, Batch: [581/730], Loss: 0.3008\n",
      "Epoch [1/3], Phase: train, Batch: [582/730], Loss: 0.3541\n",
      "Epoch [1/3], Phase: train, Batch: [583/730], Loss: 0.3694\n",
      "Epoch [1/3], Phase: train, Batch: [584/730], Loss: 0.2977\n",
      "Epoch [1/3], Phase: train, Batch: [585/730], Loss: 0.3184\n",
      "Epoch [1/3], Phase: train, Batch: [586/730], Loss: 0.3424\n",
      "Epoch [1/3], Phase: train, Batch: [587/730], Loss: 0.3507\n",
      "Epoch [1/3], Phase: train, Batch: [588/730], Loss: 0.2653\n",
      "Epoch [1/3], Phase: train, Batch: [589/730], Loss: 0.2778\n",
      "Epoch [1/3], Phase: train, Batch: [590/730], Loss: 0.4660\n",
      "Epoch [1/3], Phase: train, Batch: [591/730], Loss: 0.2872\n",
      "Epoch [1/3], Phase: train, Batch: [592/730], Loss: 0.3068\n",
      "Epoch [1/3], Phase: train, Batch: [593/730], Loss: 0.4737\n",
      "Epoch [1/3], Phase: train, Batch: [594/730], Loss: 0.3322\n",
      "Epoch [1/3], Phase: train, Batch: [595/730], Loss: 0.2974\n",
      "Epoch [1/3], Phase: train, Batch: [596/730], Loss: 0.2734\n",
      "Epoch [1/3], Phase: train, Batch: [597/730], Loss: 0.2358\n",
      "Epoch [1/3], Phase: train, Batch: [598/730], Loss: 0.2433\n",
      "Epoch [1/3], Phase: train, Batch: [599/730], Loss: 0.1623\n",
      "Epoch [1/3], Phase: train, Batch: [600/730], Loss: 0.3436\n",
      "Epoch [1/3], Phase: train, Batch: [601/730], Loss: 0.3075\n",
      "Epoch [1/3], Phase: train, Batch: [602/730], Loss: 0.2266\n",
      "Epoch [1/3], Phase: train, Batch: [603/730], Loss: 0.4381\n",
      "Epoch [1/3], Phase: train, Batch: [604/730], Loss: 0.2169\n",
      "Epoch [1/3], Phase: train, Batch: [605/730], Loss: 0.1075\n",
      "Epoch [1/3], Phase: train, Batch: [606/730], Loss: 0.3583\n",
      "Epoch [1/3], Phase: train, Batch: [607/730], Loss: 0.2909\n",
      "Epoch [1/3], Phase: train, Batch: [608/730], Loss: 0.2623\n",
      "Epoch [1/3], Phase: train, Batch: [609/730], Loss: 0.2971\n",
      "Epoch [1/3], Phase: train, Batch: [610/730], Loss: 0.3269\n",
      "Epoch [1/3], Phase: train, Batch: [611/730], Loss: 0.2221\n",
      "Epoch [1/3], Phase: train, Batch: [612/730], Loss: 0.3104\n",
      "Epoch [1/3], Phase: train, Batch: [613/730], Loss: 0.3140\n",
      "Epoch [1/3], Phase: train, Batch: [614/730], Loss: 0.3535\n",
      "Epoch [1/3], Phase: train, Batch: [615/730], Loss: 0.3489\n",
      "Epoch [1/3], Phase: train, Batch: [616/730], Loss: 0.2198\n",
      "Epoch [1/3], Phase: train, Batch: [617/730], Loss: 0.2120\n",
      "Epoch [1/3], Phase: train, Batch: [618/730], Loss: 0.1848\n",
      "Epoch [1/3], Phase: train, Batch: [619/730], Loss: 0.2541\n",
      "Epoch [1/3], Phase: train, Batch: [620/730], Loss: 0.2788\n",
      "Epoch [1/3], Phase: train, Batch: [621/730], Loss: 0.2384\n",
      "Epoch [1/3], Phase: train, Batch: [622/730], Loss: 0.1818\n",
      "Epoch [1/3], Phase: train, Batch: [623/730], Loss: 0.2883\n",
      "Epoch [1/3], Phase: train, Batch: [624/730], Loss: 0.2361\n",
      "Epoch [1/3], Phase: train, Batch: [625/730], Loss: 0.2987\n",
      "Epoch [1/3], Phase: train, Batch: [626/730], Loss: 0.2147\n",
      "Epoch [1/3], Phase: train, Batch: [627/730], Loss: 0.3713\n",
      "Epoch [1/3], Phase: train, Batch: [628/730], Loss: 0.3492\n",
      "Epoch [1/3], Phase: train, Batch: [629/730], Loss: 0.2171\n",
      "Epoch [1/3], Phase: train, Batch: [630/730], Loss: 0.2654\n",
      "Epoch [1/3], Phase: train, Batch: [631/730], Loss: 0.3599\n",
      "Epoch [1/3], Phase: train, Batch: [632/730], Loss: 0.2342\n",
      "Epoch [1/3], Phase: train, Batch: [633/730], Loss: 0.3458\n",
      "Epoch [1/3], Phase: train, Batch: [634/730], Loss: 0.3099\n",
      "Epoch [1/3], Phase: train, Batch: [635/730], Loss: 0.2550\n",
      "Epoch [1/3], Phase: train, Batch: [636/730], Loss: 0.1966\n",
      "Epoch [1/3], Phase: train, Batch: [637/730], Loss: 0.2293\n",
      "Epoch [1/3], Phase: train, Batch: [638/730], Loss: 0.3291\n",
      "Epoch [1/3], Phase: train, Batch: [639/730], Loss: 0.2360\n",
      "Epoch [1/3], Phase: train, Batch: [640/730], Loss: 0.2896\n",
      "Epoch [1/3], Phase: train, Batch: [641/730], Loss: 0.2714\n",
      "Epoch [1/3], Phase: train, Batch: [642/730], Loss: 0.3591\n",
      "Epoch [1/3], Phase: train, Batch: [643/730], Loss: 0.3093\n",
      "Epoch [1/3], Phase: train, Batch: [644/730], Loss: 0.1888\n",
      "Epoch [1/3], Phase: train, Batch: [645/730], Loss: 0.3446\n",
      "Epoch [1/3], Phase: train, Batch: [646/730], Loss: 0.2561\n",
      "Epoch [1/3], Phase: train, Batch: [647/730], Loss: 0.2757\n",
      "Epoch [1/3], Phase: train, Batch: [648/730], Loss: 0.4568\n",
      "Epoch [1/3], Phase: train, Batch: [649/730], Loss: 0.4580\n",
      "Epoch [1/3], Phase: train, Batch: [650/730], Loss: 0.3196\n",
      "Epoch [1/3], Phase: train, Batch: [651/730], Loss: 0.4075\n",
      "Epoch [1/3], Phase: train, Batch: [652/730], Loss: 0.3271\n",
      "Epoch [1/3], Phase: train, Batch: [653/730], Loss: 0.1972\n",
      "Epoch [1/3], Phase: train, Batch: [654/730], Loss: 0.3208\n",
      "Epoch [1/3], Phase: train, Batch: [655/730], Loss: 0.2239\n",
      "Epoch [1/3], Phase: train, Batch: [656/730], Loss: 0.2643\n",
      "Epoch [1/3], Phase: train, Batch: [657/730], Loss: 0.3062\n",
      "Epoch [1/3], Phase: train, Batch: [658/730], Loss: 0.2001\n",
      "Epoch [1/3], Phase: train, Batch: [659/730], Loss: 0.2757\n",
      "Epoch [1/3], Phase: train, Batch: [660/730], Loss: 0.3361\n",
      "Epoch [1/3], Phase: train, Batch: [661/730], Loss: 0.2495\n",
      "Epoch [1/3], Phase: train, Batch: [662/730], Loss: 0.2776\n",
      "Epoch [1/3], Phase: train, Batch: [663/730], Loss: 0.1446\n",
      "Epoch [1/3], Phase: train, Batch: [664/730], Loss: 0.5396\n",
      "Epoch [1/3], Phase: train, Batch: [665/730], Loss: 0.2624\n",
      "Epoch [1/3], Phase: train, Batch: [666/730], Loss: 0.1451\n",
      "Epoch [1/3], Phase: train, Batch: [667/730], Loss: 0.2282\n",
      "Epoch [1/3], Phase: train, Batch: [668/730], Loss: 0.4918\n",
      "Epoch [1/3], Phase: train, Batch: [669/730], Loss: 0.4511\n",
      "Epoch [1/3], Phase: train, Batch: [670/730], Loss: 0.3126\n",
      "Epoch [1/3], Phase: train, Batch: [671/730], Loss: 0.2845\n",
      "Epoch [1/3], Phase: train, Batch: [672/730], Loss: 0.2671\n",
      "Epoch [1/3], Phase: train, Batch: [673/730], Loss: 0.2146\n",
      "Epoch [1/3], Phase: train, Batch: [674/730], Loss: 0.2484\n",
      "Epoch [1/3], Phase: train, Batch: [675/730], Loss: 0.3625\n",
      "Epoch [1/3], Phase: train, Batch: [676/730], Loss: 0.3531\n",
      "Epoch [1/3], Phase: train, Batch: [677/730], Loss: 0.3424\n",
      "Epoch [1/3], Phase: train, Batch: [678/730], Loss: 0.3178\n",
      "Epoch [1/3], Phase: train, Batch: [679/730], Loss: 0.1935\n",
      "Epoch [1/3], Phase: train, Batch: [680/730], Loss: 0.3684\n",
      "Epoch [1/3], Phase: train, Batch: [681/730], Loss: 0.3158\n",
      "Epoch [1/3], Phase: train, Batch: [682/730], Loss: 0.3038\n",
      "Epoch [1/3], Phase: train, Batch: [683/730], Loss: 0.4250\n",
      "Epoch [1/3], Phase: train, Batch: [684/730], Loss: 0.2513\n",
      "Epoch [1/3], Phase: train, Batch: [685/730], Loss: 0.2728\n",
      "Epoch [1/3], Phase: train, Batch: [686/730], Loss: 0.2588\n",
      "Epoch [1/3], Phase: train, Batch: [687/730], Loss: 0.2910\n",
      "Epoch [1/3], Phase: train, Batch: [688/730], Loss: 0.2305\n",
      "Epoch [1/3], Phase: train, Batch: [689/730], Loss: 0.3081\n",
      "Epoch [1/3], Phase: train, Batch: [690/730], Loss: 0.4520\n",
      "Epoch [1/3], Phase: train, Batch: [691/730], Loss: 0.2692\n",
      "Epoch [1/3], Phase: train, Batch: [692/730], Loss: 0.2431\n",
      "Epoch [1/3], Phase: train, Batch: [693/730], Loss: 0.2245\n",
      "Epoch [1/3], Phase: train, Batch: [694/730], Loss: 0.2247\n",
      "Epoch [1/3], Phase: train, Batch: [695/730], Loss: 0.3908\n",
      "Epoch [1/3], Phase: train, Batch: [696/730], Loss: 0.4428\n",
      "Epoch [1/3], Phase: train, Batch: [697/730], Loss: 0.3202\n",
      "Epoch [1/3], Phase: train, Batch: [698/730], Loss: 0.4170\n",
      "Epoch [1/3], Phase: train, Batch: [699/730], Loss: 0.6704\n",
      "Epoch [1/3], Phase: train, Batch: [700/730], Loss: 0.2954\n",
      "Epoch [1/3], Phase: train, Batch: [701/730], Loss: 0.2424\n",
      "Epoch [1/3], Phase: train, Batch: [702/730], Loss: 0.3617\n",
      "Epoch [1/3], Phase: train, Batch: [703/730], Loss: 0.3550\n",
      "Epoch [1/3], Phase: train, Batch: [704/730], Loss: 0.3517\n",
      "Epoch [1/3], Phase: train, Batch: [705/730], Loss: 0.2758\n",
      "Epoch [1/3], Phase: train, Batch: [706/730], Loss: 0.3267\n",
      "Epoch [1/3], Phase: train, Batch: [707/730], Loss: 0.3091\n",
      "Epoch [1/3], Phase: train, Batch: [708/730], Loss: 0.3208\n",
      "Epoch [1/3], Phase: train, Batch: [709/730], Loss: 0.3296\n",
      "Epoch [1/3], Phase: train, Batch: [710/730], Loss: 0.2332\n",
      "Epoch [1/3], Phase: train, Batch: [711/730], Loss: 0.3391\n",
      "Epoch [1/3], Phase: train, Batch: [712/730], Loss: 0.3430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Phase: train, Batch: [713/730], Loss: 0.1774\n",
      "Epoch [1/3], Phase: train, Batch: [714/730], Loss: 0.4648\n",
      "Epoch [1/3], Phase: train, Batch: [715/730], Loss: 0.3764\n",
      "Epoch [1/3], Phase: train, Batch: [716/730], Loss: 0.2634\n",
      "Epoch [1/3], Phase: train, Batch: [717/730], Loss: 0.2960\n",
      "Epoch [1/3], Phase: train, Batch: [718/730], Loss: 0.4019\n",
      "Epoch [1/3], Phase: train, Batch: [719/730], Loss: 0.2354\n",
      "Epoch [1/3], Phase: train, Batch: [720/730], Loss: 0.3826\n",
      "Epoch [1/3], Phase: train, Batch: [721/730], Loss: 0.4400\n",
      "Epoch [1/3], Phase: train, Batch: [722/730], Loss: 0.2484\n",
      "Epoch [1/3], Phase: train, Batch: [723/730], Loss: 0.3020\n",
      "Epoch [1/3], Phase: train, Batch: [724/730], Loss: 0.2062\n",
      "Epoch [1/3], Phase: train, Batch: [725/730], Loss: 0.2585\n",
      "Epoch [1/3], Phase: train, Batch: [726/730], Loss: 0.5050\n",
      "Epoch [1/3], Phase: train, Batch: [727/730], Loss: 0.3148\n",
      "Epoch [1/3], Phase: train, Batch: [728/730], Loss: 0.4179\n",
      "Epoch [1/3], Phase: train, Batch: [729/730], Loss: 0.3665\n",
      "Epoch [1/3], Phase: train, Batch: [730/730], Loss: 0.1983\n",
      "train Loss: 0.3497 Acc: 0.8688\n",
      "Epoch [1/3], Phase: val, Batch: [1/182], Loss: 0.4354\n",
      "Epoch [1/3], Phase: val, Batch: [2/182], Loss: 0.3344\n",
      "Epoch [1/3], Phase: val, Batch: [3/182], Loss: 0.2701\n",
      "Epoch [1/3], Phase: val, Batch: [4/182], Loss: 0.3697\n",
      "Epoch [1/3], Phase: val, Batch: [5/182], Loss: 0.3206\n",
      "Epoch [1/3], Phase: val, Batch: [6/182], Loss: 0.3267\n",
      "Epoch [1/3], Phase: val, Batch: [7/182], Loss: 0.1957\n",
      "Epoch [1/3], Phase: val, Batch: [8/182], Loss: 0.3380\n",
      "Epoch [1/3], Phase: val, Batch: [9/182], Loss: 0.2779\n",
      "Epoch [1/3], Phase: val, Batch: [10/182], Loss: 0.2494\n",
      "Epoch [1/3], Phase: val, Batch: [11/182], Loss: 0.2700\n",
      "Epoch [1/3], Phase: val, Batch: [12/182], Loss: 0.3082\n",
      "Epoch [1/3], Phase: val, Batch: [13/182], Loss: 0.2665\n",
      "Epoch [1/3], Phase: val, Batch: [14/182], Loss: 0.2460\n",
      "Epoch [1/3], Phase: val, Batch: [15/182], Loss: 0.2868\n",
      "Epoch [1/3], Phase: val, Batch: [16/182], Loss: 0.3385\n",
      "Epoch [1/3], Phase: val, Batch: [17/182], Loss: 0.3856\n",
      "Epoch [1/3], Phase: val, Batch: [18/182], Loss: 0.3498\n",
      "Epoch [1/3], Phase: val, Batch: [19/182], Loss: 0.4441\n",
      "Epoch [1/3], Phase: val, Batch: [20/182], Loss: 0.4842\n",
      "Epoch [1/3], Phase: val, Batch: [21/182], Loss: 0.4351\n",
      "Epoch [1/3], Phase: val, Batch: [22/182], Loss: 0.4570\n",
      "Epoch [1/3], Phase: val, Batch: [23/182], Loss: 0.2523\n",
      "Epoch [1/3], Phase: val, Batch: [24/182], Loss: 0.4443\n",
      "Epoch [1/3], Phase: val, Batch: [25/182], Loss: 0.3383\n",
      "Epoch [1/3], Phase: val, Batch: [26/182], Loss: 0.2419\n",
      "Epoch [1/3], Phase: val, Batch: [27/182], Loss: 0.3409\n",
      "Epoch [1/3], Phase: val, Batch: [28/182], Loss: 0.4237\n",
      "Epoch [1/3], Phase: val, Batch: [29/182], Loss: 0.3930\n",
      "Epoch [1/3], Phase: val, Batch: [30/182], Loss: 0.3857\n",
      "Epoch [1/3], Phase: val, Batch: [31/182], Loss: 0.4235\n",
      "Epoch [1/3], Phase: val, Batch: [32/182], Loss: 0.2592\n",
      "Epoch [1/3], Phase: val, Batch: [33/182], Loss: 0.3733\n",
      "Epoch [1/3], Phase: val, Batch: [34/182], Loss: 0.3320\n",
      "Epoch [1/3], Phase: val, Batch: [35/182], Loss: 0.2464\n",
      "Epoch [1/3], Phase: val, Batch: [36/182], Loss: 0.3120\n",
      "Epoch [1/3], Phase: val, Batch: [37/182], Loss: 0.2530\n",
      "Epoch [1/3], Phase: val, Batch: [38/182], Loss: 0.2654\n",
      "Epoch [1/3], Phase: val, Batch: [39/182], Loss: 0.3912\n",
      "Epoch [1/3], Phase: val, Batch: [40/182], Loss: 0.3110\n",
      "Epoch [1/3], Phase: val, Batch: [41/182], Loss: 0.3237\n",
      "Epoch [1/3], Phase: val, Batch: [42/182], Loss: 0.3568\n",
      "Epoch [1/3], Phase: val, Batch: [43/182], Loss: 0.2580\n",
      "Epoch [1/3], Phase: val, Batch: [44/182], Loss: 0.4147\n",
      "Epoch [1/3], Phase: val, Batch: [45/182], Loss: 0.4417\n",
      "Epoch [1/3], Phase: val, Batch: [46/182], Loss: 0.3308\n",
      "Epoch [1/3], Phase: val, Batch: [47/182], Loss: 0.3717\n",
      "Epoch [1/3], Phase: val, Batch: [48/182], Loss: 0.2139\n",
      "Epoch [1/3], Phase: val, Batch: [49/182], Loss: 0.3448\n",
      "Epoch [1/3], Phase: val, Batch: [50/182], Loss: 0.4288\n",
      "Epoch [1/3], Phase: val, Batch: [51/182], Loss: 0.4785\n",
      "Epoch [1/3], Phase: val, Batch: [52/182], Loss: 0.3247\n",
      "Epoch [1/3], Phase: val, Batch: [53/182], Loss: 0.3283\n",
      "Epoch [1/3], Phase: val, Batch: [54/182], Loss: 0.3800\n",
      "Epoch [1/3], Phase: val, Batch: [55/182], Loss: 0.2951\n",
      "Epoch [1/3], Phase: val, Batch: [56/182], Loss: 0.2620\n",
      "Epoch [1/3], Phase: val, Batch: [57/182], Loss: 0.3561\n",
      "Epoch [1/3], Phase: val, Batch: [58/182], Loss: 0.3060\n",
      "Epoch [1/3], Phase: val, Batch: [59/182], Loss: 0.2377\n",
      "Epoch [1/3], Phase: val, Batch: [60/182], Loss: 0.2543\n",
      "Epoch [1/3], Phase: val, Batch: [61/182], Loss: 0.3833\n",
      "Epoch [1/3], Phase: val, Batch: [62/182], Loss: 0.4393\n",
      "Epoch [1/3], Phase: val, Batch: [63/182], Loss: 0.2585\n",
      "Epoch [1/3], Phase: val, Batch: [64/182], Loss: 0.3396\n",
      "Epoch [1/3], Phase: val, Batch: [65/182], Loss: 0.2662\n",
      "Epoch [1/3], Phase: val, Batch: [66/182], Loss: 0.3856\n",
      "Epoch [1/3], Phase: val, Batch: [67/182], Loss: 0.2726\n",
      "Epoch [1/3], Phase: val, Batch: [68/182], Loss: 0.2744\n",
      "Epoch [1/3], Phase: val, Batch: [69/182], Loss: 0.3796\n",
      "Epoch [1/3], Phase: val, Batch: [70/182], Loss: 0.3270\n",
      "Epoch [1/3], Phase: val, Batch: [71/182], Loss: 0.3669\n",
      "Epoch [1/3], Phase: val, Batch: [72/182], Loss: 0.2419\n",
      "Epoch [1/3], Phase: val, Batch: [73/182], Loss: 0.2665\n",
      "Epoch [1/3], Phase: val, Batch: [74/182], Loss: 0.4146\n",
      "Epoch [1/3], Phase: val, Batch: [75/182], Loss: 0.3016\n",
      "Epoch [1/3], Phase: val, Batch: [76/182], Loss: 0.3152\n",
      "Epoch [1/3], Phase: val, Batch: [77/182], Loss: 0.2695\n",
      "Epoch [1/3], Phase: val, Batch: [78/182], Loss: 0.2601\n",
      "Epoch [1/3], Phase: val, Batch: [79/182], Loss: 0.3370\n",
      "Epoch [1/3], Phase: val, Batch: [80/182], Loss: 0.3156\n",
      "Epoch [1/3], Phase: val, Batch: [81/182], Loss: 0.2079\n",
      "Epoch [1/3], Phase: val, Batch: [82/182], Loss: 0.2441\n",
      "Epoch [1/3], Phase: val, Batch: [83/182], Loss: 0.2790\n",
      "Epoch [1/3], Phase: val, Batch: [84/182], Loss: 0.2986\n",
      "Epoch [1/3], Phase: val, Batch: [85/182], Loss: 0.3183\n",
      "Epoch [1/3], Phase: val, Batch: [86/182], Loss: 0.3784\n",
      "Epoch [1/3], Phase: val, Batch: [87/182], Loss: 0.4977\n",
      "Epoch [1/3], Phase: val, Batch: [88/182], Loss: 0.3893\n",
      "Epoch [1/3], Phase: val, Batch: [89/182], Loss: 0.3383\n",
      "Epoch [1/3], Phase: val, Batch: [90/182], Loss: 0.3256\n",
      "Epoch [1/3], Phase: val, Batch: [91/182], Loss: 0.3968\n",
      "Epoch [1/3], Phase: val, Batch: [92/182], Loss: 0.2136\n",
      "Epoch [1/3], Phase: val, Batch: [93/182], Loss: 0.1777\n",
      "Epoch [1/3], Phase: val, Batch: [94/182], Loss: 0.1527\n",
      "Epoch [1/3], Phase: val, Batch: [95/182], Loss: 0.2113\n",
      "Epoch [1/3], Phase: val, Batch: [96/182], Loss: 0.1682\n",
      "Epoch [1/3], Phase: val, Batch: [97/182], Loss: 0.1831\n",
      "Epoch [1/3], Phase: val, Batch: [98/182], Loss: 0.1978\n",
      "Epoch [1/3], Phase: val, Batch: [99/182], Loss: 0.2194\n",
      "Epoch [1/3], Phase: val, Batch: [100/182], Loss: 0.2478\n",
      "Epoch [1/3], Phase: val, Batch: [101/182], Loss: 0.2816\n",
      "Epoch [1/3], Phase: val, Batch: [102/182], Loss: 0.1780\n",
      "Epoch [1/3], Phase: val, Batch: [103/182], Loss: 0.2104\n",
      "Epoch [1/3], Phase: val, Batch: [104/182], Loss: 0.2071\n",
      "Epoch [1/3], Phase: val, Batch: [105/182], Loss: 0.1568\n",
      "Epoch [1/3], Phase: val, Batch: [106/182], Loss: 0.2904\n",
      "Epoch [1/3], Phase: val, Batch: [107/182], Loss: 0.2073\n",
      "Epoch [1/3], Phase: val, Batch: [108/182], Loss: 0.1890\n",
      "Epoch [1/3], Phase: val, Batch: [109/182], Loss: 0.1991\n",
      "Epoch [1/3], Phase: val, Batch: [110/182], Loss: 0.1599\n",
      "Epoch [1/3], Phase: val, Batch: [111/182], Loss: 0.1104\n",
      "Epoch [1/3], Phase: val, Batch: [112/182], Loss: 0.1759\n",
      "Epoch [1/3], Phase: val, Batch: [113/182], Loss: 0.1358\n",
      "Epoch [1/3], Phase: val, Batch: [114/182], Loss: 0.2341\n",
      "Epoch [1/3], Phase: val, Batch: [115/182], Loss: 0.1760\n",
      "Epoch [1/3], Phase: val, Batch: [116/182], Loss: 0.2224\n",
      "Epoch [1/3], Phase: val, Batch: [117/182], Loss: 0.1382\n",
      "Epoch [1/3], Phase: val, Batch: [118/182], Loss: 0.2195\n",
      "Epoch [1/3], Phase: val, Batch: [119/182], Loss: 0.1554\n",
      "Epoch [1/3], Phase: val, Batch: [120/182], Loss: 0.1730\n",
      "Epoch [1/3], Phase: val, Batch: [121/182], Loss: 0.1980\n",
      "Epoch [1/3], Phase: val, Batch: [122/182], Loss: 0.1510\n",
      "Epoch [1/3], Phase: val, Batch: [123/182], Loss: 0.2401\n",
      "Epoch [1/3], Phase: val, Batch: [124/182], Loss: 0.1642\n",
      "Epoch [1/3], Phase: val, Batch: [125/182], Loss: 0.1557\n",
      "Epoch [1/3], Phase: val, Batch: [126/182], Loss: 0.1644\n",
      "Epoch [1/3], Phase: val, Batch: [127/182], Loss: 0.1504\n",
      "Epoch [1/3], Phase: val, Batch: [128/182], Loss: 0.1630\n",
      "Epoch [1/3], Phase: val, Batch: [129/182], Loss: 0.1927\n",
      "Epoch [1/3], Phase: val, Batch: [130/182], Loss: 0.1408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Phase: val, Batch: [131/182], Loss: 0.1927\n",
      "Epoch [1/3], Phase: val, Batch: [132/182], Loss: 0.1951\n",
      "Epoch [1/3], Phase: val, Batch: [133/182], Loss: 0.2801\n",
      "Epoch [1/3], Phase: val, Batch: [134/182], Loss: 0.1252\n",
      "Epoch [1/3], Phase: val, Batch: [135/182], Loss: 0.1840\n",
      "Epoch [1/3], Phase: val, Batch: [136/182], Loss: 0.2445\n",
      "Epoch [1/3], Phase: val, Batch: [137/182], Loss: 0.1959\n",
      "Epoch [1/3], Phase: val, Batch: [138/182], Loss: 0.2280\n",
      "Epoch [1/3], Phase: val, Batch: [139/182], Loss: 0.1435\n",
      "Epoch [1/3], Phase: val, Batch: [140/182], Loss: 0.2117\n",
      "Epoch [1/3], Phase: val, Batch: [141/182], Loss: 0.1677\n",
      "Epoch [1/3], Phase: val, Batch: [142/182], Loss: 0.1615\n",
      "Epoch [1/3], Phase: val, Batch: [143/182], Loss: 0.2511\n",
      "Epoch [1/3], Phase: val, Batch: [144/182], Loss: 0.2581\n",
      "Epoch [1/3], Phase: val, Batch: [145/182], Loss: 0.1372\n",
      "Epoch [1/3], Phase: val, Batch: [146/182], Loss: 0.1386\n",
      "Epoch [1/3], Phase: val, Batch: [147/182], Loss: 0.1855\n",
      "Epoch [1/3], Phase: val, Batch: [148/182], Loss: 0.1777\n",
      "Epoch [1/3], Phase: val, Batch: [149/182], Loss: 0.1832\n",
      "Epoch [1/3], Phase: val, Batch: [150/182], Loss: 0.2313\n",
      "Epoch [1/3], Phase: val, Batch: [151/182], Loss: 0.1959\n",
      "Epoch [1/3], Phase: val, Batch: [152/182], Loss: 0.2577\n",
      "Epoch [1/3], Phase: val, Batch: [153/182], Loss: 0.2271\n",
      "Epoch [1/3], Phase: val, Batch: [154/182], Loss: 0.2178\n",
      "Epoch [1/3], Phase: val, Batch: [155/182], Loss: 0.1657\n",
      "Epoch [1/3], Phase: val, Batch: [156/182], Loss: 0.3086\n",
      "Epoch [1/3], Phase: val, Batch: [157/182], Loss: 0.1866\n",
      "Epoch [1/3], Phase: val, Batch: [158/182], Loss: 0.2988\n",
      "Epoch [1/3], Phase: val, Batch: [159/182], Loss: 0.2213\n",
      "Epoch [1/3], Phase: val, Batch: [160/182], Loss: 0.1689\n",
      "Epoch [1/3], Phase: val, Batch: [161/182], Loss: 0.2224\n",
      "Epoch [1/3], Phase: val, Batch: [162/182], Loss: 0.2214\n",
      "Epoch [1/3], Phase: val, Batch: [163/182], Loss: 0.2659\n",
      "Epoch [1/3], Phase: val, Batch: [164/182], Loss: 0.2048\n",
      "Epoch [1/3], Phase: val, Batch: [165/182], Loss: 0.1969\n",
      "Epoch [1/3], Phase: val, Batch: [166/182], Loss: 0.1311\n",
      "Epoch [1/3], Phase: val, Batch: [167/182], Loss: 0.1787\n",
      "Epoch [1/3], Phase: val, Batch: [168/182], Loss: 0.1751\n",
      "Epoch [1/3], Phase: val, Batch: [169/182], Loss: 0.1942\n",
      "Epoch [1/3], Phase: val, Batch: [170/182], Loss: 0.2398\n",
      "Epoch [1/3], Phase: val, Batch: [171/182], Loss: 0.2495\n",
      "Epoch [1/3], Phase: val, Batch: [172/182], Loss: 0.2060\n",
      "Epoch [1/3], Phase: val, Batch: [173/182], Loss: 0.1066\n",
      "Epoch [1/3], Phase: val, Batch: [174/182], Loss: 0.1931\n",
      "Epoch [1/3], Phase: val, Batch: [175/182], Loss: 0.1484\n",
      "Epoch [1/3], Phase: val, Batch: [176/182], Loss: 0.1966\n",
      "Epoch [1/3], Phase: val, Batch: [177/182], Loss: 0.1997\n",
      "Epoch [1/3], Phase: val, Batch: [178/182], Loss: 0.1076\n",
      "Epoch [1/3], Phase: val, Batch: [179/182], Loss: 0.1780\n",
      "Epoch [1/3], Phase: val, Batch: [180/182], Loss: 0.1467\n",
      "Epoch [1/3], Phase: val, Batch: [181/182], Loss: 0.2697\n",
      "Epoch [1/3], Phase: val, Batch: [182/182], Loss: 0.1916\n",
      "val Loss: 0.2629 Acc: 0.8971\n",
      "Epoch [2/3], Phase: train, Batch: [1/730], Loss: 0.2731\n",
      "Epoch [2/3], Phase: train, Batch: [2/730], Loss: 0.2527\n",
      "Epoch [2/3], Phase: train, Batch: [3/730], Loss: 0.2863\n",
      "Epoch [2/3], Phase: train, Batch: [4/730], Loss: 0.2383\n",
      "Epoch [2/3], Phase: train, Batch: [5/730], Loss: 0.3565\n",
      "Epoch [2/3], Phase: train, Batch: [6/730], Loss: 0.2640\n",
      "Epoch [2/3], Phase: train, Batch: [7/730], Loss: 0.4029\n",
      "Epoch [2/3], Phase: train, Batch: [8/730], Loss: 0.4652\n",
      "Epoch [2/3], Phase: train, Batch: [9/730], Loss: 0.3168\n",
      "Epoch [2/3], Phase: train, Batch: [10/730], Loss: 0.3209\n",
      "Epoch [2/3], Phase: train, Batch: [11/730], Loss: 0.3049\n",
      "Epoch [2/3], Phase: train, Batch: [12/730], Loss: 0.2261\n",
      "Epoch [2/3], Phase: train, Batch: [13/730], Loss: 0.2901\n",
      "Epoch [2/3], Phase: train, Batch: [14/730], Loss: 0.3860\n",
      "Epoch [2/3], Phase: train, Batch: [15/730], Loss: 0.3139\n",
      "Epoch [2/3], Phase: train, Batch: [16/730], Loss: 0.2820\n",
      "Epoch [2/3], Phase: train, Batch: [17/730], Loss: 0.3777\n",
      "Epoch [2/3], Phase: train, Batch: [18/730], Loss: 0.2353\n",
      "Epoch [2/3], Phase: train, Batch: [19/730], Loss: 0.4212\n",
      "Epoch [2/3], Phase: train, Batch: [20/730], Loss: 0.3793\n",
      "Epoch [2/3], Phase: train, Batch: [21/730], Loss: 0.2716\n",
      "Epoch [2/3], Phase: train, Batch: [22/730], Loss: 0.2729\n",
      "Epoch [2/3], Phase: train, Batch: [23/730], Loss: 0.2676\n",
      "Epoch [2/3], Phase: train, Batch: [24/730], Loss: 0.1713\n",
      "Epoch [2/3], Phase: train, Batch: [25/730], Loss: 0.3423\n",
      "Epoch [2/3], Phase: train, Batch: [26/730], Loss: 0.3201\n",
      "Epoch [2/3], Phase: train, Batch: [27/730], Loss: 0.3864\n",
      "Epoch [2/3], Phase: train, Batch: [28/730], Loss: 0.2250\n",
      "Epoch [2/3], Phase: train, Batch: [29/730], Loss: 0.3656\n",
      "Epoch [2/3], Phase: train, Batch: [30/730], Loss: 0.4025\n",
      "Epoch [2/3], Phase: train, Batch: [31/730], Loss: 0.3837\n",
      "Epoch [2/3], Phase: train, Batch: [32/730], Loss: 0.2813\n",
      "Epoch [2/3], Phase: train, Batch: [33/730], Loss: 0.4386\n",
      "Epoch [2/3], Phase: train, Batch: [34/730], Loss: 0.2796\n",
      "Epoch [2/3], Phase: train, Batch: [35/730], Loss: 0.2499\n",
      "Epoch [2/3], Phase: train, Batch: [36/730], Loss: 0.1871\n",
      "Epoch [2/3], Phase: train, Batch: [37/730], Loss: 0.2129\n",
      "Epoch [2/3], Phase: train, Batch: [38/730], Loss: 0.3390\n",
      "Epoch [2/3], Phase: train, Batch: [39/730], Loss: 0.3040\n",
      "Epoch [2/3], Phase: train, Batch: [40/730], Loss: 0.3829\n",
      "Epoch [2/3], Phase: train, Batch: [41/730], Loss: 0.3527\n",
      "Epoch [2/3], Phase: train, Batch: [42/730], Loss: 0.3536\n",
      "Epoch [2/3], Phase: train, Batch: [43/730], Loss: 0.2485\n",
      "Epoch [2/3], Phase: train, Batch: [44/730], Loss: 0.2607\n",
      "Epoch [2/3], Phase: train, Batch: [45/730], Loss: 0.3479\n",
      "Epoch [2/3], Phase: train, Batch: [46/730], Loss: 0.1991\n",
      "Epoch [2/3], Phase: train, Batch: [47/730], Loss: 0.3878\n",
      "Epoch [2/3], Phase: train, Batch: [48/730], Loss: 0.3010\n",
      "Epoch [2/3], Phase: train, Batch: [49/730], Loss: 0.3532\n",
      "Epoch [2/3], Phase: train, Batch: [50/730], Loss: 0.2565\n",
      "Epoch [2/3], Phase: train, Batch: [51/730], Loss: 0.2755\n",
      "Epoch [2/3], Phase: train, Batch: [52/730], Loss: 0.3157\n",
      "Epoch [2/3], Phase: train, Batch: [53/730], Loss: 0.2266\n",
      "Epoch [2/3], Phase: train, Batch: [54/730], Loss: 0.4540\n",
      "Epoch [2/3], Phase: train, Batch: [55/730], Loss: 0.2541\n",
      "Epoch [2/3], Phase: train, Batch: [56/730], Loss: 0.1766\n",
      "Epoch [2/3], Phase: train, Batch: [57/730], Loss: 0.2508\n",
      "Epoch [2/3], Phase: train, Batch: [58/730], Loss: 0.2557\n",
      "Epoch [2/3], Phase: train, Batch: [59/730], Loss: 0.2437\n",
      "Epoch [2/3], Phase: train, Batch: [60/730], Loss: 0.2747\n",
      "Epoch [2/3], Phase: train, Batch: [61/730], Loss: 0.2477\n",
      "Epoch [2/3], Phase: train, Batch: [62/730], Loss: 0.5861\n",
      "Epoch [2/3], Phase: train, Batch: [63/730], Loss: 0.2189\n",
      "Epoch [2/3], Phase: train, Batch: [64/730], Loss: 0.3539\n",
      "Epoch [2/3], Phase: train, Batch: [65/730], Loss: 0.2755\n",
      "Epoch [2/3], Phase: train, Batch: [66/730], Loss: 0.2295\n",
      "Epoch [2/3], Phase: train, Batch: [67/730], Loss: 0.3139\n",
      "Epoch [2/3], Phase: train, Batch: [68/730], Loss: 0.3947\n",
      "Epoch [2/3], Phase: train, Batch: [69/730], Loss: 0.3296\n",
      "Epoch [2/3], Phase: train, Batch: [70/730], Loss: 0.2346\n",
      "Epoch [2/3], Phase: train, Batch: [71/730], Loss: 0.2937\n",
      "Epoch [2/3], Phase: train, Batch: [72/730], Loss: 0.2611\n",
      "Epoch [2/3], Phase: train, Batch: [73/730], Loss: 0.3606\n",
      "Epoch [2/3], Phase: train, Batch: [74/730], Loss: 0.3128\n",
      "Epoch [2/3], Phase: train, Batch: [75/730], Loss: 0.2455\n",
      "Epoch [2/3], Phase: train, Batch: [76/730], Loss: 0.3788\n",
      "Epoch [2/3], Phase: train, Batch: [77/730], Loss: 0.3194\n",
      "Epoch [2/3], Phase: train, Batch: [78/730], Loss: 0.2552\n",
      "Epoch [2/3], Phase: train, Batch: [79/730], Loss: 0.2516\n",
      "Epoch [2/3], Phase: train, Batch: [80/730], Loss: 0.2806\n",
      "Epoch [2/3], Phase: train, Batch: [81/730], Loss: 0.2743\n",
      "Epoch [2/3], Phase: train, Batch: [82/730], Loss: 0.2462\n",
      "Epoch [2/3], Phase: train, Batch: [83/730], Loss: 0.3718\n",
      "Epoch [2/3], Phase: train, Batch: [84/730], Loss: 0.2928\n",
      "Epoch [2/3], Phase: train, Batch: [85/730], Loss: 0.2582\n",
      "Epoch [2/3], Phase: train, Batch: [86/730], Loss: 0.3975\n",
      "Epoch [2/3], Phase: train, Batch: [87/730], Loss: 0.2083\n",
      "Epoch [2/3], Phase: train, Batch: [88/730], Loss: 0.2364\n",
      "Epoch [2/3], Phase: train, Batch: [89/730], Loss: 0.2706\n",
      "Epoch [2/3], Phase: train, Batch: [90/730], Loss: 0.3895\n",
      "Epoch [2/3], Phase: train, Batch: [91/730], Loss: 0.1836\n",
      "Epoch [2/3], Phase: train, Batch: [92/730], Loss: 0.2995\n",
      "Epoch [2/3], Phase: train, Batch: [93/730], Loss: 0.3370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Phase: train, Batch: [94/730], Loss: 0.2479\n",
      "Epoch [2/3], Phase: train, Batch: [95/730], Loss: 0.1868\n",
      "Epoch [2/3], Phase: train, Batch: [96/730], Loss: 0.2580\n",
      "Epoch [2/3], Phase: train, Batch: [97/730], Loss: 0.3349\n",
      "Epoch [2/3], Phase: train, Batch: [98/730], Loss: 0.2994\n",
      "Epoch [2/3], Phase: train, Batch: [99/730], Loss: 0.2728\n",
      "Epoch [2/3], Phase: train, Batch: [100/730], Loss: 0.3810\n",
      "Epoch [2/3], Phase: train, Batch: [101/730], Loss: 0.3188\n",
      "Epoch [2/3], Phase: train, Batch: [102/730], Loss: 0.3077\n",
      "Epoch [2/3], Phase: train, Batch: [103/730], Loss: 0.2629\n",
      "Epoch [2/3], Phase: train, Batch: [104/730], Loss: 0.3601\n",
      "Epoch [2/3], Phase: train, Batch: [105/730], Loss: 0.2357\n",
      "Epoch [2/3], Phase: train, Batch: [106/730], Loss: 0.3079\n",
      "Epoch [2/3], Phase: train, Batch: [107/730], Loss: 0.2314\n",
      "Epoch [2/3], Phase: train, Batch: [108/730], Loss: 0.2348\n",
      "Epoch [2/3], Phase: train, Batch: [109/730], Loss: 0.4168\n",
      "Epoch [2/3], Phase: train, Batch: [110/730], Loss: 0.3672\n",
      "Epoch [2/3], Phase: train, Batch: [111/730], Loss: 0.3107\n",
      "Epoch [2/3], Phase: train, Batch: [112/730], Loss: 0.2716\n",
      "Epoch [2/3], Phase: train, Batch: [113/730], Loss: 0.1964\n",
      "Epoch [2/3], Phase: train, Batch: [114/730], Loss: 0.4032\n",
      "Epoch [2/3], Phase: train, Batch: [115/730], Loss: 0.3002\n",
      "Epoch [2/3], Phase: train, Batch: [116/730], Loss: 0.2731\n",
      "Epoch [2/3], Phase: train, Batch: [117/730], Loss: 0.2819\n",
      "Epoch [2/3], Phase: train, Batch: [118/730], Loss: 0.3973\n",
      "Epoch [2/3], Phase: train, Batch: [119/730], Loss: 0.4320\n",
      "Epoch [2/3], Phase: train, Batch: [120/730], Loss: 0.1977\n",
      "Epoch [2/3], Phase: train, Batch: [121/730], Loss: 0.2270\n",
      "Epoch [2/3], Phase: train, Batch: [122/730], Loss: 0.2184\n",
      "Epoch [2/3], Phase: train, Batch: [123/730], Loss: 0.1835\n",
      "Epoch [2/3], Phase: train, Batch: [124/730], Loss: 0.3982\n",
      "Epoch [2/3], Phase: train, Batch: [125/730], Loss: 0.2261\n",
      "Epoch [2/3], Phase: train, Batch: [126/730], Loss: 0.2178\n",
      "Epoch [2/3], Phase: train, Batch: [127/730], Loss: 0.2328\n",
      "Epoch [2/3], Phase: train, Batch: [128/730], Loss: 0.3124\n",
      "Epoch [2/3], Phase: train, Batch: [129/730], Loss: 0.2648\n",
      "Epoch [2/3], Phase: train, Batch: [130/730], Loss: 0.3690\n",
      "Epoch [2/3], Phase: train, Batch: [131/730], Loss: 0.3069\n",
      "Epoch [2/3], Phase: train, Batch: [132/730], Loss: 0.3375\n",
      "Epoch [2/3], Phase: train, Batch: [133/730], Loss: 0.3439\n",
      "Epoch [2/3], Phase: train, Batch: [134/730], Loss: 0.2965\n",
      "Epoch [2/3], Phase: train, Batch: [135/730], Loss: 0.3233\n",
      "Epoch [2/3], Phase: train, Batch: [136/730], Loss: 0.2707\n",
      "Epoch [2/3], Phase: train, Batch: [137/730], Loss: 0.4163\n",
      "Epoch [2/3], Phase: train, Batch: [138/730], Loss: 0.3382\n",
      "Epoch [2/3], Phase: train, Batch: [139/730], Loss: 0.4001\n",
      "Epoch [2/3], Phase: train, Batch: [140/730], Loss: 0.2689\n",
      "Epoch [2/3], Phase: train, Batch: [141/730], Loss: 0.2298\n",
      "Epoch [2/3], Phase: train, Batch: [142/730], Loss: 0.2835\n",
      "Epoch [2/3], Phase: train, Batch: [143/730], Loss: 0.3363\n",
      "Epoch [2/3], Phase: train, Batch: [144/730], Loss: 0.2783\n",
      "Epoch [2/3], Phase: train, Batch: [145/730], Loss: 0.4096\n",
      "Epoch [2/3], Phase: train, Batch: [146/730], Loss: 0.1609\n",
      "Epoch [2/3], Phase: train, Batch: [147/730], Loss: 0.2770\n",
      "Epoch [2/3], Phase: train, Batch: [148/730], Loss: 0.2818\n",
      "Epoch [2/3], Phase: train, Batch: [149/730], Loss: 0.1541\n",
      "Epoch [2/3], Phase: train, Batch: [150/730], Loss: 0.2206\n",
      "Epoch [2/3], Phase: train, Batch: [151/730], Loss: 0.2711\n",
      "Epoch [2/3], Phase: train, Batch: [152/730], Loss: 0.2487\n",
      "Epoch [2/3], Phase: train, Batch: [153/730], Loss: 0.2798\n",
      "Epoch [2/3], Phase: train, Batch: [154/730], Loss: 0.3038\n",
      "Epoch [2/3], Phase: train, Batch: [155/730], Loss: 0.4527\n",
      "Epoch [2/3], Phase: train, Batch: [156/730], Loss: 0.3071\n",
      "Epoch [2/3], Phase: train, Batch: [157/730], Loss: 0.2168\n",
      "Epoch [2/3], Phase: train, Batch: [158/730], Loss: 0.2073\n",
      "Epoch [2/3], Phase: train, Batch: [159/730], Loss: 0.3225\n",
      "Epoch [2/3], Phase: train, Batch: [160/730], Loss: 0.2484\n",
      "Epoch [2/3], Phase: train, Batch: [161/730], Loss: 0.2237\n",
      "Epoch [2/3], Phase: train, Batch: [162/730], Loss: 0.1911\n",
      "Epoch [2/3], Phase: train, Batch: [163/730], Loss: 0.4148\n",
      "Epoch [2/3], Phase: train, Batch: [164/730], Loss: 0.2995\n",
      "Epoch [2/3], Phase: train, Batch: [165/730], Loss: 0.2813\n",
      "Epoch [2/3], Phase: train, Batch: [166/730], Loss: 0.2657\n",
      "Epoch [2/3], Phase: train, Batch: [167/730], Loss: 0.3677\n",
      "Epoch [2/3], Phase: train, Batch: [168/730], Loss: 0.3794\n",
      "Epoch [2/3], Phase: train, Batch: [169/730], Loss: 0.1805\n",
      "Epoch [2/3], Phase: train, Batch: [170/730], Loss: 0.4005\n",
      "Epoch [2/3], Phase: train, Batch: [171/730], Loss: 0.2192\n",
      "Epoch [2/3], Phase: train, Batch: [172/730], Loss: 0.3187\n",
      "Epoch [2/3], Phase: train, Batch: [173/730], Loss: 0.3360\n",
      "Epoch [2/3], Phase: train, Batch: [174/730], Loss: 0.2678\n",
      "Epoch [2/3], Phase: train, Batch: [175/730], Loss: 0.2350\n",
      "Epoch [2/3], Phase: train, Batch: [176/730], Loss: 0.2024\n",
      "Epoch [2/3], Phase: train, Batch: [177/730], Loss: 0.2768\n",
      "Epoch [2/3], Phase: train, Batch: [178/730], Loss: 0.3213\n",
      "Epoch [2/3], Phase: train, Batch: [179/730], Loss: 0.3469\n",
      "Epoch [2/3], Phase: train, Batch: [180/730], Loss: 0.2603\n",
      "Epoch [2/3], Phase: train, Batch: [181/730], Loss: 0.2689\n",
      "Epoch [2/3], Phase: train, Batch: [182/730], Loss: 0.4478\n",
      "Epoch [2/3], Phase: train, Batch: [183/730], Loss: 0.1936\n",
      "Epoch [2/3], Phase: train, Batch: [184/730], Loss: 0.2839\n",
      "Epoch [2/3], Phase: train, Batch: [185/730], Loss: 0.3118\n",
      "Epoch [2/3], Phase: train, Batch: [186/730], Loss: 0.3244\n",
      "Epoch [2/3], Phase: train, Batch: [187/730], Loss: 0.2632\n",
      "Epoch [2/3], Phase: train, Batch: [188/730], Loss: 0.2960\n",
      "Epoch [2/3], Phase: train, Batch: [189/730], Loss: 0.3295\n",
      "Epoch [2/3], Phase: train, Batch: [190/730], Loss: 0.4401\n",
      "Epoch [2/3], Phase: train, Batch: [191/730], Loss: 0.3501\n",
      "Epoch [2/3], Phase: train, Batch: [192/730], Loss: 0.2560\n",
      "Epoch [2/3], Phase: train, Batch: [193/730], Loss: 0.4461\n",
      "Epoch [2/3], Phase: train, Batch: [194/730], Loss: 0.3612\n",
      "Epoch [2/3], Phase: train, Batch: [195/730], Loss: 0.3084\n",
      "Epoch [2/3], Phase: train, Batch: [196/730], Loss: 0.2591\n",
      "Epoch [2/3], Phase: train, Batch: [197/730], Loss: 0.3362\n",
      "Epoch [2/3], Phase: train, Batch: [198/730], Loss: 0.3388\n",
      "Epoch [2/3], Phase: train, Batch: [199/730], Loss: 0.2926\n",
      "Epoch [2/3], Phase: train, Batch: [200/730], Loss: 0.2415\n",
      "Epoch [2/3], Phase: train, Batch: [201/730], Loss: 0.2655\n",
      "Epoch [2/3], Phase: train, Batch: [202/730], Loss: 0.2084\n",
      "Epoch [2/3], Phase: train, Batch: [203/730], Loss: 0.2989\n",
      "Epoch [2/3], Phase: train, Batch: [204/730], Loss: 0.3142\n",
      "Epoch [2/3], Phase: train, Batch: [205/730], Loss: 0.3503\n",
      "Epoch [2/3], Phase: train, Batch: [206/730], Loss: 0.2745\n",
      "Epoch [2/3], Phase: train, Batch: [207/730], Loss: 0.2309\n",
      "Epoch [2/3], Phase: train, Batch: [208/730], Loss: 0.1968\n",
      "Epoch [2/3], Phase: train, Batch: [209/730], Loss: 0.2654\n",
      "Epoch [2/3], Phase: train, Batch: [210/730], Loss: 0.3006\n",
      "Epoch [2/3], Phase: train, Batch: [211/730], Loss: 0.3622\n",
      "Epoch [2/3], Phase: train, Batch: [212/730], Loss: 0.3237\n",
      "Epoch [2/3], Phase: train, Batch: [213/730], Loss: 0.2516\n",
      "Epoch [2/3], Phase: train, Batch: [214/730], Loss: 0.3692\n",
      "Epoch [2/3], Phase: train, Batch: [215/730], Loss: 0.2423\n",
      "Epoch [2/3], Phase: train, Batch: [216/730], Loss: 0.2627\n",
      "Epoch [2/3], Phase: train, Batch: [217/730], Loss: 0.4469\n",
      "Epoch [2/3], Phase: train, Batch: [218/730], Loss: 0.1420\n",
      "Epoch [2/3], Phase: train, Batch: [219/730], Loss: 0.2925\n",
      "Epoch [2/3], Phase: train, Batch: [220/730], Loss: 0.2605\n",
      "Epoch [2/3], Phase: train, Batch: [221/730], Loss: 0.2926\n",
      "Epoch [2/3], Phase: train, Batch: [222/730], Loss: 0.2407\n",
      "Epoch [2/3], Phase: train, Batch: [223/730], Loss: 0.3293\n",
      "Epoch [2/3], Phase: train, Batch: [224/730], Loss: 0.2593\n",
      "Epoch [2/3], Phase: train, Batch: [225/730], Loss: 0.2072\n",
      "Epoch [2/3], Phase: train, Batch: [226/730], Loss: 0.2599\n",
      "Epoch [2/3], Phase: train, Batch: [227/730], Loss: 0.3272\n",
      "Epoch [2/3], Phase: train, Batch: [228/730], Loss: 0.3179\n",
      "Epoch [2/3], Phase: train, Batch: [229/730], Loss: 0.2400\n",
      "Epoch [2/3], Phase: train, Batch: [230/730], Loss: 0.2575\n",
      "Epoch [2/3], Phase: train, Batch: [231/730], Loss: 0.1838\n",
      "Epoch [2/3], Phase: train, Batch: [232/730], Loss: 0.4623\n",
      "Epoch [2/3], Phase: train, Batch: [233/730], Loss: 0.3548\n",
      "Epoch [2/3], Phase: train, Batch: [234/730], Loss: 0.2510\n",
      "Epoch [2/3], Phase: train, Batch: [235/730], Loss: 0.4241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Phase: train, Batch: [236/730], Loss: 0.3120\n",
      "Epoch [2/3], Phase: train, Batch: [237/730], Loss: 0.2539\n",
      "Epoch [2/3], Phase: train, Batch: [238/730], Loss: 0.4449\n",
      "Epoch [2/3], Phase: train, Batch: [239/730], Loss: 0.4107\n",
      "Epoch [2/3], Phase: train, Batch: [240/730], Loss: 0.2708\n",
      "Epoch [2/3], Phase: train, Batch: [241/730], Loss: 0.2541\n",
      "Epoch [2/3], Phase: train, Batch: [242/730], Loss: 0.1680\n",
      "Epoch [2/3], Phase: train, Batch: [243/730], Loss: 0.4344\n",
      "Epoch [2/3], Phase: train, Batch: [244/730], Loss: 0.1323\n",
      "Epoch [2/3], Phase: train, Batch: [245/730], Loss: 0.2243\n",
      "Epoch [2/3], Phase: train, Batch: [246/730], Loss: 0.2643\n",
      "Epoch [2/3], Phase: train, Batch: [247/730], Loss: 0.2407\n",
      "Epoch [2/3], Phase: train, Batch: [248/730], Loss: 0.3051\n",
      "Epoch [2/3], Phase: train, Batch: [249/730], Loss: 0.3413\n",
      "Epoch [2/3], Phase: train, Batch: [250/730], Loss: 0.2410\n",
      "Epoch [2/3], Phase: train, Batch: [251/730], Loss: 0.2461\n",
      "Epoch [2/3], Phase: train, Batch: [252/730], Loss: 0.2661\n",
      "Epoch [2/3], Phase: train, Batch: [253/730], Loss: 0.3631\n",
      "Epoch [2/3], Phase: train, Batch: [254/730], Loss: 0.2367\n",
      "Epoch [2/3], Phase: train, Batch: [255/730], Loss: 0.4295\n",
      "Epoch [2/3], Phase: train, Batch: [256/730], Loss: 0.3238\n",
      "Epoch [2/3], Phase: train, Batch: [257/730], Loss: 0.2484\n",
      "Epoch [2/3], Phase: train, Batch: [258/730], Loss: 0.2512\n",
      "Epoch [2/3], Phase: train, Batch: [259/730], Loss: 0.2417\n",
      "Epoch [2/3], Phase: train, Batch: [260/730], Loss: 0.3190\n",
      "Epoch [2/3], Phase: train, Batch: [261/730], Loss: 0.3439\n",
      "Epoch [2/3], Phase: train, Batch: [262/730], Loss: 0.2936\n",
      "Epoch [2/3], Phase: train, Batch: [263/730], Loss: 0.3006\n",
      "Epoch [2/3], Phase: train, Batch: [264/730], Loss: 0.2981\n",
      "Epoch [2/3], Phase: train, Batch: [265/730], Loss: 0.4214\n",
      "Epoch [2/3], Phase: train, Batch: [266/730], Loss: 0.3914\n",
      "Epoch [2/3], Phase: train, Batch: [267/730], Loss: 0.6458\n",
      "Epoch [2/3], Phase: train, Batch: [268/730], Loss: 0.2986\n",
      "Epoch [2/3], Phase: train, Batch: [269/730], Loss: 0.3258\n",
      "Epoch [2/3], Phase: train, Batch: [270/730], Loss: 0.4673\n",
      "Epoch [2/3], Phase: train, Batch: [271/730], Loss: 0.1747\n",
      "Epoch [2/3], Phase: train, Batch: [272/730], Loss: 0.4011\n",
      "Epoch [2/3], Phase: train, Batch: [273/730], Loss: 0.3488\n",
      "Epoch [2/3], Phase: train, Batch: [274/730], Loss: 0.4126\n",
      "Epoch [2/3], Phase: train, Batch: [275/730], Loss: 0.2879\n",
      "Epoch [2/3], Phase: train, Batch: [276/730], Loss: 0.2852\n",
      "Epoch [2/3], Phase: train, Batch: [277/730], Loss: 0.2704\n",
      "Epoch [2/3], Phase: train, Batch: [278/730], Loss: 0.2619\n",
      "Epoch [2/3], Phase: train, Batch: [279/730], Loss: 0.2453\n",
      "Epoch [2/3], Phase: train, Batch: [280/730], Loss: 0.2991\n",
      "Epoch [2/3], Phase: train, Batch: [281/730], Loss: 0.2781\n",
      "Epoch [2/3], Phase: train, Batch: [282/730], Loss: 0.2103\n",
      "Epoch [2/3], Phase: train, Batch: [283/730], Loss: 0.2039\n",
      "Epoch [2/3], Phase: train, Batch: [284/730], Loss: 0.3290\n",
      "Epoch [2/3], Phase: train, Batch: [285/730], Loss: 0.3495\n",
      "Epoch [2/3], Phase: train, Batch: [286/730], Loss: 0.3395\n",
      "Epoch [2/3], Phase: train, Batch: [287/730], Loss: 0.2869\n",
      "Epoch [2/3], Phase: train, Batch: [288/730], Loss: 0.2567\n",
      "Epoch [2/3], Phase: train, Batch: [289/730], Loss: 0.2691\n",
      "Epoch [2/3], Phase: train, Batch: [290/730], Loss: 0.2006\n",
      "Epoch [2/3], Phase: train, Batch: [291/730], Loss: 0.1935\n",
      "Epoch [2/3], Phase: train, Batch: [292/730], Loss: 0.2098\n",
      "Epoch [2/3], Phase: train, Batch: [293/730], Loss: 0.2787\n",
      "Epoch [2/3], Phase: train, Batch: [294/730], Loss: 0.2408\n",
      "Epoch [2/3], Phase: train, Batch: [295/730], Loss: 0.2698\n",
      "Epoch [2/3], Phase: train, Batch: [296/730], Loss: 0.3541\n",
      "Epoch [2/3], Phase: train, Batch: [297/730], Loss: 0.2947\n",
      "Epoch [2/3], Phase: train, Batch: [298/730], Loss: 0.3536\n",
      "Epoch [2/3], Phase: train, Batch: [299/730], Loss: 0.3230\n",
      "Epoch [2/3], Phase: train, Batch: [300/730], Loss: 0.5483\n",
      "Epoch [2/3], Phase: train, Batch: [301/730], Loss: 0.2548\n",
      "Epoch [2/3], Phase: train, Batch: [302/730], Loss: 0.2171\n",
      "Epoch [2/3], Phase: train, Batch: [303/730], Loss: 0.2348\n",
      "Epoch [2/3], Phase: train, Batch: [304/730], Loss: 0.1384\n",
      "Epoch [2/3], Phase: train, Batch: [305/730], Loss: 0.3693\n",
      "Epoch [2/3], Phase: train, Batch: [306/730], Loss: 0.3475\n",
      "Epoch [2/3], Phase: train, Batch: [307/730], Loss: 0.3118\n",
      "Epoch [2/3], Phase: train, Batch: [308/730], Loss: 0.3392\n",
      "Epoch [2/3], Phase: train, Batch: [309/730], Loss: 0.3329\n",
      "Epoch [2/3], Phase: train, Batch: [310/730], Loss: 0.2690\n",
      "Epoch [2/3], Phase: train, Batch: [311/730], Loss: 0.2393\n",
      "Epoch [2/3], Phase: train, Batch: [312/730], Loss: 0.2487\n",
      "Epoch [2/3], Phase: train, Batch: [313/730], Loss: 0.2738\n",
      "Epoch [2/3], Phase: train, Batch: [314/730], Loss: 0.3011\n",
      "Epoch [2/3], Phase: train, Batch: [315/730], Loss: 0.3201\n",
      "Epoch [2/3], Phase: train, Batch: [316/730], Loss: 0.2707\n",
      "Epoch [2/3], Phase: train, Batch: [317/730], Loss: 0.3132\n",
      "Epoch [2/3], Phase: train, Batch: [318/730], Loss: 0.2901\n",
      "Epoch [2/3], Phase: train, Batch: [319/730], Loss: 0.1543\n",
      "Epoch [2/3], Phase: train, Batch: [320/730], Loss: 0.2300\n",
      "Epoch [2/3], Phase: train, Batch: [321/730], Loss: 0.3337\n",
      "Epoch [2/3], Phase: train, Batch: [322/730], Loss: 0.3068\n",
      "Epoch [2/3], Phase: train, Batch: [323/730], Loss: 0.2822\n",
      "Epoch [2/3], Phase: train, Batch: [324/730], Loss: 0.3250\n",
      "Epoch [2/3], Phase: train, Batch: [325/730], Loss: 0.3569\n",
      "Epoch [2/3], Phase: train, Batch: [326/730], Loss: 0.3859\n",
      "Epoch [2/3], Phase: train, Batch: [327/730], Loss: 0.3037\n",
      "Epoch [2/3], Phase: train, Batch: [328/730], Loss: 0.2187\n",
      "Epoch [2/3], Phase: train, Batch: [329/730], Loss: 0.2676\n",
      "Epoch [2/3], Phase: train, Batch: [330/730], Loss: 0.2335\n",
      "Epoch [2/3], Phase: train, Batch: [331/730], Loss: 0.4030\n",
      "Epoch [2/3], Phase: train, Batch: [332/730], Loss: 0.1823\n",
      "Epoch [2/3], Phase: train, Batch: [333/730], Loss: 0.2191\n",
      "Epoch [2/3], Phase: train, Batch: [334/730], Loss: 0.3077\n",
      "Epoch [2/3], Phase: train, Batch: [335/730], Loss: 0.3169\n",
      "Epoch [2/3], Phase: train, Batch: [336/730], Loss: 0.1838\n",
      "Epoch [2/3], Phase: train, Batch: [337/730], Loss: 0.5474\n",
      "Epoch [2/3], Phase: train, Batch: [338/730], Loss: 0.3542\n",
      "Epoch [2/3], Phase: train, Batch: [339/730], Loss: 0.2273\n",
      "Epoch [2/3], Phase: train, Batch: [340/730], Loss: 0.3912\n",
      "Epoch [2/3], Phase: train, Batch: [341/730], Loss: 0.3146\n",
      "Epoch [2/3], Phase: train, Batch: [342/730], Loss: 0.3420\n",
      "Epoch [2/3], Phase: train, Batch: [343/730], Loss: 0.3446\n",
      "Epoch [2/3], Phase: train, Batch: [344/730], Loss: 0.3646\n",
      "Epoch [2/3], Phase: train, Batch: [345/730], Loss: 0.1563\n",
      "Epoch [2/3], Phase: train, Batch: [346/730], Loss: 0.2437\n",
      "Epoch [2/3], Phase: train, Batch: [347/730], Loss: 0.2180\n",
      "Epoch [2/3], Phase: train, Batch: [348/730], Loss: 0.3199\n",
      "Epoch [2/3], Phase: train, Batch: [349/730], Loss: 0.2353\n",
      "Epoch [2/3], Phase: train, Batch: [350/730], Loss: 0.3242\n",
      "Epoch [2/3], Phase: train, Batch: [351/730], Loss: 0.4749\n",
      "Epoch [2/3], Phase: train, Batch: [352/730], Loss: 0.1879\n",
      "Epoch [2/3], Phase: train, Batch: [353/730], Loss: 0.4221\n",
      "Epoch [2/3], Phase: train, Batch: [354/730], Loss: 0.3386\n",
      "Epoch [2/3], Phase: train, Batch: [355/730], Loss: 0.2069\n",
      "Epoch [2/3], Phase: train, Batch: [356/730], Loss: 0.1276\n",
      "Epoch [2/3], Phase: train, Batch: [357/730], Loss: 0.2951\n",
      "Epoch [2/3], Phase: train, Batch: [358/730], Loss: 0.2823\n",
      "Epoch [2/3], Phase: train, Batch: [359/730], Loss: 0.3442\n",
      "Epoch [2/3], Phase: train, Batch: [360/730], Loss: 0.2299\n",
      "Epoch [2/3], Phase: train, Batch: [361/730], Loss: 0.2645\n",
      "Epoch [2/3], Phase: train, Batch: [362/730], Loss: 0.3033\n",
      "Epoch [2/3], Phase: train, Batch: [363/730], Loss: 0.3926\n",
      "Epoch [2/3], Phase: train, Batch: [364/730], Loss: 0.3024\n",
      "Epoch [2/3], Phase: train, Batch: [365/730], Loss: 0.1554\n",
      "Epoch [2/3], Phase: train, Batch: [366/730], Loss: 0.2305\n",
      "Epoch [2/3], Phase: train, Batch: [367/730], Loss: 0.2246\n",
      "Epoch [2/3], Phase: train, Batch: [368/730], Loss: 0.2743\n",
      "Epoch [2/3], Phase: train, Batch: [369/730], Loss: 0.3125\n",
      "Epoch [2/3], Phase: train, Batch: [370/730], Loss: 0.2555\n",
      "Epoch [2/3], Phase: train, Batch: [371/730], Loss: 0.2345\n",
      "Epoch [2/3], Phase: train, Batch: [372/730], Loss: 0.3422\n",
      "Epoch [2/3], Phase: train, Batch: [373/730], Loss: 0.3304\n",
      "Epoch [2/3], Phase: train, Batch: [374/730], Loss: 0.2490\n",
      "Epoch [2/3], Phase: train, Batch: [375/730], Loss: 0.1755\n",
      "Epoch [2/3], Phase: train, Batch: [376/730], Loss: 0.2357\n",
      "Epoch [2/3], Phase: train, Batch: [377/730], Loss: 0.2615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Phase: train, Batch: [378/730], Loss: 0.1667\n",
      "Epoch [2/3], Phase: train, Batch: [379/730], Loss: 0.3167\n",
      "Epoch [2/3], Phase: train, Batch: [380/730], Loss: 0.2700\n",
      "Epoch [2/3], Phase: train, Batch: [381/730], Loss: 0.4245\n",
      "Epoch [2/3], Phase: train, Batch: [382/730], Loss: 0.3765\n",
      "Epoch [2/3], Phase: train, Batch: [383/730], Loss: 0.2832\n",
      "Epoch [2/3], Phase: train, Batch: [384/730], Loss: 0.2426\n",
      "Epoch [2/3], Phase: train, Batch: [385/730], Loss: 0.3374\n",
      "Epoch [2/3], Phase: train, Batch: [386/730], Loss: 0.3866\n",
      "Epoch [2/3], Phase: train, Batch: [387/730], Loss: 0.1987\n",
      "Epoch [2/3], Phase: train, Batch: [388/730], Loss: 0.3323\n",
      "Epoch [2/3], Phase: train, Batch: [389/730], Loss: 0.2287\n",
      "Epoch [2/3], Phase: train, Batch: [390/730], Loss: 0.2591\n",
      "Epoch [2/3], Phase: train, Batch: [391/730], Loss: 0.3801\n",
      "Epoch [2/3], Phase: train, Batch: [392/730], Loss: 0.5815\n",
      "Epoch [2/3], Phase: train, Batch: [393/730], Loss: 0.4100\n",
      "Epoch [2/3], Phase: train, Batch: [394/730], Loss: 0.1837\n",
      "Epoch [2/3], Phase: train, Batch: [395/730], Loss: 0.2703\n",
      "Epoch [2/3], Phase: train, Batch: [396/730], Loss: 0.2276\n",
      "Epoch [2/3], Phase: train, Batch: [397/730], Loss: 0.2905\n",
      "Epoch [2/3], Phase: train, Batch: [398/730], Loss: 0.3270\n",
      "Epoch [2/3], Phase: train, Batch: [399/730], Loss: 0.2171\n",
      "Epoch [2/3], Phase: train, Batch: [400/730], Loss: 0.2959\n",
      "Epoch [2/3], Phase: train, Batch: [401/730], Loss: 0.2697\n",
      "Epoch [2/3], Phase: train, Batch: [402/730], Loss: 0.2073\n",
      "Epoch [2/3], Phase: train, Batch: [403/730], Loss: 0.2929\n",
      "Epoch [2/3], Phase: train, Batch: [404/730], Loss: 0.2617\n",
      "Epoch [2/3], Phase: train, Batch: [405/730], Loss: 0.3670\n",
      "Epoch [2/3], Phase: train, Batch: [406/730], Loss: 0.2891\n",
      "Epoch [2/3], Phase: train, Batch: [407/730], Loss: 0.3096\n",
      "Epoch [2/3], Phase: train, Batch: [408/730], Loss: 0.3223\n",
      "Epoch [2/3], Phase: train, Batch: [409/730], Loss: 0.3211\n",
      "Epoch [2/3], Phase: train, Batch: [410/730], Loss: 0.2065\n",
      "Epoch [2/3], Phase: train, Batch: [411/730], Loss: 0.2757\n",
      "Epoch [2/3], Phase: train, Batch: [412/730], Loss: 0.2502\n",
      "Epoch [2/3], Phase: train, Batch: [413/730], Loss: 0.2265\n",
      "Epoch [2/3], Phase: train, Batch: [414/730], Loss: 0.2078\n",
      "Epoch [2/3], Phase: train, Batch: [415/730], Loss: 0.2133\n",
      "Epoch [2/3], Phase: train, Batch: [416/730], Loss: 0.2490\n",
      "Epoch [2/3], Phase: train, Batch: [417/730], Loss: 0.2079\n",
      "Epoch [2/3], Phase: train, Batch: [418/730], Loss: 0.2782\n",
      "Epoch [2/3], Phase: train, Batch: [419/730], Loss: 0.2472\n",
      "Epoch [2/3], Phase: train, Batch: [420/730], Loss: 0.3017\n",
      "Epoch [2/3], Phase: train, Batch: [421/730], Loss: 0.1616\n",
      "Epoch [2/3], Phase: train, Batch: [422/730], Loss: 0.3195\n",
      "Epoch [2/3], Phase: train, Batch: [423/730], Loss: 0.4613\n",
      "Epoch [2/3], Phase: train, Batch: [424/730], Loss: 0.3331\n",
      "Epoch [2/3], Phase: train, Batch: [425/730], Loss: 0.3157\n",
      "Epoch [2/3], Phase: train, Batch: [426/730], Loss: 0.3839\n",
      "Epoch [2/3], Phase: train, Batch: [427/730], Loss: 0.3958\n",
      "Epoch [2/3], Phase: train, Batch: [428/730], Loss: 0.1968\n",
      "Epoch [2/3], Phase: train, Batch: [429/730], Loss: 0.4493\n",
      "Epoch [2/3], Phase: train, Batch: [430/730], Loss: 0.3055\n",
      "Epoch [2/3], Phase: train, Batch: [431/730], Loss: 0.4135\n",
      "Epoch [2/3], Phase: train, Batch: [432/730], Loss: 0.3874\n",
      "Epoch [2/3], Phase: train, Batch: [433/730], Loss: 0.2687\n",
      "Epoch [2/3], Phase: train, Batch: [434/730], Loss: 0.3060\n",
      "Epoch [2/3], Phase: train, Batch: [435/730], Loss: 0.2389\n",
      "Epoch [2/3], Phase: train, Batch: [436/730], Loss: 0.2816\n",
      "Epoch [2/3], Phase: train, Batch: [437/730], Loss: 0.2286\n",
      "Epoch [2/3], Phase: train, Batch: [438/730], Loss: 0.3141\n",
      "Epoch [2/3], Phase: train, Batch: [439/730], Loss: 0.2372\n",
      "Epoch [2/3], Phase: train, Batch: [440/730], Loss: 0.3710\n",
      "Epoch [2/3], Phase: train, Batch: [441/730], Loss: 0.2859\n",
      "Epoch [2/3], Phase: train, Batch: [442/730], Loss: 0.2813\n",
      "Epoch [2/3], Phase: train, Batch: [443/730], Loss: 0.2803\n",
      "Epoch [2/3], Phase: train, Batch: [444/730], Loss: 0.3283\n",
      "Epoch [2/3], Phase: train, Batch: [445/730], Loss: 0.2488\n",
      "Epoch [2/3], Phase: train, Batch: [446/730], Loss: 0.2498\n",
      "Epoch [2/3], Phase: train, Batch: [447/730], Loss: 0.1464\n",
      "Epoch [2/3], Phase: train, Batch: [448/730], Loss: 0.2216\n",
      "Epoch [2/3], Phase: train, Batch: [449/730], Loss: 0.2685\n",
      "Epoch [2/3], Phase: train, Batch: [450/730], Loss: 0.3542\n",
      "Epoch [2/3], Phase: train, Batch: [451/730], Loss: 0.2208\n",
      "Epoch [2/3], Phase: train, Batch: [452/730], Loss: 0.2120\n",
      "Epoch [2/3], Phase: train, Batch: [453/730], Loss: 0.1744\n",
      "Epoch [2/3], Phase: train, Batch: [454/730], Loss: 0.3251\n",
      "Epoch [2/3], Phase: train, Batch: [455/730], Loss: 0.3235\n",
      "Epoch [2/3], Phase: train, Batch: [456/730], Loss: 0.2394\n",
      "Epoch [2/3], Phase: train, Batch: [457/730], Loss: 0.1898\n",
      "Epoch [2/3], Phase: train, Batch: [458/730], Loss: 0.3410\n",
      "Epoch [2/3], Phase: train, Batch: [459/730], Loss: 0.3480\n",
      "Epoch [2/3], Phase: train, Batch: [460/730], Loss: 0.3398\n",
      "Epoch [2/3], Phase: train, Batch: [461/730], Loss: 0.3334\n",
      "Epoch [2/3], Phase: train, Batch: [462/730], Loss: 0.4016\n",
      "Epoch [2/3], Phase: train, Batch: [463/730], Loss: 0.2585\n",
      "Epoch [2/3], Phase: train, Batch: [464/730], Loss: 0.1649\n",
      "Epoch [2/3], Phase: train, Batch: [465/730], Loss: 0.3059\n",
      "Epoch [2/3], Phase: train, Batch: [466/730], Loss: 0.2802\n",
      "Epoch [2/3], Phase: train, Batch: [467/730], Loss: 0.2600\n",
      "Epoch [2/3], Phase: train, Batch: [468/730], Loss: 0.2955\n",
      "Epoch [2/3], Phase: train, Batch: [469/730], Loss: 0.1696\n",
      "Epoch [2/3], Phase: train, Batch: [470/730], Loss: 0.3053\n",
      "Epoch [2/3], Phase: train, Batch: [471/730], Loss: 0.1713\n",
      "Epoch [2/3], Phase: train, Batch: [472/730], Loss: 0.2707\n",
      "Epoch [2/3], Phase: train, Batch: [473/730], Loss: 0.2890\n",
      "Epoch [2/3], Phase: train, Batch: [474/730], Loss: 0.2956\n",
      "Epoch [2/3], Phase: train, Batch: [475/730], Loss: 0.2129\n",
      "Epoch [2/3], Phase: train, Batch: [476/730], Loss: 0.4255\n",
      "Epoch [2/3], Phase: train, Batch: [477/730], Loss: 0.4726\n",
      "Epoch [2/3], Phase: train, Batch: [478/730], Loss: 0.1920\n",
      "Epoch [2/3], Phase: train, Batch: [479/730], Loss: 0.2845\n",
      "Epoch [2/3], Phase: train, Batch: [480/730], Loss: 0.2243\n",
      "Epoch [2/3], Phase: train, Batch: [481/730], Loss: 0.2797\n",
      "Epoch [2/3], Phase: train, Batch: [482/730], Loss: 0.3372\n",
      "Epoch [2/3], Phase: train, Batch: [483/730], Loss: 0.3164\n",
      "Epoch [2/3], Phase: train, Batch: [484/730], Loss: 0.3221\n",
      "Epoch [2/3], Phase: train, Batch: [485/730], Loss: 0.2702\n",
      "Epoch [2/3], Phase: train, Batch: [486/730], Loss: 0.2494\n",
      "Epoch [2/3], Phase: train, Batch: [487/730], Loss: 0.2403\n",
      "Epoch [2/3], Phase: train, Batch: [488/730], Loss: 0.3906\n",
      "Epoch [2/3], Phase: train, Batch: [489/730], Loss: 0.2619\n",
      "Epoch [2/3], Phase: train, Batch: [490/730], Loss: 0.3726\n",
      "Epoch [2/3], Phase: train, Batch: [491/730], Loss: 0.2571\n",
      "Epoch [2/3], Phase: train, Batch: [492/730], Loss: 0.2811\n",
      "Epoch [2/3], Phase: train, Batch: [493/730], Loss: 0.3572\n",
      "Epoch [2/3], Phase: train, Batch: [494/730], Loss: 0.2438\n",
      "Epoch [2/3], Phase: train, Batch: [495/730], Loss: 0.1726\n",
      "Epoch [2/3], Phase: train, Batch: [496/730], Loss: 0.3002\n",
      "Epoch [2/3], Phase: train, Batch: [497/730], Loss: 0.3871\n",
      "Epoch [2/3], Phase: train, Batch: [498/730], Loss: 0.3334\n",
      "Epoch [2/3], Phase: train, Batch: [499/730], Loss: 0.2204\n",
      "Epoch [2/3], Phase: train, Batch: [500/730], Loss: 0.2850\n",
      "Epoch [2/3], Phase: train, Batch: [501/730], Loss: 0.2837\n",
      "Epoch [2/3], Phase: train, Batch: [502/730], Loss: 0.1854\n",
      "Epoch [2/3], Phase: train, Batch: [503/730], Loss: 0.1970\n",
      "Epoch [2/3], Phase: train, Batch: [504/730], Loss: 0.2745\n",
      "Epoch [2/3], Phase: train, Batch: [505/730], Loss: 0.2024\n",
      "Epoch [2/3], Phase: train, Batch: [506/730], Loss: 0.2871\n",
      "Epoch [2/3], Phase: train, Batch: [507/730], Loss: 0.2602\n",
      "Epoch [2/3], Phase: train, Batch: [508/730], Loss: 0.1633\n",
      "Epoch [2/3], Phase: train, Batch: [509/730], Loss: 0.3548\n",
      "Epoch [2/3], Phase: train, Batch: [510/730], Loss: 0.3445\n",
      "Epoch [2/3], Phase: train, Batch: [511/730], Loss: 0.2541\n",
      "Epoch [2/3], Phase: train, Batch: [512/730], Loss: 0.2698\n",
      "Epoch [2/3], Phase: train, Batch: [513/730], Loss: 0.3808\n",
      "Epoch [2/3], Phase: train, Batch: [514/730], Loss: 0.3036\n",
      "Epoch [2/3], Phase: train, Batch: [515/730], Loss: 0.3310\n",
      "Epoch [2/3], Phase: train, Batch: [516/730], Loss: 0.2121\n",
      "Epoch [2/3], Phase: train, Batch: [517/730], Loss: 0.2838\n",
      "Epoch [2/3], Phase: train, Batch: [518/730], Loss: 0.4486\n",
      "Epoch [2/3], Phase: train, Batch: [519/730], Loss: 0.3707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Phase: train, Batch: [520/730], Loss: 0.1630\n",
      "Epoch [2/3], Phase: train, Batch: [521/730], Loss: 0.3545\n",
      "Epoch [2/3], Phase: train, Batch: [522/730], Loss: 0.4566\n",
      "Epoch [2/3], Phase: train, Batch: [523/730], Loss: 0.5642\n",
      "Epoch [2/3], Phase: train, Batch: [524/730], Loss: 0.2222\n",
      "Epoch [2/3], Phase: train, Batch: [525/730], Loss: 0.2605\n",
      "Epoch [2/3], Phase: train, Batch: [526/730], Loss: 0.3538\n",
      "Epoch [2/3], Phase: train, Batch: [527/730], Loss: 0.2488\n",
      "Epoch [2/3], Phase: train, Batch: [528/730], Loss: 0.3927\n",
      "Epoch [2/3], Phase: train, Batch: [529/730], Loss: 0.3792\n",
      "Epoch [2/3], Phase: train, Batch: [530/730], Loss: 0.2402\n",
      "Epoch [2/3], Phase: train, Batch: [531/730], Loss: 0.3005\n",
      "Epoch [2/3], Phase: train, Batch: [532/730], Loss: 0.2448\n",
      "Epoch [2/3], Phase: train, Batch: [533/730], Loss: 0.2528\n",
      "Epoch [2/3], Phase: train, Batch: [534/730], Loss: 0.3182\n",
      "Epoch [2/3], Phase: train, Batch: [535/730], Loss: 0.4784\n",
      "Epoch [2/3], Phase: train, Batch: [536/730], Loss: 0.3550\n",
      "Epoch [2/3], Phase: train, Batch: [537/730], Loss: 0.3523\n",
      "Epoch [2/3], Phase: train, Batch: [538/730], Loss: 0.2812\n",
      "Epoch [2/3], Phase: train, Batch: [539/730], Loss: 0.2329\n",
      "Epoch [2/3], Phase: train, Batch: [540/730], Loss: 0.2525\n",
      "Epoch [2/3], Phase: train, Batch: [541/730], Loss: 0.2524\n",
      "Epoch [2/3], Phase: train, Batch: [542/730], Loss: 0.4173\n",
      "Epoch [2/3], Phase: train, Batch: [543/730], Loss: 0.3483\n",
      "Epoch [2/3], Phase: train, Batch: [544/730], Loss: 0.2117\n",
      "Epoch [2/3], Phase: train, Batch: [545/730], Loss: 0.4200\n",
      "Epoch [2/3], Phase: train, Batch: [546/730], Loss: 0.2653\n",
      "Epoch [2/3], Phase: train, Batch: [547/730], Loss: 0.3847\n",
      "Epoch [2/3], Phase: train, Batch: [548/730], Loss: 0.2264\n",
      "Epoch [2/3], Phase: train, Batch: [549/730], Loss: 0.2467\n",
      "Epoch [2/3], Phase: train, Batch: [550/730], Loss: 0.3108\n",
      "Epoch [2/3], Phase: train, Batch: [551/730], Loss: 0.3698\n",
      "Epoch [2/3], Phase: train, Batch: [552/730], Loss: 0.2670\n",
      "Epoch [2/3], Phase: train, Batch: [553/730], Loss: 0.1583\n",
      "Epoch [2/3], Phase: train, Batch: [554/730], Loss: 0.3379\n",
      "Epoch [2/3], Phase: train, Batch: [555/730], Loss: 0.2475\n",
      "Epoch [2/3], Phase: train, Batch: [556/730], Loss: 0.2473\n",
      "Epoch [2/3], Phase: train, Batch: [557/730], Loss: 0.3004\n",
      "Epoch [2/3], Phase: train, Batch: [558/730], Loss: 0.2978\n",
      "Epoch [2/3], Phase: train, Batch: [559/730], Loss: 0.3877\n",
      "Epoch [2/3], Phase: train, Batch: [560/730], Loss: 0.4006\n",
      "Epoch [2/3], Phase: train, Batch: [561/730], Loss: 0.2396\n",
      "Epoch [2/3], Phase: train, Batch: [562/730], Loss: 0.3242\n",
      "Epoch [2/3], Phase: train, Batch: [563/730], Loss: 0.2622\n",
      "Epoch [2/3], Phase: train, Batch: [564/730], Loss: 0.1997\n",
      "Epoch [2/3], Phase: train, Batch: [565/730], Loss: 0.1408\n",
      "Epoch [2/3], Phase: train, Batch: [566/730], Loss: 0.2499\n",
      "Epoch [2/3], Phase: train, Batch: [567/730], Loss: 0.2771\n",
      "Epoch [2/3], Phase: train, Batch: [568/730], Loss: 0.1985\n",
      "Epoch [2/3], Phase: train, Batch: [569/730], Loss: 0.2561\n",
      "Epoch [2/3], Phase: train, Batch: [570/730], Loss: 0.2283\n",
      "Epoch [2/3], Phase: train, Batch: [571/730], Loss: 0.2319\n",
      "Epoch [2/3], Phase: train, Batch: [572/730], Loss: 0.2301\n",
      "Epoch [2/3], Phase: train, Batch: [573/730], Loss: 0.2100\n",
      "Epoch [2/3], Phase: train, Batch: [574/730], Loss: 0.5515\n",
      "Epoch [2/3], Phase: train, Batch: [575/730], Loss: 0.4406\n",
      "Epoch [2/3], Phase: train, Batch: [576/730], Loss: 0.4318\n",
      "Epoch [2/3], Phase: train, Batch: [577/730], Loss: 0.2393\n",
      "Epoch [2/3], Phase: train, Batch: [578/730], Loss: 0.2550\n",
      "Epoch [2/3], Phase: train, Batch: [579/730], Loss: 0.2935\n",
      "Epoch [2/3], Phase: train, Batch: [580/730], Loss: 0.3676\n",
      "Epoch [2/3], Phase: train, Batch: [581/730], Loss: 0.2551\n",
      "Epoch [2/3], Phase: train, Batch: [582/730], Loss: 0.3859\n",
      "Epoch [2/3], Phase: train, Batch: [583/730], Loss: 0.4147\n",
      "Epoch [2/3], Phase: train, Batch: [584/730], Loss: 0.1997\n",
      "Epoch [2/3], Phase: train, Batch: [585/730], Loss: 0.3091\n",
      "Epoch [2/3], Phase: train, Batch: [586/730], Loss: 0.2242\n",
      "Epoch [2/3], Phase: train, Batch: [587/730], Loss: 0.1862\n",
      "Epoch [2/3], Phase: train, Batch: [588/730], Loss: 0.3073\n",
      "Epoch [2/3], Phase: train, Batch: [589/730], Loss: 0.2544\n",
      "Epoch [2/3], Phase: train, Batch: [590/730], Loss: 0.2825\n",
      "Epoch [2/3], Phase: train, Batch: [591/730], Loss: 0.3911\n",
      "Epoch [2/3], Phase: train, Batch: [592/730], Loss: 0.3865\n",
      "Epoch [2/3], Phase: train, Batch: [593/730], Loss: 0.1442\n",
      "Epoch [2/3], Phase: train, Batch: [594/730], Loss: 0.2896\n",
      "Epoch [2/3], Phase: train, Batch: [595/730], Loss: 0.2930\n",
      "Epoch [2/3], Phase: train, Batch: [596/730], Loss: 0.2810\n",
      "Epoch [2/3], Phase: train, Batch: [597/730], Loss: 0.2028\n",
      "Epoch [2/3], Phase: train, Batch: [598/730], Loss: 0.2515\n",
      "Epoch [2/3], Phase: train, Batch: [599/730], Loss: 0.2512\n",
      "Epoch [2/3], Phase: train, Batch: [600/730], Loss: 0.3410\n",
      "Epoch [2/3], Phase: train, Batch: [601/730], Loss: 0.3567\n",
      "Epoch [2/3], Phase: train, Batch: [602/730], Loss: 0.2657\n",
      "Epoch [2/3], Phase: train, Batch: [603/730], Loss: 0.4187\n",
      "Epoch [2/3], Phase: train, Batch: [604/730], Loss: 0.3837\n",
      "Epoch [2/3], Phase: train, Batch: [605/730], Loss: 0.2899\n",
      "Epoch [2/3], Phase: train, Batch: [606/730], Loss: 0.2144\n",
      "Epoch [2/3], Phase: train, Batch: [607/730], Loss: 0.2740\n",
      "Epoch [2/3], Phase: train, Batch: [608/730], Loss: 0.2849\n",
      "Epoch [2/3], Phase: train, Batch: [609/730], Loss: 0.4009\n",
      "Epoch [2/3], Phase: train, Batch: [610/730], Loss: 0.2988\n",
      "Epoch [2/3], Phase: train, Batch: [611/730], Loss: 0.1349\n",
      "Epoch [2/3], Phase: train, Batch: [612/730], Loss: 0.3344\n",
      "Epoch [2/3], Phase: train, Batch: [613/730], Loss: 0.2992\n",
      "Epoch [2/3], Phase: train, Batch: [614/730], Loss: 0.2534\n",
      "Epoch [2/3], Phase: train, Batch: [615/730], Loss: 0.1558\n",
      "Epoch [2/3], Phase: train, Batch: [616/730], Loss: 0.4436\n",
      "Epoch [2/3], Phase: train, Batch: [617/730], Loss: 0.2005\n",
      "Epoch [2/3], Phase: train, Batch: [618/730], Loss: 0.2710\n",
      "Epoch [2/3], Phase: train, Batch: [619/730], Loss: 0.2316\n",
      "Epoch [2/3], Phase: train, Batch: [620/730], Loss: 0.2260\n",
      "Epoch [2/3], Phase: train, Batch: [621/730], Loss: 0.4935\n",
      "Epoch [2/3], Phase: train, Batch: [622/730], Loss: 0.4479\n",
      "Epoch [2/3], Phase: train, Batch: [623/730], Loss: 0.2697\n",
      "Epoch [2/3], Phase: train, Batch: [624/730], Loss: 0.2612\n",
      "Epoch [2/3], Phase: train, Batch: [625/730], Loss: 0.2790\n",
      "Epoch [2/3], Phase: train, Batch: [626/730], Loss: 0.1787\n",
      "Epoch [2/3], Phase: train, Batch: [627/730], Loss: 0.1792\n",
      "Epoch [2/3], Phase: train, Batch: [628/730], Loss: 0.3119\n",
      "Epoch [2/3], Phase: train, Batch: [629/730], Loss: 0.3332\n",
      "Epoch [2/3], Phase: train, Batch: [630/730], Loss: 0.3238\n",
      "Epoch [2/3], Phase: train, Batch: [631/730], Loss: 0.3075\n",
      "Epoch [2/3], Phase: train, Batch: [632/730], Loss: 0.3426\n",
      "Epoch [2/3], Phase: train, Batch: [633/730], Loss: 0.2325\n",
      "Epoch [2/3], Phase: train, Batch: [634/730], Loss: 0.4673\n",
      "Epoch [2/3], Phase: train, Batch: [635/730], Loss: 0.3931\n",
      "Epoch [2/3], Phase: train, Batch: [636/730], Loss: 0.2363\n",
      "Epoch [2/3], Phase: train, Batch: [637/730], Loss: 0.2274\n",
      "Epoch [2/3], Phase: train, Batch: [638/730], Loss: 0.2788\n",
      "Epoch [2/3], Phase: train, Batch: [639/730], Loss: 0.2550\n",
      "Epoch [2/3], Phase: train, Batch: [640/730], Loss: 0.2479\n",
      "Epoch [2/3], Phase: train, Batch: [641/730], Loss: 0.2058\n",
      "Epoch [2/3], Phase: train, Batch: [642/730], Loss: 0.2423\n",
      "Epoch [2/3], Phase: train, Batch: [643/730], Loss: 0.2667\n",
      "Epoch [2/3], Phase: train, Batch: [644/730], Loss: 0.3436\n",
      "Epoch [2/3], Phase: train, Batch: [645/730], Loss: 0.2375\n",
      "Epoch [2/3], Phase: train, Batch: [646/730], Loss: 0.2296\n",
      "Epoch [2/3], Phase: train, Batch: [647/730], Loss: 0.1448\n",
      "Epoch [2/3], Phase: train, Batch: [648/730], Loss: 0.2300\n",
      "Epoch [2/3], Phase: train, Batch: [649/730], Loss: 0.2470\n",
      "Epoch [2/3], Phase: train, Batch: [650/730], Loss: 0.3589\n",
      "Epoch [2/3], Phase: train, Batch: [651/730], Loss: 0.1873\n",
      "Epoch [2/3], Phase: train, Batch: [652/730], Loss: 0.3687\n",
      "Epoch [2/3], Phase: train, Batch: [653/730], Loss: 0.2020\n",
      "Epoch [2/3], Phase: train, Batch: [654/730], Loss: 0.3831\n",
      "Epoch [2/3], Phase: train, Batch: [655/730], Loss: 0.2425\n",
      "Epoch [2/3], Phase: train, Batch: [656/730], Loss: 0.3858\n",
      "Epoch [2/3], Phase: train, Batch: [657/730], Loss: 0.3356\n",
      "Epoch [2/3], Phase: train, Batch: [658/730], Loss: 0.4264\n",
      "Epoch [2/3], Phase: train, Batch: [659/730], Loss: 0.4226\n",
      "Epoch [2/3], Phase: train, Batch: [660/730], Loss: 0.2763\n",
      "Epoch [2/3], Phase: train, Batch: [661/730], Loss: 0.2841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Phase: train, Batch: [662/730], Loss: 0.3194\n",
      "Epoch [2/3], Phase: train, Batch: [663/730], Loss: 0.2445\n",
      "Epoch [2/3], Phase: train, Batch: [664/730], Loss: 0.1634\n",
      "Epoch [2/3], Phase: train, Batch: [665/730], Loss: 0.2557\n",
      "Epoch [2/3], Phase: train, Batch: [666/730], Loss: 0.2748\n",
      "Epoch [2/3], Phase: train, Batch: [667/730], Loss: 0.2595\n",
      "Epoch [2/3], Phase: train, Batch: [668/730], Loss: 0.1661\n",
      "Epoch [2/3], Phase: train, Batch: [669/730], Loss: 0.3655\n",
      "Epoch [2/3], Phase: train, Batch: [670/730], Loss: 0.3463\n",
      "Epoch [2/3], Phase: train, Batch: [671/730], Loss: 0.2068\n",
      "Epoch [2/3], Phase: train, Batch: [672/730], Loss: 0.2993\n",
      "Epoch [2/3], Phase: train, Batch: [673/730], Loss: 0.2273\n",
      "Epoch [2/3], Phase: train, Batch: [674/730], Loss: 0.3015\n",
      "Epoch [2/3], Phase: train, Batch: [675/730], Loss: 0.2938\n",
      "Epoch [2/3], Phase: train, Batch: [676/730], Loss: 0.2029\n",
      "Epoch [2/3], Phase: train, Batch: [677/730], Loss: 0.2699\n",
      "Epoch [2/3], Phase: train, Batch: [678/730], Loss: 0.4284\n",
      "Epoch [2/3], Phase: train, Batch: [679/730], Loss: 0.2607\n",
      "Epoch [2/3], Phase: train, Batch: [680/730], Loss: 0.3277\n",
      "Epoch [2/3], Phase: train, Batch: [681/730], Loss: 0.3981\n",
      "Epoch [2/3], Phase: train, Batch: [682/730], Loss: 0.2994\n",
      "Epoch [2/3], Phase: train, Batch: [683/730], Loss: 0.2364\n",
      "Epoch [2/3], Phase: train, Batch: [684/730], Loss: 0.3345\n",
      "Epoch [2/3], Phase: train, Batch: [685/730], Loss: 0.2098\n",
      "Epoch [2/3], Phase: train, Batch: [686/730], Loss: 0.2227\n",
      "Epoch [2/3], Phase: train, Batch: [687/730], Loss: 0.3249\n",
      "Epoch [2/3], Phase: train, Batch: [688/730], Loss: 0.2140\n",
      "Epoch [2/3], Phase: train, Batch: [689/730], Loss: 0.3438\n",
      "Epoch [2/3], Phase: train, Batch: [690/730], Loss: 0.2466\n",
      "Epoch [2/3], Phase: train, Batch: [691/730], Loss: 0.2068\n",
      "Epoch [2/3], Phase: train, Batch: [692/730], Loss: 0.2310\n",
      "Epoch [2/3], Phase: train, Batch: [693/730], Loss: 0.2396\n",
      "Epoch [2/3], Phase: train, Batch: [694/730], Loss: 0.3706\n",
      "Epoch [2/3], Phase: train, Batch: [695/730], Loss: 0.2216\n",
      "Epoch [2/3], Phase: train, Batch: [696/730], Loss: 0.2739\n",
      "Epoch [2/3], Phase: train, Batch: [697/730], Loss: 0.1465\n",
      "Epoch [2/3], Phase: train, Batch: [698/730], Loss: 0.5042\n",
      "Epoch [2/3], Phase: train, Batch: [699/730], Loss: 0.2152\n",
      "Epoch [2/3], Phase: train, Batch: [700/730], Loss: 0.2893\n",
      "Epoch [2/3], Phase: train, Batch: [701/730], Loss: 0.2956\n",
      "Epoch [2/3], Phase: train, Batch: [702/730], Loss: 0.3516\n",
      "Epoch [2/3], Phase: train, Batch: [703/730], Loss: 0.1665\n",
      "Epoch [2/3], Phase: train, Batch: [704/730], Loss: 0.1567\n",
      "Epoch [2/3], Phase: train, Batch: [705/730], Loss: 0.1991\n",
      "Epoch [2/3], Phase: train, Batch: [706/730], Loss: 0.2350\n",
      "Epoch [2/3], Phase: train, Batch: [707/730], Loss: 0.2161\n",
      "Epoch [2/3], Phase: train, Batch: [708/730], Loss: 0.3095\n",
      "Epoch [2/3], Phase: train, Batch: [709/730], Loss: 0.4039\n",
      "Epoch [2/3], Phase: train, Batch: [710/730], Loss: 0.3099\n",
      "Epoch [2/3], Phase: train, Batch: [711/730], Loss: 0.2058\n",
      "Epoch [2/3], Phase: train, Batch: [712/730], Loss: 0.3100\n",
      "Epoch [2/3], Phase: train, Batch: [713/730], Loss: 0.3441\n",
      "Epoch [2/3], Phase: train, Batch: [714/730], Loss: 0.3156\n",
      "Epoch [2/3], Phase: train, Batch: [715/730], Loss: 0.3386\n",
      "Epoch [2/3], Phase: train, Batch: [716/730], Loss: 0.2476\n",
      "Epoch [2/3], Phase: train, Batch: [717/730], Loss: 0.2799\n",
      "Epoch [2/3], Phase: train, Batch: [718/730], Loss: 0.2547\n",
      "Epoch [2/3], Phase: train, Batch: [719/730], Loss: 0.3325\n",
      "Epoch [2/3], Phase: train, Batch: [720/730], Loss: 0.3559\n",
      "Epoch [2/3], Phase: train, Batch: [721/730], Loss: 0.2316\n",
      "Epoch [2/3], Phase: train, Batch: [722/730], Loss: 0.2381\n",
      "Epoch [2/3], Phase: train, Batch: [723/730], Loss: 0.2998\n",
      "Epoch [2/3], Phase: train, Batch: [724/730], Loss: 0.1709\n",
      "Epoch [2/3], Phase: train, Batch: [725/730], Loss: 0.2118\n",
      "Epoch [2/3], Phase: train, Batch: [726/730], Loss: 0.2629\n",
      "Epoch [2/3], Phase: train, Batch: [727/730], Loss: 0.2397\n",
      "Epoch [2/3], Phase: train, Batch: [728/730], Loss: 0.3168\n",
      "Epoch [2/3], Phase: train, Batch: [729/730], Loss: 0.2449\n",
      "Epoch [2/3], Phase: train, Batch: [730/730], Loss: 0.2841\n",
      "train Loss: 0.2923 Acc: 0.8821\n",
      "Epoch [2/3], Phase: val, Batch: [1/182], Loss: 0.2797\n",
      "Epoch [2/3], Phase: val, Batch: [2/182], Loss: 0.1915\n",
      "Epoch [2/3], Phase: val, Batch: [3/182], Loss: 0.1434\n",
      "Epoch [2/3], Phase: val, Batch: [4/182], Loss: 0.2123\n",
      "Epoch [2/3], Phase: val, Batch: [5/182], Loss: 0.1700\n",
      "Epoch [2/3], Phase: val, Batch: [6/182], Loss: 0.1416\n",
      "Epoch [2/3], Phase: val, Batch: [7/182], Loss: 0.0849\n",
      "Epoch [2/3], Phase: val, Batch: [8/182], Loss: 0.2028\n",
      "Epoch [2/3], Phase: val, Batch: [9/182], Loss: 0.1659\n",
      "Epoch [2/3], Phase: val, Batch: [10/182], Loss: 0.1274\n",
      "Epoch [2/3], Phase: val, Batch: [11/182], Loss: 0.1120\n",
      "Epoch [2/3], Phase: val, Batch: [12/182], Loss: 0.1803\n",
      "Epoch [2/3], Phase: val, Batch: [13/182], Loss: 0.1471\n",
      "Epoch [2/3], Phase: val, Batch: [14/182], Loss: 0.1111\n",
      "Epoch [2/3], Phase: val, Batch: [15/182], Loss: 0.1576\n",
      "Epoch [2/3], Phase: val, Batch: [16/182], Loss: 0.2160\n",
      "Epoch [2/3], Phase: val, Batch: [17/182], Loss: 0.2033\n",
      "Epoch [2/3], Phase: val, Batch: [18/182], Loss: 0.1872\n",
      "Epoch [2/3], Phase: val, Batch: [19/182], Loss: 0.2673\n",
      "Epoch [2/3], Phase: val, Batch: [20/182], Loss: 0.2896\n",
      "Epoch [2/3], Phase: val, Batch: [21/182], Loss: 0.2727\n",
      "Epoch [2/3], Phase: val, Batch: [22/182], Loss: 0.2517\n",
      "Epoch [2/3], Phase: val, Batch: [23/182], Loss: 0.1219\n",
      "Epoch [2/3], Phase: val, Batch: [24/182], Loss: 0.2762\n",
      "Epoch [2/3], Phase: val, Batch: [25/182], Loss: 0.2005\n",
      "Epoch [2/3], Phase: val, Batch: [26/182], Loss: 0.1156\n",
      "Epoch [2/3], Phase: val, Batch: [27/182], Loss: 0.1627\n",
      "Epoch [2/3], Phase: val, Batch: [28/182], Loss: 0.2848\n",
      "Epoch [2/3], Phase: val, Batch: [29/182], Loss: 0.2278\n",
      "Epoch [2/3], Phase: val, Batch: [30/182], Loss: 0.2296\n",
      "Epoch [2/3], Phase: val, Batch: [31/182], Loss: 0.2622\n",
      "Epoch [2/3], Phase: val, Batch: [32/182], Loss: 0.1170\n",
      "Epoch [2/3], Phase: val, Batch: [33/182], Loss: 0.2073\n",
      "Epoch [2/3], Phase: val, Batch: [34/182], Loss: 0.2041\n",
      "Epoch [2/3], Phase: val, Batch: [35/182], Loss: 0.1222\n",
      "Epoch [2/3], Phase: val, Batch: [36/182], Loss: 0.1857\n",
      "Epoch [2/3], Phase: val, Batch: [37/182], Loss: 0.1273\n",
      "Epoch [2/3], Phase: val, Batch: [38/182], Loss: 0.1318\n",
      "Epoch [2/3], Phase: val, Batch: [39/182], Loss: 0.2438\n",
      "Epoch [2/3], Phase: val, Batch: [40/182], Loss: 0.1728\n",
      "Epoch [2/3], Phase: val, Batch: [41/182], Loss: 0.1668\n",
      "Epoch [2/3], Phase: val, Batch: [42/182], Loss: 0.2193\n",
      "Epoch [2/3], Phase: val, Batch: [43/182], Loss: 0.1624\n",
      "Epoch [2/3], Phase: val, Batch: [44/182], Loss: 0.2757\n",
      "Epoch [2/3], Phase: val, Batch: [45/182], Loss: 0.2402\n",
      "Epoch [2/3], Phase: val, Batch: [46/182], Loss: 0.1537\n",
      "Epoch [2/3], Phase: val, Batch: [47/182], Loss: 0.2096\n",
      "Epoch [2/3], Phase: val, Batch: [48/182], Loss: 0.0907\n",
      "Epoch [2/3], Phase: val, Batch: [49/182], Loss: 0.2160\n",
      "Epoch [2/3], Phase: val, Batch: [50/182], Loss: 0.2702\n",
      "Epoch [2/3], Phase: val, Batch: [51/182], Loss: 0.3172\n",
      "Epoch [2/3], Phase: val, Batch: [52/182], Loss: 0.1853\n",
      "Epoch [2/3], Phase: val, Batch: [53/182], Loss: 0.1805\n",
      "Epoch [2/3], Phase: val, Batch: [54/182], Loss: 0.2414\n",
      "Epoch [2/3], Phase: val, Batch: [55/182], Loss: 0.1419\n",
      "Epoch [2/3], Phase: val, Batch: [56/182], Loss: 0.1482\n",
      "Epoch [2/3], Phase: val, Batch: [57/182], Loss: 0.1837\n",
      "Epoch [2/3], Phase: val, Batch: [58/182], Loss: 0.1625\n",
      "Epoch [2/3], Phase: val, Batch: [59/182], Loss: 0.1283\n",
      "Epoch [2/3], Phase: val, Batch: [60/182], Loss: 0.1270\n",
      "Epoch [2/3], Phase: val, Batch: [61/182], Loss: 0.2309\n",
      "Epoch [2/3], Phase: val, Batch: [62/182], Loss: 0.2842\n",
      "Epoch [2/3], Phase: val, Batch: [63/182], Loss: 0.1444\n",
      "Epoch [2/3], Phase: val, Batch: [64/182], Loss: 0.2168\n",
      "Epoch [2/3], Phase: val, Batch: [65/182], Loss: 0.1411\n",
      "Epoch [2/3], Phase: val, Batch: [66/182], Loss: 0.2276\n",
      "Epoch [2/3], Phase: val, Batch: [67/182], Loss: 0.1662\n",
      "Epoch [2/3], Phase: val, Batch: [68/182], Loss: 0.1547\n",
      "Epoch [2/3], Phase: val, Batch: [69/182], Loss: 0.2113\n",
      "Epoch [2/3], Phase: val, Batch: [70/182], Loss: 0.1713\n",
      "Epoch [2/3], Phase: val, Batch: [71/182], Loss: 0.2851\n",
      "Epoch [2/3], Phase: val, Batch: [72/182], Loss: 0.1675\n",
      "Epoch [2/3], Phase: val, Batch: [73/182], Loss: 0.1260\n",
      "Epoch [2/3], Phase: val, Batch: [74/182], Loss: 0.2770\n",
      "Epoch [2/3], Phase: val, Batch: [75/182], Loss: 0.1722\n",
      "Epoch [2/3], Phase: val, Batch: [76/182], Loss: 0.1247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Phase: val, Batch: [77/182], Loss: 0.1265\n",
      "Epoch [2/3], Phase: val, Batch: [78/182], Loss: 0.1233\n",
      "Epoch [2/3], Phase: val, Batch: [79/182], Loss: 0.1925\n",
      "Epoch [2/3], Phase: val, Batch: [80/182], Loss: 0.1526\n",
      "Epoch [2/3], Phase: val, Batch: [81/182], Loss: 0.0879\n",
      "Epoch [2/3], Phase: val, Batch: [82/182], Loss: 0.1417\n",
      "Epoch [2/3], Phase: val, Batch: [83/182], Loss: 0.1618\n",
      "Epoch [2/3], Phase: val, Batch: [84/182], Loss: 0.1742\n",
      "Epoch [2/3], Phase: val, Batch: [85/182], Loss: 0.1614\n",
      "Epoch [2/3], Phase: val, Batch: [86/182], Loss: 0.2270\n",
      "Epoch [2/3], Phase: val, Batch: [87/182], Loss: 0.2921\n",
      "Epoch [2/3], Phase: val, Batch: [88/182], Loss: 0.1983\n",
      "Epoch [2/3], Phase: val, Batch: [89/182], Loss: 0.1851\n",
      "Epoch [2/3], Phase: val, Batch: [90/182], Loss: 0.2191\n",
      "Epoch [2/3], Phase: val, Batch: [91/182], Loss: 0.2324\n",
      "Epoch [2/3], Phase: val, Batch: [92/182], Loss: 0.2436\n",
      "Epoch [2/3], Phase: val, Batch: [93/182], Loss: 0.2350\n",
      "Epoch [2/3], Phase: val, Batch: [94/182], Loss: 0.2242\n",
      "Epoch [2/3], Phase: val, Batch: [95/182], Loss: 0.3075\n",
      "Epoch [2/3], Phase: val, Batch: [96/182], Loss: 0.2697\n",
      "Epoch [2/3], Phase: val, Batch: [97/182], Loss: 0.2745\n",
      "Epoch [2/3], Phase: val, Batch: [98/182], Loss: 0.2739\n",
      "Epoch [2/3], Phase: val, Batch: [99/182], Loss: 0.3171\n",
      "Epoch [2/3], Phase: val, Batch: [100/182], Loss: 0.3308\n",
      "Epoch [2/3], Phase: val, Batch: [101/182], Loss: 0.3988\n",
      "Epoch [2/3], Phase: val, Batch: [102/182], Loss: 0.2552\n",
      "Epoch [2/3], Phase: val, Batch: [103/182], Loss: 0.2805\n",
      "Epoch [2/3], Phase: val, Batch: [104/182], Loss: 0.2870\n",
      "Epoch [2/3], Phase: val, Batch: [105/182], Loss: 0.2111\n",
      "Epoch [2/3], Phase: val, Batch: [106/182], Loss: 0.4260\n",
      "Epoch [2/3], Phase: val, Batch: [107/182], Loss: 0.2994\n",
      "Epoch [2/3], Phase: val, Batch: [108/182], Loss: 0.2771\n",
      "Epoch [2/3], Phase: val, Batch: [109/182], Loss: 0.2944\n",
      "Epoch [2/3], Phase: val, Batch: [110/182], Loss: 0.2235\n",
      "Epoch [2/3], Phase: val, Batch: [111/182], Loss: 0.1530\n",
      "Epoch [2/3], Phase: val, Batch: [112/182], Loss: 0.2314\n",
      "Epoch [2/3], Phase: val, Batch: [113/182], Loss: 0.1737\n",
      "Epoch [2/3], Phase: val, Batch: [114/182], Loss: 0.3191\n",
      "Epoch [2/3], Phase: val, Batch: [115/182], Loss: 0.2344\n",
      "Epoch [2/3], Phase: val, Batch: [116/182], Loss: 0.3037\n",
      "Epoch [2/3], Phase: val, Batch: [117/182], Loss: 0.1832\n",
      "Epoch [2/3], Phase: val, Batch: [118/182], Loss: 0.2776\n",
      "Epoch [2/3], Phase: val, Batch: [119/182], Loss: 0.2174\n",
      "Epoch [2/3], Phase: val, Batch: [120/182], Loss: 0.2543\n",
      "Epoch [2/3], Phase: val, Batch: [121/182], Loss: 0.2679\n",
      "Epoch [2/3], Phase: val, Batch: [122/182], Loss: 0.2377\n",
      "Epoch [2/3], Phase: val, Batch: [123/182], Loss: 0.3457\n",
      "Epoch [2/3], Phase: val, Batch: [124/182], Loss: 0.1826\n",
      "Epoch [2/3], Phase: val, Batch: [125/182], Loss: 0.2247\n",
      "Epoch [2/3], Phase: val, Batch: [126/182], Loss: 0.2825\n",
      "Epoch [2/3], Phase: val, Batch: [127/182], Loss: 0.2310\n",
      "Epoch [2/3], Phase: val, Batch: [128/182], Loss: 0.2502\n",
      "Epoch [2/3], Phase: val, Batch: [129/182], Loss: 0.2750\n",
      "Epoch [2/3], Phase: val, Batch: [130/182], Loss: 0.1992\n",
      "Epoch [2/3], Phase: val, Batch: [131/182], Loss: 0.2921\n",
      "Epoch [2/3], Phase: val, Batch: [132/182], Loss: 0.2889\n",
      "Epoch [2/3], Phase: val, Batch: [133/182], Loss: 0.4216\n",
      "Epoch [2/3], Phase: val, Batch: [134/182], Loss: 0.1667\n",
      "Epoch [2/3], Phase: val, Batch: [135/182], Loss: 0.2356\n",
      "Epoch [2/3], Phase: val, Batch: [136/182], Loss: 0.3290\n",
      "Epoch [2/3], Phase: val, Batch: [137/182], Loss: 0.2652\n",
      "Epoch [2/3], Phase: val, Batch: [138/182], Loss: 0.3000\n",
      "Epoch [2/3], Phase: val, Batch: [139/182], Loss: 0.1887\n",
      "Epoch [2/3], Phase: val, Batch: [140/182], Loss: 0.3018\n",
      "Epoch [2/3], Phase: val, Batch: [141/182], Loss: 0.2507\n",
      "Epoch [2/3], Phase: val, Batch: [142/182], Loss: 0.2205\n",
      "Epoch [2/3], Phase: val, Batch: [143/182], Loss: 0.3186\n",
      "Epoch [2/3], Phase: val, Batch: [144/182], Loss: 0.3348\n",
      "Epoch [2/3], Phase: val, Batch: [145/182], Loss: 0.1642\n",
      "Epoch [2/3], Phase: val, Batch: [146/182], Loss: 0.2491\n",
      "Epoch [2/3], Phase: val, Batch: [147/182], Loss: 0.2928\n",
      "Epoch [2/3], Phase: val, Batch: [148/182], Loss: 0.2098\n",
      "Epoch [2/3], Phase: val, Batch: [149/182], Loss: 0.2909\n",
      "Epoch [2/3], Phase: val, Batch: [150/182], Loss: 0.3329\n",
      "Epoch [2/3], Phase: val, Batch: [151/182], Loss: 0.2923\n",
      "Epoch [2/3], Phase: val, Batch: [152/182], Loss: 0.3366\n",
      "Epoch [2/3], Phase: val, Batch: [153/182], Loss: 0.3454\n",
      "Epoch [2/3], Phase: val, Batch: [154/182], Loss: 0.3395\n",
      "Epoch [2/3], Phase: val, Batch: [155/182], Loss: 0.2441\n",
      "Epoch [2/3], Phase: val, Batch: [156/182], Loss: 0.3943\n",
      "Epoch [2/3], Phase: val, Batch: [157/182], Loss: 0.2864\n",
      "Epoch [2/3], Phase: val, Batch: [158/182], Loss: 0.4464\n",
      "Epoch [2/3], Phase: val, Batch: [159/182], Loss: 0.3132\n",
      "Epoch [2/3], Phase: val, Batch: [160/182], Loss: 0.2266\n",
      "Epoch [2/3], Phase: val, Batch: [161/182], Loss: 0.2835\n",
      "Epoch [2/3], Phase: val, Batch: [162/182], Loss: 0.3558\n",
      "Epoch [2/3], Phase: val, Batch: [163/182], Loss: 0.3800\n",
      "Epoch [2/3], Phase: val, Batch: [164/182], Loss: 0.2346\n",
      "Epoch [2/3], Phase: val, Batch: [165/182], Loss: 0.2776\n",
      "Epoch [2/3], Phase: val, Batch: [166/182], Loss: 0.1730\n",
      "Epoch [2/3], Phase: val, Batch: [167/182], Loss: 0.2179\n",
      "Epoch [2/3], Phase: val, Batch: [168/182], Loss: 0.2475\n",
      "Epoch [2/3], Phase: val, Batch: [169/182], Loss: 0.2835\n",
      "Epoch [2/3], Phase: val, Batch: [170/182], Loss: 0.3043\n",
      "Epoch [2/3], Phase: val, Batch: [171/182], Loss: 0.3602\n",
      "Epoch [2/3], Phase: val, Batch: [172/182], Loss: 0.2711\n",
      "Epoch [2/3], Phase: val, Batch: [173/182], Loss: 0.1499\n",
      "Epoch [2/3], Phase: val, Batch: [174/182], Loss: 0.3058\n",
      "Epoch [2/3], Phase: val, Batch: [175/182], Loss: 0.1977\n",
      "Epoch [2/3], Phase: val, Batch: [176/182], Loss: 0.2813\n",
      "Epoch [2/3], Phase: val, Batch: [177/182], Loss: 0.3089\n",
      "Epoch [2/3], Phase: val, Batch: [178/182], Loss: 0.1406\n",
      "Epoch [2/3], Phase: val, Batch: [179/182], Loss: 0.2450\n",
      "Epoch [2/3], Phase: val, Batch: [180/182], Loss: 0.2405\n",
      "Epoch [2/3], Phase: val, Batch: [181/182], Loss: 0.3835\n",
      "Epoch [2/3], Phase: val, Batch: [182/182], Loss: 0.2729\n",
      "val Loss: 0.2306 Acc: 0.9103\n",
      "Epoch [3/3], Phase: train, Batch: [1/730], Loss: 0.2303\n",
      "Epoch [3/3], Phase: train, Batch: [2/730], Loss: 0.2041\n",
      "Epoch [3/3], Phase: train, Batch: [3/730], Loss: 0.2644\n",
      "Epoch [3/3], Phase: train, Batch: [4/730], Loss: 0.2291\n",
      "Epoch [3/3], Phase: train, Batch: [5/730], Loss: 0.2381\n",
      "Epoch [3/3], Phase: train, Batch: [6/730], Loss: 0.3441\n",
      "Epoch [3/3], Phase: train, Batch: [7/730], Loss: 0.2435\n",
      "Epoch [3/3], Phase: train, Batch: [8/730], Loss: 0.3303\n",
      "Epoch [3/3], Phase: train, Batch: [9/730], Loss: 0.3994\n",
      "Epoch [3/3], Phase: train, Batch: [10/730], Loss: 0.2965\n",
      "Epoch [3/3], Phase: train, Batch: [11/730], Loss: 0.2414\n",
      "Epoch [3/3], Phase: train, Batch: [12/730], Loss: 0.2393\n",
      "Epoch [3/3], Phase: train, Batch: [13/730], Loss: 0.2987\n",
      "Epoch [3/3], Phase: train, Batch: [14/730], Loss: 0.3314\n",
      "Epoch [3/3], Phase: train, Batch: [15/730], Loss: 0.2314\n",
      "Epoch [3/3], Phase: train, Batch: [16/730], Loss: 0.3545\n",
      "Epoch [3/3], Phase: train, Batch: [17/730], Loss: 0.2937\n",
      "Epoch [3/3], Phase: train, Batch: [18/730], Loss: 0.3444\n",
      "Epoch [3/3], Phase: train, Batch: [19/730], Loss: 0.2948\n",
      "Epoch [3/3], Phase: train, Batch: [20/730], Loss: 0.4308\n",
      "Epoch [3/3], Phase: train, Batch: [21/730], Loss: 0.3732\n",
      "Epoch [3/3], Phase: train, Batch: [22/730], Loss: 0.2691\n",
      "Epoch [3/3], Phase: train, Batch: [23/730], Loss: 0.3590\n",
      "Epoch [3/3], Phase: train, Batch: [24/730], Loss: 0.2348\n",
      "Epoch [3/3], Phase: train, Batch: [25/730], Loss: 0.3794\n",
      "Epoch [3/3], Phase: train, Batch: [26/730], Loss: 0.4099\n",
      "Epoch [3/3], Phase: train, Batch: [27/730], Loss: 0.3476\n",
      "Epoch [3/3], Phase: train, Batch: [28/730], Loss: 0.2628\n",
      "Epoch [3/3], Phase: train, Batch: [29/730], Loss: 0.2202\n",
      "Epoch [3/3], Phase: train, Batch: [30/730], Loss: 0.1812\n",
      "Epoch [3/3], Phase: train, Batch: [31/730], Loss: 0.2639\n",
      "Epoch [3/3], Phase: train, Batch: [32/730], Loss: 0.2676\n",
      "Epoch [3/3], Phase: train, Batch: [33/730], Loss: 0.4847\n",
      "Epoch [3/3], Phase: train, Batch: [34/730], Loss: 0.2833\n",
      "Epoch [3/3], Phase: train, Batch: [35/730], Loss: 0.1580\n",
      "Epoch [3/3], Phase: train, Batch: [36/730], Loss: 0.1528\n",
      "Epoch [3/3], Phase: train, Batch: [37/730], Loss: 0.1923\n",
      "Epoch [3/3], Phase: train, Batch: [38/730], Loss: 0.2545\n",
      "Epoch [3/3], Phase: train, Batch: [39/730], Loss: 0.3064\n",
      "Epoch [3/3], Phase: train, Batch: [40/730], Loss: 0.2803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Phase: train, Batch: [41/730], Loss: 0.1754\n",
      "Epoch [3/3], Phase: train, Batch: [42/730], Loss: 0.3199\n",
      "Epoch [3/3], Phase: train, Batch: [43/730], Loss: 0.1412\n",
      "Epoch [3/3], Phase: train, Batch: [44/730], Loss: 0.3849\n",
      "Epoch [3/3], Phase: train, Batch: [45/730], Loss: 0.2594\n",
      "Epoch [3/3], Phase: train, Batch: [46/730], Loss: 0.2728\n",
      "Epoch [3/3], Phase: train, Batch: [47/730], Loss: 0.3197\n",
      "Epoch [3/3], Phase: train, Batch: [48/730], Loss: 0.3231\n",
      "Epoch [3/3], Phase: train, Batch: [49/730], Loss: 0.2943\n",
      "Epoch [3/3], Phase: train, Batch: [50/730], Loss: 0.3585\n",
      "Epoch [3/3], Phase: train, Batch: [51/730], Loss: 0.4048\n",
      "Epoch [3/3], Phase: train, Batch: [52/730], Loss: 0.2367\n",
      "Epoch [3/3], Phase: train, Batch: [53/730], Loss: 0.2248\n",
      "Epoch [3/3], Phase: train, Batch: [54/730], Loss: 0.3934\n",
      "Epoch [3/3], Phase: train, Batch: [55/730], Loss: 0.1945\n",
      "Epoch [3/3], Phase: train, Batch: [56/730], Loss: 0.2388\n",
      "Epoch [3/3], Phase: train, Batch: [57/730], Loss: 0.2234\n",
      "Epoch [3/3], Phase: train, Batch: [58/730], Loss: 0.3382\n",
      "Epoch [3/3], Phase: train, Batch: [59/730], Loss: 0.2316\n",
      "Epoch [3/3], Phase: train, Batch: [60/730], Loss: 0.3085\n",
      "Epoch [3/3], Phase: train, Batch: [61/730], Loss: 0.2540\n",
      "Epoch [3/3], Phase: train, Batch: [62/730], Loss: 0.3932\n",
      "Epoch [3/3], Phase: train, Batch: [63/730], Loss: 0.2818\n",
      "Epoch [3/3], Phase: train, Batch: [64/730], Loss: 0.2124\n",
      "Epoch [3/3], Phase: train, Batch: [65/730], Loss: 0.2492\n",
      "Epoch [3/3], Phase: train, Batch: [66/730], Loss: 0.3084\n",
      "Epoch [3/3], Phase: train, Batch: [67/730], Loss: 0.3154\n",
      "Epoch [3/3], Phase: train, Batch: [68/730], Loss: 0.3509\n",
      "Epoch [3/3], Phase: train, Batch: [69/730], Loss: 0.3633\n",
      "Epoch [3/3], Phase: train, Batch: [70/730], Loss: 0.3049\n",
      "Epoch [3/3], Phase: train, Batch: [71/730], Loss: 0.1836\n",
      "Epoch [3/3], Phase: train, Batch: [72/730], Loss: 0.2154\n",
      "Epoch [3/3], Phase: train, Batch: [73/730], Loss: 0.3312\n",
      "Epoch [3/3], Phase: train, Batch: [74/730], Loss: 0.3233\n",
      "Epoch [3/3], Phase: train, Batch: [75/730], Loss: 0.3166\n",
      "Epoch [3/3], Phase: train, Batch: [76/730], Loss: 0.2422\n",
      "Epoch [3/3], Phase: train, Batch: [77/730], Loss: 0.2661\n",
      "Epoch [3/3], Phase: train, Batch: [78/730], Loss: 0.2895\n",
      "Epoch [3/3], Phase: train, Batch: [79/730], Loss: 0.2299\n",
      "Epoch [3/3], Phase: train, Batch: [80/730], Loss: 0.1954\n",
      "Epoch [3/3], Phase: train, Batch: [81/730], Loss: 0.2744\n",
      "Epoch [3/3], Phase: train, Batch: [82/730], Loss: 0.2118\n",
      "Epoch [3/3], Phase: train, Batch: [83/730], Loss: 0.2483\n",
      "Epoch [3/3], Phase: train, Batch: [84/730], Loss: 0.2405\n",
      "Epoch [3/3], Phase: train, Batch: [85/730], Loss: 0.2360\n",
      "Epoch [3/3], Phase: train, Batch: [86/730], Loss: 0.2104\n",
      "Epoch [3/3], Phase: train, Batch: [87/730], Loss: 0.3464\n",
      "Epoch [3/3], Phase: train, Batch: [88/730], Loss: 0.2948\n",
      "Epoch [3/3], Phase: train, Batch: [89/730], Loss: 0.2461\n",
      "Epoch [3/3], Phase: train, Batch: [90/730], Loss: 0.4481\n",
      "Epoch [3/3], Phase: train, Batch: [91/730], Loss: 0.1854\n",
      "Epoch [3/3], Phase: train, Batch: [92/730], Loss: 0.2577\n",
      "Epoch [3/3], Phase: train, Batch: [93/730], Loss: 0.2314\n",
      "Epoch [3/3], Phase: train, Batch: [94/730], Loss: 0.3149\n",
      "Epoch [3/3], Phase: train, Batch: [95/730], Loss: 0.2396\n",
      "Epoch [3/3], Phase: train, Batch: [96/730], Loss: 0.3219\n",
      "Epoch [3/3], Phase: train, Batch: [97/730], Loss: 0.3041\n",
      "Epoch [3/3], Phase: train, Batch: [98/730], Loss: 0.2037\n",
      "Epoch [3/3], Phase: train, Batch: [99/730], Loss: 0.2124\n",
      "Epoch [3/3], Phase: train, Batch: [100/730], Loss: 0.2532\n",
      "Epoch [3/3], Phase: train, Batch: [101/730], Loss: 0.4625\n",
      "Epoch [3/3], Phase: train, Batch: [102/730], Loss: 0.1762\n",
      "Epoch [3/3], Phase: train, Batch: [103/730], Loss: 0.1704\n",
      "Epoch [3/3], Phase: train, Batch: [104/730], Loss: 0.3783\n",
      "Epoch [3/3], Phase: train, Batch: [105/730], Loss: 0.3963\n",
      "Epoch [3/3], Phase: train, Batch: [106/730], Loss: 0.3684\n",
      "Epoch [3/3], Phase: train, Batch: [107/730], Loss: 0.3181\n",
      "Epoch [3/3], Phase: train, Batch: [108/730], Loss: 0.2156\n",
      "Epoch [3/3], Phase: train, Batch: [109/730], Loss: 0.2519\n",
      "Epoch [3/3], Phase: train, Batch: [110/730], Loss: 0.3464\n",
      "Epoch [3/3], Phase: train, Batch: [111/730], Loss: 0.3899\n",
      "Epoch [3/3], Phase: train, Batch: [112/730], Loss: 0.2187\n",
      "Epoch [3/3], Phase: train, Batch: [113/730], Loss: 0.2513\n",
      "Epoch [3/3], Phase: train, Batch: [114/730], Loss: 0.4093\n",
      "Epoch [3/3], Phase: train, Batch: [115/730], Loss: 0.2799\n",
      "Epoch [3/3], Phase: train, Batch: [116/730], Loss: 0.2749\n",
      "Epoch [3/3], Phase: train, Batch: [117/730], Loss: 0.2260\n",
      "Epoch [3/3], Phase: train, Batch: [118/730], Loss: 0.2959\n",
      "Epoch [3/3], Phase: train, Batch: [119/730], Loss: 0.3069\n",
      "Epoch [3/3], Phase: train, Batch: [120/730], Loss: 0.2616\n",
      "Epoch [3/3], Phase: train, Batch: [121/730], Loss: 0.3630\n",
      "Epoch [3/3], Phase: train, Batch: [122/730], Loss: 0.4456\n",
      "Epoch [3/3], Phase: train, Batch: [123/730], Loss: 0.4198\n",
      "Epoch [3/3], Phase: train, Batch: [124/730], Loss: 0.4316\n",
      "Epoch [3/3], Phase: train, Batch: [125/730], Loss: 0.3439\n",
      "Epoch [3/3], Phase: train, Batch: [126/730], Loss: 0.2810\n",
      "Epoch [3/3], Phase: train, Batch: [127/730], Loss: 0.2545\n",
      "Epoch [3/3], Phase: train, Batch: [128/730], Loss: 0.2847\n",
      "Epoch [3/3], Phase: train, Batch: [129/730], Loss: 0.2975\n",
      "Epoch [3/3], Phase: train, Batch: [130/730], Loss: 0.2819\n",
      "Epoch [3/3], Phase: train, Batch: [131/730], Loss: 0.2309\n",
      "Epoch [3/3], Phase: train, Batch: [132/730], Loss: 0.5561\n",
      "Epoch [3/3], Phase: train, Batch: [133/730], Loss: 0.1959\n",
      "Epoch [3/3], Phase: train, Batch: [134/730], Loss: 0.2423\n",
      "Epoch [3/3], Phase: train, Batch: [135/730], Loss: 0.3955\n",
      "Epoch [3/3], Phase: train, Batch: [136/730], Loss: 0.2639\n",
      "Epoch [3/3], Phase: train, Batch: [137/730], Loss: 0.3077\n",
      "Epoch [3/3], Phase: train, Batch: [138/730], Loss: 0.2939\n",
      "Epoch [3/3], Phase: train, Batch: [139/730], Loss: 0.3229\n",
      "Epoch [3/3], Phase: train, Batch: [140/730], Loss: 0.3230\n",
      "Epoch [3/3], Phase: train, Batch: [141/730], Loss: 0.3283\n",
      "Epoch [3/3], Phase: train, Batch: [142/730], Loss: 0.2594\n",
      "Epoch [3/3], Phase: train, Batch: [143/730], Loss: 0.2093\n",
      "Epoch [3/3], Phase: train, Batch: [144/730], Loss: 0.2545\n",
      "Epoch [3/3], Phase: train, Batch: [145/730], Loss: 0.3809\n",
      "Epoch [3/3], Phase: train, Batch: [146/730], Loss: 0.3532\n",
      "Epoch [3/3], Phase: train, Batch: [147/730], Loss: 0.2509\n",
      "Epoch [3/3], Phase: train, Batch: [148/730], Loss: 0.3713\n",
      "Epoch [3/3], Phase: train, Batch: [149/730], Loss: 0.3764\n",
      "Epoch [3/3], Phase: train, Batch: [150/730], Loss: 0.2209\n",
      "Epoch [3/3], Phase: train, Batch: [151/730], Loss: 0.3574\n",
      "Epoch [3/3], Phase: train, Batch: [152/730], Loss: 0.1451\n",
      "Epoch [3/3], Phase: train, Batch: [153/730], Loss: 0.2556\n",
      "Epoch [3/3], Phase: train, Batch: [154/730], Loss: 0.2671\n",
      "Epoch [3/3], Phase: train, Batch: [155/730], Loss: 0.2585\n",
      "Epoch [3/3], Phase: train, Batch: [156/730], Loss: 0.2506\n",
      "Epoch [3/3], Phase: train, Batch: [157/730], Loss: 0.3101\n",
      "Epoch [3/3], Phase: train, Batch: [158/730], Loss: 0.4423\n",
      "Epoch [3/3], Phase: train, Batch: [159/730], Loss: 0.2321\n",
      "Epoch [3/3], Phase: train, Batch: [160/730], Loss: 0.1674\n",
      "Epoch [3/3], Phase: train, Batch: [161/730], Loss: 0.1637\n",
      "Epoch [3/3], Phase: train, Batch: [162/730], Loss: 0.2296\n",
      "Epoch [3/3], Phase: train, Batch: [163/730], Loss: 0.2605\n",
      "Epoch [3/3], Phase: train, Batch: [164/730], Loss: 0.2122\n",
      "Epoch [3/3], Phase: train, Batch: [165/730], Loss: 0.2314\n",
      "Epoch [3/3], Phase: train, Batch: [166/730], Loss: 0.1885\n",
      "Epoch [3/3], Phase: train, Batch: [167/730], Loss: 0.4039\n",
      "Epoch [3/3], Phase: train, Batch: [168/730], Loss: 0.4459\n",
      "Epoch [3/3], Phase: train, Batch: [169/730], Loss: 0.3287\n",
      "Epoch [3/3], Phase: train, Batch: [170/730], Loss: 0.2486\n",
      "Epoch [3/3], Phase: train, Batch: [171/730], Loss: 0.1877\n",
      "Epoch [3/3], Phase: train, Batch: [172/730], Loss: 0.2505\n",
      "Epoch [3/3], Phase: train, Batch: [173/730], Loss: 0.3758\n",
      "Epoch [3/3], Phase: train, Batch: [174/730], Loss: 0.3098\n",
      "Epoch [3/3], Phase: train, Batch: [175/730], Loss: 0.2445\n",
      "Epoch [3/3], Phase: train, Batch: [176/730], Loss: 0.1757\n",
      "Epoch [3/3], Phase: train, Batch: [177/730], Loss: 0.2745\n",
      "Epoch [3/3], Phase: train, Batch: [178/730], Loss: 0.4380\n",
      "Epoch [3/3], Phase: train, Batch: [179/730], Loss: 0.2539\n",
      "Epoch [3/3], Phase: train, Batch: [180/730], Loss: 0.2067\n",
      "Epoch [3/3], Phase: train, Batch: [181/730], Loss: 0.3954\n",
      "Epoch [3/3], Phase: train, Batch: [182/730], Loss: 0.3780\n",
      "Epoch [3/3], Phase: train, Batch: [183/730], Loss: 0.2739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Phase: train, Batch: [184/730], Loss: 0.3630\n",
      "Epoch [3/3], Phase: train, Batch: [185/730], Loss: 0.2601\n",
      "Epoch [3/3], Phase: train, Batch: [186/730], Loss: 0.2618\n",
      "Epoch [3/3], Phase: train, Batch: [187/730], Loss: 0.2822\n",
      "Epoch [3/3], Phase: train, Batch: [188/730], Loss: 0.2179\n",
      "Epoch [3/3], Phase: train, Batch: [189/730], Loss: 0.2460\n",
      "Epoch [3/3], Phase: train, Batch: [190/730], Loss: 0.2181\n",
      "Epoch [3/3], Phase: train, Batch: [191/730], Loss: 0.1587\n",
      "Epoch [3/3], Phase: train, Batch: [192/730], Loss: 0.1946\n",
      "Epoch [3/3], Phase: train, Batch: [193/730], Loss: 0.3511\n",
      "Epoch [3/3], Phase: train, Batch: [194/730], Loss: 0.2275\n",
      "Epoch [3/3], Phase: train, Batch: [195/730], Loss: 0.1711\n",
      "Epoch [3/3], Phase: train, Batch: [196/730], Loss: 0.2715\n",
      "Epoch [3/3], Phase: train, Batch: [197/730], Loss: 0.3784\n",
      "Epoch [3/3], Phase: train, Batch: [198/730], Loss: 0.2355\n",
      "Epoch [3/3], Phase: train, Batch: [199/730], Loss: 0.2758\n",
      "Epoch [3/3], Phase: train, Batch: [200/730], Loss: 0.2515\n",
      "Epoch [3/3], Phase: train, Batch: [201/730], Loss: 0.2037\n",
      "Epoch [3/3], Phase: train, Batch: [202/730], Loss: 0.4179\n",
      "Epoch [3/3], Phase: train, Batch: [203/730], Loss: 0.2202\n",
      "Epoch [3/3], Phase: train, Batch: [204/730], Loss: 0.3268\n",
      "Epoch [3/3], Phase: train, Batch: [205/730], Loss: 0.4332\n",
      "Epoch [3/3], Phase: train, Batch: [206/730], Loss: 0.2869\n",
      "Epoch [3/3], Phase: train, Batch: [207/730], Loss: 0.2950\n",
      "Epoch [3/3], Phase: train, Batch: [208/730], Loss: 0.2661\n",
      "Epoch [3/3], Phase: train, Batch: [209/730], Loss: 0.3016\n",
      "Epoch [3/3], Phase: train, Batch: [210/730], Loss: 0.2315\n",
      "Epoch [3/3], Phase: train, Batch: [211/730], Loss: 0.1686\n",
      "Epoch [3/3], Phase: train, Batch: [212/730], Loss: 0.3431\n",
      "Epoch [3/3], Phase: train, Batch: [213/730], Loss: 0.2709\n",
      "Epoch [3/3], Phase: train, Batch: [214/730], Loss: 0.3479\n",
      "Epoch [3/3], Phase: train, Batch: [215/730], Loss: 0.3970\n",
      "Epoch [3/3], Phase: train, Batch: [216/730], Loss: 0.2961\n",
      "Epoch [3/3], Phase: train, Batch: [217/730], Loss: 0.2143\n",
      "Epoch [3/3], Phase: train, Batch: [218/730], Loss: 0.2750\n",
      "Epoch [3/3], Phase: train, Batch: [219/730], Loss: 0.3331\n",
      "Epoch [3/3], Phase: train, Batch: [220/730], Loss: 0.1387\n",
      "Epoch [3/3], Phase: train, Batch: [221/730], Loss: 0.2209\n",
      "Epoch [3/3], Phase: train, Batch: [222/730], Loss: 0.2048\n",
      "Epoch [3/3], Phase: train, Batch: [223/730], Loss: 0.1853\n",
      "Epoch [3/3], Phase: train, Batch: [224/730], Loss: 0.1628\n",
      "Epoch [3/3], Phase: train, Batch: [225/730], Loss: 0.3507\n",
      "Epoch [3/3], Phase: train, Batch: [226/730], Loss: 0.4366\n",
      "Epoch [3/3], Phase: train, Batch: [227/730], Loss: 0.5128\n",
      "Epoch [3/3], Phase: train, Batch: [228/730], Loss: 0.2361\n",
      "Epoch [3/3], Phase: train, Batch: [229/730], Loss: 0.2750\n",
      "Epoch [3/3], Phase: train, Batch: [230/730], Loss: 0.2409\n",
      "Epoch [3/3], Phase: train, Batch: [231/730], Loss: 0.1913\n",
      "Epoch [3/3], Phase: train, Batch: [232/730], Loss: 0.2694\n",
      "Epoch [3/3], Phase: train, Batch: [233/730], Loss: 0.1897\n",
      "Epoch [3/3], Phase: train, Batch: [234/730], Loss: 0.3120\n",
      "Epoch [3/3], Phase: train, Batch: [235/730], Loss: 0.4137\n",
      "Epoch [3/3], Phase: train, Batch: [236/730], Loss: 0.3541\n",
      "Epoch [3/3], Phase: train, Batch: [237/730], Loss: 0.3159\n",
      "Epoch [3/3], Phase: train, Batch: [238/730], Loss: 0.3127\n",
      "Epoch [3/3], Phase: train, Batch: [239/730], Loss: 0.2058\n",
      "Epoch [3/3], Phase: train, Batch: [240/730], Loss: 0.2973\n",
      "Epoch [3/3], Phase: train, Batch: [241/730], Loss: 0.3027\n",
      "Epoch [3/3], Phase: train, Batch: [242/730], Loss: 0.2476\n",
      "Epoch [3/3], Phase: train, Batch: [243/730], Loss: 0.3418\n",
      "Epoch [3/3], Phase: train, Batch: [244/730], Loss: 0.3680\n",
      "Epoch [3/3], Phase: train, Batch: [245/730], Loss: 0.2794\n",
      "Epoch [3/3], Phase: train, Batch: [246/730], Loss: 0.2691\n",
      "Epoch [3/3], Phase: train, Batch: [247/730], Loss: 0.3253\n",
      "Epoch [3/3], Phase: train, Batch: [248/730], Loss: 0.2430\n",
      "Epoch [3/3], Phase: train, Batch: [249/730], Loss: 0.3767\n",
      "Epoch [3/3], Phase: train, Batch: [250/730], Loss: 0.2170\n",
      "Epoch [3/3], Phase: train, Batch: [251/730], Loss: 0.2838\n",
      "Epoch [3/3], Phase: train, Batch: [252/730], Loss: 0.2602\n",
      "Epoch [3/3], Phase: train, Batch: [253/730], Loss: 0.3831\n",
      "Epoch [3/3], Phase: train, Batch: [254/730], Loss: 0.2808\n",
      "Epoch [3/3], Phase: train, Batch: [255/730], Loss: 0.2972\n",
      "Epoch [3/3], Phase: train, Batch: [256/730], Loss: 0.2355\n",
      "Epoch [3/3], Phase: train, Batch: [257/730], Loss: 0.4327\n",
      "Epoch [3/3], Phase: train, Batch: [258/730], Loss: 0.2195\n",
      "Epoch [3/3], Phase: train, Batch: [259/730], Loss: 0.2338\n",
      "Epoch [3/3], Phase: train, Batch: [260/730], Loss: 0.2536\n",
      "Epoch [3/3], Phase: train, Batch: [261/730], Loss: 0.3559\n",
      "Epoch [3/3], Phase: train, Batch: [262/730], Loss: 0.2377\n",
      "Epoch [3/3], Phase: train, Batch: [263/730], Loss: 0.3599\n",
      "Epoch [3/3], Phase: train, Batch: [264/730], Loss: 0.3270\n",
      "Epoch [3/3], Phase: train, Batch: [265/730], Loss: 0.3170\n",
      "Epoch [3/3], Phase: train, Batch: [266/730], Loss: 0.2985\n",
      "Epoch [3/3], Phase: train, Batch: [267/730], Loss: 0.2933\n",
      "Epoch [3/3], Phase: train, Batch: [268/730], Loss: 0.2949\n",
      "Epoch [3/3], Phase: train, Batch: [269/730], Loss: 0.1798\n",
      "Epoch [3/3], Phase: train, Batch: [270/730], Loss: 0.2547\n",
      "Epoch [3/3], Phase: train, Batch: [271/730], Loss: 0.2313\n",
      "Epoch [3/3], Phase: train, Batch: [272/730], Loss: 0.3361\n",
      "Epoch [3/3], Phase: train, Batch: [273/730], Loss: 0.2610\n",
      "Epoch [3/3], Phase: train, Batch: [274/730], Loss: 0.3515\n",
      "Epoch [3/3], Phase: train, Batch: [275/730], Loss: 0.2637\n",
      "Epoch [3/3], Phase: train, Batch: [276/730], Loss: 0.1884\n",
      "Epoch [3/3], Phase: train, Batch: [277/730], Loss: 0.2365\n",
      "Epoch [3/3], Phase: train, Batch: [278/730], Loss: 0.3021\n",
      "Epoch [3/3], Phase: train, Batch: [279/730], Loss: 0.3757\n",
      "Epoch [3/3], Phase: train, Batch: [280/730], Loss: 0.2456\n",
      "Epoch [3/3], Phase: train, Batch: [281/730], Loss: 0.4137\n",
      "Epoch [3/3], Phase: train, Batch: [282/730], Loss: 0.2759\n",
      "Epoch [3/3], Phase: train, Batch: [283/730], Loss: 0.3705\n",
      "Epoch [3/3], Phase: train, Batch: [284/730], Loss: 0.3003\n",
      "Epoch [3/3], Phase: train, Batch: [285/730], Loss: 0.2356\n",
      "Epoch [3/3], Phase: train, Batch: [286/730], Loss: 0.1769\n",
      "Epoch [3/3], Phase: train, Batch: [287/730], Loss: 0.2034\n",
      "Epoch [3/3], Phase: train, Batch: [288/730], Loss: 0.2449\n",
      "Epoch [3/3], Phase: train, Batch: [289/730], Loss: 0.2912\n",
      "Epoch [3/3], Phase: train, Batch: [290/730], Loss: 0.2998\n",
      "Epoch [3/3], Phase: train, Batch: [291/730], Loss: 0.1793\n",
      "Epoch [3/3], Phase: train, Batch: [292/730], Loss: 0.3005\n",
      "Epoch [3/3], Phase: train, Batch: [293/730], Loss: 0.2443\n",
      "Epoch [3/3], Phase: train, Batch: [294/730], Loss: 0.2936\n",
      "Epoch [3/3], Phase: train, Batch: [295/730], Loss: 0.3979\n",
      "Epoch [3/3], Phase: train, Batch: [296/730], Loss: 0.1919\n",
      "Epoch [3/3], Phase: train, Batch: [297/730], Loss: 0.2251\n",
      "Epoch [3/3], Phase: train, Batch: [298/730], Loss: 0.5491\n",
      "Epoch [3/3], Phase: train, Batch: [299/730], Loss: 0.2055\n",
      "Epoch [3/3], Phase: train, Batch: [300/730], Loss: 0.2044\n",
      "Epoch [3/3], Phase: train, Batch: [301/730], Loss: 0.2195\n",
      "Epoch [3/3], Phase: train, Batch: [302/730], Loss: 0.2262\n",
      "Epoch [3/3], Phase: train, Batch: [303/730], Loss: 0.3727\n",
      "Epoch [3/3], Phase: train, Batch: [304/730], Loss: 0.3154\n",
      "Epoch [3/3], Phase: train, Batch: [305/730], Loss: 0.3035\n",
      "Epoch [3/3], Phase: train, Batch: [306/730], Loss: 0.2388\n",
      "Epoch [3/3], Phase: train, Batch: [307/730], Loss: 0.3419\n",
      "Epoch [3/3], Phase: train, Batch: [308/730], Loss: 0.4414\n",
      "Epoch [3/3], Phase: train, Batch: [309/730], Loss: 0.2533\n",
      "Epoch [3/3], Phase: train, Batch: [310/730], Loss: 0.2362\n",
      "Epoch [3/3], Phase: train, Batch: [311/730], Loss: 0.2952\n",
      "Epoch [3/3], Phase: train, Batch: [312/730], Loss: 0.1993\n",
      "Epoch [3/3], Phase: train, Batch: [313/730], Loss: 0.1901\n",
      "Epoch [3/3], Phase: train, Batch: [314/730], Loss: 0.2215\n",
      "Epoch [3/3], Phase: train, Batch: [315/730], Loss: 0.2048\n",
      "Epoch [3/3], Phase: train, Batch: [316/730], Loss: 0.1915\n",
      "Epoch [3/3], Phase: train, Batch: [317/730], Loss: 0.3498\n",
      "Epoch [3/3], Phase: train, Batch: [318/730], Loss: 0.3570\n",
      "Epoch [3/3], Phase: train, Batch: [319/730], Loss: 0.1421\n",
      "Epoch [3/3], Phase: train, Batch: [320/730], Loss: 0.2702\n",
      "Epoch [3/3], Phase: train, Batch: [321/730], Loss: 0.4016\n",
      "Epoch [3/3], Phase: train, Batch: [322/730], Loss: 0.3365\n",
      "Epoch [3/3], Phase: train, Batch: [323/730], Loss: 0.2449\n",
      "Epoch [3/3], Phase: train, Batch: [324/730], Loss: 0.2988\n",
      "Epoch [3/3], Phase: train, Batch: [325/730], Loss: 0.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Phase: train, Batch: [326/730], Loss: 0.3914\n",
      "Epoch [3/3], Phase: train, Batch: [327/730], Loss: 0.2432\n",
      "Epoch [3/3], Phase: train, Batch: [328/730], Loss: 0.3302\n",
      "Epoch [3/3], Phase: train, Batch: [329/730], Loss: 0.2300\n",
      "Epoch [3/3], Phase: train, Batch: [330/730], Loss: 0.2208\n",
      "Epoch [3/3], Phase: train, Batch: [331/730], Loss: 0.3183\n",
      "Epoch [3/3], Phase: train, Batch: [332/730], Loss: 0.3811\n",
      "Epoch [3/3], Phase: train, Batch: [333/730], Loss: 0.3160\n",
      "Epoch [3/3], Phase: train, Batch: [334/730], Loss: 0.2504\n",
      "Epoch [3/3], Phase: train, Batch: [335/730], Loss: 0.2921\n",
      "Epoch [3/3], Phase: train, Batch: [336/730], Loss: 0.2465\n",
      "Epoch [3/3], Phase: train, Batch: [337/730], Loss: 0.4270\n",
      "Epoch [3/3], Phase: train, Batch: [338/730], Loss: 0.2653\n",
      "Epoch [3/3], Phase: train, Batch: [339/730], Loss: 0.2531\n",
      "Epoch [3/3], Phase: train, Batch: [340/730], Loss: 0.2283\n",
      "Epoch [3/3], Phase: train, Batch: [341/730], Loss: 0.3413\n",
      "Epoch [3/3], Phase: train, Batch: [342/730], Loss: 0.2687\n",
      "Epoch [3/3], Phase: train, Batch: [343/730], Loss: 0.2280\n",
      "Epoch [3/3], Phase: train, Batch: [344/730], Loss: 0.2714\n",
      "Epoch [3/3], Phase: train, Batch: [345/730], Loss: 0.2627\n",
      "Epoch [3/3], Phase: train, Batch: [346/730], Loss: 0.2328\n",
      "Epoch [3/3], Phase: train, Batch: [347/730], Loss: 0.2470\n",
      "Epoch [3/3], Phase: train, Batch: [348/730], Loss: 0.2627\n",
      "Epoch [3/3], Phase: train, Batch: [349/730], Loss: 0.2599\n",
      "Epoch [3/3], Phase: train, Batch: [350/730], Loss: 0.2136\n",
      "Epoch [3/3], Phase: train, Batch: [351/730], Loss: 0.3953\n",
      "Epoch [3/3], Phase: train, Batch: [352/730], Loss: 0.3556\n",
      "Epoch [3/3], Phase: train, Batch: [353/730], Loss: 0.3586\n",
      "Epoch [3/3], Phase: train, Batch: [354/730], Loss: 0.3624\n",
      "Epoch [3/3], Phase: train, Batch: [355/730], Loss: 0.2401\n",
      "Epoch [3/3], Phase: train, Batch: [356/730], Loss: 0.4570\n",
      "Epoch [3/3], Phase: train, Batch: [357/730], Loss: 0.2222\n",
      "Epoch [3/3], Phase: train, Batch: [358/730], Loss: 0.3401\n",
      "Epoch [3/3], Phase: train, Batch: [359/730], Loss: 0.2975\n",
      "Epoch [3/3], Phase: train, Batch: [360/730], Loss: 0.2108\n",
      "Epoch [3/3], Phase: train, Batch: [361/730], Loss: 0.2640\n",
      "Epoch [3/3], Phase: train, Batch: [362/730], Loss: 0.2522\n",
      "Epoch [3/3], Phase: train, Batch: [363/730], Loss: 0.2399\n",
      "Epoch [3/3], Phase: train, Batch: [364/730], Loss: 0.3120\n",
      "Epoch [3/3], Phase: train, Batch: [365/730], Loss: 0.3158\n",
      "Epoch [3/3], Phase: train, Batch: [366/730], Loss: 0.2868\n",
      "Epoch [3/3], Phase: train, Batch: [367/730], Loss: 0.3861\n",
      "Epoch [3/3], Phase: train, Batch: [368/730], Loss: 0.1760\n",
      "Epoch [3/3], Phase: train, Batch: [369/730], Loss: 0.2443\n",
      "Epoch [3/3], Phase: train, Batch: [370/730], Loss: 0.2324\n",
      "Epoch [3/3], Phase: train, Batch: [371/730], Loss: 0.1986\n",
      "Epoch [3/3], Phase: train, Batch: [372/730], Loss: 0.3428\n",
      "Epoch [3/3], Phase: train, Batch: [373/730], Loss: 0.2860\n",
      "Epoch [3/3], Phase: train, Batch: [374/730], Loss: 0.2977\n",
      "Epoch [3/3], Phase: train, Batch: [375/730], Loss: 0.3852\n",
      "Epoch [3/3], Phase: train, Batch: [376/730], Loss: 0.2183\n",
      "Epoch [3/3], Phase: train, Batch: [377/730], Loss: 0.3206\n",
      "Epoch [3/3], Phase: train, Batch: [378/730], Loss: 0.3380\n",
      "Epoch [3/3], Phase: train, Batch: [379/730], Loss: 0.3377\n",
      "Epoch [3/3], Phase: train, Batch: [380/730], Loss: 0.3623\n",
      "Epoch [3/3], Phase: train, Batch: [381/730], Loss: 0.2268\n",
      "Epoch [3/3], Phase: train, Batch: [382/730], Loss: 0.3174\n",
      "Epoch [3/3], Phase: train, Batch: [383/730], Loss: 0.3390\n",
      "Epoch [3/3], Phase: train, Batch: [384/730], Loss: 0.2185\n",
      "Epoch [3/3], Phase: train, Batch: [385/730], Loss: 0.2749\n",
      "Epoch [3/3], Phase: train, Batch: [386/730], Loss: 0.2469\n",
      "Epoch [3/3], Phase: train, Batch: [387/730], Loss: 0.3617\n",
      "Epoch [3/3], Phase: train, Batch: [388/730], Loss: 0.2430\n",
      "Epoch [3/3], Phase: train, Batch: [389/730], Loss: 0.1958\n",
      "Epoch [3/3], Phase: train, Batch: [390/730], Loss: 0.2599\n",
      "Epoch [3/3], Phase: train, Batch: [391/730], Loss: 0.2732\n",
      "Epoch [3/3], Phase: train, Batch: [392/730], Loss: 0.2402\n",
      "Epoch [3/3], Phase: train, Batch: [393/730], Loss: 0.2754\n",
      "Epoch [3/3], Phase: train, Batch: [394/730], Loss: 0.3604\n",
      "Epoch [3/3], Phase: train, Batch: [395/730], Loss: 0.3094\n",
      "Epoch [3/3], Phase: train, Batch: [396/730], Loss: 0.3820\n",
      "Epoch [3/3], Phase: train, Batch: [397/730], Loss: 0.1909\n",
      "Epoch [3/3], Phase: train, Batch: [398/730], Loss: 0.2662\n",
      "Epoch [3/3], Phase: train, Batch: [399/730], Loss: 0.2470\n",
      "Epoch [3/3], Phase: train, Batch: [400/730], Loss: 0.2627\n",
      "Epoch [3/3], Phase: train, Batch: [401/730], Loss: 0.3748\n",
      "Epoch [3/3], Phase: train, Batch: [402/730], Loss: 0.2179\n",
      "Epoch [3/3], Phase: train, Batch: [403/730], Loss: 0.1773\n",
      "Epoch [3/3], Phase: train, Batch: [404/730], Loss: 0.4192\n",
      "Epoch [3/3], Phase: train, Batch: [405/730], Loss: 0.3397\n",
      "Epoch [3/3], Phase: train, Batch: [406/730], Loss: 0.3117\n",
      "Epoch [3/3], Phase: train, Batch: [407/730], Loss: 0.2799\n",
      "Epoch [3/3], Phase: train, Batch: [408/730], Loss: 0.1815\n",
      "Epoch [3/3], Phase: train, Batch: [409/730], Loss: 0.2982\n",
      "Epoch [3/3], Phase: train, Batch: [410/730], Loss: 0.3095\n",
      "Epoch [3/3], Phase: train, Batch: [411/730], Loss: 0.3035\n",
      "Epoch [3/3], Phase: train, Batch: [412/730], Loss: 0.3368\n",
      "Epoch [3/3], Phase: train, Batch: [413/730], Loss: 0.3011\n",
      "Epoch [3/3], Phase: train, Batch: [414/730], Loss: 0.2803\n",
      "Epoch [3/3], Phase: train, Batch: [415/730], Loss: 0.3124\n",
      "Epoch [3/3], Phase: train, Batch: [416/730], Loss: 0.4208\n",
      "Epoch [3/3], Phase: train, Batch: [417/730], Loss: 0.2313\n",
      "Epoch [3/3], Phase: train, Batch: [418/730], Loss: 0.1744\n",
      "Epoch [3/3], Phase: train, Batch: [419/730], Loss: 0.3204\n",
      "Epoch [3/3], Phase: train, Batch: [420/730], Loss: 0.4128\n",
      "Epoch [3/3], Phase: train, Batch: [421/730], Loss: 0.3001\n",
      "Epoch [3/3], Phase: train, Batch: [422/730], Loss: 0.3176\n",
      "Epoch [3/3], Phase: train, Batch: [423/730], Loss: 0.1894\n",
      "Epoch [3/3], Phase: train, Batch: [424/730], Loss: 0.2295\n",
      "Epoch [3/3], Phase: train, Batch: [425/730], Loss: 0.3313\n",
      "Epoch [3/3], Phase: train, Batch: [426/730], Loss: 0.2527\n",
      "Epoch [3/3], Phase: train, Batch: [427/730], Loss: 0.2390\n",
      "Epoch [3/3], Phase: train, Batch: [428/730], Loss: 0.3116\n",
      "Epoch [3/3], Phase: train, Batch: [429/730], Loss: 0.3640\n",
      "Epoch [3/3], Phase: train, Batch: [430/730], Loss: 0.2334\n",
      "Epoch [3/3], Phase: train, Batch: [431/730], Loss: 0.3583\n",
      "Epoch [3/3], Phase: train, Batch: [432/730], Loss: 0.2788\n",
      "Epoch [3/3], Phase: train, Batch: [433/730], Loss: 0.3040\n",
      "Epoch [3/3], Phase: train, Batch: [434/730], Loss: 0.2132\n",
      "Epoch [3/3], Phase: train, Batch: [435/730], Loss: 0.1868\n",
      "Epoch [3/3], Phase: train, Batch: [436/730], Loss: 0.1971\n",
      "Epoch [3/3], Phase: train, Batch: [437/730], Loss: 0.3855\n",
      "Epoch [3/3], Phase: train, Batch: [438/730], Loss: 0.2090\n",
      "Epoch [3/3], Phase: train, Batch: [439/730], Loss: 0.2832\n",
      "Epoch [3/3], Phase: train, Batch: [440/730], Loss: 0.2358\n",
      "Epoch [3/3], Phase: train, Batch: [441/730], Loss: 0.3475\n",
      "Epoch [3/3], Phase: train, Batch: [442/730], Loss: 0.2966\n",
      "Epoch [3/3], Phase: train, Batch: [443/730], Loss: 0.4435\n",
      "Epoch [3/3], Phase: train, Batch: [444/730], Loss: 0.2279\n",
      "Epoch [3/3], Phase: train, Batch: [445/730], Loss: 0.2769\n",
      "Epoch [3/3], Phase: train, Batch: [446/730], Loss: 0.3151\n",
      "Epoch [3/3], Phase: train, Batch: [447/730], Loss: 0.3116\n",
      "Epoch [3/3], Phase: train, Batch: [448/730], Loss: 0.3502\n",
      "Epoch [3/3], Phase: train, Batch: [449/730], Loss: 0.2244\n",
      "Epoch [3/3], Phase: train, Batch: [450/730], Loss: 0.2822\n",
      "Epoch [3/3], Phase: train, Batch: [451/730], Loss: 0.3731\n",
      "Epoch [3/3], Phase: train, Batch: [452/730], Loss: 0.1449\n",
      "Epoch [3/3], Phase: train, Batch: [453/730], Loss: 0.1851\n",
      "Epoch [3/3], Phase: train, Batch: [454/730], Loss: 0.3090\n",
      "Epoch [3/3], Phase: train, Batch: [455/730], Loss: 0.2393\n",
      "Epoch [3/3], Phase: train, Batch: [456/730], Loss: 0.3354\n",
      "Epoch [3/3], Phase: train, Batch: [457/730], Loss: 0.3515\n",
      "Epoch [3/3], Phase: train, Batch: [458/730], Loss: 0.2435\n",
      "Epoch [3/3], Phase: train, Batch: [459/730], Loss: 0.1998\n",
      "Epoch [3/3], Phase: train, Batch: [460/730], Loss: 0.2368\n",
      "Epoch [3/3], Phase: train, Batch: [461/730], Loss: 0.3303\n",
      "Epoch [3/3], Phase: train, Batch: [462/730], Loss: 0.2400\n",
      "Epoch [3/3], Phase: train, Batch: [463/730], Loss: 0.2737\n",
      "Epoch [3/3], Phase: train, Batch: [464/730], Loss: 0.3451\n",
      "Epoch [3/3], Phase: train, Batch: [465/730], Loss: 0.3160\n",
      "Epoch [3/3], Phase: train, Batch: [466/730], Loss: 0.2981\n",
      "Epoch [3/3], Phase: train, Batch: [467/730], Loss: 0.4653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Phase: train, Batch: [468/730], Loss: 0.2269\n",
      "Epoch [3/3], Phase: train, Batch: [469/730], Loss: 0.2235\n",
      "Epoch [3/3], Phase: train, Batch: [470/730], Loss: 0.2669\n",
      "Epoch [3/3], Phase: train, Batch: [471/730], Loss: 0.2352\n",
      "Epoch [3/3], Phase: train, Batch: [472/730], Loss: 0.3547\n",
      "Epoch [3/3], Phase: train, Batch: [473/730], Loss: 0.3329\n",
      "Epoch [3/3], Phase: train, Batch: [474/730], Loss: 0.3025\n",
      "Epoch [3/3], Phase: train, Batch: [475/730], Loss: 0.2721\n",
      "Epoch [3/3], Phase: train, Batch: [476/730], Loss: 0.4072\n",
      "Epoch [3/3], Phase: train, Batch: [477/730], Loss: 0.2418\n",
      "Epoch [3/3], Phase: train, Batch: [478/730], Loss: 0.2534\n",
      "Epoch [3/3], Phase: train, Batch: [479/730], Loss: 0.2482\n",
      "Epoch [3/3], Phase: train, Batch: [480/730], Loss: 0.2034\n",
      "Epoch [3/3], Phase: train, Batch: [481/730], Loss: 0.3557\n",
      "Epoch [3/3], Phase: train, Batch: [482/730], Loss: 0.3256\n",
      "Epoch [3/3], Phase: train, Batch: [483/730], Loss: 0.2759\n",
      "Epoch [3/3], Phase: train, Batch: [484/730], Loss: 0.3379\n",
      "Epoch [3/3], Phase: train, Batch: [485/730], Loss: 0.2248\n",
      "Epoch [3/3], Phase: train, Batch: [486/730], Loss: 0.2945\n",
      "Epoch [3/3], Phase: train, Batch: [487/730], Loss: 0.3102\n",
      "Epoch [3/3], Phase: train, Batch: [488/730], Loss: 0.3345\n",
      "Epoch [3/3], Phase: train, Batch: [489/730], Loss: 0.3017\n",
      "Epoch [3/3], Phase: train, Batch: [490/730], Loss: 0.3399\n",
      "Epoch [3/3], Phase: train, Batch: [491/730], Loss: 0.2275\n",
      "Epoch [3/3], Phase: train, Batch: [492/730], Loss: 0.2972\n",
      "Epoch [3/3], Phase: train, Batch: [493/730], Loss: 0.1838\n",
      "Epoch [3/3], Phase: train, Batch: [494/730], Loss: 0.2764\n",
      "Epoch [3/3], Phase: train, Batch: [495/730], Loss: 0.3099\n",
      "Epoch [3/3], Phase: train, Batch: [496/730], Loss: 0.3497\n",
      "Epoch [3/3], Phase: train, Batch: [497/730], Loss: 0.3411\n",
      "Epoch [3/3], Phase: train, Batch: [498/730], Loss: 0.1433\n",
      "Epoch [3/3], Phase: train, Batch: [499/730], Loss: 0.3489\n",
      "Epoch [3/3], Phase: train, Batch: [500/730], Loss: 0.2580\n",
      "Epoch [3/3], Phase: train, Batch: [501/730], Loss: 0.2607\n",
      "Epoch [3/3], Phase: train, Batch: [502/730], Loss: 0.2421\n",
      "Epoch [3/3], Phase: train, Batch: [503/730], Loss: 0.1786\n",
      "Epoch [3/3], Phase: train, Batch: [504/730], Loss: 0.2519\n",
      "Epoch [3/3], Phase: train, Batch: [505/730], Loss: 0.3532\n",
      "Epoch [3/3], Phase: train, Batch: [506/730], Loss: 0.3181\n",
      "Epoch [3/3], Phase: train, Batch: [507/730], Loss: 0.3657\n",
      "Epoch [3/3], Phase: train, Batch: [508/730], Loss: 0.3359\n",
      "Epoch [3/3], Phase: train, Batch: [509/730], Loss: 0.1950\n",
      "Epoch [3/3], Phase: train, Batch: [510/730], Loss: 0.3167\n",
      "Epoch [3/3], Phase: train, Batch: [511/730], Loss: 0.2562\n",
      "Epoch [3/3], Phase: train, Batch: [512/730], Loss: 0.2597\n",
      "Epoch [3/3], Phase: train, Batch: [513/730], Loss: 0.2215\n",
      "Epoch [3/3], Phase: train, Batch: [514/730], Loss: 0.2757\n",
      "Epoch [3/3], Phase: train, Batch: [515/730], Loss: 0.1960\n",
      "Epoch [3/3], Phase: train, Batch: [516/730], Loss: 0.3525\n",
      "Epoch [3/3], Phase: train, Batch: [517/730], Loss: 0.4118\n",
      "Epoch [3/3], Phase: train, Batch: [518/730], Loss: 0.3407\n",
      "Epoch [3/3], Phase: train, Batch: [519/730], Loss: 0.2030\n",
      "Epoch [3/3], Phase: train, Batch: [520/730], Loss: 0.2810\n",
      "Epoch [3/3], Phase: train, Batch: [521/730], Loss: 0.2548\n",
      "Epoch [3/3], Phase: train, Batch: [522/730], Loss: 0.2955\n",
      "Epoch [3/3], Phase: train, Batch: [523/730], Loss: 0.2061\n",
      "Epoch [3/3], Phase: train, Batch: [524/730], Loss: 0.3192\n",
      "Epoch [3/3], Phase: train, Batch: [525/730], Loss: 0.3657\n",
      "Epoch [3/3], Phase: train, Batch: [526/730], Loss: 0.2911\n",
      "Epoch [3/3], Phase: train, Batch: [527/730], Loss: 0.2585\n",
      "Epoch [3/3], Phase: train, Batch: [528/730], Loss: 0.2073\n",
      "Epoch [3/3], Phase: train, Batch: [529/730], Loss: 0.2563\n",
      "Epoch [3/3], Phase: train, Batch: [530/730], Loss: 0.3332\n",
      "Epoch [3/3], Phase: train, Batch: [531/730], Loss: 0.2013\n",
      "Epoch [3/3], Phase: train, Batch: [532/730], Loss: 0.2531\n",
      "Epoch [3/3], Phase: train, Batch: [533/730], Loss: 0.2353\n",
      "Epoch [3/3], Phase: train, Batch: [534/730], Loss: 0.3014\n",
      "Epoch [3/3], Phase: train, Batch: [535/730], Loss: 0.2392\n",
      "Epoch [3/3], Phase: train, Batch: [536/730], Loss: 0.2197\n",
      "Epoch [3/3], Phase: train, Batch: [537/730], Loss: 0.2341\n",
      "Epoch [3/3], Phase: train, Batch: [538/730], Loss: 0.2620\n",
      "Epoch [3/3], Phase: train, Batch: [539/730], Loss: 0.2252\n",
      "Epoch [3/3], Phase: train, Batch: [540/730], Loss: 0.3030\n",
      "Epoch [3/3], Phase: train, Batch: [541/730], Loss: 0.3866\n",
      "Epoch [3/3], Phase: train, Batch: [542/730], Loss: 0.3311\n",
      "Epoch [3/3], Phase: train, Batch: [543/730], Loss: 0.2887\n",
      "Epoch [3/3], Phase: train, Batch: [544/730], Loss: 0.3003\n",
      "Epoch [3/3], Phase: train, Batch: [545/730], Loss: 0.3776\n",
      "Epoch [3/3], Phase: train, Batch: [546/730], Loss: 0.3030\n",
      "Epoch [3/3], Phase: train, Batch: [547/730], Loss: 0.2076\n",
      "Epoch [3/3], Phase: train, Batch: [548/730], Loss: 0.1953\n",
      "Epoch [3/3], Phase: train, Batch: [549/730], Loss: 0.3847\n",
      "Epoch [3/3], Phase: train, Batch: [550/730], Loss: 0.3502\n",
      "Epoch [3/3], Phase: train, Batch: [551/730], Loss: 0.2212\n",
      "Epoch [3/3], Phase: train, Batch: [552/730], Loss: 0.3835\n",
      "Epoch [3/3], Phase: train, Batch: [553/730], Loss: 0.2596\n",
      "Epoch [3/3], Phase: train, Batch: [554/730], Loss: 0.2816\n",
      "Epoch [3/3], Phase: train, Batch: [555/730], Loss: 0.2501\n",
      "Epoch [3/3], Phase: train, Batch: [556/730], Loss: 0.3449\n",
      "Epoch [3/3], Phase: train, Batch: [557/730], Loss: 0.3406\n",
      "Epoch [3/3], Phase: train, Batch: [558/730], Loss: 0.2633\n",
      "Epoch [3/3], Phase: train, Batch: [559/730], Loss: 0.3553\n",
      "Epoch [3/3], Phase: train, Batch: [560/730], Loss: 0.2073\n",
      "Epoch [3/3], Phase: train, Batch: [561/730], Loss: 0.2934\n",
      "Epoch [3/3], Phase: train, Batch: [562/730], Loss: 0.3920\n",
      "Epoch [3/3], Phase: train, Batch: [563/730], Loss: 0.2437\n",
      "Epoch [3/3], Phase: train, Batch: [564/730], Loss: 0.2739\n",
      "Epoch [3/3], Phase: train, Batch: [565/730], Loss: 0.2395\n",
      "Epoch [3/3], Phase: train, Batch: [566/730], Loss: 0.2244\n",
      "Epoch [3/3], Phase: train, Batch: [567/730], Loss: 0.2089\n",
      "Epoch [3/3], Phase: train, Batch: [568/730], Loss: 0.1929\n",
      "Epoch [3/3], Phase: train, Batch: [569/730], Loss: 0.2333\n",
      "Epoch [3/3], Phase: train, Batch: [570/730], Loss: 0.2076\n",
      "Epoch [3/3], Phase: train, Batch: [571/730], Loss: 0.2628\n",
      "Epoch [3/3], Phase: train, Batch: [572/730], Loss: 0.2645\n",
      "Epoch [3/3], Phase: train, Batch: [573/730], Loss: 0.2263\n",
      "Epoch [3/3], Phase: train, Batch: [574/730], Loss: 0.2746\n",
      "Epoch [3/3], Phase: train, Batch: [575/730], Loss: 0.3736\n",
      "Epoch [3/3], Phase: train, Batch: [576/730], Loss: 0.2658\n",
      "Epoch [3/3], Phase: train, Batch: [577/730], Loss: 0.3115\n",
      "Epoch [3/3], Phase: train, Batch: [578/730], Loss: 0.1445\n",
      "Epoch [3/3], Phase: train, Batch: [579/730], Loss: 0.2370\n",
      "Epoch [3/3], Phase: train, Batch: [580/730], Loss: 0.2434\n",
      "Epoch [3/3], Phase: train, Batch: [581/730], Loss: 0.2648\n",
      "Epoch [3/3], Phase: train, Batch: [582/730], Loss: 0.3721\n",
      "Epoch [3/3], Phase: train, Batch: [583/730], Loss: 0.2554\n",
      "Epoch [3/3], Phase: train, Batch: [584/730], Loss: 0.2576\n",
      "Epoch [3/3], Phase: train, Batch: [585/730], Loss: 0.2560\n",
      "Epoch [3/3], Phase: train, Batch: [586/730], Loss: 0.1827\n",
      "Epoch [3/3], Phase: train, Batch: [587/730], Loss: 0.2758\n",
      "Epoch [3/3], Phase: train, Batch: [588/730], Loss: 0.1971\n",
      "Epoch [3/3], Phase: train, Batch: [589/730], Loss: 0.1956\n",
      "Epoch [3/3], Phase: train, Batch: [590/730], Loss: 0.2121\n",
      "Epoch [3/3], Phase: train, Batch: [591/730], Loss: 0.2313\n",
      "Epoch [3/3], Phase: train, Batch: [592/730], Loss: 0.4422\n",
      "Epoch [3/3], Phase: train, Batch: [593/730], Loss: 0.3360\n",
      "Epoch [3/3], Phase: train, Batch: [594/730], Loss: 0.2590\n",
      "Epoch [3/3], Phase: train, Batch: [595/730], Loss: 0.2565\n",
      "Epoch [3/3], Phase: train, Batch: [596/730], Loss: 0.3438\n",
      "Epoch [3/3], Phase: train, Batch: [597/730], Loss: 0.4055\n",
      "Epoch [3/3], Phase: train, Batch: [598/730], Loss: 0.2796\n",
      "Epoch [3/3], Phase: train, Batch: [599/730], Loss: 0.2186\n",
      "Epoch [3/3], Phase: train, Batch: [600/730], Loss: 0.2553\n",
      "Epoch [3/3], Phase: train, Batch: [601/730], Loss: 0.2338\n",
      "Epoch [3/3], Phase: train, Batch: [602/730], Loss: 0.1910\n",
      "Epoch [3/3], Phase: train, Batch: [603/730], Loss: 0.3518\n",
      "Epoch [3/3], Phase: train, Batch: [604/730], Loss: 0.3087\n",
      "Epoch [3/3], Phase: train, Batch: [605/730], Loss: 0.2704\n",
      "Epoch [3/3], Phase: train, Batch: [606/730], Loss: 0.3481\n",
      "Epoch [3/3], Phase: train, Batch: [607/730], Loss: 0.2630\n",
      "Epoch [3/3], Phase: train, Batch: [608/730], Loss: 0.3005\n",
      "Epoch [3/3], Phase: train, Batch: [609/730], Loss: 0.1988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Phase: train, Batch: [610/730], Loss: 0.2607\n",
      "Epoch [3/3], Phase: train, Batch: [611/730], Loss: 0.1509\n",
      "Epoch [3/3], Phase: train, Batch: [612/730], Loss: 0.2706\n",
      "Epoch [3/3], Phase: train, Batch: [613/730], Loss: 0.2414\n",
      "Epoch [3/3], Phase: train, Batch: [614/730], Loss: 0.2394\n",
      "Epoch [3/3], Phase: train, Batch: [615/730], Loss: 0.3074\n",
      "Epoch [3/3], Phase: train, Batch: [616/730], Loss: 0.2350\n",
      "Epoch [3/3], Phase: train, Batch: [617/730], Loss: 0.2261\n",
      "Epoch [3/3], Phase: train, Batch: [618/730], Loss: 0.4887\n",
      "Epoch [3/3], Phase: train, Batch: [619/730], Loss: 0.3266\n",
      "Epoch [3/3], Phase: train, Batch: [620/730], Loss: 0.2916\n",
      "Epoch [3/3], Phase: train, Batch: [621/730], Loss: 0.3164\n",
      "Epoch [3/3], Phase: train, Batch: [622/730], Loss: 0.3221\n",
      "Epoch [3/3], Phase: train, Batch: [623/730], Loss: 0.2381\n",
      "Epoch [3/3], Phase: train, Batch: [624/730], Loss: 0.3568\n",
      "Epoch [3/3], Phase: train, Batch: [625/730], Loss: 0.2668\n",
      "Epoch [3/3], Phase: train, Batch: [626/730], Loss: 0.2267\n",
      "Epoch [3/3], Phase: train, Batch: [627/730], Loss: 0.3057\n",
      "Epoch [3/3], Phase: train, Batch: [628/730], Loss: 0.2464\n",
      "Epoch [3/3], Phase: train, Batch: [629/730], Loss: 0.2499\n",
      "Epoch [3/3], Phase: train, Batch: [630/730], Loss: 0.4926\n",
      "Epoch [3/3], Phase: train, Batch: [631/730], Loss: 0.1593\n",
      "Epoch [3/3], Phase: train, Batch: [632/730], Loss: 0.2543\n",
      "Epoch [3/3], Phase: train, Batch: [633/730], Loss: 0.2931\n",
      "Epoch [3/3], Phase: train, Batch: [634/730], Loss: 0.3144\n",
      "Epoch [3/3], Phase: train, Batch: [635/730], Loss: 0.3118\n",
      "Epoch [3/3], Phase: train, Batch: [636/730], Loss: 0.3741\n",
      "Epoch [3/3], Phase: train, Batch: [637/730], Loss: 0.4299\n",
      "Epoch [3/3], Phase: train, Batch: [638/730], Loss: 0.3956\n",
      "Epoch [3/3], Phase: train, Batch: [639/730], Loss: 0.2949\n",
      "Epoch [3/3], Phase: train, Batch: [640/730], Loss: 0.3823\n",
      "Epoch [3/3], Phase: train, Batch: [641/730], Loss: 0.3996\n",
      "Epoch [3/3], Phase: train, Batch: [642/730], Loss: 0.2931\n",
      "Epoch [3/3], Phase: train, Batch: [643/730], Loss: 0.3485\n",
      "Epoch [3/3], Phase: train, Batch: [644/730], Loss: 0.4601\n",
      "Epoch [3/3], Phase: train, Batch: [645/730], Loss: 0.3426\n",
      "Epoch [3/3], Phase: train, Batch: [646/730], Loss: 0.2241\n",
      "Epoch [3/3], Phase: train, Batch: [647/730], Loss: 0.3782\n",
      "Epoch [3/3], Phase: train, Batch: [648/730], Loss: 0.2214\n",
      "Epoch [3/3], Phase: train, Batch: [649/730], Loss: 0.3609\n",
      "Epoch [3/3], Phase: train, Batch: [650/730], Loss: 0.3821\n",
      "Epoch [3/3], Phase: train, Batch: [651/730], Loss: 0.2207\n",
      "Epoch [3/3], Phase: train, Batch: [652/730], Loss: 0.2214\n",
      "Epoch [3/3], Phase: train, Batch: [653/730], Loss: 0.2079\n",
      "Epoch [3/3], Phase: train, Batch: [654/730], Loss: 0.3619\n",
      "Epoch [3/3], Phase: train, Batch: [655/730], Loss: 0.2185\n",
      "Epoch [3/3], Phase: train, Batch: [656/730], Loss: 0.3902\n",
      "Epoch [3/3], Phase: train, Batch: [657/730], Loss: 0.2528\n",
      "Epoch [3/3], Phase: train, Batch: [658/730], Loss: 0.3048\n",
      "Epoch [3/3], Phase: train, Batch: [659/730], Loss: 0.2720\n",
      "Epoch [3/3], Phase: train, Batch: [660/730], Loss: 0.2596\n",
      "Epoch [3/3], Phase: train, Batch: [661/730], Loss: 0.2105\n",
      "Epoch [3/3], Phase: train, Batch: [662/730], Loss: 0.3748\n",
      "Epoch [3/3], Phase: train, Batch: [663/730], Loss: 0.2724\n",
      "Epoch [3/3], Phase: train, Batch: [664/730], Loss: 0.3290\n",
      "Epoch [3/3], Phase: train, Batch: [665/730], Loss: 0.3705\n",
      "Epoch [3/3], Phase: train, Batch: [666/730], Loss: 0.2020\n",
      "Epoch [3/3], Phase: train, Batch: [667/730], Loss: 0.2976\n",
      "Epoch [3/3], Phase: train, Batch: [668/730], Loss: 0.2338\n",
      "Epoch [3/3], Phase: train, Batch: [669/730], Loss: 0.2905\n",
      "Epoch [3/3], Phase: train, Batch: [670/730], Loss: 0.2043\n",
      "Epoch [3/3], Phase: train, Batch: [671/730], Loss: 0.3903\n",
      "Epoch [3/3], Phase: train, Batch: [672/730], Loss: 0.2891\n",
      "Epoch [3/3], Phase: train, Batch: [673/730], Loss: 0.2516\n",
      "Epoch [3/3], Phase: train, Batch: [674/730], Loss: 0.2455\n",
      "Epoch [3/3], Phase: train, Batch: [675/730], Loss: 0.1964\n",
      "Epoch [3/3], Phase: train, Batch: [676/730], Loss: 0.4043\n",
      "Epoch [3/3], Phase: train, Batch: [677/730], Loss: 0.3137\n",
      "Epoch [3/3], Phase: train, Batch: [678/730], Loss: 0.2627\n",
      "Epoch [3/3], Phase: train, Batch: [679/730], Loss: 0.3245\n",
      "Epoch [3/3], Phase: train, Batch: [680/730], Loss: 0.1686\n",
      "Epoch [3/3], Phase: train, Batch: [681/730], Loss: 0.2957\n",
      "Epoch [3/3], Phase: train, Batch: [682/730], Loss: 0.2859\n",
      "Epoch [3/3], Phase: train, Batch: [683/730], Loss: 0.2609\n",
      "Epoch [3/3], Phase: train, Batch: [684/730], Loss: 0.1959\n",
      "Epoch [3/3], Phase: train, Batch: [685/730], Loss: 0.3226\n",
      "Epoch [3/3], Phase: train, Batch: [686/730], Loss: 0.2116\n",
      "Epoch [3/3], Phase: train, Batch: [687/730], Loss: 0.4032\n",
      "Epoch [3/3], Phase: train, Batch: [688/730], Loss: 0.2977\n",
      "Epoch [3/3], Phase: train, Batch: [689/730], Loss: 0.2325\n",
      "Epoch [3/3], Phase: train, Batch: [690/730], Loss: 0.2246\n",
      "Epoch [3/3], Phase: train, Batch: [691/730], Loss: 0.2520\n",
      "Epoch [3/3], Phase: train, Batch: [692/730], Loss: 0.3240\n",
      "Epoch [3/3], Phase: train, Batch: [693/730], Loss: 0.1977\n",
      "Epoch [3/3], Phase: train, Batch: [694/730], Loss: 0.2298\n",
      "Epoch [3/3], Phase: train, Batch: [695/730], Loss: 0.4234\n",
      "Epoch [3/3], Phase: train, Batch: [696/730], Loss: 0.2960\n",
      "Epoch [3/3], Phase: train, Batch: [697/730], Loss: 0.2290\n",
      "Epoch [3/3], Phase: train, Batch: [698/730], Loss: 0.2803\n",
      "Epoch [3/3], Phase: train, Batch: [699/730], Loss: 0.4071\n",
      "Epoch [3/3], Phase: train, Batch: [700/730], Loss: 0.3994\n",
      "Epoch [3/3], Phase: train, Batch: [701/730], Loss: 0.1921\n",
      "Epoch [3/3], Phase: train, Batch: [702/730], Loss: 0.2266\n",
      "Epoch [3/3], Phase: train, Batch: [703/730], Loss: 0.2518\n",
      "Epoch [3/3], Phase: train, Batch: [704/730], Loss: 0.4128\n",
      "Epoch [3/3], Phase: train, Batch: [705/730], Loss: 0.2842\n",
      "Epoch [3/3], Phase: train, Batch: [706/730], Loss: 0.2435\n",
      "Epoch [3/3], Phase: train, Batch: [707/730], Loss: 0.3000\n",
      "Epoch [3/3], Phase: train, Batch: [708/730], Loss: 0.3050\n",
      "Epoch [3/3], Phase: train, Batch: [709/730], Loss: 0.2167\n",
      "Epoch [3/3], Phase: train, Batch: [710/730], Loss: 0.2436\n",
      "Epoch [3/3], Phase: train, Batch: [711/730], Loss: 0.3500\n",
      "Epoch [3/3], Phase: train, Batch: [712/730], Loss: 0.2145\n",
      "Epoch [3/3], Phase: train, Batch: [713/730], Loss: 0.3466\n",
      "Epoch [3/3], Phase: train, Batch: [714/730], Loss: 0.4299\n",
      "Epoch [3/3], Phase: train, Batch: [715/730], Loss: 0.3418\n",
      "Epoch [3/3], Phase: train, Batch: [716/730], Loss: 0.2056\n",
      "Epoch [3/3], Phase: train, Batch: [717/730], Loss: 0.2869\n",
      "Epoch [3/3], Phase: train, Batch: [718/730], Loss: 0.2560\n",
      "Epoch [3/3], Phase: train, Batch: [719/730], Loss: 0.1871\n",
      "Epoch [3/3], Phase: train, Batch: [720/730], Loss: 0.2621\n",
      "Epoch [3/3], Phase: train, Batch: [721/730], Loss: 0.2763\n",
      "Epoch [3/3], Phase: train, Batch: [722/730], Loss: 0.2274\n",
      "Epoch [3/3], Phase: train, Batch: [723/730], Loss: 0.2671\n",
      "Epoch [3/3], Phase: train, Batch: [724/730], Loss: 0.2261\n",
      "Epoch [3/3], Phase: train, Batch: [725/730], Loss: 0.3888\n",
      "Epoch [3/3], Phase: train, Batch: [726/730], Loss: 0.2831\n",
      "Epoch [3/3], Phase: train, Batch: [727/730], Loss: 0.3726\n",
      "Epoch [3/3], Phase: train, Batch: [728/730], Loss: 0.2592\n",
      "Epoch [3/3], Phase: train, Batch: [729/730], Loss: 0.2249\n",
      "Epoch [3/3], Phase: train, Batch: [730/730], Loss: 0.1748\n",
      "train Loss: 0.2851 Acc: 0.8841\n",
      "Epoch [3/3], Phase: val, Batch: [1/182], Loss: 0.3142\n",
      "Epoch [3/3], Phase: val, Batch: [2/182], Loss: 0.2281\n",
      "Epoch [3/3], Phase: val, Batch: [3/182], Loss: 0.1754\n",
      "Epoch [3/3], Phase: val, Batch: [4/182], Loss: 0.2420\n",
      "Epoch [3/3], Phase: val, Batch: [5/182], Loss: 0.2051\n",
      "Epoch [3/3], Phase: val, Batch: [6/182], Loss: 0.1775\n",
      "Epoch [3/3], Phase: val, Batch: [7/182], Loss: 0.1066\n",
      "Epoch [3/3], Phase: val, Batch: [8/182], Loss: 0.2360\n",
      "Epoch [3/3], Phase: val, Batch: [9/182], Loss: 0.1991\n",
      "Epoch [3/3], Phase: val, Batch: [10/182], Loss: 0.1584\n",
      "Epoch [3/3], Phase: val, Batch: [11/182], Loss: 0.1419\n",
      "Epoch [3/3], Phase: val, Batch: [12/182], Loss: 0.2074\n",
      "Epoch [3/3], Phase: val, Batch: [13/182], Loss: 0.1804\n",
      "Epoch [3/3], Phase: val, Batch: [14/182], Loss: 0.1381\n",
      "Epoch [3/3], Phase: val, Batch: [15/182], Loss: 0.1872\n",
      "Epoch [3/3], Phase: val, Batch: [16/182], Loss: 0.2505\n",
      "Epoch [3/3], Phase: val, Batch: [17/182], Loss: 0.2358\n",
      "Epoch [3/3], Phase: val, Batch: [18/182], Loss: 0.2210\n",
      "Epoch [3/3], Phase: val, Batch: [19/182], Loss: 0.2990\n",
      "Epoch [3/3], Phase: val, Batch: [20/182], Loss: 0.3220\n",
      "Epoch [3/3], Phase: val, Batch: [21/182], Loss: 0.3059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Phase: val, Batch: [22/182], Loss: 0.2897\n",
      "Epoch [3/3], Phase: val, Batch: [23/182], Loss: 0.1469\n",
      "Epoch [3/3], Phase: val, Batch: [24/182], Loss: 0.3089\n",
      "Epoch [3/3], Phase: val, Batch: [25/182], Loss: 0.2320\n",
      "Epoch [3/3], Phase: val, Batch: [26/182], Loss: 0.1426\n",
      "Epoch [3/3], Phase: val, Batch: [27/182], Loss: 0.1944\n",
      "Epoch [3/3], Phase: val, Batch: [28/182], Loss: 0.3209\n",
      "Epoch [3/3], Phase: val, Batch: [29/182], Loss: 0.2590\n",
      "Epoch [3/3], Phase: val, Batch: [30/182], Loss: 0.2560\n",
      "Epoch [3/3], Phase: val, Batch: [31/182], Loss: 0.3035\n",
      "Epoch [3/3], Phase: val, Batch: [32/182], Loss: 0.1478\n",
      "Epoch [3/3], Phase: val, Batch: [33/182], Loss: 0.2395\n",
      "Epoch [3/3], Phase: val, Batch: [34/182], Loss: 0.2373\n",
      "Epoch [3/3], Phase: val, Batch: [35/182], Loss: 0.1510\n",
      "Epoch [3/3], Phase: val, Batch: [36/182], Loss: 0.2210\n",
      "Epoch [3/3], Phase: val, Batch: [37/182], Loss: 0.1578\n",
      "Epoch [3/3], Phase: val, Batch: [38/182], Loss: 0.1661\n",
      "Epoch [3/3], Phase: val, Batch: [39/182], Loss: 0.2760\n",
      "Epoch [3/3], Phase: val, Batch: [40/182], Loss: 0.2061\n",
      "Epoch [3/3], Phase: val, Batch: [41/182], Loss: 0.1956\n",
      "Epoch [3/3], Phase: val, Batch: [42/182], Loss: 0.2486\n",
      "Epoch [3/3], Phase: val, Batch: [43/182], Loss: 0.1907\n",
      "Epoch [3/3], Phase: val, Batch: [44/182], Loss: 0.3116\n",
      "Epoch [3/3], Phase: val, Batch: [45/182], Loss: 0.2663\n",
      "Epoch [3/3], Phase: val, Batch: [46/182], Loss: 0.1854\n",
      "Epoch [3/3], Phase: val, Batch: [47/182], Loss: 0.2462\n",
      "Epoch [3/3], Phase: val, Batch: [48/182], Loss: 0.1166\n",
      "Epoch [3/3], Phase: val, Batch: [49/182], Loss: 0.2490\n",
      "Epoch [3/3], Phase: val, Batch: [50/182], Loss: 0.3060\n",
      "Epoch [3/3], Phase: val, Batch: [51/182], Loss: 0.3528\n",
      "Epoch [3/3], Phase: val, Batch: [52/182], Loss: 0.2176\n",
      "Epoch [3/3], Phase: val, Batch: [53/182], Loss: 0.2147\n",
      "Epoch [3/3], Phase: val, Batch: [54/182], Loss: 0.2736\n",
      "Epoch [3/3], Phase: val, Batch: [55/182], Loss: 0.1708\n",
      "Epoch [3/3], Phase: val, Batch: [56/182], Loss: 0.1756\n",
      "Epoch [3/3], Phase: val, Batch: [57/182], Loss: 0.2108\n",
      "Epoch [3/3], Phase: val, Batch: [58/182], Loss: 0.1954\n",
      "Epoch [3/3], Phase: val, Batch: [59/182], Loss: 0.1549\n",
      "Epoch [3/3], Phase: val, Batch: [60/182], Loss: 0.1516\n",
      "Epoch [3/3], Phase: val, Batch: [61/182], Loss: 0.2643\n",
      "Epoch [3/3], Phase: val, Batch: [62/182], Loss: 0.3219\n",
      "Epoch [3/3], Phase: val, Batch: [63/182], Loss: 0.1721\n",
      "Epoch [3/3], Phase: val, Batch: [64/182], Loss: 0.2515\n",
      "Epoch [3/3], Phase: val, Batch: [65/182], Loss: 0.1711\n",
      "Epoch [3/3], Phase: val, Batch: [66/182], Loss: 0.2600\n",
      "Epoch [3/3], Phase: val, Batch: [67/182], Loss: 0.1959\n",
      "Epoch [3/3], Phase: val, Batch: [68/182], Loss: 0.1888\n",
      "Epoch [3/3], Phase: val, Batch: [69/182], Loss: 0.2484\n",
      "Epoch [3/3], Phase: val, Batch: [70/182], Loss: 0.2050\n",
      "Epoch [3/3], Phase: val, Batch: [71/182], Loss: 0.3206\n",
      "Epoch [3/3], Phase: val, Batch: [72/182], Loss: 0.1963\n",
      "Epoch [3/3], Phase: val, Batch: [73/182], Loss: 0.1556\n",
      "Epoch [3/3], Phase: val, Batch: [74/182], Loss: 0.3106\n",
      "Epoch [3/3], Phase: val, Batch: [75/182], Loss: 0.2026\n",
      "Epoch [3/3], Phase: val, Batch: [76/182], Loss: 0.1600\n",
      "Epoch [3/3], Phase: val, Batch: [77/182], Loss: 0.1575\n",
      "Epoch [3/3], Phase: val, Batch: [78/182], Loss: 0.1518\n",
      "Epoch [3/3], Phase: val, Batch: [79/182], Loss: 0.2246\n",
      "Epoch [3/3], Phase: val, Batch: [80/182], Loss: 0.1832\n",
      "Epoch [3/3], Phase: val, Batch: [81/182], Loss: 0.1171\n",
      "Epoch [3/3], Phase: val, Batch: [82/182], Loss: 0.1702\n",
      "Epoch [3/3], Phase: val, Batch: [83/182], Loss: 0.1948\n",
      "Epoch [3/3], Phase: val, Batch: [84/182], Loss: 0.2031\n",
      "Epoch [3/3], Phase: val, Batch: [85/182], Loss: 0.1918\n",
      "Epoch [3/3], Phase: val, Batch: [86/182], Loss: 0.2596\n",
      "Epoch [3/3], Phase: val, Batch: [87/182], Loss: 0.3283\n",
      "Epoch [3/3], Phase: val, Batch: [88/182], Loss: 0.2335\n",
      "Epoch [3/3], Phase: val, Batch: [89/182], Loss: 0.2198\n",
      "Epoch [3/3], Phase: val, Batch: [90/182], Loss: 0.2497\n",
      "Epoch [3/3], Phase: val, Batch: [91/182], Loss: 0.2677\n",
      "Epoch [3/3], Phase: val, Batch: [92/182], Loss: 0.2255\n",
      "Epoch [3/3], Phase: val, Batch: [93/182], Loss: 0.2037\n",
      "Epoch [3/3], Phase: val, Batch: [94/182], Loss: 0.1927\n",
      "Epoch [3/3], Phase: val, Batch: [95/182], Loss: 0.2695\n",
      "Epoch [3/3], Phase: val, Batch: [96/182], Loss: 0.2322\n",
      "Epoch [3/3], Phase: val, Batch: [97/182], Loss: 0.2392\n",
      "Epoch [3/3], Phase: val, Batch: [98/182], Loss: 0.2343\n",
      "Epoch [3/3], Phase: val, Batch: [99/182], Loss: 0.2749\n",
      "Epoch [3/3], Phase: val, Batch: [100/182], Loss: 0.2863\n",
      "Epoch [3/3], Phase: val, Batch: [101/182], Loss: 0.3454\n",
      "Epoch [3/3], Phase: val, Batch: [102/182], Loss: 0.2206\n",
      "Epoch [3/3], Phase: val, Batch: [103/182], Loss: 0.2455\n",
      "Epoch [3/3], Phase: val, Batch: [104/182], Loss: 0.2502\n",
      "Epoch [3/3], Phase: val, Batch: [105/182], Loss: 0.1832\n",
      "Epoch [3/3], Phase: val, Batch: [106/182], Loss: 0.3734\n",
      "Epoch [3/3], Phase: val, Batch: [107/182], Loss: 0.2607\n",
      "Epoch [3/3], Phase: val, Batch: [108/182], Loss: 0.2423\n",
      "Epoch [3/3], Phase: val, Batch: [109/182], Loss: 0.2574\n",
      "Epoch [3/3], Phase: val, Batch: [110/182], Loss: 0.1968\n",
      "Epoch [3/3], Phase: val, Batch: [111/182], Loss: 0.1337\n",
      "Epoch [3/3], Phase: val, Batch: [112/182], Loss: 0.1993\n",
      "Epoch [3/3], Phase: val, Batch: [113/182], Loss: 0.1507\n",
      "Epoch [3/3], Phase: val, Batch: [114/182], Loss: 0.2753\n",
      "Epoch [3/3], Phase: val, Batch: [115/182], Loss: 0.2059\n",
      "Epoch [3/3], Phase: val, Batch: [116/182], Loss: 0.2624\n",
      "Epoch [3/3], Phase: val, Batch: [117/182], Loss: 0.1583\n",
      "Epoch [3/3], Phase: val, Batch: [118/182], Loss: 0.2419\n",
      "Epoch [3/3], Phase: val, Batch: [119/182], Loss: 0.1923\n",
      "Epoch [3/3], Phase: val, Batch: [120/182], Loss: 0.2219\n",
      "Epoch [3/3], Phase: val, Batch: [121/182], Loss: 0.2332\n",
      "Epoch [3/3], Phase: val, Batch: [122/182], Loss: 0.2082\n",
      "Epoch [3/3], Phase: val, Batch: [123/182], Loss: 0.2973\n",
      "Epoch [3/3], Phase: val, Batch: [124/182], Loss: 0.1604\n",
      "Epoch [3/3], Phase: val, Batch: [125/182], Loss: 0.1955\n",
      "Epoch [3/3], Phase: val, Batch: [126/182], Loss: 0.2457\n",
      "Epoch [3/3], Phase: val, Batch: [127/182], Loss: 0.2029\n",
      "Epoch [3/3], Phase: val, Batch: [128/182], Loss: 0.2179\n",
      "Epoch [3/3], Phase: val, Batch: [129/182], Loss: 0.2385\n",
      "Epoch [3/3], Phase: val, Batch: [130/182], Loss: 0.1750\n",
      "Epoch [3/3], Phase: val, Batch: [131/182], Loss: 0.2528\n",
      "Epoch [3/3], Phase: val, Batch: [132/182], Loss: 0.2506\n",
      "Epoch [3/3], Phase: val, Batch: [133/182], Loss: 0.3654\n",
      "Epoch [3/3], Phase: val, Batch: [134/182], Loss: 0.1449\n",
      "Epoch [3/3], Phase: val, Batch: [135/182], Loss: 0.2056\n",
      "Epoch [3/3], Phase: val, Batch: [136/182], Loss: 0.2835\n",
      "Epoch [3/3], Phase: val, Batch: [137/182], Loss: 0.2308\n",
      "Epoch [3/3], Phase: val, Batch: [138/182], Loss: 0.2594\n",
      "Epoch [3/3], Phase: val, Batch: [139/182], Loss: 0.1647\n",
      "Epoch [3/3], Phase: val, Batch: [140/182], Loss: 0.2620\n",
      "Epoch [3/3], Phase: val, Batch: [141/182], Loss: 0.2226\n",
      "Epoch [3/3], Phase: val, Batch: [142/182], Loss: 0.1918\n",
      "Epoch [3/3], Phase: val, Batch: [143/182], Loss: 0.2802\n",
      "Epoch [3/3], Phase: val, Batch: [144/182], Loss: 0.2884\n",
      "Epoch [3/3], Phase: val, Batch: [145/182], Loss: 0.1432\n",
      "Epoch [3/3], Phase: val, Batch: [146/182], Loss: 0.2165\n",
      "Epoch [3/3], Phase: val, Batch: [147/182], Loss: 0.2552\n",
      "Epoch [3/3], Phase: val, Batch: [148/182], Loss: 0.1805\n",
      "Epoch [3/3], Phase: val, Batch: [149/182], Loss: 0.2548\n",
      "Epoch [3/3], Phase: val, Batch: [150/182], Loss: 0.2865\n",
      "Epoch [3/3], Phase: val, Batch: [151/182], Loss: 0.2545\n",
      "Epoch [3/3], Phase: val, Batch: [152/182], Loss: 0.2904\n",
      "Epoch [3/3], Phase: val, Batch: [153/182], Loss: 0.2978\n",
      "Epoch [3/3], Phase: val, Batch: [154/182], Loss: 0.2936\n",
      "Epoch [3/3], Phase: val, Batch: [155/182], Loss: 0.2122\n",
      "Epoch [3/3], Phase: val, Batch: [156/182], Loss: 0.3413\n",
      "Epoch [3/3], Phase: val, Batch: [157/182], Loss: 0.2452\n",
      "Epoch [3/3], Phase: val, Batch: [158/182], Loss: 0.3894\n",
      "Epoch [3/3], Phase: val, Batch: [159/182], Loss: 0.2729\n",
      "Epoch [3/3], Phase: val, Batch: [160/182], Loss: 0.2005\n",
      "Epoch [3/3], Phase: val, Batch: [161/182], Loss: 0.2465\n",
      "Epoch [3/3], Phase: val, Batch: [162/182], Loss: 0.3059\n",
      "Epoch [3/3], Phase: val, Batch: [163/182], Loss: 0.3255\n",
      "Epoch [3/3], Phase: val, Batch: [164/182], Loss: 0.2033\n",
      "Epoch [3/3], Phase: val, Batch: [165/182], Loss: 0.2416\n",
      "Epoch [3/3], Phase: val, Batch: [166/182], Loss: 0.1532\n",
      "Epoch [3/3], Phase: val, Batch: [167/182], Loss: 0.1895\n",
      "Epoch [3/3], Phase: val, Batch: [168/182], Loss: 0.2210\n",
      "Epoch [3/3], Phase: val, Batch: [169/182], Loss: 0.2494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Phase: val, Batch: [170/182], Loss: 0.2619\n",
      "Epoch [3/3], Phase: val, Batch: [171/182], Loss: 0.3099\n",
      "Epoch [3/3], Phase: val, Batch: [172/182], Loss: 0.2418\n",
      "Epoch [3/3], Phase: val, Batch: [173/182], Loss: 0.1330\n",
      "Epoch [3/3], Phase: val, Batch: [174/182], Loss: 0.2636\n",
      "Epoch [3/3], Phase: val, Batch: [175/182], Loss: 0.1740\n",
      "Epoch [3/3], Phase: val, Batch: [176/182], Loss: 0.2417\n",
      "Epoch [3/3], Phase: val, Batch: [177/182], Loss: 0.2679\n",
      "Epoch [3/3], Phase: val, Batch: [178/182], Loss: 0.1262\n",
      "Epoch [3/3], Phase: val, Batch: [179/182], Loss: 0.2118\n",
      "Epoch [3/3], Phase: val, Batch: [180/182], Loss: 0.2098\n",
      "Epoch [3/3], Phase: val, Batch: [181/182], Loss: 0.3290\n",
      "Epoch [3/3], Phase: val, Batch: [182/182], Loss: 0.2441\n",
      "val Loss: 0.2288 Acc: 0.9123\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_batches = len(dataloaders[phase])\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            batch_loss = loss.item()\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Phase: {phase}, Batch: [{batch_idx+1}/{total_batches}], Loss: {batch_loss:.4f}')\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        scheduler.step()\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da10535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[75764 11239]\n",
      " [ 9062 78880]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "classification_rep = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143a17fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.89      0.87      0.88     87003\n",
      "        male       0.88      0.90      0.89     87942\n",
      "\n",
      "    accuracy                           0.88    174945\n",
      "   macro avg       0.88      0.88      0.88    174945\n",
      "weighted avg       0.88      0.88      0.88    174945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8215dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = ['Male', 'Female'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b0ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'vgg_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d2d1e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c346f9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = models.vgg16(pretrained=False)  # Load a new instance of VGG16\n",
    "num_features = loaded_model.classifier[6].in_features\n",
    "loaded_model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "loaded_model.load_state_dict(torch.load('vgg_model.pth'))\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2bf01f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: harun.jpg, Predicted Gender: male\n",
      "Image: arda.jpg, Predicted Gender: male\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image.to(device)  # Move the image to GPU if available\n",
    "\n",
    "image_paths = ['harun.jpg', 'arda.jpg']  # Provide paths to the images\n",
    "for image_path in image_paths:\n",
    "    input_image = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(input_image)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        predicted_label = class_names[predicted_class]\n",
    "        print(f\"Image: {image_path}, Predicted Gender: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
