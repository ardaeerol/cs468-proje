{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb3cc07",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network  - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe92c4b",
   "metadata": {},
   "source": [
    "Dataset in use: https://www.kaggle.com/datasets/cashutosh/gender-classification-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4f83e",
   "metadata": {},
   "source": [
    "Feedbackte istendiği gibi Early Stop eklendi, test ve validation setleri ayrıştırıldı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf7bba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640d1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./dataset/Training\"\n",
    "val_dir = \"./dataset/Validation\"\n",
    "input_size = (224, 224)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aba002f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec86a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4e21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(root=train_dir, transform=transform['train']),\n",
    "    'val': datasets.ImageFolder(root=val_dir, transform=transform['val'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf15b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f79de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze Layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Custom Classifier\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1), # Dropout is applied with probability 0.1 to prevent overfitting\n",
    "    nn.Linear(256, 2)  # Output is 2 dimensional (male and female)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.013) # Adam Optimizer\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7af19a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ee80a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = np.inf\n",
    "patience = 3\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4811a6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [1/730], Loss: 0.7110\n",
      "Epoch [1/10], Phase: train, Batch: [2/730], Loss: 5.2324\n",
      "Epoch [1/10], Phase: train, Batch: [3/730], Loss: 8.0156\n",
      "Epoch [1/10], Phase: train, Batch: [4/730], Loss: 5.5205\n",
      "Epoch [1/10], Phase: train, Batch: [5/730], Loss: 1.7592\n",
      "Epoch [1/10], Phase: train, Batch: [6/730], Loss: 0.5470\n",
      "Epoch [1/10], Phase: train, Batch: [7/730], Loss: 1.2411\n",
      "Epoch [1/10], Phase: train, Batch: [8/730], Loss: 1.2298\n",
      "Epoch [1/10], Phase: train, Batch: [9/730], Loss: 0.7053\n",
      "Epoch [1/10], Phase: train, Batch: [10/730], Loss: 0.4364\n",
      "Epoch [1/10], Phase: train, Batch: [11/730], Loss: 0.4962\n",
      "Epoch [1/10], Phase: train, Batch: [12/730], Loss: 0.7222\n",
      "Epoch [1/10], Phase: train, Batch: [13/730], Loss: 0.4847\n",
      "Epoch [1/10], Phase: train, Batch: [14/730], Loss: 0.4511\n",
      "Epoch [1/10], Phase: train, Batch: [15/730], Loss: 0.4752\n",
      "Epoch [1/10], Phase: train, Batch: [16/730], Loss: 0.3779\n",
      "Epoch [1/10], Phase: train, Batch: [17/730], Loss: 0.4946\n",
      "Epoch [1/10], Phase: train, Batch: [18/730], Loss: 0.4415\n",
      "Epoch [1/10], Phase: train, Batch: [19/730], Loss: 0.3128\n",
      "Epoch [1/10], Phase: train, Batch: [20/730], Loss: 0.5217\n",
      "Epoch [1/10], Phase: train, Batch: [21/730], Loss: 0.3698\n",
      "Epoch [1/10], Phase: train, Batch: [22/730], Loss: 0.4114\n",
      "Epoch [1/10], Phase: train, Batch: [23/730], Loss: 0.4167\n",
      "Epoch [1/10], Phase: train, Batch: [24/730], Loss: 0.4611\n",
      "Epoch [1/10], Phase: train, Batch: [25/730], Loss: 0.4345\n",
      "Epoch [1/10], Phase: train, Batch: [26/730], Loss: 0.3320\n",
      "Epoch [1/10], Phase: train, Batch: [27/730], Loss: 0.5305\n",
      "Epoch [1/10], Phase: train, Batch: [28/730], Loss: 0.5103\n",
      "Epoch [1/10], Phase: train, Batch: [29/730], Loss: 0.3863\n",
      "Epoch [1/10], Phase: train, Batch: [30/730], Loss: 0.3622\n",
      "Epoch [1/10], Phase: train, Batch: [31/730], Loss: 0.3222\n",
      "Epoch [1/10], Phase: train, Batch: [32/730], Loss: 0.3114\n",
      "Epoch [1/10], Phase: train, Batch: [33/730], Loss: 0.3765\n",
      "Epoch [1/10], Phase: train, Batch: [34/730], Loss: 0.2879\n",
      "Epoch [1/10], Phase: train, Batch: [35/730], Loss: 0.2991\n",
      "Epoch [1/10], Phase: train, Batch: [36/730], Loss: 0.2452\n",
      "Epoch [1/10], Phase: train, Batch: [37/730], Loss: 0.2945\n",
      "Epoch [1/10], Phase: train, Batch: [38/730], Loss: 0.2529\n",
      "Epoch [1/10], Phase: train, Batch: [39/730], Loss: 0.1739\n",
      "Epoch [1/10], Phase: train, Batch: [40/730], Loss: 0.2662\n",
      "Epoch [1/10], Phase: train, Batch: [41/730], Loss: 0.2456\n",
      "Epoch [1/10], Phase: train, Batch: [42/730], Loss: 0.2610\n",
      "Epoch [1/10], Phase: train, Batch: [43/730], Loss: 0.2382\n",
      "Epoch [1/10], Phase: train, Batch: [44/730], Loss: 0.3629\n",
      "Epoch [1/10], Phase: train, Batch: [45/730], Loss: 0.3015\n",
      "Epoch [1/10], Phase: train, Batch: [46/730], Loss: 0.3453\n",
      "Epoch [1/10], Phase: train, Batch: [47/730], Loss: 0.3432\n",
      "Epoch [1/10], Phase: train, Batch: [48/730], Loss: 0.1662\n",
      "Epoch [1/10], Phase: train, Batch: [49/730], Loss: 0.3748\n",
      "Epoch [1/10], Phase: train, Batch: [50/730], Loss: 0.4031\n",
      "Epoch [1/10], Phase: train, Batch: [51/730], Loss: 0.2621\n",
      "Epoch [1/10], Phase: train, Batch: [52/730], Loss: 0.1978\n",
      "Epoch [1/10], Phase: train, Batch: [53/730], Loss: 0.2721\n",
      "Epoch [1/10], Phase: train, Batch: [54/730], Loss: 0.2213\n",
      "Epoch [1/10], Phase: train, Batch: [55/730], Loss: 0.2390\n",
      "Epoch [1/10], Phase: train, Batch: [56/730], Loss: 0.4608\n",
      "Epoch [1/10], Phase: train, Batch: [57/730], Loss: 0.3347\n",
      "Epoch [1/10], Phase: train, Batch: [58/730], Loss: 0.3445\n",
      "Epoch [1/10], Phase: train, Batch: [59/730], Loss: 0.4074\n",
      "Epoch [1/10], Phase: train, Batch: [60/730], Loss: 0.2297\n",
      "Epoch [1/10], Phase: train, Batch: [61/730], Loss: 0.2956\n",
      "Epoch [1/10], Phase: train, Batch: [62/730], Loss: 0.5314\n",
      "Epoch [1/10], Phase: train, Batch: [63/730], Loss: 0.2798\n",
      "Epoch [1/10], Phase: train, Batch: [64/730], Loss: 0.3477\n",
      "Epoch [1/10], Phase: train, Batch: [65/730], Loss: 0.2417\n",
      "Epoch [1/10], Phase: train, Batch: [66/730], Loss: 0.2229\n",
      "Epoch [1/10], Phase: train, Batch: [67/730], Loss: 0.3290\n",
      "Epoch [1/10], Phase: train, Batch: [68/730], Loss: 0.2491\n",
      "Epoch [1/10], Phase: train, Batch: [69/730], Loss: 0.3735\n",
      "Epoch [1/10], Phase: train, Batch: [70/730], Loss: 0.4156\n",
      "Epoch [1/10], Phase: train, Batch: [71/730], Loss: 0.4126\n",
      "Epoch [1/10], Phase: train, Batch: [72/730], Loss: 0.5756\n",
      "Epoch [1/10], Phase: train, Batch: [73/730], Loss: 0.2969\n",
      "Epoch [1/10], Phase: train, Batch: [74/730], Loss: 0.3040\n",
      "Epoch [1/10], Phase: train, Batch: [75/730], Loss: 0.4118\n",
      "Epoch [1/10], Phase: train, Batch: [76/730], Loss: 0.2754\n",
      "Epoch [1/10], Phase: train, Batch: [77/730], Loss: 0.5114\n",
      "Epoch [1/10], Phase: train, Batch: [78/730], Loss: 0.1812\n",
      "Epoch [1/10], Phase: train, Batch: [79/730], Loss: 0.3536\n",
      "Epoch [1/10], Phase: train, Batch: [80/730], Loss: 0.3760\n",
      "Epoch [1/10], Phase: train, Batch: [81/730], Loss: 0.2443\n",
      "Epoch [1/10], Phase: train, Batch: [82/730], Loss: 0.3611\n",
      "Epoch [1/10], Phase: train, Batch: [83/730], Loss: 0.2279\n",
      "Epoch [1/10], Phase: train, Batch: [84/730], Loss: 0.2870\n",
      "Epoch [1/10], Phase: train, Batch: [85/730], Loss: 0.2617\n",
      "Epoch [1/10], Phase: train, Batch: [86/730], Loss: 0.4116\n",
      "Epoch [1/10], Phase: train, Batch: [87/730], Loss: 0.2801\n",
      "Epoch [1/10], Phase: train, Batch: [88/730], Loss: 0.4424\n",
      "Epoch [1/10], Phase: train, Batch: [89/730], Loss: 0.4039\n",
      "Epoch [1/10], Phase: train, Batch: [90/730], Loss: 0.2872\n",
      "Epoch [1/10], Phase: train, Batch: [91/730], Loss: 0.3498\n",
      "Epoch [1/10], Phase: train, Batch: [92/730], Loss: 0.2474\n",
      "Epoch [1/10], Phase: train, Batch: [93/730], Loss: 0.2025\n",
      "Epoch [1/10], Phase: train, Batch: [94/730], Loss: 0.2312\n",
      "Epoch [1/10], Phase: train, Batch: [95/730], Loss: 0.2832\n",
      "Epoch [1/10], Phase: train, Batch: [96/730], Loss: 0.2757\n",
      "Epoch [1/10], Phase: train, Batch: [97/730], Loss: 0.3225\n",
      "Epoch [1/10], Phase: train, Batch: [98/730], Loss: 0.3358\n",
      "Epoch [1/10], Phase: train, Batch: [99/730], Loss: 0.2654\n",
      "Epoch [1/10], Phase: train, Batch: [100/730], Loss: 0.2338\n",
      "Epoch [1/10], Phase: train, Batch: [101/730], Loss: 0.3053\n",
      "Epoch [1/10], Phase: train, Batch: [102/730], Loss: 0.2510\n",
      "Epoch [1/10], Phase: train, Batch: [103/730], Loss: 0.3462\n",
      "Epoch [1/10], Phase: train, Batch: [104/730], Loss: 0.3024\n",
      "Epoch [1/10], Phase: train, Batch: [105/730], Loss: 0.4402\n",
      "Epoch [1/10], Phase: train, Batch: [106/730], Loss: 0.1486\n",
      "Epoch [1/10], Phase: train, Batch: [107/730], Loss: 0.2517\n",
      "Epoch [1/10], Phase: train, Batch: [108/730], Loss: 0.3861\n",
      "Epoch [1/10], Phase: train, Batch: [109/730], Loss: 0.2863\n",
      "Epoch [1/10], Phase: train, Batch: [110/730], Loss: 0.3390\n",
      "Epoch [1/10], Phase: train, Batch: [111/730], Loss: 0.2579\n",
      "Epoch [1/10], Phase: train, Batch: [112/730], Loss: 0.2929\n",
      "Epoch [1/10], Phase: train, Batch: [113/730], Loss: 0.2971\n",
      "Epoch [1/10], Phase: train, Batch: [114/730], Loss: 0.3122\n",
      "Epoch [1/10], Phase: train, Batch: [115/730], Loss: 0.2820\n",
      "Epoch [1/10], Phase: train, Batch: [116/730], Loss: 0.2731\n",
      "Epoch [1/10], Phase: train, Batch: [117/730], Loss: 0.2390\n",
      "Epoch [1/10], Phase: train, Batch: [118/730], Loss: 0.4317\n",
      "Epoch [1/10], Phase: train, Batch: [119/730], Loss: 0.1705\n",
      "Epoch [1/10], Phase: train, Batch: [120/730], Loss: 0.5750\n",
      "Epoch [1/10], Phase: train, Batch: [121/730], Loss: 0.3423\n",
      "Epoch [1/10], Phase: train, Batch: [122/730], Loss: 0.3803\n",
      "Epoch [1/10], Phase: train, Batch: [123/730], Loss: 0.3948\n",
      "Epoch [1/10], Phase: train, Batch: [124/730], Loss: 0.2965\n",
      "Epoch [1/10], Phase: train, Batch: [125/730], Loss: 0.2662\n",
      "Epoch [1/10], Phase: train, Batch: [126/730], Loss: 0.3172\n",
      "Epoch [1/10], Phase: train, Batch: [127/730], Loss: 0.2731\n",
      "Epoch [1/10], Phase: train, Batch: [128/730], Loss: 0.3181\n",
      "Epoch [1/10], Phase: train, Batch: [129/730], Loss: 0.3062\n",
      "Epoch [1/10], Phase: train, Batch: [130/730], Loss: 0.3933\n",
      "Epoch [1/10], Phase: train, Batch: [131/730], Loss: 0.4032\n",
      "Epoch [1/10], Phase: train, Batch: [132/730], Loss: 0.3803\n",
      "Epoch [1/10], Phase: train, Batch: [133/730], Loss: 0.2743\n",
      "Epoch [1/10], Phase: train, Batch: [134/730], Loss: 0.2661\n",
      "Epoch [1/10], Phase: train, Batch: [135/730], Loss: 0.3347\n",
      "Epoch [1/10], Phase: train, Batch: [136/730], Loss: 0.3885\n",
      "Epoch [1/10], Phase: train, Batch: [137/730], Loss: 0.4284\n",
      "Epoch [1/10], Phase: train, Batch: [138/730], Loss: 0.2234\n",
      "Epoch [1/10], Phase: train, Batch: [139/730], Loss: 0.2880\n",
      "Epoch [1/10], Phase: train, Batch: [140/730], Loss: 0.2730\n",
      "Epoch [1/10], Phase: train, Batch: [141/730], Loss: 0.3101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [142/730], Loss: 0.2933\n",
      "Epoch [1/10], Phase: train, Batch: [143/730], Loss: 0.5004\n",
      "Epoch [1/10], Phase: train, Batch: [144/730], Loss: 0.3234\n",
      "Epoch [1/10], Phase: train, Batch: [145/730], Loss: 0.4183\n",
      "Epoch [1/10], Phase: train, Batch: [146/730], Loss: 0.2712\n",
      "Epoch [1/10], Phase: train, Batch: [147/730], Loss: 0.3539\n",
      "Epoch [1/10], Phase: train, Batch: [148/730], Loss: 0.2665\n",
      "Epoch [1/10], Phase: train, Batch: [149/730], Loss: 0.3361\n",
      "Epoch [1/10], Phase: train, Batch: [150/730], Loss: 0.3718\n",
      "Epoch [1/10], Phase: train, Batch: [151/730], Loss: 0.3671\n",
      "Epoch [1/10], Phase: train, Batch: [152/730], Loss: 0.2318\n",
      "Epoch [1/10], Phase: train, Batch: [153/730], Loss: 0.3167\n",
      "Epoch [1/10], Phase: train, Batch: [154/730], Loss: 0.3238\n",
      "Epoch [1/10], Phase: train, Batch: [155/730], Loss: 0.3697\n",
      "Epoch [1/10], Phase: train, Batch: [156/730], Loss: 0.3073\n",
      "Epoch [1/10], Phase: train, Batch: [157/730], Loss: 0.4686\n",
      "Epoch [1/10], Phase: train, Batch: [158/730], Loss: 0.2317\n",
      "Epoch [1/10], Phase: train, Batch: [159/730], Loss: 0.2717\n",
      "Epoch [1/10], Phase: train, Batch: [160/730], Loss: 0.3061\n",
      "Epoch [1/10], Phase: train, Batch: [161/730], Loss: 0.2366\n",
      "Epoch [1/10], Phase: train, Batch: [162/730], Loss: 0.1964\n",
      "Epoch [1/10], Phase: train, Batch: [163/730], Loss: 0.3723\n",
      "Epoch [1/10], Phase: train, Batch: [164/730], Loss: 0.3442\n",
      "Epoch [1/10], Phase: train, Batch: [165/730], Loss: 0.4598\n",
      "Epoch [1/10], Phase: train, Batch: [166/730], Loss: 0.4655\n",
      "Epoch [1/10], Phase: train, Batch: [167/730], Loss: 0.6404\n",
      "Epoch [1/10], Phase: train, Batch: [168/730], Loss: 0.2523\n",
      "Epoch [1/10], Phase: train, Batch: [169/730], Loss: 0.2095\n",
      "Epoch [1/10], Phase: train, Batch: [170/730], Loss: 0.3119\n",
      "Epoch [1/10], Phase: train, Batch: [171/730], Loss: 0.2305\n",
      "Epoch [1/10], Phase: train, Batch: [172/730], Loss: 0.3599\n",
      "Epoch [1/10], Phase: train, Batch: [173/730], Loss: 0.3069\n",
      "Epoch [1/10], Phase: train, Batch: [174/730], Loss: 0.2491\n",
      "Epoch [1/10], Phase: train, Batch: [175/730], Loss: 0.2792\n",
      "Epoch [1/10], Phase: train, Batch: [176/730], Loss: 0.2906\n",
      "Epoch [1/10], Phase: train, Batch: [177/730], Loss: 0.3747\n",
      "Epoch [1/10], Phase: train, Batch: [178/730], Loss: 0.2383\n",
      "Epoch [1/10], Phase: train, Batch: [179/730], Loss: 0.2609\n",
      "Epoch [1/10], Phase: train, Batch: [180/730], Loss: 0.4646\n",
      "Epoch [1/10], Phase: train, Batch: [181/730], Loss: 0.3178\n",
      "Epoch [1/10], Phase: train, Batch: [182/730], Loss: 0.3262\n",
      "Epoch [1/10], Phase: train, Batch: [183/730], Loss: 0.3128\n",
      "Epoch [1/10], Phase: train, Batch: [184/730], Loss: 0.3098\n",
      "Epoch [1/10], Phase: train, Batch: [185/730], Loss: 0.3633\n",
      "Epoch [1/10], Phase: train, Batch: [186/730], Loss: 0.4178\n",
      "Epoch [1/10], Phase: train, Batch: [187/730], Loss: 0.1742\n",
      "Epoch [1/10], Phase: train, Batch: [188/730], Loss: 0.3050\n",
      "Epoch [1/10], Phase: train, Batch: [189/730], Loss: 0.3031\n",
      "Epoch [1/10], Phase: train, Batch: [190/730], Loss: 0.4512\n",
      "Epoch [1/10], Phase: train, Batch: [191/730], Loss: 0.4044\n",
      "Epoch [1/10], Phase: train, Batch: [192/730], Loss: 0.3184\n",
      "Epoch [1/10], Phase: train, Batch: [193/730], Loss: 0.2259\n",
      "Epoch [1/10], Phase: train, Batch: [194/730], Loss: 0.3164\n",
      "Epoch [1/10], Phase: train, Batch: [195/730], Loss: 0.3551\n",
      "Epoch [1/10], Phase: train, Batch: [196/730], Loss: 0.2431\n",
      "Epoch [1/10], Phase: train, Batch: [197/730], Loss: 0.3554\n",
      "Epoch [1/10], Phase: train, Batch: [198/730], Loss: 0.1847\n",
      "Epoch [1/10], Phase: train, Batch: [199/730], Loss: 0.2605\n",
      "Epoch [1/10], Phase: train, Batch: [200/730], Loss: 0.4527\n",
      "Epoch [1/10], Phase: train, Batch: [201/730], Loss: 0.4148\n",
      "Epoch [1/10], Phase: train, Batch: [202/730], Loss: 0.2792\n",
      "Epoch [1/10], Phase: train, Batch: [203/730], Loss: 0.3103\n",
      "Epoch [1/10], Phase: train, Batch: [204/730], Loss: 0.3626\n",
      "Epoch [1/10], Phase: train, Batch: [205/730], Loss: 0.3267\n",
      "Epoch [1/10], Phase: train, Batch: [206/730], Loss: 0.2688\n",
      "Epoch [1/10], Phase: train, Batch: [207/730], Loss: 0.3285\n",
      "Epoch [1/10], Phase: train, Batch: [208/730], Loss: 0.3848\n",
      "Epoch [1/10], Phase: train, Batch: [209/730], Loss: 0.3765\n",
      "Epoch [1/10], Phase: train, Batch: [210/730], Loss: 0.4287\n",
      "Epoch [1/10], Phase: train, Batch: [211/730], Loss: 0.4141\n",
      "Epoch [1/10], Phase: train, Batch: [212/730], Loss: 0.2677\n",
      "Epoch [1/10], Phase: train, Batch: [213/730], Loss: 0.2753\n",
      "Epoch [1/10], Phase: train, Batch: [214/730], Loss: 0.2858\n",
      "Epoch [1/10], Phase: train, Batch: [215/730], Loss: 0.3082\n",
      "Epoch [1/10], Phase: train, Batch: [216/730], Loss: 0.3235\n",
      "Epoch [1/10], Phase: train, Batch: [217/730], Loss: 0.4725\n",
      "Epoch [1/10], Phase: train, Batch: [218/730], Loss: 0.3578\n",
      "Epoch [1/10], Phase: train, Batch: [219/730], Loss: 0.2883\n",
      "Epoch [1/10], Phase: train, Batch: [220/730], Loss: 0.4977\n",
      "Epoch [1/10], Phase: train, Batch: [221/730], Loss: 0.2432\n",
      "Epoch [1/10], Phase: train, Batch: [222/730], Loss: 0.2774\n",
      "Epoch [1/10], Phase: train, Batch: [223/730], Loss: 0.3719\n",
      "Epoch [1/10], Phase: train, Batch: [224/730], Loss: 0.3155\n",
      "Epoch [1/10], Phase: train, Batch: [225/730], Loss: 0.2168\n",
      "Epoch [1/10], Phase: train, Batch: [226/730], Loss: 0.3541\n",
      "Epoch [1/10], Phase: train, Batch: [227/730], Loss: 0.3557\n",
      "Epoch [1/10], Phase: train, Batch: [228/730], Loss: 0.3476\n",
      "Epoch [1/10], Phase: train, Batch: [229/730], Loss: 0.3382\n",
      "Epoch [1/10], Phase: train, Batch: [230/730], Loss: 0.3476\n",
      "Epoch [1/10], Phase: train, Batch: [231/730], Loss: 0.2753\n",
      "Epoch [1/10], Phase: train, Batch: [232/730], Loss: 0.1937\n",
      "Epoch [1/10], Phase: train, Batch: [233/730], Loss: 0.3013\n",
      "Epoch [1/10], Phase: train, Batch: [234/730], Loss: 0.1906\n",
      "Epoch [1/10], Phase: train, Batch: [235/730], Loss: 0.4253\n",
      "Epoch [1/10], Phase: train, Batch: [236/730], Loss: 0.5230\n",
      "Epoch [1/10], Phase: train, Batch: [237/730], Loss: 0.3237\n",
      "Epoch [1/10], Phase: train, Batch: [238/730], Loss: 0.5247\n",
      "Epoch [1/10], Phase: train, Batch: [239/730], Loss: 0.3852\n",
      "Epoch [1/10], Phase: train, Batch: [240/730], Loss: 0.3022\n",
      "Epoch [1/10], Phase: train, Batch: [241/730], Loss: 0.3016\n",
      "Epoch [1/10], Phase: train, Batch: [242/730], Loss: 0.3102\n",
      "Epoch [1/10], Phase: train, Batch: [243/730], Loss: 0.2602\n",
      "Epoch [1/10], Phase: train, Batch: [244/730], Loss: 0.4063\n",
      "Epoch [1/10], Phase: train, Batch: [245/730], Loss: 0.3202\n",
      "Epoch [1/10], Phase: train, Batch: [246/730], Loss: 0.2853\n",
      "Epoch [1/10], Phase: train, Batch: [247/730], Loss: 0.2392\n",
      "Epoch [1/10], Phase: train, Batch: [248/730], Loss: 0.2818\n",
      "Epoch [1/10], Phase: train, Batch: [249/730], Loss: 0.3169\n",
      "Epoch [1/10], Phase: train, Batch: [250/730], Loss: 0.2535\n",
      "Epoch [1/10], Phase: train, Batch: [251/730], Loss: 0.3054\n",
      "Epoch [1/10], Phase: train, Batch: [252/730], Loss: 0.2514\n",
      "Epoch [1/10], Phase: train, Batch: [253/730], Loss: 0.1643\n",
      "Epoch [1/10], Phase: train, Batch: [254/730], Loss: 0.4563\n",
      "Epoch [1/10], Phase: train, Batch: [255/730], Loss: 0.1890\n",
      "Epoch [1/10], Phase: train, Batch: [256/730], Loss: 0.4256\n",
      "Epoch [1/10], Phase: train, Batch: [257/730], Loss: 0.3320\n",
      "Epoch [1/10], Phase: train, Batch: [258/730], Loss: 0.2515\n",
      "Epoch [1/10], Phase: train, Batch: [259/730], Loss: 0.2776\n",
      "Epoch [1/10], Phase: train, Batch: [260/730], Loss: 0.2347\n",
      "Epoch [1/10], Phase: train, Batch: [261/730], Loss: 0.3303\n",
      "Epoch [1/10], Phase: train, Batch: [262/730], Loss: 0.2630\n",
      "Epoch [1/10], Phase: train, Batch: [263/730], Loss: 0.2260\n",
      "Epoch [1/10], Phase: train, Batch: [264/730], Loss: 0.3228\n",
      "Epoch [1/10], Phase: train, Batch: [265/730], Loss: 0.2287\n",
      "Epoch [1/10], Phase: train, Batch: [266/730], Loss: 0.3995\n",
      "Epoch [1/10], Phase: train, Batch: [267/730], Loss: 0.4098\n",
      "Epoch [1/10], Phase: train, Batch: [268/730], Loss: 0.3391\n",
      "Epoch [1/10], Phase: train, Batch: [269/730], Loss: 0.3029\n",
      "Epoch [1/10], Phase: train, Batch: [270/730], Loss: 0.2642\n",
      "Epoch [1/10], Phase: train, Batch: [271/730], Loss: 0.2280\n",
      "Epoch [1/10], Phase: train, Batch: [272/730], Loss: 0.2801\n",
      "Epoch [1/10], Phase: train, Batch: [273/730], Loss: 0.3389\n",
      "Epoch [1/10], Phase: train, Batch: [274/730], Loss: 0.1786\n",
      "Epoch [1/10], Phase: train, Batch: [275/730], Loss: 0.6397\n",
      "Epoch [1/10], Phase: train, Batch: [276/730], Loss: 0.3068\n",
      "Epoch [1/10], Phase: train, Batch: [277/730], Loss: 0.4053\n",
      "Epoch [1/10], Phase: train, Batch: [278/730], Loss: 0.4177\n",
      "Epoch [1/10], Phase: train, Batch: [279/730], Loss: 0.2836\n",
      "Epoch [1/10], Phase: train, Batch: [280/730], Loss: 0.3737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [281/730], Loss: 0.3055\n",
      "Epoch [1/10], Phase: train, Batch: [282/730], Loss: 0.2513\n",
      "Epoch [1/10], Phase: train, Batch: [283/730], Loss: 0.3411\n",
      "Epoch [1/10], Phase: train, Batch: [284/730], Loss: 0.3897\n",
      "Epoch [1/10], Phase: train, Batch: [285/730], Loss: 0.3201\n",
      "Epoch [1/10], Phase: train, Batch: [286/730], Loss: 0.3669\n",
      "Epoch [1/10], Phase: train, Batch: [287/730], Loss: 0.2959\n",
      "Epoch [1/10], Phase: train, Batch: [288/730], Loss: 0.3005\n",
      "Epoch [1/10], Phase: train, Batch: [289/730], Loss: 0.2622\n",
      "Epoch [1/10], Phase: train, Batch: [290/730], Loss: 0.2837\n",
      "Epoch [1/10], Phase: train, Batch: [291/730], Loss: 0.2515\n",
      "Epoch [1/10], Phase: train, Batch: [292/730], Loss: 0.2416\n",
      "Epoch [1/10], Phase: train, Batch: [293/730], Loss: 0.4275\n",
      "Epoch [1/10], Phase: train, Batch: [294/730], Loss: 0.4316\n",
      "Epoch [1/10], Phase: train, Batch: [295/730], Loss: 0.3200\n",
      "Epoch [1/10], Phase: train, Batch: [296/730], Loss: 0.1920\n",
      "Epoch [1/10], Phase: train, Batch: [297/730], Loss: 0.1667\n",
      "Epoch [1/10], Phase: train, Batch: [298/730], Loss: 0.3069\n",
      "Epoch [1/10], Phase: train, Batch: [299/730], Loss: 0.2438\n",
      "Epoch [1/10], Phase: train, Batch: [300/730], Loss: 0.4215\n",
      "Epoch [1/10], Phase: train, Batch: [301/730], Loss: 0.3883\n",
      "Epoch [1/10], Phase: train, Batch: [302/730], Loss: 0.2517\n",
      "Epoch [1/10], Phase: train, Batch: [303/730], Loss: 0.4456\n",
      "Epoch [1/10], Phase: train, Batch: [304/730], Loss: 0.3805\n",
      "Epoch [1/10], Phase: train, Batch: [305/730], Loss: 0.2675\n",
      "Epoch [1/10], Phase: train, Batch: [306/730], Loss: 0.2653\n",
      "Epoch [1/10], Phase: train, Batch: [307/730], Loss: 0.3452\n",
      "Epoch [1/10], Phase: train, Batch: [308/730], Loss: 0.2925\n",
      "Epoch [1/10], Phase: train, Batch: [309/730], Loss: 0.3529\n",
      "Epoch [1/10], Phase: train, Batch: [310/730], Loss: 0.2304\n",
      "Epoch [1/10], Phase: train, Batch: [311/730], Loss: 0.2103\n",
      "Epoch [1/10], Phase: train, Batch: [312/730], Loss: 0.2956\n",
      "Epoch [1/10], Phase: train, Batch: [313/730], Loss: 0.5380\n",
      "Epoch [1/10], Phase: train, Batch: [314/730], Loss: 0.3411\n",
      "Epoch [1/10], Phase: train, Batch: [315/730], Loss: 0.4062\n",
      "Epoch [1/10], Phase: train, Batch: [316/730], Loss: 0.4056\n",
      "Epoch [1/10], Phase: train, Batch: [317/730], Loss: 0.2127\n",
      "Epoch [1/10], Phase: train, Batch: [318/730], Loss: 0.3334\n",
      "Epoch [1/10], Phase: train, Batch: [319/730], Loss: 0.2819\n",
      "Epoch [1/10], Phase: train, Batch: [320/730], Loss: 0.4316\n",
      "Epoch [1/10], Phase: train, Batch: [321/730], Loss: 0.3264\n",
      "Epoch [1/10], Phase: train, Batch: [322/730], Loss: 0.2364\n",
      "Epoch [1/10], Phase: train, Batch: [323/730], Loss: 0.3446\n",
      "Epoch [1/10], Phase: train, Batch: [324/730], Loss: 0.4134\n",
      "Epoch [1/10], Phase: train, Batch: [325/730], Loss: 0.4403\n",
      "Epoch [1/10], Phase: train, Batch: [326/730], Loss: 0.3887\n",
      "Epoch [1/10], Phase: train, Batch: [327/730], Loss: 0.3105\n",
      "Epoch [1/10], Phase: train, Batch: [328/730], Loss: 0.3058\n",
      "Epoch [1/10], Phase: train, Batch: [329/730], Loss: 0.3763\n",
      "Epoch [1/10], Phase: train, Batch: [330/730], Loss: 0.2674\n",
      "Epoch [1/10], Phase: train, Batch: [331/730], Loss: 0.2708\n",
      "Epoch [1/10], Phase: train, Batch: [332/730], Loss: 0.4011\n",
      "Epoch [1/10], Phase: train, Batch: [333/730], Loss: 0.3217\n",
      "Epoch [1/10], Phase: train, Batch: [334/730], Loss: 0.2233\n",
      "Epoch [1/10], Phase: train, Batch: [335/730], Loss: 0.3827\n",
      "Epoch [1/10], Phase: train, Batch: [336/730], Loss: 0.3128\n",
      "Epoch [1/10], Phase: train, Batch: [337/730], Loss: 0.3077\n",
      "Epoch [1/10], Phase: train, Batch: [338/730], Loss: 0.3237\n",
      "Epoch [1/10], Phase: train, Batch: [339/730], Loss: 0.2849\n",
      "Epoch [1/10], Phase: train, Batch: [340/730], Loss: 0.3895\n",
      "Epoch [1/10], Phase: train, Batch: [341/730], Loss: 0.3196\n",
      "Epoch [1/10], Phase: train, Batch: [342/730], Loss: 0.3486\n",
      "Epoch [1/10], Phase: train, Batch: [343/730], Loss: 0.5132\n",
      "Epoch [1/10], Phase: train, Batch: [344/730], Loss: 0.3935\n",
      "Epoch [1/10], Phase: train, Batch: [345/730], Loss: 0.2765\n",
      "Epoch [1/10], Phase: train, Batch: [346/730], Loss: 0.3894\n",
      "Epoch [1/10], Phase: train, Batch: [347/730], Loss: 0.2982\n",
      "Epoch [1/10], Phase: train, Batch: [348/730], Loss: 0.3365\n",
      "Epoch [1/10], Phase: train, Batch: [349/730], Loss: 0.3533\n",
      "Epoch [1/10], Phase: train, Batch: [350/730], Loss: 0.3709\n",
      "Epoch [1/10], Phase: train, Batch: [351/730], Loss: 0.4090\n",
      "Epoch [1/10], Phase: train, Batch: [352/730], Loss: 0.2792\n",
      "Epoch [1/10], Phase: train, Batch: [353/730], Loss: 0.3731\n",
      "Epoch [1/10], Phase: train, Batch: [354/730], Loss: 0.4875\n",
      "Epoch [1/10], Phase: train, Batch: [355/730], Loss: 0.3009\n",
      "Epoch [1/10], Phase: train, Batch: [356/730], Loss: 0.3696\n",
      "Epoch [1/10], Phase: train, Batch: [357/730], Loss: 0.3032\n",
      "Epoch [1/10], Phase: train, Batch: [358/730], Loss: 0.4192\n",
      "Epoch [1/10], Phase: train, Batch: [359/730], Loss: 0.2437\n",
      "Epoch [1/10], Phase: train, Batch: [360/730], Loss: 0.3354\n",
      "Epoch [1/10], Phase: train, Batch: [361/730], Loss: 0.2847\n",
      "Epoch [1/10], Phase: train, Batch: [362/730], Loss: 0.3851\n",
      "Epoch [1/10], Phase: train, Batch: [363/730], Loss: 0.1863\n",
      "Epoch [1/10], Phase: train, Batch: [364/730], Loss: 0.3508\n",
      "Epoch [1/10], Phase: train, Batch: [365/730], Loss: 0.2402\n",
      "Epoch [1/10], Phase: train, Batch: [366/730], Loss: 0.4006\n",
      "Epoch [1/10], Phase: train, Batch: [367/730], Loss: 0.2412\n",
      "Epoch [1/10], Phase: train, Batch: [368/730], Loss: 0.2474\n",
      "Epoch [1/10], Phase: train, Batch: [369/730], Loss: 0.2906\n",
      "Epoch [1/10], Phase: train, Batch: [370/730], Loss: 0.4134\n",
      "Epoch [1/10], Phase: train, Batch: [371/730], Loss: 0.3815\n",
      "Epoch [1/10], Phase: train, Batch: [372/730], Loss: 0.2188\n",
      "Epoch [1/10], Phase: train, Batch: [373/730], Loss: 0.2770\n",
      "Epoch [1/10], Phase: train, Batch: [374/730], Loss: 0.2354\n",
      "Epoch [1/10], Phase: train, Batch: [375/730], Loss: 0.2180\n",
      "Epoch [1/10], Phase: train, Batch: [376/730], Loss: 0.3142\n",
      "Epoch [1/10], Phase: train, Batch: [377/730], Loss: 0.2842\n",
      "Epoch [1/10], Phase: train, Batch: [378/730], Loss: 0.2899\n",
      "Epoch [1/10], Phase: train, Batch: [379/730], Loss: 0.4030\n",
      "Epoch [1/10], Phase: train, Batch: [380/730], Loss: 0.4118\n",
      "Epoch [1/10], Phase: train, Batch: [381/730], Loss: 0.4862\n",
      "Epoch [1/10], Phase: train, Batch: [382/730], Loss: 0.3951\n",
      "Epoch [1/10], Phase: train, Batch: [383/730], Loss: 0.2462\n",
      "Epoch [1/10], Phase: train, Batch: [384/730], Loss: 0.2891\n",
      "Epoch [1/10], Phase: train, Batch: [385/730], Loss: 0.4031\n",
      "Epoch [1/10], Phase: train, Batch: [386/730], Loss: 0.4063\n",
      "Epoch [1/10], Phase: train, Batch: [387/730], Loss: 0.2503\n",
      "Epoch [1/10], Phase: train, Batch: [388/730], Loss: 0.3059\n",
      "Epoch [1/10], Phase: train, Batch: [389/730], Loss: 0.3693\n",
      "Epoch [1/10], Phase: train, Batch: [390/730], Loss: 0.2742\n",
      "Epoch [1/10], Phase: train, Batch: [391/730], Loss: 0.3130\n",
      "Epoch [1/10], Phase: train, Batch: [392/730], Loss: 0.4197\n",
      "Epoch [1/10], Phase: train, Batch: [393/730], Loss: 0.2001\n",
      "Epoch [1/10], Phase: train, Batch: [394/730], Loss: 0.2993\n",
      "Epoch [1/10], Phase: train, Batch: [395/730], Loss: 0.3999\n",
      "Epoch [1/10], Phase: train, Batch: [396/730], Loss: 0.3372\n",
      "Epoch [1/10], Phase: train, Batch: [397/730], Loss: 0.3226\n",
      "Epoch [1/10], Phase: train, Batch: [398/730], Loss: 0.4680\n",
      "Epoch [1/10], Phase: train, Batch: [399/730], Loss: 0.3287\n",
      "Epoch [1/10], Phase: train, Batch: [400/730], Loss: 0.3101\n",
      "Epoch [1/10], Phase: train, Batch: [401/730], Loss: 0.2894\n",
      "Epoch [1/10], Phase: train, Batch: [402/730], Loss: 0.2465\n",
      "Epoch [1/10], Phase: train, Batch: [403/730], Loss: 0.2717\n",
      "Epoch [1/10], Phase: train, Batch: [404/730], Loss: 0.3702\n",
      "Epoch [1/10], Phase: train, Batch: [405/730], Loss: 0.2866\n",
      "Epoch [1/10], Phase: train, Batch: [406/730], Loss: 0.3318\n",
      "Epoch [1/10], Phase: train, Batch: [407/730], Loss: 0.2866\n",
      "Epoch [1/10], Phase: train, Batch: [408/730], Loss: 0.3533\n",
      "Epoch [1/10], Phase: train, Batch: [409/730], Loss: 0.2580\n",
      "Epoch [1/10], Phase: train, Batch: [410/730], Loss: 0.4353\n",
      "Epoch [1/10], Phase: train, Batch: [411/730], Loss: 0.3003\n",
      "Epoch [1/10], Phase: train, Batch: [412/730], Loss: 0.4189\n",
      "Epoch [1/10], Phase: train, Batch: [413/730], Loss: 0.3341\n",
      "Epoch [1/10], Phase: train, Batch: [414/730], Loss: 0.3001\n",
      "Epoch [1/10], Phase: train, Batch: [415/730], Loss: 0.2556\n",
      "Epoch [1/10], Phase: train, Batch: [416/730], Loss: 0.3671\n",
      "Epoch [1/10], Phase: train, Batch: [417/730], Loss: 0.3351\n",
      "Epoch [1/10], Phase: train, Batch: [418/730], Loss: 0.3363\n",
      "Epoch [1/10], Phase: train, Batch: [419/730], Loss: 0.2235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [420/730], Loss: 0.2391\n",
      "Epoch [1/10], Phase: train, Batch: [421/730], Loss: 0.3953\n",
      "Epoch [1/10], Phase: train, Batch: [422/730], Loss: 0.3747\n",
      "Epoch [1/10], Phase: train, Batch: [423/730], Loss: 0.3283\n",
      "Epoch [1/10], Phase: train, Batch: [424/730], Loss: 0.4155\n",
      "Epoch [1/10], Phase: train, Batch: [425/730], Loss: 0.3211\n",
      "Epoch [1/10], Phase: train, Batch: [426/730], Loss: 0.2668\n",
      "Epoch [1/10], Phase: train, Batch: [427/730], Loss: 0.3090\n",
      "Epoch [1/10], Phase: train, Batch: [428/730], Loss: 0.3110\n",
      "Epoch [1/10], Phase: train, Batch: [429/730], Loss: 0.2895\n",
      "Epoch [1/10], Phase: train, Batch: [430/730], Loss: 0.3682\n",
      "Epoch [1/10], Phase: train, Batch: [431/730], Loss: 0.3563\n",
      "Epoch [1/10], Phase: train, Batch: [432/730], Loss: 0.3515\n",
      "Epoch [1/10], Phase: train, Batch: [433/730], Loss: 0.2550\n",
      "Epoch [1/10], Phase: train, Batch: [434/730], Loss: 0.2529\n",
      "Epoch [1/10], Phase: train, Batch: [435/730], Loss: 0.1899\n",
      "Epoch [1/10], Phase: train, Batch: [436/730], Loss: 0.3049\n",
      "Epoch [1/10], Phase: train, Batch: [437/730], Loss: 0.5581\n",
      "Epoch [1/10], Phase: train, Batch: [438/730], Loss: 0.2357\n",
      "Epoch [1/10], Phase: train, Batch: [439/730], Loss: 0.6226\n",
      "Epoch [1/10], Phase: train, Batch: [440/730], Loss: 0.2723\n",
      "Epoch [1/10], Phase: train, Batch: [441/730], Loss: 0.4277\n",
      "Epoch [1/10], Phase: train, Batch: [442/730], Loss: 0.3326\n",
      "Epoch [1/10], Phase: train, Batch: [443/730], Loss: 0.3591\n",
      "Epoch [1/10], Phase: train, Batch: [444/730], Loss: 0.3401\n",
      "Epoch [1/10], Phase: train, Batch: [445/730], Loss: 0.2922\n",
      "Epoch [1/10], Phase: train, Batch: [446/730], Loss: 0.3875\n",
      "Epoch [1/10], Phase: train, Batch: [447/730], Loss: 0.4355\n",
      "Epoch [1/10], Phase: train, Batch: [448/730], Loss: 0.2564\n",
      "Epoch [1/10], Phase: train, Batch: [449/730], Loss: 0.3445\n",
      "Epoch [1/10], Phase: train, Batch: [450/730], Loss: 0.2679\n",
      "Epoch [1/10], Phase: train, Batch: [451/730], Loss: 0.4341\n",
      "Epoch [1/10], Phase: train, Batch: [452/730], Loss: 0.2747\n",
      "Epoch [1/10], Phase: train, Batch: [453/730], Loss: 0.3032\n",
      "Epoch [1/10], Phase: train, Batch: [454/730], Loss: 0.2246\n",
      "Epoch [1/10], Phase: train, Batch: [455/730], Loss: 0.3779\n",
      "Epoch [1/10], Phase: train, Batch: [456/730], Loss: 0.3492\n",
      "Epoch [1/10], Phase: train, Batch: [457/730], Loss: 0.2552\n",
      "Epoch [1/10], Phase: train, Batch: [458/730], Loss: 0.3449\n",
      "Epoch [1/10], Phase: train, Batch: [459/730], Loss: 0.2786\n",
      "Epoch [1/10], Phase: train, Batch: [460/730], Loss: 0.2989\n",
      "Epoch [1/10], Phase: train, Batch: [461/730], Loss: 0.2762\n",
      "Epoch [1/10], Phase: train, Batch: [462/730], Loss: 0.2540\n",
      "Epoch [1/10], Phase: train, Batch: [463/730], Loss: 0.3247\n",
      "Epoch [1/10], Phase: train, Batch: [464/730], Loss: 0.3334\n",
      "Epoch [1/10], Phase: train, Batch: [465/730], Loss: 0.4311\n",
      "Epoch [1/10], Phase: train, Batch: [466/730], Loss: 0.2151\n",
      "Epoch [1/10], Phase: train, Batch: [467/730], Loss: 0.1982\n",
      "Epoch [1/10], Phase: train, Batch: [468/730], Loss: 0.6015\n",
      "Epoch [1/10], Phase: train, Batch: [469/730], Loss: 0.3000\n",
      "Epoch [1/10], Phase: train, Batch: [470/730], Loss: 0.3314\n",
      "Epoch [1/10], Phase: train, Batch: [471/730], Loss: 0.3921\n",
      "Epoch [1/10], Phase: train, Batch: [472/730], Loss: 0.3645\n",
      "Epoch [1/10], Phase: train, Batch: [473/730], Loss: 0.3678\n",
      "Epoch [1/10], Phase: train, Batch: [474/730], Loss: 0.3217\n",
      "Epoch [1/10], Phase: train, Batch: [475/730], Loss: 0.3502\n",
      "Epoch [1/10], Phase: train, Batch: [476/730], Loss: 0.2933\n",
      "Epoch [1/10], Phase: train, Batch: [477/730], Loss: 0.2991\n",
      "Epoch [1/10], Phase: train, Batch: [478/730], Loss: 0.4044\n",
      "Epoch [1/10], Phase: train, Batch: [479/730], Loss: 0.2299\n",
      "Epoch [1/10], Phase: train, Batch: [480/730], Loss: 0.4620\n",
      "Epoch [1/10], Phase: train, Batch: [481/730], Loss: 0.3111\n",
      "Epoch [1/10], Phase: train, Batch: [482/730], Loss: 0.2739\n",
      "Epoch [1/10], Phase: train, Batch: [483/730], Loss: 0.4135\n",
      "Epoch [1/10], Phase: train, Batch: [484/730], Loss: 0.3204\n",
      "Epoch [1/10], Phase: train, Batch: [485/730], Loss: 0.2414\n",
      "Epoch [1/10], Phase: train, Batch: [486/730], Loss: 0.2866\n",
      "Epoch [1/10], Phase: train, Batch: [487/730], Loss: 0.2325\n",
      "Epoch [1/10], Phase: train, Batch: [488/730], Loss: 0.2157\n",
      "Epoch [1/10], Phase: train, Batch: [489/730], Loss: 0.2199\n",
      "Epoch [1/10], Phase: train, Batch: [490/730], Loss: 0.3478\n",
      "Epoch [1/10], Phase: train, Batch: [491/730], Loss: 0.3333\n",
      "Epoch [1/10], Phase: train, Batch: [492/730], Loss: 0.4741\n",
      "Epoch [1/10], Phase: train, Batch: [493/730], Loss: 0.3905\n",
      "Epoch [1/10], Phase: train, Batch: [494/730], Loss: 0.3576\n",
      "Epoch [1/10], Phase: train, Batch: [495/730], Loss: 0.4251\n",
      "Epoch [1/10], Phase: train, Batch: [496/730], Loss: 0.3249\n",
      "Epoch [1/10], Phase: train, Batch: [497/730], Loss: 0.3166\n",
      "Epoch [1/10], Phase: train, Batch: [498/730], Loss: 0.3123\n",
      "Epoch [1/10], Phase: train, Batch: [499/730], Loss: 0.2765\n",
      "Epoch [1/10], Phase: train, Batch: [500/730], Loss: 0.3297\n",
      "Epoch [1/10], Phase: train, Batch: [501/730], Loss: 0.3046\n",
      "Epoch [1/10], Phase: train, Batch: [502/730], Loss: 0.2275\n",
      "Epoch [1/10], Phase: train, Batch: [503/730], Loss: 0.3573\n",
      "Epoch [1/10], Phase: train, Batch: [504/730], Loss: 0.4900\n",
      "Epoch [1/10], Phase: train, Batch: [505/730], Loss: 0.2546\n",
      "Epoch [1/10], Phase: train, Batch: [506/730], Loss: 0.5528\n",
      "Epoch [1/10], Phase: train, Batch: [507/730], Loss: 0.3987\n",
      "Epoch [1/10], Phase: train, Batch: [508/730], Loss: 0.3642\n",
      "Epoch [1/10], Phase: train, Batch: [509/730], Loss: 0.2313\n",
      "Epoch [1/10], Phase: train, Batch: [510/730], Loss: 0.3265\n",
      "Epoch [1/10], Phase: train, Batch: [511/730], Loss: 0.3617\n",
      "Epoch [1/10], Phase: train, Batch: [512/730], Loss: 0.3063\n",
      "Epoch [1/10], Phase: train, Batch: [513/730], Loss: 0.3797\n",
      "Epoch [1/10], Phase: train, Batch: [514/730], Loss: 0.4769\n",
      "Epoch [1/10], Phase: train, Batch: [515/730], Loss: 0.3873\n",
      "Epoch [1/10], Phase: train, Batch: [516/730], Loss: 0.2947\n",
      "Epoch [1/10], Phase: train, Batch: [517/730], Loss: 0.3054\n",
      "Epoch [1/10], Phase: train, Batch: [518/730], Loss: 0.3038\n",
      "Epoch [1/10], Phase: train, Batch: [519/730], Loss: 0.3239\n",
      "Epoch [1/10], Phase: train, Batch: [520/730], Loss: 0.1651\n",
      "Epoch [1/10], Phase: train, Batch: [521/730], Loss: 0.2642\n",
      "Epoch [1/10], Phase: train, Batch: [522/730], Loss: 0.2448\n",
      "Epoch [1/10], Phase: train, Batch: [523/730], Loss: 0.4267\n",
      "Epoch [1/10], Phase: train, Batch: [524/730], Loss: 0.4327\n",
      "Epoch [1/10], Phase: train, Batch: [525/730], Loss: 0.2824\n",
      "Epoch [1/10], Phase: train, Batch: [526/730], Loss: 0.2182\n",
      "Epoch [1/10], Phase: train, Batch: [527/730], Loss: 0.3224\n",
      "Epoch [1/10], Phase: train, Batch: [528/730], Loss: 0.1529\n",
      "Epoch [1/10], Phase: train, Batch: [529/730], Loss: 0.2413\n",
      "Epoch [1/10], Phase: train, Batch: [530/730], Loss: 0.3330\n",
      "Epoch [1/10], Phase: train, Batch: [531/730], Loss: 0.2355\n",
      "Epoch [1/10], Phase: train, Batch: [532/730], Loss: 0.3728\n",
      "Epoch [1/10], Phase: train, Batch: [533/730], Loss: 0.1544\n",
      "Epoch [1/10], Phase: train, Batch: [534/730], Loss: 0.3150\n",
      "Epoch [1/10], Phase: train, Batch: [535/730], Loss: 0.3754\n",
      "Epoch [1/10], Phase: train, Batch: [536/730], Loss: 0.2953\n",
      "Epoch [1/10], Phase: train, Batch: [537/730], Loss: 0.4131\n",
      "Epoch [1/10], Phase: train, Batch: [538/730], Loss: 0.4322\n",
      "Epoch [1/10], Phase: train, Batch: [539/730], Loss: 0.2190\n",
      "Epoch [1/10], Phase: train, Batch: [540/730], Loss: 0.3475\n",
      "Epoch [1/10], Phase: train, Batch: [541/730], Loss: 0.2586\n",
      "Epoch [1/10], Phase: train, Batch: [542/730], Loss: 0.3766\n",
      "Epoch [1/10], Phase: train, Batch: [543/730], Loss: 0.2498\n",
      "Epoch [1/10], Phase: train, Batch: [544/730], Loss: 0.1574\n",
      "Epoch [1/10], Phase: train, Batch: [545/730], Loss: 0.4108\n",
      "Epoch [1/10], Phase: train, Batch: [546/730], Loss: 0.2681\n",
      "Epoch [1/10], Phase: train, Batch: [547/730], Loss: 0.2993\n",
      "Epoch [1/10], Phase: train, Batch: [548/730], Loss: 0.3246\n",
      "Epoch [1/10], Phase: train, Batch: [549/730], Loss: 0.2207\n",
      "Epoch [1/10], Phase: train, Batch: [550/730], Loss: 0.2819\n",
      "Epoch [1/10], Phase: train, Batch: [551/730], Loss: 0.2217\n",
      "Epoch [1/10], Phase: train, Batch: [552/730], Loss: 0.2623\n",
      "Epoch [1/10], Phase: train, Batch: [553/730], Loss: 0.2903\n",
      "Epoch [1/10], Phase: train, Batch: [554/730], Loss: 0.2235\n",
      "Epoch [1/10], Phase: train, Batch: [555/730], Loss: 0.3429\n",
      "Epoch [1/10], Phase: train, Batch: [556/730], Loss: 0.1877\n",
      "Epoch [1/10], Phase: train, Batch: [557/730], Loss: 0.5523\n",
      "Epoch [1/10], Phase: train, Batch: [558/730], Loss: 0.3195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [559/730], Loss: 0.5140\n",
      "Epoch [1/10], Phase: train, Batch: [560/730], Loss: 0.3045\n",
      "Epoch [1/10], Phase: train, Batch: [561/730], Loss: 0.2818\n",
      "Epoch [1/10], Phase: train, Batch: [562/730], Loss: 0.3503\n",
      "Epoch [1/10], Phase: train, Batch: [563/730], Loss: 0.2821\n",
      "Epoch [1/10], Phase: train, Batch: [564/730], Loss: 0.3475\n",
      "Epoch [1/10], Phase: train, Batch: [565/730], Loss: 0.3204\n",
      "Epoch [1/10], Phase: train, Batch: [566/730], Loss: 0.3054\n",
      "Epoch [1/10], Phase: train, Batch: [567/730], Loss: 0.3545\n",
      "Epoch [1/10], Phase: train, Batch: [568/730], Loss: 0.2517\n",
      "Epoch [1/10], Phase: train, Batch: [569/730], Loss: 0.2283\n",
      "Epoch [1/10], Phase: train, Batch: [570/730], Loss: 0.3802\n",
      "Epoch [1/10], Phase: train, Batch: [571/730], Loss: 0.3236\n",
      "Epoch [1/10], Phase: train, Batch: [572/730], Loss: 0.4419\n",
      "Epoch [1/10], Phase: train, Batch: [573/730], Loss: 0.3262\n",
      "Epoch [1/10], Phase: train, Batch: [574/730], Loss: 0.1885\n",
      "Epoch [1/10], Phase: train, Batch: [575/730], Loss: 0.4811\n",
      "Epoch [1/10], Phase: train, Batch: [576/730], Loss: 0.3402\n",
      "Epoch [1/10], Phase: train, Batch: [577/730], Loss: 0.2680\n",
      "Epoch [1/10], Phase: train, Batch: [578/730], Loss: 0.2898\n",
      "Epoch [1/10], Phase: train, Batch: [579/730], Loss: 0.3760\n",
      "Epoch [1/10], Phase: train, Batch: [580/730], Loss: 0.3466\n",
      "Epoch [1/10], Phase: train, Batch: [581/730], Loss: 0.3082\n",
      "Epoch [1/10], Phase: train, Batch: [582/730], Loss: 0.3095\n",
      "Epoch [1/10], Phase: train, Batch: [583/730], Loss: 0.3011\n",
      "Epoch [1/10], Phase: train, Batch: [584/730], Loss: 0.3309\n",
      "Epoch [1/10], Phase: train, Batch: [585/730], Loss: 0.4014\n",
      "Epoch [1/10], Phase: train, Batch: [586/730], Loss: 0.3108\n",
      "Epoch [1/10], Phase: train, Batch: [587/730], Loss: 0.4206\n",
      "Epoch [1/10], Phase: train, Batch: [588/730], Loss: 0.2520\n",
      "Epoch [1/10], Phase: train, Batch: [589/730], Loss: 0.2984\n",
      "Epoch [1/10], Phase: train, Batch: [590/730], Loss: 0.2797\n",
      "Epoch [1/10], Phase: train, Batch: [591/730], Loss: 0.3938\n",
      "Epoch [1/10], Phase: train, Batch: [592/730], Loss: 0.2978\n",
      "Epoch [1/10], Phase: train, Batch: [593/730], Loss: 0.3134\n",
      "Epoch [1/10], Phase: train, Batch: [594/730], Loss: 0.1989\n",
      "Epoch [1/10], Phase: train, Batch: [595/730], Loss: 0.2909\n",
      "Epoch [1/10], Phase: train, Batch: [596/730], Loss: 0.3986\n",
      "Epoch [1/10], Phase: train, Batch: [597/730], Loss: 0.4355\n",
      "Epoch [1/10], Phase: train, Batch: [598/730], Loss: 0.3330\n",
      "Epoch [1/10], Phase: train, Batch: [599/730], Loss: 0.2370\n",
      "Epoch [1/10], Phase: train, Batch: [600/730], Loss: 0.2383\n",
      "Epoch [1/10], Phase: train, Batch: [601/730], Loss: 0.2387\n",
      "Epoch [1/10], Phase: train, Batch: [602/730], Loss: 0.2503\n",
      "Epoch [1/10], Phase: train, Batch: [603/730], Loss: 0.3237\n",
      "Epoch [1/10], Phase: train, Batch: [604/730], Loss: 0.2959\n",
      "Epoch [1/10], Phase: train, Batch: [605/730], Loss: 0.2536\n",
      "Epoch [1/10], Phase: train, Batch: [606/730], Loss: 0.2550\n",
      "Epoch [1/10], Phase: train, Batch: [607/730], Loss: 0.2371\n",
      "Epoch [1/10], Phase: train, Batch: [608/730], Loss: 0.3611\n",
      "Epoch [1/10], Phase: train, Batch: [609/730], Loss: 0.3328\n",
      "Epoch [1/10], Phase: train, Batch: [610/730], Loss: 0.2982\n",
      "Epoch [1/10], Phase: train, Batch: [611/730], Loss: 0.3089\n",
      "Epoch [1/10], Phase: train, Batch: [612/730], Loss: 0.3126\n",
      "Epoch [1/10], Phase: train, Batch: [613/730], Loss: 0.2987\n",
      "Epoch [1/10], Phase: train, Batch: [614/730], Loss: 0.1613\n",
      "Epoch [1/10], Phase: train, Batch: [615/730], Loss: 0.3820\n",
      "Epoch [1/10], Phase: train, Batch: [616/730], Loss: 0.3102\n",
      "Epoch [1/10], Phase: train, Batch: [617/730], Loss: 0.3105\n",
      "Epoch [1/10], Phase: train, Batch: [618/730], Loss: 0.2488\n",
      "Epoch [1/10], Phase: train, Batch: [619/730], Loss: 0.1953\n",
      "Epoch [1/10], Phase: train, Batch: [620/730], Loss: 0.3687\n",
      "Epoch [1/10], Phase: train, Batch: [621/730], Loss: 0.1820\n",
      "Epoch [1/10], Phase: train, Batch: [622/730], Loss: 0.3970\n",
      "Epoch [1/10], Phase: train, Batch: [623/730], Loss: 0.2849\n",
      "Epoch [1/10], Phase: train, Batch: [624/730], Loss: 0.1737\n",
      "Epoch [1/10], Phase: train, Batch: [625/730], Loss: 0.6006\n",
      "Epoch [1/10], Phase: train, Batch: [626/730], Loss: 0.3336\n",
      "Epoch [1/10], Phase: train, Batch: [627/730], Loss: 0.3704\n",
      "Epoch [1/10], Phase: train, Batch: [628/730], Loss: 0.4215\n",
      "Epoch [1/10], Phase: train, Batch: [629/730], Loss: 0.2181\n",
      "Epoch [1/10], Phase: train, Batch: [630/730], Loss: 0.3480\n",
      "Epoch [1/10], Phase: train, Batch: [631/730], Loss: 0.2514\n",
      "Epoch [1/10], Phase: train, Batch: [632/730], Loss: 0.3371\n",
      "Epoch [1/10], Phase: train, Batch: [633/730], Loss: 0.3057\n",
      "Epoch [1/10], Phase: train, Batch: [634/730], Loss: 0.2855\n",
      "Epoch [1/10], Phase: train, Batch: [635/730], Loss: 0.3385\n",
      "Epoch [1/10], Phase: train, Batch: [636/730], Loss: 0.3621\n",
      "Epoch [1/10], Phase: train, Batch: [637/730], Loss: 0.2296\n",
      "Epoch [1/10], Phase: train, Batch: [638/730], Loss: 0.2293\n",
      "Epoch [1/10], Phase: train, Batch: [639/730], Loss: 0.3522\n",
      "Epoch [1/10], Phase: train, Batch: [640/730], Loss: 0.1796\n",
      "Epoch [1/10], Phase: train, Batch: [641/730], Loss: 0.2550\n",
      "Epoch [1/10], Phase: train, Batch: [642/730], Loss: 0.2633\n",
      "Epoch [1/10], Phase: train, Batch: [643/730], Loss: 0.1495\n",
      "Epoch [1/10], Phase: train, Batch: [644/730], Loss: 0.2910\n",
      "Epoch [1/10], Phase: train, Batch: [645/730], Loss: 0.1577\n",
      "Epoch [1/10], Phase: train, Batch: [646/730], Loss: 0.1347\n",
      "Epoch [1/10], Phase: train, Batch: [647/730], Loss: 0.2487\n",
      "Epoch [1/10], Phase: train, Batch: [648/730], Loss: 0.2385\n",
      "Epoch [1/10], Phase: train, Batch: [649/730], Loss: 0.2705\n",
      "Epoch [1/10], Phase: train, Batch: [650/730], Loss: 0.4085\n",
      "Epoch [1/10], Phase: train, Batch: [651/730], Loss: 0.2558\n",
      "Epoch [1/10], Phase: train, Batch: [652/730], Loss: 0.5292\n",
      "Epoch [1/10], Phase: train, Batch: [653/730], Loss: 0.2176\n",
      "Epoch [1/10], Phase: train, Batch: [654/730], Loss: 0.3631\n",
      "Epoch [1/10], Phase: train, Batch: [655/730], Loss: 0.2319\n",
      "Epoch [1/10], Phase: train, Batch: [656/730], Loss: 0.3060\n",
      "Epoch [1/10], Phase: train, Batch: [657/730], Loss: 0.4249\n",
      "Epoch [1/10], Phase: train, Batch: [658/730], Loss: 0.4060\n",
      "Epoch [1/10], Phase: train, Batch: [659/730], Loss: 0.3340\n",
      "Epoch [1/10], Phase: train, Batch: [660/730], Loss: 0.3176\n",
      "Epoch [1/10], Phase: train, Batch: [661/730], Loss: 0.3113\n",
      "Epoch [1/10], Phase: train, Batch: [662/730], Loss: 0.3624\n",
      "Epoch [1/10], Phase: train, Batch: [663/730], Loss: 0.2255\n",
      "Epoch [1/10], Phase: train, Batch: [664/730], Loss: 0.3522\n",
      "Epoch [1/10], Phase: train, Batch: [665/730], Loss: 0.3452\n",
      "Epoch [1/10], Phase: train, Batch: [666/730], Loss: 0.2333\n",
      "Epoch [1/10], Phase: train, Batch: [667/730], Loss: 0.3689\n",
      "Epoch [1/10], Phase: train, Batch: [668/730], Loss: 0.5721\n",
      "Epoch [1/10], Phase: train, Batch: [669/730], Loss: 0.3665\n",
      "Epoch [1/10], Phase: train, Batch: [670/730], Loss: 0.5054\n",
      "Epoch [1/10], Phase: train, Batch: [671/730], Loss: 0.3139\n",
      "Epoch [1/10], Phase: train, Batch: [672/730], Loss: 0.2339\n",
      "Epoch [1/10], Phase: train, Batch: [673/730], Loss: 0.4137\n",
      "Epoch [1/10], Phase: train, Batch: [674/730], Loss: 0.2954\n",
      "Epoch [1/10], Phase: train, Batch: [675/730], Loss: 0.3266\n",
      "Epoch [1/10], Phase: train, Batch: [676/730], Loss: 0.3040\n",
      "Epoch [1/10], Phase: train, Batch: [677/730], Loss: 0.2234\n",
      "Epoch [1/10], Phase: train, Batch: [678/730], Loss: 0.3035\n",
      "Epoch [1/10], Phase: train, Batch: [679/730], Loss: 0.2945\n",
      "Epoch [1/10], Phase: train, Batch: [680/730], Loss: 0.3090\n",
      "Epoch [1/10], Phase: train, Batch: [681/730], Loss: 0.3928\n",
      "Epoch [1/10], Phase: train, Batch: [682/730], Loss: 0.1999\n",
      "Epoch [1/10], Phase: train, Batch: [683/730], Loss: 0.3280\n",
      "Epoch [1/10], Phase: train, Batch: [684/730], Loss: 0.3175\n",
      "Epoch [1/10], Phase: train, Batch: [685/730], Loss: 0.2131\n",
      "Epoch [1/10], Phase: train, Batch: [686/730], Loss: 0.3316\n",
      "Epoch [1/10], Phase: train, Batch: [687/730], Loss: 0.3141\n",
      "Epoch [1/10], Phase: train, Batch: [688/730], Loss: 0.4441\n",
      "Epoch [1/10], Phase: train, Batch: [689/730], Loss: 0.4097\n",
      "Epoch [1/10], Phase: train, Batch: [690/730], Loss: 0.1946\n",
      "Epoch [1/10], Phase: train, Batch: [691/730], Loss: 0.2590\n",
      "Epoch [1/10], Phase: train, Batch: [692/730], Loss: 0.2749\n",
      "Epoch [1/10], Phase: train, Batch: [693/730], Loss: 0.3288\n",
      "Epoch [1/10], Phase: train, Batch: [694/730], Loss: 0.2986\n",
      "Epoch [1/10], Phase: train, Batch: [695/730], Loss: 0.3062\n",
      "Epoch [1/10], Phase: train, Batch: [696/730], Loss: 0.2603\n",
      "Epoch [1/10], Phase: train, Batch: [697/730], Loss: 0.2850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [698/730], Loss: 0.2925\n",
      "Epoch [1/10], Phase: train, Batch: [699/730], Loss: 0.3348\n",
      "Epoch [1/10], Phase: train, Batch: [700/730], Loss: 0.2907\n",
      "Epoch [1/10], Phase: train, Batch: [701/730], Loss: 0.2350\n",
      "Epoch [1/10], Phase: train, Batch: [702/730], Loss: 0.2687\n",
      "Epoch [1/10], Phase: train, Batch: [703/730], Loss: 0.4053\n",
      "Epoch [1/10], Phase: train, Batch: [704/730], Loss: 0.2356\n",
      "Epoch [1/10], Phase: train, Batch: [705/730], Loss: 0.3696\n",
      "Epoch [1/10], Phase: train, Batch: [706/730], Loss: 0.3326\n",
      "Epoch [1/10], Phase: train, Batch: [707/730], Loss: 0.2746\n",
      "Epoch [1/10], Phase: train, Batch: [708/730], Loss: 0.2734\n",
      "Epoch [1/10], Phase: train, Batch: [709/730], Loss: 0.3025\n",
      "Epoch [1/10], Phase: train, Batch: [710/730], Loss: 0.2691\n",
      "Epoch [1/10], Phase: train, Batch: [711/730], Loss: 0.4075\n",
      "Epoch [1/10], Phase: train, Batch: [712/730], Loss: 0.3785\n",
      "Epoch [1/10], Phase: train, Batch: [713/730], Loss: 0.3561\n",
      "Epoch [1/10], Phase: train, Batch: [714/730], Loss: 0.2737\n",
      "Epoch [1/10], Phase: train, Batch: [715/730], Loss: 0.1430\n",
      "Epoch [1/10], Phase: train, Batch: [716/730], Loss: 0.3904\n",
      "Epoch [1/10], Phase: train, Batch: [717/730], Loss: 0.3608\n",
      "Epoch [1/10], Phase: train, Batch: [718/730], Loss: 0.4308\n",
      "Epoch [1/10], Phase: train, Batch: [719/730], Loss: 0.4166\n",
      "Epoch [1/10], Phase: train, Batch: [720/730], Loss: 0.3092\n",
      "Epoch [1/10], Phase: train, Batch: [721/730], Loss: 0.3438\n",
      "Epoch [1/10], Phase: train, Batch: [722/730], Loss: 0.4355\n",
      "Epoch [1/10], Phase: train, Batch: [723/730], Loss: 0.3352\n",
      "Epoch [1/10], Phase: train, Batch: [724/730], Loss: 0.3280\n",
      "Epoch [1/10], Phase: train, Batch: [725/730], Loss: 0.3402\n",
      "Epoch [1/10], Phase: train, Batch: [726/730], Loss: 0.3254\n",
      "Epoch [1/10], Phase: train, Batch: [727/730], Loss: 0.3150\n",
      "Epoch [1/10], Phase: train, Batch: [728/730], Loss: 0.2335\n",
      "Epoch [1/10], Phase: train, Batch: [729/730], Loss: 0.3444\n",
      "Epoch [1/10], Phase: train, Batch: [730/730], Loss: 0.3300\n",
      "train Loss: 0.3544 Acc: 0.8655\n",
      "Epoch [1/10], Phase: val, Batch: [1/182], Loss: 0.4561\n",
      "Epoch [1/10], Phase: val, Batch: [2/182], Loss: 0.2978\n",
      "Epoch [1/10], Phase: val, Batch: [3/182], Loss: 0.2349\n",
      "Epoch [1/10], Phase: val, Batch: [4/182], Loss: 0.3504\n",
      "Epoch [1/10], Phase: val, Batch: [5/182], Loss: 0.2894\n",
      "Epoch [1/10], Phase: val, Batch: [6/182], Loss: 0.2630\n",
      "Epoch [1/10], Phase: val, Batch: [7/182], Loss: 0.1463\n",
      "Epoch [1/10], Phase: val, Batch: [8/182], Loss: 0.3057\n",
      "Epoch [1/10], Phase: val, Batch: [9/182], Loss: 0.2691\n",
      "Epoch [1/10], Phase: val, Batch: [10/182], Loss: 0.2213\n",
      "Epoch [1/10], Phase: val, Batch: [11/182], Loss: 0.2060\n",
      "Epoch [1/10], Phase: val, Batch: [12/182], Loss: 0.3164\n",
      "Epoch [1/10], Phase: val, Batch: [13/182], Loss: 0.2348\n",
      "Epoch [1/10], Phase: val, Batch: [14/182], Loss: 0.1929\n",
      "Epoch [1/10], Phase: val, Batch: [15/182], Loss: 0.2625\n",
      "Epoch [1/10], Phase: val, Batch: [16/182], Loss: 0.3142\n",
      "Epoch [1/10], Phase: val, Batch: [17/182], Loss: 0.2974\n",
      "Epoch [1/10], Phase: val, Batch: [18/182], Loss: 0.2924\n",
      "Epoch [1/10], Phase: val, Batch: [19/182], Loss: 0.4221\n",
      "Epoch [1/10], Phase: val, Batch: [20/182], Loss: 0.4505\n",
      "Epoch [1/10], Phase: val, Batch: [21/182], Loss: 0.4385\n",
      "Epoch [1/10], Phase: val, Batch: [22/182], Loss: 0.4735\n",
      "Epoch [1/10], Phase: val, Batch: [23/182], Loss: 0.2278\n",
      "Epoch [1/10], Phase: val, Batch: [24/182], Loss: 0.4524\n",
      "Epoch [1/10], Phase: val, Batch: [25/182], Loss: 0.3278\n",
      "Epoch [1/10], Phase: val, Batch: [26/182], Loss: 0.1955\n",
      "Epoch [1/10], Phase: val, Batch: [27/182], Loss: 0.2595\n",
      "Epoch [1/10], Phase: val, Batch: [28/182], Loss: 0.4147\n",
      "Epoch [1/10], Phase: val, Batch: [29/182], Loss: 0.3713\n",
      "Epoch [1/10], Phase: val, Batch: [30/182], Loss: 0.3924\n",
      "Epoch [1/10], Phase: val, Batch: [31/182], Loss: 0.4640\n",
      "Epoch [1/10], Phase: val, Batch: [32/182], Loss: 0.1927\n",
      "Epoch [1/10], Phase: val, Batch: [33/182], Loss: 0.3367\n",
      "Epoch [1/10], Phase: val, Batch: [34/182], Loss: 0.3314\n",
      "Epoch [1/10], Phase: val, Batch: [35/182], Loss: 0.2178\n",
      "Epoch [1/10], Phase: val, Batch: [36/182], Loss: 0.2955\n",
      "Epoch [1/10], Phase: val, Batch: [37/182], Loss: 0.2108\n",
      "Epoch [1/10], Phase: val, Batch: [38/182], Loss: 0.2139\n",
      "Epoch [1/10], Phase: val, Batch: [39/182], Loss: 0.3414\n",
      "Epoch [1/10], Phase: val, Batch: [40/182], Loss: 0.2981\n",
      "Epoch [1/10], Phase: val, Batch: [41/182], Loss: 0.2799\n",
      "Epoch [1/10], Phase: val, Batch: [42/182], Loss: 0.3482\n",
      "Epoch [1/10], Phase: val, Batch: [43/182], Loss: 0.2198\n",
      "Epoch [1/10], Phase: val, Batch: [44/182], Loss: 0.3782\n",
      "Epoch [1/10], Phase: val, Batch: [45/182], Loss: 0.3675\n",
      "Epoch [1/10], Phase: val, Batch: [46/182], Loss: 0.2704\n",
      "Epoch [1/10], Phase: val, Batch: [47/182], Loss: 0.3781\n",
      "Epoch [1/10], Phase: val, Batch: [48/182], Loss: 0.1590\n",
      "Epoch [1/10], Phase: val, Batch: [49/182], Loss: 0.3436\n",
      "Epoch [1/10], Phase: val, Batch: [50/182], Loss: 0.4556\n",
      "Epoch [1/10], Phase: val, Batch: [51/182], Loss: 0.4779\n",
      "Epoch [1/10], Phase: val, Batch: [52/182], Loss: 0.2748\n",
      "Epoch [1/10], Phase: val, Batch: [53/182], Loss: 0.2763\n",
      "Epoch [1/10], Phase: val, Batch: [54/182], Loss: 0.3505\n",
      "Epoch [1/10], Phase: val, Batch: [55/182], Loss: 0.2457\n",
      "Epoch [1/10], Phase: val, Batch: [56/182], Loss: 0.2256\n",
      "Epoch [1/10], Phase: val, Batch: [57/182], Loss: 0.3114\n",
      "Epoch [1/10], Phase: val, Batch: [58/182], Loss: 0.2453\n",
      "Epoch [1/10], Phase: val, Batch: [59/182], Loss: 0.2277\n",
      "Epoch [1/10], Phase: val, Batch: [60/182], Loss: 0.2269\n",
      "Epoch [1/10], Phase: val, Batch: [61/182], Loss: 0.3612\n",
      "Epoch [1/10], Phase: val, Batch: [62/182], Loss: 0.4325\n",
      "Epoch [1/10], Phase: val, Batch: [63/182], Loss: 0.2170\n",
      "Epoch [1/10], Phase: val, Batch: [64/182], Loss: 0.3370\n",
      "Epoch [1/10], Phase: val, Batch: [65/182], Loss: 0.2320\n",
      "Epoch [1/10], Phase: val, Batch: [66/182], Loss: 0.3179\n",
      "Epoch [1/10], Phase: val, Batch: [67/182], Loss: 0.2671\n",
      "Epoch [1/10], Phase: val, Batch: [68/182], Loss: 0.2580\n",
      "Epoch [1/10], Phase: val, Batch: [69/182], Loss: 0.3297\n",
      "Epoch [1/10], Phase: val, Batch: [70/182], Loss: 0.2915\n",
      "Epoch [1/10], Phase: val, Batch: [71/182], Loss: 0.4135\n",
      "Epoch [1/10], Phase: val, Batch: [72/182], Loss: 0.2483\n",
      "Epoch [1/10], Phase: val, Batch: [73/182], Loss: 0.2307\n",
      "Epoch [1/10], Phase: val, Batch: [74/182], Loss: 0.4257\n",
      "Epoch [1/10], Phase: val, Batch: [75/182], Loss: 0.2604\n",
      "Epoch [1/10], Phase: val, Batch: [76/182], Loss: 0.2515\n",
      "Epoch [1/10], Phase: val, Batch: [77/182], Loss: 0.2004\n",
      "Epoch [1/10], Phase: val, Batch: [78/182], Loss: 0.2111\n",
      "Epoch [1/10], Phase: val, Batch: [79/182], Loss: 0.2788\n",
      "Epoch [1/10], Phase: val, Batch: [80/182], Loss: 0.2342\n",
      "Epoch [1/10], Phase: val, Batch: [81/182], Loss: 0.1704\n",
      "Epoch [1/10], Phase: val, Batch: [82/182], Loss: 0.2306\n",
      "Epoch [1/10], Phase: val, Batch: [83/182], Loss: 0.2740\n",
      "Epoch [1/10], Phase: val, Batch: [84/182], Loss: 0.2542\n",
      "Epoch [1/10], Phase: val, Batch: [85/182], Loss: 0.2781\n",
      "Epoch [1/10], Phase: val, Batch: [86/182], Loss: 0.3382\n",
      "Epoch [1/10], Phase: val, Batch: [87/182], Loss: 0.4662\n",
      "Epoch [1/10], Phase: val, Batch: [88/182], Loss: 0.3546\n",
      "Epoch [1/10], Phase: val, Batch: [89/182], Loss: 0.2864\n",
      "Epoch [1/10], Phase: val, Batch: [90/182], Loss: 0.3350\n",
      "Epoch [1/10], Phase: val, Batch: [91/182], Loss: 0.3313\n",
      "Epoch [1/10], Phase: val, Batch: [92/182], Loss: 0.2059\n",
      "Epoch [1/10], Phase: val, Batch: [93/182], Loss: 0.1449\n",
      "Epoch [1/10], Phase: val, Batch: [94/182], Loss: 0.1514\n",
      "Epoch [1/10], Phase: val, Batch: [95/182], Loss: 0.2162\n",
      "Epoch [1/10], Phase: val, Batch: [96/182], Loss: 0.1618\n",
      "Epoch [1/10], Phase: val, Batch: [97/182], Loss: 0.1964\n",
      "Epoch [1/10], Phase: val, Batch: [98/182], Loss: 0.1649\n",
      "Epoch [1/10], Phase: val, Batch: [99/182], Loss: 0.2062\n",
      "Epoch [1/10], Phase: val, Batch: [100/182], Loss: 0.2035\n",
      "Epoch [1/10], Phase: val, Batch: [101/182], Loss: 0.2777\n",
      "Epoch [1/10], Phase: val, Batch: [102/182], Loss: 0.1372\n",
      "Epoch [1/10], Phase: val, Batch: [103/182], Loss: 0.2029\n",
      "Epoch [1/10], Phase: val, Batch: [104/182], Loss: 0.2067\n",
      "Epoch [1/10], Phase: val, Batch: [105/182], Loss: 0.1487\n",
      "Epoch [1/10], Phase: val, Batch: [106/182], Loss: 0.3274\n",
      "Epoch [1/10], Phase: val, Batch: [107/182], Loss: 0.2047\n",
      "Epoch [1/10], Phase: val, Batch: [108/182], Loss: 0.1849\n",
      "Epoch [1/10], Phase: val, Batch: [109/182], Loss: 0.1975\n",
      "Epoch [1/10], Phase: val, Batch: [110/182], Loss: 0.1740\n",
      "Epoch [1/10], Phase: val, Batch: [111/182], Loss: 0.1022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: val, Batch: [112/182], Loss: 0.1516\n",
      "Epoch [1/10], Phase: val, Batch: [113/182], Loss: 0.1226\n",
      "Epoch [1/10], Phase: val, Batch: [114/182], Loss: 0.2214\n",
      "Epoch [1/10], Phase: val, Batch: [115/182], Loss: 0.1521\n",
      "Epoch [1/10], Phase: val, Batch: [116/182], Loss: 0.2291\n",
      "Epoch [1/10], Phase: val, Batch: [117/182], Loss: 0.1282\n",
      "Epoch [1/10], Phase: val, Batch: [118/182], Loss: 0.1964\n",
      "Epoch [1/10], Phase: val, Batch: [119/182], Loss: 0.1453\n",
      "Epoch [1/10], Phase: val, Batch: [120/182], Loss: 0.1580\n",
      "Epoch [1/10], Phase: val, Batch: [121/182], Loss: 0.1841\n",
      "Epoch [1/10], Phase: val, Batch: [122/182], Loss: 0.1660\n",
      "Epoch [1/10], Phase: val, Batch: [123/182], Loss: 0.2314\n",
      "Epoch [1/10], Phase: val, Batch: [124/182], Loss: 0.1335\n",
      "Epoch [1/10], Phase: val, Batch: [125/182], Loss: 0.1448\n",
      "Epoch [1/10], Phase: val, Batch: [126/182], Loss: 0.1714\n",
      "Epoch [1/10], Phase: val, Batch: [127/182], Loss: 0.1580\n",
      "Epoch [1/10], Phase: val, Batch: [128/182], Loss: 0.1584\n",
      "Epoch [1/10], Phase: val, Batch: [129/182], Loss: 0.1831\n",
      "Epoch [1/10], Phase: val, Batch: [130/182], Loss: 0.1321\n",
      "Epoch [1/10], Phase: val, Batch: [131/182], Loss: 0.1931\n",
      "Epoch [1/10], Phase: val, Batch: [132/182], Loss: 0.1966\n",
      "Epoch [1/10], Phase: val, Batch: [133/182], Loss: 0.2701\n",
      "Epoch [1/10], Phase: val, Batch: [134/182], Loss: 0.0942\n",
      "Epoch [1/10], Phase: val, Batch: [135/182], Loss: 0.1788\n",
      "Epoch [1/10], Phase: val, Batch: [136/182], Loss: 0.2384\n",
      "Epoch [1/10], Phase: val, Batch: [137/182], Loss: 0.1870\n",
      "Epoch [1/10], Phase: val, Batch: [138/182], Loss: 0.2255\n",
      "Epoch [1/10], Phase: val, Batch: [139/182], Loss: 0.1285\n",
      "Epoch [1/10], Phase: val, Batch: [140/182], Loss: 0.1938\n",
      "Epoch [1/10], Phase: val, Batch: [141/182], Loss: 0.1650\n",
      "Epoch [1/10], Phase: val, Batch: [142/182], Loss: 0.1704\n",
      "Epoch [1/10], Phase: val, Batch: [143/182], Loss: 0.2315\n",
      "Epoch [1/10], Phase: val, Batch: [144/182], Loss: 0.2311\n",
      "Epoch [1/10], Phase: val, Batch: [145/182], Loss: 0.1194\n",
      "Epoch [1/10], Phase: val, Batch: [146/182], Loss: 0.1467\n",
      "Epoch [1/10], Phase: val, Batch: [147/182], Loss: 0.2058\n",
      "Epoch [1/10], Phase: val, Batch: [148/182], Loss: 0.1606\n",
      "Epoch [1/10], Phase: val, Batch: [149/182], Loss: 0.2187\n",
      "Epoch [1/10], Phase: val, Batch: [150/182], Loss: 0.2300\n",
      "Epoch [1/10], Phase: val, Batch: [151/182], Loss: 0.2066\n",
      "Epoch [1/10], Phase: val, Batch: [152/182], Loss: 0.2401\n",
      "Epoch [1/10], Phase: val, Batch: [153/182], Loss: 0.2061\n",
      "Epoch [1/10], Phase: val, Batch: [154/182], Loss: 0.1902\n",
      "Epoch [1/10], Phase: val, Batch: [155/182], Loss: 0.1671\n",
      "Epoch [1/10], Phase: val, Batch: [156/182], Loss: 0.2947\n",
      "Epoch [1/10], Phase: val, Batch: [157/182], Loss: 0.1920\n",
      "Epoch [1/10], Phase: val, Batch: [158/182], Loss: 0.3051\n",
      "Epoch [1/10], Phase: val, Batch: [159/182], Loss: 0.2195\n",
      "Epoch [1/10], Phase: val, Batch: [160/182], Loss: 0.1692\n",
      "Epoch [1/10], Phase: val, Batch: [161/182], Loss: 0.2230\n",
      "Epoch [1/10], Phase: val, Batch: [162/182], Loss: 0.2357\n",
      "Epoch [1/10], Phase: val, Batch: [163/182], Loss: 0.2317\n",
      "Epoch [1/10], Phase: val, Batch: [164/182], Loss: 0.1678\n",
      "Epoch [1/10], Phase: val, Batch: [165/182], Loss: 0.2117\n",
      "Epoch [1/10], Phase: val, Batch: [166/182], Loss: 0.1203\n",
      "Epoch [1/10], Phase: val, Batch: [167/182], Loss: 0.1683\n",
      "Epoch [1/10], Phase: val, Batch: [168/182], Loss: 0.1705\n",
      "Epoch [1/10], Phase: val, Batch: [169/182], Loss: 0.1948\n",
      "Epoch [1/10], Phase: val, Batch: [170/182], Loss: 0.2278\n",
      "Epoch [1/10], Phase: val, Batch: [171/182], Loss: 0.2442\n",
      "Epoch [1/10], Phase: val, Batch: [172/182], Loss: 0.1896\n",
      "Epoch [1/10], Phase: val, Batch: [173/182], Loss: 0.0872\n",
      "Epoch [1/10], Phase: val, Batch: [174/182], Loss: 0.2160\n",
      "Epoch [1/10], Phase: val, Batch: [175/182], Loss: 0.1296\n",
      "Epoch [1/10], Phase: val, Batch: [176/182], Loss: 0.1751\n",
      "Epoch [1/10], Phase: val, Batch: [177/182], Loss: 0.2103\n",
      "Epoch [1/10], Phase: val, Batch: [178/182], Loss: 0.0997\n",
      "Epoch [1/10], Phase: val, Batch: [179/182], Loss: 0.1607\n",
      "Epoch [1/10], Phase: val, Batch: [180/182], Loss: 0.1662\n",
      "Epoch [1/10], Phase: val, Batch: [181/182], Loss: 0.2828\n",
      "Epoch [1/10], Phase: val, Batch: [182/182], Loss: 0.1999\n",
      "val Loss: 0.2447 Acc: 0.9050\n",
      "Epoch [2/10], Phase: train, Batch: [1/730], Loss: 0.2588\n",
      "Epoch [2/10], Phase: train, Batch: [2/730], Loss: 0.3817\n",
      "Epoch [2/10], Phase: train, Batch: [3/730], Loss: 0.3573\n",
      "Epoch [2/10], Phase: train, Batch: [4/730], Loss: 0.3598\n",
      "Epoch [2/10], Phase: train, Batch: [5/730], Loss: 0.2700\n",
      "Epoch [2/10], Phase: train, Batch: [6/730], Loss: 0.2255\n",
      "Epoch [2/10], Phase: train, Batch: [7/730], Loss: 0.3307\n",
      "Epoch [2/10], Phase: train, Batch: [8/730], Loss: 0.4435\n",
      "Epoch [2/10], Phase: train, Batch: [9/730], Loss: 0.4421\n",
      "Epoch [2/10], Phase: train, Batch: [10/730], Loss: 0.1977\n",
      "Epoch [2/10], Phase: train, Batch: [11/730], Loss: 0.3568\n",
      "Epoch [2/10], Phase: train, Batch: [12/730], Loss: 0.2946\n",
      "Epoch [2/10], Phase: train, Batch: [13/730], Loss: 0.2470\n",
      "Epoch [2/10], Phase: train, Batch: [14/730], Loss: 0.2814\n",
      "Epoch [2/10], Phase: train, Batch: [15/730], Loss: 0.2832\n",
      "Epoch [2/10], Phase: train, Batch: [16/730], Loss: 0.2023\n",
      "Epoch [2/10], Phase: train, Batch: [17/730], Loss: 0.2080\n",
      "Epoch [2/10], Phase: train, Batch: [18/730], Loss: 0.1772\n",
      "Epoch [2/10], Phase: train, Batch: [19/730], Loss: 0.2269\n",
      "Epoch [2/10], Phase: train, Batch: [20/730], Loss: 0.1397\n",
      "Epoch [2/10], Phase: train, Batch: [21/730], Loss: 0.4572\n",
      "Epoch [2/10], Phase: train, Batch: [22/730], Loss: 0.2446\n",
      "Epoch [2/10], Phase: train, Batch: [23/730], Loss: 0.2419\n",
      "Epoch [2/10], Phase: train, Batch: [24/730], Loss: 0.2147\n",
      "Epoch [2/10], Phase: train, Batch: [25/730], Loss: 0.2953\n",
      "Epoch [2/10], Phase: train, Batch: [26/730], Loss: 0.2704\n",
      "Epoch [2/10], Phase: train, Batch: [27/730], Loss: 0.2963\n",
      "Epoch [2/10], Phase: train, Batch: [28/730], Loss: 0.2864\n",
      "Epoch [2/10], Phase: train, Batch: [29/730], Loss: 0.2383\n",
      "Epoch [2/10], Phase: train, Batch: [30/730], Loss: 0.3294\n",
      "Epoch [2/10], Phase: train, Batch: [31/730], Loss: 0.1940\n",
      "Epoch [2/10], Phase: train, Batch: [32/730], Loss: 0.1790\n",
      "Epoch [2/10], Phase: train, Batch: [33/730], Loss: 0.2634\n",
      "Epoch [2/10], Phase: train, Batch: [34/730], Loss: 0.2091\n",
      "Epoch [2/10], Phase: train, Batch: [35/730], Loss: 0.1719\n",
      "Epoch [2/10], Phase: train, Batch: [36/730], Loss: 0.4358\n",
      "Epoch [2/10], Phase: train, Batch: [37/730], Loss: 0.2007\n",
      "Epoch [2/10], Phase: train, Batch: [38/730], Loss: 0.3598\n",
      "Epoch [2/10], Phase: train, Batch: [39/730], Loss: 0.2252\n",
      "Epoch [2/10], Phase: train, Batch: [40/730], Loss: 0.2835\n",
      "Epoch [2/10], Phase: train, Batch: [41/730], Loss: 0.3565\n",
      "Epoch [2/10], Phase: train, Batch: [42/730], Loss: 0.3291\n",
      "Epoch [2/10], Phase: train, Batch: [43/730], Loss: 0.3438\n",
      "Epoch [2/10], Phase: train, Batch: [44/730], Loss: 0.2157\n",
      "Epoch [2/10], Phase: train, Batch: [45/730], Loss: 0.1922\n",
      "Epoch [2/10], Phase: train, Batch: [46/730], Loss: 0.2765\n",
      "Epoch [2/10], Phase: train, Batch: [47/730], Loss: 0.3075\n",
      "Epoch [2/10], Phase: train, Batch: [48/730], Loss: 0.2471\n",
      "Epoch [2/10], Phase: train, Batch: [49/730], Loss: 0.3468\n",
      "Epoch [2/10], Phase: train, Batch: [50/730], Loss: 0.2367\n",
      "Epoch [2/10], Phase: train, Batch: [51/730], Loss: 0.2220\n",
      "Epoch [2/10], Phase: train, Batch: [52/730], Loss: 0.3292\n",
      "Epoch [2/10], Phase: train, Batch: [53/730], Loss: 0.2454\n",
      "Epoch [2/10], Phase: train, Batch: [54/730], Loss: 0.2506\n",
      "Epoch [2/10], Phase: train, Batch: [55/730], Loss: 0.2647\n",
      "Epoch [2/10], Phase: train, Batch: [56/730], Loss: 0.3103\n",
      "Epoch [2/10], Phase: train, Batch: [57/730], Loss: 0.2649\n",
      "Epoch [2/10], Phase: train, Batch: [58/730], Loss: 0.3578\n",
      "Epoch [2/10], Phase: train, Batch: [59/730], Loss: 0.3854\n",
      "Epoch [2/10], Phase: train, Batch: [60/730], Loss: 0.2477\n",
      "Epoch [2/10], Phase: train, Batch: [61/730], Loss: 0.3609\n",
      "Epoch [2/10], Phase: train, Batch: [62/730], Loss: 0.3780\n",
      "Epoch [2/10], Phase: train, Batch: [63/730], Loss: 0.3027\n",
      "Epoch [2/10], Phase: train, Batch: [64/730], Loss: 0.3086\n",
      "Epoch [2/10], Phase: train, Batch: [65/730], Loss: 0.2916\n",
      "Epoch [2/10], Phase: train, Batch: [66/730], Loss: 0.6282\n",
      "Epoch [2/10], Phase: train, Batch: [67/730], Loss: 0.1956\n",
      "Epoch [2/10], Phase: train, Batch: [68/730], Loss: 0.2216\n",
      "Epoch [2/10], Phase: train, Batch: [69/730], Loss: 0.2833\n",
      "Epoch [2/10], Phase: train, Batch: [70/730], Loss: 0.3331\n",
      "Epoch [2/10], Phase: train, Batch: [71/730], Loss: 0.2335\n",
      "Epoch [2/10], Phase: train, Batch: [72/730], Loss: 0.2528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [73/730], Loss: 0.3303\n",
      "Epoch [2/10], Phase: train, Batch: [74/730], Loss: 0.2035\n",
      "Epoch [2/10], Phase: train, Batch: [75/730], Loss: 0.4771\n",
      "Epoch [2/10], Phase: train, Batch: [76/730], Loss: 0.2352\n",
      "Epoch [2/10], Phase: train, Batch: [77/730], Loss: 0.2178\n",
      "Epoch [2/10], Phase: train, Batch: [78/730], Loss: 0.1695\n",
      "Epoch [2/10], Phase: train, Batch: [79/730], Loss: 0.2125\n",
      "Epoch [2/10], Phase: train, Batch: [80/730], Loss: 0.2611\n",
      "Epoch [2/10], Phase: train, Batch: [81/730], Loss: 0.3452\n",
      "Epoch [2/10], Phase: train, Batch: [82/730], Loss: 0.3498\n",
      "Epoch [2/10], Phase: train, Batch: [83/730], Loss: 0.3810\n",
      "Epoch [2/10], Phase: train, Batch: [84/730], Loss: 0.3352\n",
      "Epoch [2/10], Phase: train, Batch: [85/730], Loss: 0.3044\n",
      "Epoch [2/10], Phase: train, Batch: [86/730], Loss: 0.2939\n",
      "Epoch [2/10], Phase: train, Batch: [87/730], Loss: 0.2888\n",
      "Epoch [2/10], Phase: train, Batch: [88/730], Loss: 0.4062\n",
      "Epoch [2/10], Phase: train, Batch: [89/730], Loss: 0.3132\n",
      "Epoch [2/10], Phase: train, Batch: [90/730], Loss: 0.3271\n",
      "Epoch [2/10], Phase: train, Batch: [91/730], Loss: 0.3110\n",
      "Epoch [2/10], Phase: train, Batch: [92/730], Loss: 0.3678\n",
      "Epoch [2/10], Phase: train, Batch: [93/730], Loss: 0.3023\n",
      "Epoch [2/10], Phase: train, Batch: [94/730], Loss: 0.3130\n",
      "Epoch [2/10], Phase: train, Batch: [95/730], Loss: 0.2697\n",
      "Epoch [2/10], Phase: train, Batch: [96/730], Loss: 0.2304\n",
      "Epoch [2/10], Phase: train, Batch: [97/730], Loss: 0.3146\n",
      "Epoch [2/10], Phase: train, Batch: [98/730], Loss: 0.2473\n",
      "Epoch [2/10], Phase: train, Batch: [99/730], Loss: 0.3312\n",
      "Epoch [2/10], Phase: train, Batch: [100/730], Loss: 0.3403\n",
      "Epoch [2/10], Phase: train, Batch: [101/730], Loss: 0.2366\n",
      "Epoch [2/10], Phase: train, Batch: [102/730], Loss: 0.3216\n",
      "Epoch [2/10], Phase: train, Batch: [103/730], Loss: 0.3422\n",
      "Epoch [2/10], Phase: train, Batch: [104/730], Loss: 0.2920\n",
      "Epoch [2/10], Phase: train, Batch: [105/730], Loss: 0.2555\n",
      "Epoch [2/10], Phase: train, Batch: [106/730], Loss: 0.2465\n",
      "Epoch [2/10], Phase: train, Batch: [107/730], Loss: 0.2646\n",
      "Epoch [2/10], Phase: train, Batch: [108/730], Loss: 0.3193\n",
      "Epoch [2/10], Phase: train, Batch: [109/730], Loss: 0.3372\n",
      "Epoch [2/10], Phase: train, Batch: [110/730], Loss: 0.2950\n",
      "Epoch [2/10], Phase: train, Batch: [111/730], Loss: 0.2876\n",
      "Epoch [2/10], Phase: train, Batch: [112/730], Loss: 0.3394\n",
      "Epoch [2/10], Phase: train, Batch: [113/730], Loss: 0.3305\n",
      "Epoch [2/10], Phase: train, Batch: [114/730], Loss: 0.2314\n",
      "Epoch [2/10], Phase: train, Batch: [115/730], Loss: 0.2809\n",
      "Epoch [2/10], Phase: train, Batch: [116/730], Loss: 0.1917\n",
      "Epoch [2/10], Phase: train, Batch: [117/730], Loss: 0.3573\n",
      "Epoch [2/10], Phase: train, Batch: [118/730], Loss: 0.2498\n",
      "Epoch [2/10], Phase: train, Batch: [119/730], Loss: 0.3015\n",
      "Epoch [2/10], Phase: train, Batch: [120/730], Loss: 0.2691\n",
      "Epoch [2/10], Phase: train, Batch: [121/730], Loss: 0.2616\n",
      "Epoch [2/10], Phase: train, Batch: [122/730], Loss: 0.2494\n",
      "Epoch [2/10], Phase: train, Batch: [123/730], Loss: 0.2000\n",
      "Epoch [2/10], Phase: train, Batch: [124/730], Loss: 0.2252\n",
      "Epoch [2/10], Phase: train, Batch: [125/730], Loss: 0.2820\n",
      "Epoch [2/10], Phase: train, Batch: [126/730], Loss: 0.4232\n",
      "Epoch [2/10], Phase: train, Batch: [127/730], Loss: 0.2891\n",
      "Epoch [2/10], Phase: train, Batch: [128/730], Loss: 0.2262\n",
      "Epoch [2/10], Phase: train, Batch: [129/730], Loss: 0.4049\n",
      "Epoch [2/10], Phase: train, Batch: [130/730], Loss: 0.2970\n",
      "Epoch [2/10], Phase: train, Batch: [131/730], Loss: 0.2624\n",
      "Epoch [2/10], Phase: train, Batch: [132/730], Loss: 0.1390\n",
      "Epoch [2/10], Phase: train, Batch: [133/730], Loss: 0.1325\n",
      "Epoch [2/10], Phase: train, Batch: [134/730], Loss: 0.3843\n",
      "Epoch [2/10], Phase: train, Batch: [135/730], Loss: 0.3985\n",
      "Epoch [2/10], Phase: train, Batch: [136/730], Loss: 0.2840\n",
      "Epoch [2/10], Phase: train, Batch: [137/730], Loss: 0.2646\n",
      "Epoch [2/10], Phase: train, Batch: [138/730], Loss: 0.1544\n",
      "Epoch [2/10], Phase: train, Batch: [139/730], Loss: 0.2561\n",
      "Epoch [2/10], Phase: train, Batch: [140/730], Loss: 0.2957\n",
      "Epoch [2/10], Phase: train, Batch: [141/730], Loss: 0.3962\n",
      "Epoch [2/10], Phase: train, Batch: [142/730], Loss: 0.4067\n",
      "Epoch [2/10], Phase: train, Batch: [143/730], Loss: 0.2816\n",
      "Epoch [2/10], Phase: train, Batch: [144/730], Loss: 0.4119\n",
      "Epoch [2/10], Phase: train, Batch: [145/730], Loss: 0.2633\n",
      "Epoch [2/10], Phase: train, Batch: [146/730], Loss: 0.2744\n",
      "Epoch [2/10], Phase: train, Batch: [147/730], Loss: 0.2181\n",
      "Epoch [2/10], Phase: train, Batch: [148/730], Loss: 0.3022\n",
      "Epoch [2/10], Phase: train, Batch: [149/730], Loss: 0.2972\n",
      "Epoch [2/10], Phase: train, Batch: [150/730], Loss: 0.2245\n",
      "Epoch [2/10], Phase: train, Batch: [151/730], Loss: 0.3486\n",
      "Epoch [2/10], Phase: train, Batch: [152/730], Loss: 0.2647\n",
      "Epoch [2/10], Phase: train, Batch: [153/730], Loss: 0.2366\n",
      "Epoch [2/10], Phase: train, Batch: [154/730], Loss: 0.2167\n",
      "Epoch [2/10], Phase: train, Batch: [155/730], Loss: 0.2167\n",
      "Epoch [2/10], Phase: train, Batch: [156/730], Loss: 0.2637\n",
      "Epoch [2/10], Phase: train, Batch: [157/730], Loss: 0.4394\n",
      "Epoch [2/10], Phase: train, Batch: [158/730], Loss: 0.3286\n",
      "Epoch [2/10], Phase: train, Batch: [159/730], Loss: 0.3460\n",
      "Epoch [2/10], Phase: train, Batch: [160/730], Loss: 0.3398\n",
      "Epoch [2/10], Phase: train, Batch: [161/730], Loss: 0.2348\n",
      "Epoch [2/10], Phase: train, Batch: [162/730], Loss: 0.2489\n",
      "Epoch [2/10], Phase: train, Batch: [163/730], Loss: 0.2262\n",
      "Epoch [2/10], Phase: train, Batch: [164/730], Loss: 0.3161\n",
      "Epoch [2/10], Phase: train, Batch: [165/730], Loss: 0.2481\n",
      "Epoch [2/10], Phase: train, Batch: [166/730], Loss: 0.3392\n",
      "Epoch [2/10], Phase: train, Batch: [167/730], Loss: 0.3316\n",
      "Epoch [2/10], Phase: train, Batch: [168/730], Loss: 0.2899\n",
      "Epoch [2/10], Phase: train, Batch: [169/730], Loss: 0.2005\n",
      "Epoch [2/10], Phase: train, Batch: [170/730], Loss: 0.2457\n",
      "Epoch [2/10], Phase: train, Batch: [171/730], Loss: 0.3120\n",
      "Epoch [2/10], Phase: train, Batch: [172/730], Loss: 0.2031\n",
      "Epoch [2/10], Phase: train, Batch: [173/730], Loss: 0.2457\n",
      "Epoch [2/10], Phase: train, Batch: [174/730], Loss: 0.2824\n",
      "Epoch [2/10], Phase: train, Batch: [175/730], Loss: 0.3893\n",
      "Epoch [2/10], Phase: train, Batch: [176/730], Loss: 0.2440\n",
      "Epoch [2/10], Phase: train, Batch: [177/730], Loss: 0.2303\n",
      "Epoch [2/10], Phase: train, Batch: [178/730], Loss: 0.1705\n",
      "Epoch [2/10], Phase: train, Batch: [179/730], Loss: 0.2592\n",
      "Epoch [2/10], Phase: train, Batch: [180/730], Loss: 0.2169\n",
      "Epoch [2/10], Phase: train, Batch: [181/730], Loss: 0.2867\n",
      "Epoch [2/10], Phase: train, Batch: [182/730], Loss: 0.2901\n",
      "Epoch [2/10], Phase: train, Batch: [183/730], Loss: 0.2761\n",
      "Epoch [2/10], Phase: train, Batch: [184/730], Loss: 0.2454\n",
      "Epoch [2/10], Phase: train, Batch: [185/730], Loss: 0.2901\n",
      "Epoch [2/10], Phase: train, Batch: [186/730], Loss: 0.2315\n",
      "Epoch [2/10], Phase: train, Batch: [187/730], Loss: 0.3396\n",
      "Epoch [2/10], Phase: train, Batch: [188/730], Loss: 0.5626\n",
      "Epoch [2/10], Phase: train, Batch: [189/730], Loss: 0.2002\n",
      "Epoch [2/10], Phase: train, Batch: [190/730], Loss: 0.2067\n",
      "Epoch [2/10], Phase: train, Batch: [191/730], Loss: 0.3141\n",
      "Epoch [2/10], Phase: train, Batch: [192/730], Loss: 0.1226\n",
      "Epoch [2/10], Phase: train, Batch: [193/730], Loss: 0.3146\n",
      "Epoch [2/10], Phase: train, Batch: [194/730], Loss: 0.2426\n",
      "Epoch [2/10], Phase: train, Batch: [195/730], Loss: 0.2517\n",
      "Epoch [2/10], Phase: train, Batch: [196/730], Loss: 0.3212\n",
      "Epoch [2/10], Phase: train, Batch: [197/730], Loss: 0.2375\n",
      "Epoch [2/10], Phase: train, Batch: [198/730], Loss: 0.3968\n",
      "Epoch [2/10], Phase: train, Batch: [199/730], Loss: 0.3569\n",
      "Epoch [2/10], Phase: train, Batch: [200/730], Loss: 0.2387\n",
      "Epoch [2/10], Phase: train, Batch: [201/730], Loss: 0.2174\n",
      "Epoch [2/10], Phase: train, Batch: [202/730], Loss: 0.2556\n",
      "Epoch [2/10], Phase: train, Batch: [203/730], Loss: 0.2063\n",
      "Epoch [2/10], Phase: train, Batch: [204/730], Loss: 0.2040\n",
      "Epoch [2/10], Phase: train, Batch: [205/730], Loss: 0.2486\n",
      "Epoch [2/10], Phase: train, Batch: [206/730], Loss: 0.1977\n",
      "Epoch [2/10], Phase: train, Batch: [207/730], Loss: 0.2006\n",
      "Epoch [2/10], Phase: train, Batch: [208/730], Loss: 0.4201\n",
      "Epoch [2/10], Phase: train, Batch: [209/730], Loss: 0.2726\n",
      "Epoch [2/10], Phase: train, Batch: [210/730], Loss: 0.2197\n",
      "Epoch [2/10], Phase: train, Batch: [211/730], Loss: 0.4312\n",
      "Epoch [2/10], Phase: train, Batch: [212/730], Loss: 0.3414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [213/730], Loss: 0.3936\n",
      "Epoch [2/10], Phase: train, Batch: [214/730], Loss: 0.2253\n",
      "Epoch [2/10], Phase: train, Batch: [215/730], Loss: 0.3252\n",
      "Epoch [2/10], Phase: train, Batch: [216/730], Loss: 0.2047\n",
      "Epoch [2/10], Phase: train, Batch: [217/730], Loss: 0.3219\n",
      "Epoch [2/10], Phase: train, Batch: [218/730], Loss: 0.2601\n",
      "Epoch [2/10], Phase: train, Batch: [219/730], Loss: 0.2114\n",
      "Epoch [2/10], Phase: train, Batch: [220/730], Loss: 0.3591\n",
      "Epoch [2/10], Phase: train, Batch: [221/730], Loss: 0.4455\n",
      "Epoch [2/10], Phase: train, Batch: [222/730], Loss: 0.2127\n",
      "Epoch [2/10], Phase: train, Batch: [223/730], Loss: 0.3918\n",
      "Epoch [2/10], Phase: train, Batch: [224/730], Loss: 0.2300\n",
      "Epoch [2/10], Phase: train, Batch: [225/730], Loss: 0.1775\n",
      "Epoch [2/10], Phase: train, Batch: [226/730], Loss: 0.2597\n",
      "Epoch [2/10], Phase: train, Batch: [227/730], Loss: 0.3903\n",
      "Epoch [2/10], Phase: train, Batch: [228/730], Loss: 0.3718\n",
      "Epoch [2/10], Phase: train, Batch: [229/730], Loss: 0.3602\n",
      "Epoch [2/10], Phase: train, Batch: [230/730], Loss: 0.3609\n",
      "Epoch [2/10], Phase: train, Batch: [231/730], Loss: 0.4534\n",
      "Epoch [2/10], Phase: train, Batch: [232/730], Loss: 0.2151\n",
      "Epoch [2/10], Phase: train, Batch: [233/730], Loss: 0.2305\n",
      "Epoch [2/10], Phase: train, Batch: [234/730], Loss: 0.2423\n",
      "Epoch [2/10], Phase: train, Batch: [235/730], Loss: 0.1934\n",
      "Epoch [2/10], Phase: train, Batch: [236/730], Loss: 0.2586\n",
      "Epoch [2/10], Phase: train, Batch: [237/730], Loss: 0.3721\n",
      "Epoch [2/10], Phase: train, Batch: [238/730], Loss: 0.3398\n",
      "Epoch [2/10], Phase: train, Batch: [239/730], Loss: 0.2975\n",
      "Epoch [2/10], Phase: train, Batch: [240/730], Loss: 0.3355\n",
      "Epoch [2/10], Phase: train, Batch: [241/730], Loss: 0.3147\n",
      "Epoch [2/10], Phase: train, Batch: [242/730], Loss: 0.3005\n",
      "Epoch [2/10], Phase: train, Batch: [243/730], Loss: 0.2936\n",
      "Epoch [2/10], Phase: train, Batch: [244/730], Loss: 0.2860\n",
      "Epoch [2/10], Phase: train, Batch: [245/730], Loss: 0.4046\n",
      "Epoch [2/10], Phase: train, Batch: [246/730], Loss: 0.3230\n",
      "Epoch [2/10], Phase: train, Batch: [247/730], Loss: 0.3064\n",
      "Epoch [2/10], Phase: train, Batch: [248/730], Loss: 0.2524\n",
      "Epoch [2/10], Phase: train, Batch: [249/730], Loss: 0.4537\n",
      "Epoch [2/10], Phase: train, Batch: [250/730], Loss: 0.3113\n",
      "Epoch [2/10], Phase: train, Batch: [251/730], Loss: 0.2462\n",
      "Epoch [2/10], Phase: train, Batch: [252/730], Loss: 0.2066\n",
      "Epoch [2/10], Phase: train, Batch: [253/730], Loss: 0.3054\n",
      "Epoch [2/10], Phase: train, Batch: [254/730], Loss: 0.3264\n",
      "Epoch [2/10], Phase: train, Batch: [255/730], Loss: 0.3310\n",
      "Epoch [2/10], Phase: train, Batch: [256/730], Loss: 0.4167\n",
      "Epoch [2/10], Phase: train, Batch: [257/730], Loss: 0.2623\n",
      "Epoch [2/10], Phase: train, Batch: [258/730], Loss: 0.3081\n",
      "Epoch [2/10], Phase: train, Batch: [259/730], Loss: 0.2257\n",
      "Epoch [2/10], Phase: train, Batch: [260/730], Loss: 0.3508\n",
      "Epoch [2/10], Phase: train, Batch: [261/730], Loss: 0.2146\n",
      "Epoch [2/10], Phase: train, Batch: [262/730], Loss: 0.2747\n",
      "Epoch [2/10], Phase: train, Batch: [263/730], Loss: 0.2720\n",
      "Epoch [2/10], Phase: train, Batch: [264/730], Loss: 0.4924\n",
      "Epoch [2/10], Phase: train, Batch: [265/730], Loss: 0.3599\n",
      "Epoch [2/10], Phase: train, Batch: [266/730], Loss: 0.3590\n",
      "Epoch [2/10], Phase: train, Batch: [267/730], Loss: 0.2419\n",
      "Epoch [2/10], Phase: train, Batch: [268/730], Loss: 0.1797\n",
      "Epoch [2/10], Phase: train, Batch: [269/730], Loss: 0.2008\n",
      "Epoch [2/10], Phase: train, Batch: [270/730], Loss: 0.2892\n",
      "Epoch [2/10], Phase: train, Batch: [271/730], Loss: 0.2021\n",
      "Epoch [2/10], Phase: train, Batch: [272/730], Loss: 0.2850\n",
      "Epoch [2/10], Phase: train, Batch: [273/730], Loss: 0.3088\n",
      "Epoch [2/10], Phase: train, Batch: [274/730], Loss: 0.3450\n",
      "Epoch [2/10], Phase: train, Batch: [275/730], Loss: 0.1913\n",
      "Epoch [2/10], Phase: train, Batch: [276/730], Loss: 0.3004\n",
      "Epoch [2/10], Phase: train, Batch: [277/730], Loss: 0.2093\n",
      "Epoch [2/10], Phase: train, Batch: [278/730], Loss: 0.2841\n",
      "Epoch [2/10], Phase: train, Batch: [279/730], Loss: 0.1298\n",
      "Epoch [2/10], Phase: train, Batch: [280/730], Loss: 0.3174\n",
      "Epoch [2/10], Phase: train, Batch: [281/730], Loss: 0.3047\n",
      "Epoch [2/10], Phase: train, Batch: [282/730], Loss: 0.4356\n",
      "Epoch [2/10], Phase: train, Batch: [283/730], Loss: 0.2821\n",
      "Epoch [2/10], Phase: train, Batch: [284/730], Loss: 0.1836\n",
      "Epoch [2/10], Phase: train, Batch: [285/730], Loss: 0.3026\n",
      "Epoch [2/10], Phase: train, Batch: [286/730], Loss: 0.2297\n",
      "Epoch [2/10], Phase: train, Batch: [287/730], Loss: 0.4009\n",
      "Epoch [2/10], Phase: train, Batch: [288/730], Loss: 0.3943\n",
      "Epoch [2/10], Phase: train, Batch: [289/730], Loss: 0.2185\n",
      "Epoch [2/10], Phase: train, Batch: [290/730], Loss: 0.2537\n",
      "Epoch [2/10], Phase: train, Batch: [291/730], Loss: 0.2131\n",
      "Epoch [2/10], Phase: train, Batch: [292/730], Loss: 0.4000\n",
      "Epoch [2/10], Phase: train, Batch: [293/730], Loss: 0.2646\n",
      "Epoch [2/10], Phase: train, Batch: [294/730], Loss: 0.1691\n",
      "Epoch [2/10], Phase: train, Batch: [295/730], Loss: 0.2551\n",
      "Epoch [2/10], Phase: train, Batch: [296/730], Loss: 0.2992\n",
      "Epoch [2/10], Phase: train, Batch: [297/730], Loss: 0.3542\n",
      "Epoch [2/10], Phase: train, Batch: [298/730], Loss: 0.3403\n",
      "Epoch [2/10], Phase: train, Batch: [299/730], Loss: 0.2105\n",
      "Epoch [2/10], Phase: train, Batch: [300/730], Loss: 0.2660\n",
      "Epoch [2/10], Phase: train, Batch: [301/730], Loss: 0.2041\n",
      "Epoch [2/10], Phase: train, Batch: [302/730], Loss: 0.3251\n",
      "Epoch [2/10], Phase: train, Batch: [303/730], Loss: 0.2415\n",
      "Epoch [2/10], Phase: train, Batch: [304/730], Loss: 0.2018\n",
      "Epoch [2/10], Phase: train, Batch: [305/730], Loss: 0.2432\n",
      "Epoch [2/10], Phase: train, Batch: [306/730], Loss: 0.2080\n",
      "Epoch [2/10], Phase: train, Batch: [307/730], Loss: 0.2989\n",
      "Epoch [2/10], Phase: train, Batch: [308/730], Loss: 0.2396\n",
      "Epoch [2/10], Phase: train, Batch: [309/730], Loss: 0.2163\n",
      "Epoch [2/10], Phase: train, Batch: [310/730], Loss: 0.2632\n",
      "Epoch [2/10], Phase: train, Batch: [311/730], Loss: 0.2445\n",
      "Epoch [2/10], Phase: train, Batch: [312/730], Loss: 0.3957\n",
      "Epoch [2/10], Phase: train, Batch: [313/730], Loss: 0.3859\n",
      "Epoch [2/10], Phase: train, Batch: [314/730], Loss: 0.3983\n",
      "Epoch [2/10], Phase: train, Batch: [315/730], Loss: 0.2500\n",
      "Epoch [2/10], Phase: train, Batch: [316/730], Loss: 0.3436\n",
      "Epoch [2/10], Phase: train, Batch: [317/730], Loss: 0.2232\n",
      "Epoch [2/10], Phase: train, Batch: [318/730], Loss: 0.2392\n",
      "Epoch [2/10], Phase: train, Batch: [319/730], Loss: 0.1968\n",
      "Epoch [2/10], Phase: train, Batch: [320/730], Loss: 0.3049\n",
      "Epoch [2/10], Phase: train, Batch: [321/730], Loss: 0.3182\n",
      "Epoch [2/10], Phase: train, Batch: [322/730], Loss: 0.3032\n",
      "Epoch [2/10], Phase: train, Batch: [323/730], Loss: 0.2659\n",
      "Epoch [2/10], Phase: train, Batch: [324/730], Loss: 0.3359\n",
      "Epoch [2/10], Phase: train, Batch: [325/730], Loss: 0.3999\n",
      "Epoch [2/10], Phase: train, Batch: [326/730], Loss: 0.3929\n",
      "Epoch [2/10], Phase: train, Batch: [327/730], Loss: 0.1669\n",
      "Epoch [2/10], Phase: train, Batch: [328/730], Loss: 0.2880\n",
      "Epoch [2/10], Phase: train, Batch: [329/730], Loss: 0.2940\n",
      "Epoch [2/10], Phase: train, Batch: [330/730], Loss: 0.3232\n",
      "Epoch [2/10], Phase: train, Batch: [331/730], Loss: 0.3880\n",
      "Epoch [2/10], Phase: train, Batch: [332/730], Loss: 0.3574\n",
      "Epoch [2/10], Phase: train, Batch: [333/730], Loss: 0.3984\n",
      "Epoch [2/10], Phase: train, Batch: [334/730], Loss: 0.2677\n",
      "Epoch [2/10], Phase: train, Batch: [335/730], Loss: 0.3225\n",
      "Epoch [2/10], Phase: train, Batch: [336/730], Loss: 0.3278\n",
      "Epoch [2/10], Phase: train, Batch: [337/730], Loss: 0.2824\n",
      "Epoch [2/10], Phase: train, Batch: [338/730], Loss: 0.3678\n",
      "Epoch [2/10], Phase: train, Batch: [339/730], Loss: 0.2593\n",
      "Epoch [2/10], Phase: train, Batch: [340/730], Loss: 0.3323\n",
      "Epoch [2/10], Phase: train, Batch: [341/730], Loss: 0.2888\n",
      "Epoch [2/10], Phase: train, Batch: [342/730], Loss: 0.1860\n",
      "Epoch [2/10], Phase: train, Batch: [343/730], Loss: 0.2310\n",
      "Epoch [2/10], Phase: train, Batch: [344/730], Loss: 0.1805\n",
      "Epoch [2/10], Phase: train, Batch: [345/730], Loss: 0.3342\n",
      "Epoch [2/10], Phase: train, Batch: [346/730], Loss: 0.3017\n",
      "Epoch [2/10], Phase: train, Batch: [347/730], Loss: 0.2885\n",
      "Epoch [2/10], Phase: train, Batch: [348/730], Loss: 0.2616\n",
      "Epoch [2/10], Phase: train, Batch: [349/730], Loss: 0.3443\n",
      "Epoch [2/10], Phase: train, Batch: [350/730], Loss: 0.2685\n",
      "Epoch [2/10], Phase: train, Batch: [351/730], Loss: 0.3326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [352/730], Loss: 0.2940\n",
      "Epoch [2/10], Phase: train, Batch: [353/730], Loss: 0.3496\n",
      "Epoch [2/10], Phase: train, Batch: [354/730], Loss: 0.3710\n",
      "Epoch [2/10], Phase: train, Batch: [355/730], Loss: 0.2761\n",
      "Epoch [2/10], Phase: train, Batch: [356/730], Loss: 0.3418\n",
      "Epoch [2/10], Phase: train, Batch: [357/730], Loss: 0.3185\n",
      "Epoch [2/10], Phase: train, Batch: [358/730], Loss: 0.2890\n",
      "Epoch [2/10], Phase: train, Batch: [359/730], Loss: 0.3678\n",
      "Epoch [2/10], Phase: train, Batch: [360/730], Loss: 0.3365\n",
      "Epoch [2/10], Phase: train, Batch: [361/730], Loss: 0.4243\n",
      "Epoch [2/10], Phase: train, Batch: [362/730], Loss: 0.3436\n",
      "Epoch [2/10], Phase: train, Batch: [363/730], Loss: 0.2100\n",
      "Epoch [2/10], Phase: train, Batch: [364/730], Loss: 0.3321\n",
      "Epoch [2/10], Phase: train, Batch: [365/730], Loss: 0.2566\n",
      "Epoch [2/10], Phase: train, Batch: [366/730], Loss: 0.2906\n",
      "Epoch [2/10], Phase: train, Batch: [367/730], Loss: 0.3585\n",
      "Epoch [2/10], Phase: train, Batch: [368/730], Loss: 0.2894\n",
      "Epoch [2/10], Phase: train, Batch: [369/730], Loss: 0.1815\n",
      "Epoch [2/10], Phase: train, Batch: [370/730], Loss: 0.1934\n",
      "Epoch [2/10], Phase: train, Batch: [371/730], Loss: 0.2734\n",
      "Epoch [2/10], Phase: train, Batch: [372/730], Loss: 0.4747\n",
      "Epoch [2/10], Phase: train, Batch: [373/730], Loss: 0.3229\n",
      "Epoch [2/10], Phase: train, Batch: [374/730], Loss: 0.3589\n",
      "Epoch [2/10], Phase: train, Batch: [375/730], Loss: 0.4705\n",
      "Epoch [2/10], Phase: train, Batch: [376/730], Loss: 0.2841\n",
      "Epoch [2/10], Phase: train, Batch: [377/730], Loss: 0.2473\n",
      "Epoch [2/10], Phase: train, Batch: [378/730], Loss: 0.2861\n",
      "Epoch [2/10], Phase: train, Batch: [379/730], Loss: 0.2118\n",
      "Epoch [2/10], Phase: train, Batch: [380/730], Loss: 0.1918\n",
      "Epoch [2/10], Phase: train, Batch: [381/730], Loss: 0.2481\n",
      "Epoch [2/10], Phase: train, Batch: [382/730], Loss: 0.3128\n",
      "Epoch [2/10], Phase: train, Batch: [383/730], Loss: 0.2776\n",
      "Epoch [2/10], Phase: train, Batch: [384/730], Loss: 0.2797\n",
      "Epoch [2/10], Phase: train, Batch: [385/730], Loss: 0.1993\n",
      "Epoch [2/10], Phase: train, Batch: [386/730], Loss: 0.2382\n",
      "Epoch [2/10], Phase: train, Batch: [387/730], Loss: 0.2527\n",
      "Epoch [2/10], Phase: train, Batch: [388/730], Loss: 0.2776\n",
      "Epoch [2/10], Phase: train, Batch: [389/730], Loss: 0.2449\n",
      "Epoch [2/10], Phase: train, Batch: [390/730], Loss: 0.1900\n",
      "Epoch [2/10], Phase: train, Batch: [391/730], Loss: 0.3104\n",
      "Epoch [2/10], Phase: train, Batch: [392/730], Loss: 0.2727\n",
      "Epoch [2/10], Phase: train, Batch: [393/730], Loss: 0.2873\n",
      "Epoch [2/10], Phase: train, Batch: [394/730], Loss: 0.2355\n",
      "Epoch [2/10], Phase: train, Batch: [395/730], Loss: 0.3164\n",
      "Epoch [2/10], Phase: train, Batch: [396/730], Loss: 0.3281\n",
      "Epoch [2/10], Phase: train, Batch: [397/730], Loss: 0.3694\n",
      "Epoch [2/10], Phase: train, Batch: [398/730], Loss: 0.2878\n",
      "Epoch [2/10], Phase: train, Batch: [399/730], Loss: 0.1538\n",
      "Epoch [2/10], Phase: train, Batch: [400/730], Loss: 0.2147\n",
      "Epoch [2/10], Phase: train, Batch: [401/730], Loss: 0.2047\n",
      "Epoch [2/10], Phase: train, Batch: [402/730], Loss: 0.3610\n",
      "Epoch [2/10], Phase: train, Batch: [403/730], Loss: 0.4418\n",
      "Epoch [2/10], Phase: train, Batch: [404/730], Loss: 0.2459\n",
      "Epoch [2/10], Phase: train, Batch: [405/730], Loss: 0.2599\n",
      "Epoch [2/10], Phase: train, Batch: [406/730], Loss: 0.3589\n",
      "Epoch [2/10], Phase: train, Batch: [407/730], Loss: 0.3099\n",
      "Epoch [2/10], Phase: train, Batch: [408/730], Loss: 0.3593\n",
      "Epoch [2/10], Phase: train, Batch: [409/730], Loss: 0.1776\n",
      "Epoch [2/10], Phase: train, Batch: [410/730], Loss: 0.3097\n",
      "Epoch [2/10], Phase: train, Batch: [411/730], Loss: 0.4013\n",
      "Epoch [2/10], Phase: train, Batch: [412/730], Loss: 0.2786\n",
      "Epoch [2/10], Phase: train, Batch: [413/730], Loss: 0.1454\n",
      "Epoch [2/10], Phase: train, Batch: [414/730], Loss: 0.2534\n",
      "Epoch [2/10], Phase: train, Batch: [415/730], Loss: 0.3787\n",
      "Epoch [2/10], Phase: train, Batch: [416/730], Loss: 0.2464\n",
      "Epoch [2/10], Phase: train, Batch: [417/730], Loss: 0.4289\n",
      "Epoch [2/10], Phase: train, Batch: [418/730], Loss: 0.3188\n",
      "Epoch [2/10], Phase: train, Batch: [419/730], Loss: 0.3285\n",
      "Epoch [2/10], Phase: train, Batch: [420/730], Loss: 0.3413\n",
      "Epoch [2/10], Phase: train, Batch: [421/730], Loss: 0.2494\n",
      "Epoch [2/10], Phase: train, Batch: [422/730], Loss: 0.4051\n",
      "Epoch [2/10], Phase: train, Batch: [423/730], Loss: 0.3236\n",
      "Epoch [2/10], Phase: train, Batch: [424/730], Loss: 0.4940\n",
      "Epoch [2/10], Phase: train, Batch: [425/730], Loss: 0.2709\n",
      "Epoch [2/10], Phase: train, Batch: [426/730], Loss: 0.3031\n",
      "Epoch [2/10], Phase: train, Batch: [427/730], Loss: 0.3323\n",
      "Epoch [2/10], Phase: train, Batch: [428/730], Loss: 0.3635\n",
      "Epoch [2/10], Phase: train, Batch: [429/730], Loss: 0.3750\n",
      "Epoch [2/10], Phase: train, Batch: [430/730], Loss: 0.2779\n",
      "Epoch [2/10], Phase: train, Batch: [431/730], Loss: 0.2728\n",
      "Epoch [2/10], Phase: train, Batch: [432/730], Loss: 0.3512\n",
      "Epoch [2/10], Phase: train, Batch: [433/730], Loss: 0.2583\n",
      "Epoch [2/10], Phase: train, Batch: [434/730], Loss: 0.2554\n",
      "Epoch [2/10], Phase: train, Batch: [435/730], Loss: 0.2778\n",
      "Epoch [2/10], Phase: train, Batch: [436/730], Loss: 0.2280\n",
      "Epoch [2/10], Phase: train, Batch: [437/730], Loss: 0.2196\n",
      "Epoch [2/10], Phase: train, Batch: [438/730], Loss: 0.2746\n",
      "Epoch [2/10], Phase: train, Batch: [439/730], Loss: 0.3462\n",
      "Epoch [2/10], Phase: train, Batch: [440/730], Loss: 0.2374\n",
      "Epoch [2/10], Phase: train, Batch: [441/730], Loss: 0.3537\n",
      "Epoch [2/10], Phase: train, Batch: [442/730], Loss: 0.2496\n",
      "Epoch [2/10], Phase: train, Batch: [443/730], Loss: 0.3038\n",
      "Epoch [2/10], Phase: train, Batch: [444/730], Loss: 0.2384\n",
      "Epoch [2/10], Phase: train, Batch: [445/730], Loss: 0.4636\n",
      "Epoch [2/10], Phase: train, Batch: [446/730], Loss: 0.2647\n",
      "Epoch [2/10], Phase: train, Batch: [447/730], Loss: 0.4091\n",
      "Epoch [2/10], Phase: train, Batch: [448/730], Loss: 0.2288\n",
      "Epoch [2/10], Phase: train, Batch: [449/730], Loss: 0.2771\n",
      "Epoch [2/10], Phase: train, Batch: [450/730], Loss: 0.3486\n",
      "Epoch [2/10], Phase: train, Batch: [451/730], Loss: 0.2166\n",
      "Epoch [2/10], Phase: train, Batch: [452/730], Loss: 0.4026\n",
      "Epoch [2/10], Phase: train, Batch: [453/730], Loss: 0.3042\n",
      "Epoch [2/10], Phase: train, Batch: [454/730], Loss: 0.2271\n",
      "Epoch [2/10], Phase: train, Batch: [455/730], Loss: 0.2032\n",
      "Epoch [2/10], Phase: train, Batch: [456/730], Loss: 0.2618\n",
      "Epoch [2/10], Phase: train, Batch: [457/730], Loss: 0.2874\n",
      "Epoch [2/10], Phase: train, Batch: [458/730], Loss: 0.3123\n",
      "Epoch [2/10], Phase: train, Batch: [459/730], Loss: 0.2461\n",
      "Epoch [2/10], Phase: train, Batch: [460/730], Loss: 0.2277\n",
      "Epoch [2/10], Phase: train, Batch: [461/730], Loss: 0.2523\n",
      "Epoch [2/10], Phase: train, Batch: [462/730], Loss: 0.2850\n",
      "Epoch [2/10], Phase: train, Batch: [463/730], Loss: 0.3814\n",
      "Epoch [2/10], Phase: train, Batch: [464/730], Loss: 0.3456\n",
      "Epoch [2/10], Phase: train, Batch: [465/730], Loss: 0.2820\n",
      "Epoch [2/10], Phase: train, Batch: [466/730], Loss: 0.2877\n",
      "Epoch [2/10], Phase: train, Batch: [467/730], Loss: 0.2703\n",
      "Epoch [2/10], Phase: train, Batch: [468/730], Loss: 0.2228\n",
      "Epoch [2/10], Phase: train, Batch: [469/730], Loss: 0.1997\n",
      "Epoch [2/10], Phase: train, Batch: [470/730], Loss: 0.3207\n",
      "Epoch [2/10], Phase: train, Batch: [471/730], Loss: 0.4419\n",
      "Epoch [2/10], Phase: train, Batch: [472/730], Loss: 0.4008\n",
      "Epoch [2/10], Phase: train, Batch: [473/730], Loss: 0.2555\n",
      "Epoch [2/10], Phase: train, Batch: [474/730], Loss: 0.1872\n",
      "Epoch [2/10], Phase: train, Batch: [475/730], Loss: 0.3492\n",
      "Epoch [2/10], Phase: train, Batch: [476/730], Loss: 0.4093\n",
      "Epoch [2/10], Phase: train, Batch: [477/730], Loss: 0.3756\n",
      "Epoch [2/10], Phase: train, Batch: [478/730], Loss: 0.3458\n",
      "Epoch [2/10], Phase: train, Batch: [479/730], Loss: 0.2313\n",
      "Epoch [2/10], Phase: train, Batch: [480/730], Loss: 0.2125\n",
      "Epoch [2/10], Phase: train, Batch: [481/730], Loss: 0.3068\n",
      "Epoch [2/10], Phase: train, Batch: [482/730], Loss: 0.3031\n",
      "Epoch [2/10], Phase: train, Batch: [483/730], Loss: 0.2615\n",
      "Epoch [2/10], Phase: train, Batch: [484/730], Loss: 0.4862\n",
      "Epoch [2/10], Phase: train, Batch: [485/730], Loss: 0.3452\n",
      "Epoch [2/10], Phase: train, Batch: [486/730], Loss: 0.3857\n",
      "Epoch [2/10], Phase: train, Batch: [487/730], Loss: 0.3738\n",
      "Epoch [2/10], Phase: train, Batch: [488/730], Loss: 0.2517\n",
      "Epoch [2/10], Phase: train, Batch: [489/730], Loss: 0.4875\n",
      "Epoch [2/10], Phase: train, Batch: [490/730], Loss: 0.2746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [491/730], Loss: 0.2852\n",
      "Epoch [2/10], Phase: train, Batch: [492/730], Loss: 0.3350\n",
      "Epoch [2/10], Phase: train, Batch: [493/730], Loss: 0.2964\n",
      "Epoch [2/10], Phase: train, Batch: [494/730], Loss: 0.4191\n",
      "Epoch [2/10], Phase: train, Batch: [495/730], Loss: 0.2316\n",
      "Epoch [2/10], Phase: train, Batch: [496/730], Loss: 0.3250\n",
      "Epoch [2/10], Phase: train, Batch: [497/730], Loss: 0.3995\n",
      "Epoch [2/10], Phase: train, Batch: [498/730], Loss: 0.1948\n",
      "Epoch [2/10], Phase: train, Batch: [499/730], Loss: 0.3476\n",
      "Epoch [2/10], Phase: train, Batch: [500/730], Loss: 0.2959\n",
      "Epoch [2/10], Phase: train, Batch: [501/730], Loss: 0.4412\n",
      "Epoch [2/10], Phase: train, Batch: [502/730], Loss: 0.2831\n",
      "Epoch [2/10], Phase: train, Batch: [503/730], Loss: 0.2724\n",
      "Epoch [2/10], Phase: train, Batch: [504/730], Loss: 0.2211\n",
      "Epoch [2/10], Phase: train, Batch: [505/730], Loss: 0.2000\n",
      "Epoch [2/10], Phase: train, Batch: [506/730], Loss: 0.3793\n",
      "Epoch [2/10], Phase: train, Batch: [507/730], Loss: 0.2290\n",
      "Epoch [2/10], Phase: train, Batch: [508/730], Loss: 0.3318\n",
      "Epoch [2/10], Phase: train, Batch: [509/730], Loss: 0.2486\n",
      "Epoch [2/10], Phase: train, Batch: [510/730], Loss: 0.2697\n",
      "Epoch [2/10], Phase: train, Batch: [511/730], Loss: 0.3312\n",
      "Epoch [2/10], Phase: train, Batch: [512/730], Loss: 0.2777\n",
      "Epoch [2/10], Phase: train, Batch: [513/730], Loss: 0.1756\n",
      "Epoch [2/10], Phase: train, Batch: [514/730], Loss: 0.2841\n",
      "Epoch [2/10], Phase: train, Batch: [515/730], Loss: 0.2202\n",
      "Epoch [2/10], Phase: train, Batch: [516/730], Loss: 0.3594\n",
      "Epoch [2/10], Phase: train, Batch: [517/730], Loss: 0.2381\n",
      "Epoch [2/10], Phase: train, Batch: [518/730], Loss: 0.3113\n",
      "Epoch [2/10], Phase: train, Batch: [519/730], Loss: 0.3619\n",
      "Epoch [2/10], Phase: train, Batch: [520/730], Loss: 0.4399\n",
      "Epoch [2/10], Phase: train, Batch: [521/730], Loss: 0.3964\n",
      "Epoch [2/10], Phase: train, Batch: [522/730], Loss: 0.4228\n",
      "Epoch [2/10], Phase: train, Batch: [523/730], Loss: 0.2519\n",
      "Epoch [2/10], Phase: train, Batch: [524/730], Loss: 0.2039\n",
      "Epoch [2/10], Phase: train, Batch: [525/730], Loss: 0.3728\n",
      "Epoch [2/10], Phase: train, Batch: [526/730], Loss: 0.3838\n",
      "Epoch [2/10], Phase: train, Batch: [527/730], Loss: 0.3191\n",
      "Epoch [2/10], Phase: train, Batch: [528/730], Loss: 0.2666\n",
      "Epoch [2/10], Phase: train, Batch: [529/730], Loss: 0.3263\n",
      "Epoch [2/10], Phase: train, Batch: [530/730], Loss: 0.3910\n",
      "Epoch [2/10], Phase: train, Batch: [531/730], Loss: 0.3897\n",
      "Epoch [2/10], Phase: train, Batch: [532/730], Loss: 0.4473\n",
      "Epoch [2/10], Phase: train, Batch: [533/730], Loss: 0.2969\n",
      "Epoch [2/10], Phase: train, Batch: [534/730], Loss: 0.3670\n",
      "Epoch [2/10], Phase: train, Batch: [535/730], Loss: 0.2767\n",
      "Epoch [2/10], Phase: train, Batch: [536/730], Loss: 0.3115\n",
      "Epoch [2/10], Phase: train, Batch: [537/730], Loss: 0.4102\n",
      "Epoch [2/10], Phase: train, Batch: [538/730], Loss: 0.2657\n",
      "Epoch [2/10], Phase: train, Batch: [539/730], Loss: 0.3038\n",
      "Epoch [2/10], Phase: train, Batch: [540/730], Loss: 0.2877\n",
      "Epoch [2/10], Phase: train, Batch: [541/730], Loss: 0.3622\n",
      "Epoch [2/10], Phase: train, Batch: [542/730], Loss: 0.3404\n",
      "Epoch [2/10], Phase: train, Batch: [543/730], Loss: 0.2573\n",
      "Epoch [2/10], Phase: train, Batch: [544/730], Loss: 0.3181\n",
      "Epoch [2/10], Phase: train, Batch: [545/730], Loss: 0.2845\n",
      "Epoch [2/10], Phase: train, Batch: [546/730], Loss: 0.2931\n",
      "Epoch [2/10], Phase: train, Batch: [547/730], Loss: 0.2399\n",
      "Epoch [2/10], Phase: train, Batch: [548/730], Loss: 0.2545\n",
      "Epoch [2/10], Phase: train, Batch: [549/730], Loss: 0.2148\n",
      "Epoch [2/10], Phase: train, Batch: [550/730], Loss: 0.3468\n",
      "Epoch [2/10], Phase: train, Batch: [551/730], Loss: 0.3161\n",
      "Epoch [2/10], Phase: train, Batch: [552/730], Loss: 0.2335\n",
      "Epoch [2/10], Phase: train, Batch: [553/730], Loss: 0.3501\n",
      "Epoch [2/10], Phase: train, Batch: [554/730], Loss: 0.2068\n",
      "Epoch [2/10], Phase: train, Batch: [555/730], Loss: 0.4239\n",
      "Epoch [2/10], Phase: train, Batch: [556/730], Loss: 0.3681\n",
      "Epoch [2/10], Phase: train, Batch: [557/730], Loss: 0.1616\n",
      "Epoch [2/10], Phase: train, Batch: [558/730], Loss: 0.2681\n",
      "Epoch [2/10], Phase: train, Batch: [559/730], Loss: 0.2722\n",
      "Epoch [2/10], Phase: train, Batch: [560/730], Loss: 0.2838\n",
      "Epoch [2/10], Phase: train, Batch: [561/730], Loss: 0.2410\n",
      "Epoch [2/10], Phase: train, Batch: [562/730], Loss: 0.2163\n",
      "Epoch [2/10], Phase: train, Batch: [563/730], Loss: 0.3045\n",
      "Epoch [2/10], Phase: train, Batch: [564/730], Loss: 0.3872\n",
      "Epoch [2/10], Phase: train, Batch: [565/730], Loss: 0.1983\n",
      "Epoch [2/10], Phase: train, Batch: [566/730], Loss: 0.2771\n",
      "Epoch [2/10], Phase: train, Batch: [567/730], Loss: 0.2595\n",
      "Epoch [2/10], Phase: train, Batch: [568/730], Loss: 0.3533\n",
      "Epoch [2/10], Phase: train, Batch: [569/730], Loss: 0.3295\n",
      "Epoch [2/10], Phase: train, Batch: [570/730], Loss: 0.3806\n",
      "Epoch [2/10], Phase: train, Batch: [571/730], Loss: 0.3517\n",
      "Epoch [2/10], Phase: train, Batch: [572/730], Loss: 0.1190\n",
      "Epoch [2/10], Phase: train, Batch: [573/730], Loss: 0.3463\n",
      "Epoch [2/10], Phase: train, Batch: [574/730], Loss: 0.3267\n",
      "Epoch [2/10], Phase: train, Batch: [575/730], Loss: 0.3026\n",
      "Epoch [2/10], Phase: train, Batch: [576/730], Loss: 0.3621\n",
      "Epoch [2/10], Phase: train, Batch: [577/730], Loss: 0.1931\n",
      "Epoch [2/10], Phase: train, Batch: [578/730], Loss: 0.2202\n",
      "Epoch [2/10], Phase: train, Batch: [579/730], Loss: 0.3722\n",
      "Epoch [2/10], Phase: train, Batch: [580/730], Loss: 0.2496\n",
      "Epoch [2/10], Phase: train, Batch: [581/730], Loss: 0.2877\n",
      "Epoch [2/10], Phase: train, Batch: [582/730], Loss: 0.2196\n",
      "Epoch [2/10], Phase: train, Batch: [583/730], Loss: 0.2700\n",
      "Epoch [2/10], Phase: train, Batch: [584/730], Loss: 0.2278\n",
      "Epoch [2/10], Phase: train, Batch: [585/730], Loss: 0.3609\n",
      "Epoch [2/10], Phase: train, Batch: [586/730], Loss: 0.3427\n",
      "Epoch [2/10], Phase: train, Batch: [587/730], Loss: 0.2950\n",
      "Epoch [2/10], Phase: train, Batch: [588/730], Loss: 0.2043\n",
      "Epoch [2/10], Phase: train, Batch: [589/730], Loss: 0.2951\n",
      "Epoch [2/10], Phase: train, Batch: [590/730], Loss: 0.3291\n",
      "Epoch [2/10], Phase: train, Batch: [591/730], Loss: 0.3291\n",
      "Epoch [2/10], Phase: train, Batch: [592/730], Loss: 0.3585\n",
      "Epoch [2/10], Phase: train, Batch: [593/730], Loss: 0.2206\n",
      "Epoch [2/10], Phase: train, Batch: [594/730], Loss: 0.3397\n",
      "Epoch [2/10], Phase: train, Batch: [595/730], Loss: 0.3092\n",
      "Epoch [2/10], Phase: train, Batch: [596/730], Loss: 0.1897\n",
      "Epoch [2/10], Phase: train, Batch: [597/730], Loss: 0.4156\n",
      "Epoch [2/10], Phase: train, Batch: [598/730], Loss: 0.2784\n",
      "Epoch [2/10], Phase: train, Batch: [599/730], Loss: 0.2252\n",
      "Epoch [2/10], Phase: train, Batch: [600/730], Loss: 0.2273\n",
      "Epoch [2/10], Phase: train, Batch: [601/730], Loss: 0.2578\n",
      "Epoch [2/10], Phase: train, Batch: [602/730], Loss: 0.1837\n",
      "Epoch [2/10], Phase: train, Batch: [603/730], Loss: 0.4020\n",
      "Epoch [2/10], Phase: train, Batch: [604/730], Loss: 0.1790\n",
      "Epoch [2/10], Phase: train, Batch: [605/730], Loss: 0.1857\n",
      "Epoch [2/10], Phase: train, Batch: [606/730], Loss: 0.1997\n",
      "Epoch [2/10], Phase: train, Batch: [607/730], Loss: 0.2225\n",
      "Epoch [2/10], Phase: train, Batch: [608/730], Loss: 0.3190\n",
      "Epoch [2/10], Phase: train, Batch: [609/730], Loss: 0.4372\n",
      "Epoch [2/10], Phase: train, Batch: [610/730], Loss: 0.2044\n",
      "Epoch [2/10], Phase: train, Batch: [611/730], Loss: 0.2584\n",
      "Epoch [2/10], Phase: train, Batch: [612/730], Loss: 0.2848\n",
      "Epoch [2/10], Phase: train, Batch: [613/730], Loss: 0.2637\n",
      "Epoch [2/10], Phase: train, Batch: [614/730], Loss: 0.2179\n",
      "Epoch [2/10], Phase: train, Batch: [615/730], Loss: 0.3881\n",
      "Epoch [2/10], Phase: train, Batch: [616/730], Loss: 0.2702\n",
      "Epoch [2/10], Phase: train, Batch: [617/730], Loss: 0.4464\n",
      "Epoch [2/10], Phase: train, Batch: [618/730], Loss: 0.1760\n",
      "Epoch [2/10], Phase: train, Batch: [619/730], Loss: 0.2784\n",
      "Epoch [2/10], Phase: train, Batch: [620/730], Loss: 0.2417\n",
      "Epoch [2/10], Phase: train, Batch: [621/730], Loss: 0.2408\n",
      "Epoch [2/10], Phase: train, Batch: [622/730], Loss: 0.2587\n",
      "Epoch [2/10], Phase: train, Batch: [623/730], Loss: 0.3523\n",
      "Epoch [2/10], Phase: train, Batch: [624/730], Loss: 0.2466\n",
      "Epoch [2/10], Phase: train, Batch: [625/730], Loss: 0.3544\n",
      "Epoch [2/10], Phase: train, Batch: [626/730], Loss: 0.2789\n",
      "Epoch [2/10], Phase: train, Batch: [627/730], Loss: 0.3078\n",
      "Epoch [2/10], Phase: train, Batch: [628/730], Loss: 0.2065\n",
      "Epoch [2/10], Phase: train, Batch: [629/730], Loss: 0.1889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [630/730], Loss: 0.2464\n",
      "Epoch [2/10], Phase: train, Batch: [631/730], Loss: 0.3620\n",
      "Epoch [2/10], Phase: train, Batch: [632/730], Loss: 0.4612\n",
      "Epoch [2/10], Phase: train, Batch: [633/730], Loss: 0.2417\n",
      "Epoch [2/10], Phase: train, Batch: [634/730], Loss: 0.2460\n",
      "Epoch [2/10], Phase: train, Batch: [635/730], Loss: 0.3605\n",
      "Epoch [2/10], Phase: train, Batch: [636/730], Loss: 0.3161\n",
      "Epoch [2/10], Phase: train, Batch: [637/730], Loss: 0.3385\n",
      "Epoch [2/10], Phase: train, Batch: [638/730], Loss: 0.3303\n",
      "Epoch [2/10], Phase: train, Batch: [639/730], Loss: 0.2149\n",
      "Epoch [2/10], Phase: train, Batch: [640/730], Loss: 0.4235\n",
      "Epoch [2/10], Phase: train, Batch: [641/730], Loss: 0.4120\n",
      "Epoch [2/10], Phase: train, Batch: [642/730], Loss: 0.3231\n",
      "Epoch [2/10], Phase: train, Batch: [643/730], Loss: 0.2498\n",
      "Epoch [2/10], Phase: train, Batch: [644/730], Loss: 0.3512\n",
      "Epoch [2/10], Phase: train, Batch: [645/730], Loss: 0.4212\n",
      "Epoch [2/10], Phase: train, Batch: [646/730], Loss: 0.3088\n",
      "Epoch [2/10], Phase: train, Batch: [647/730], Loss: 0.3298\n",
      "Epoch [2/10], Phase: train, Batch: [648/730], Loss: 0.2993\n",
      "Epoch [2/10], Phase: train, Batch: [649/730], Loss: 0.2274\n",
      "Epoch [2/10], Phase: train, Batch: [650/730], Loss: 0.3928\n",
      "Epoch [2/10], Phase: train, Batch: [651/730], Loss: 0.2857\n",
      "Epoch [2/10], Phase: train, Batch: [652/730], Loss: 0.2881\n",
      "Epoch [2/10], Phase: train, Batch: [653/730], Loss: 0.2901\n",
      "Epoch [2/10], Phase: train, Batch: [654/730], Loss: 0.3019\n",
      "Epoch [2/10], Phase: train, Batch: [655/730], Loss: 0.2270\n",
      "Epoch [2/10], Phase: train, Batch: [656/730], Loss: 0.2381\n",
      "Epoch [2/10], Phase: train, Batch: [657/730], Loss: 0.1801\n",
      "Epoch [2/10], Phase: train, Batch: [658/730], Loss: 0.2458\n",
      "Epoch [2/10], Phase: train, Batch: [659/730], Loss: 0.2233\n",
      "Epoch [2/10], Phase: train, Batch: [660/730], Loss: 0.3573\n",
      "Epoch [2/10], Phase: train, Batch: [661/730], Loss: 0.3276\n",
      "Epoch [2/10], Phase: train, Batch: [662/730], Loss: 0.4714\n",
      "Epoch [2/10], Phase: train, Batch: [663/730], Loss: 0.2904\n",
      "Epoch [2/10], Phase: train, Batch: [664/730], Loss: 0.2377\n",
      "Epoch [2/10], Phase: train, Batch: [665/730], Loss: 0.2392\n",
      "Epoch [2/10], Phase: train, Batch: [666/730], Loss: 0.2042\n",
      "Epoch [2/10], Phase: train, Batch: [667/730], Loss: 0.4326\n",
      "Epoch [2/10], Phase: train, Batch: [668/730], Loss: 0.2644\n",
      "Epoch [2/10], Phase: train, Batch: [669/730], Loss: 0.2841\n",
      "Epoch [2/10], Phase: train, Batch: [670/730], Loss: 0.2596\n",
      "Epoch [2/10], Phase: train, Batch: [671/730], Loss: 0.2758\n",
      "Epoch [2/10], Phase: train, Batch: [672/730], Loss: 0.3669\n",
      "Epoch [2/10], Phase: train, Batch: [673/730], Loss: 0.2382\n",
      "Epoch [2/10], Phase: train, Batch: [674/730], Loss: 0.3469\n",
      "Epoch [2/10], Phase: train, Batch: [675/730], Loss: 0.2445\n",
      "Epoch [2/10], Phase: train, Batch: [676/730], Loss: 0.2249\n",
      "Epoch [2/10], Phase: train, Batch: [677/730], Loss: 0.3479\n",
      "Epoch [2/10], Phase: train, Batch: [678/730], Loss: 0.2753\n",
      "Epoch [2/10], Phase: train, Batch: [679/730], Loss: 0.2771\n",
      "Epoch [2/10], Phase: train, Batch: [680/730], Loss: 0.3054\n",
      "Epoch [2/10], Phase: train, Batch: [681/730], Loss: 0.2318\n",
      "Epoch [2/10], Phase: train, Batch: [682/730], Loss: 0.2960\n",
      "Epoch [2/10], Phase: train, Batch: [683/730], Loss: 0.3647\n",
      "Epoch [2/10], Phase: train, Batch: [684/730], Loss: 0.2937\n",
      "Epoch [2/10], Phase: train, Batch: [685/730], Loss: 0.2977\n",
      "Epoch [2/10], Phase: train, Batch: [686/730], Loss: 0.2400\n",
      "Epoch [2/10], Phase: train, Batch: [687/730], Loss: 0.3993\n",
      "Epoch [2/10], Phase: train, Batch: [688/730], Loss: 0.3022\n",
      "Epoch [2/10], Phase: train, Batch: [689/730], Loss: 0.4283\n",
      "Epoch [2/10], Phase: train, Batch: [690/730], Loss: 0.2859\n",
      "Epoch [2/10], Phase: train, Batch: [691/730], Loss: 0.3904\n",
      "Epoch [2/10], Phase: train, Batch: [692/730], Loss: 0.1798\n",
      "Epoch [2/10], Phase: train, Batch: [693/730], Loss: 0.2160\n",
      "Epoch [2/10], Phase: train, Batch: [694/730], Loss: 0.2527\n",
      "Epoch [2/10], Phase: train, Batch: [695/730], Loss: 0.3540\n",
      "Epoch [2/10], Phase: train, Batch: [696/730], Loss: 0.2626\n",
      "Epoch [2/10], Phase: train, Batch: [697/730], Loss: 0.1725\n",
      "Epoch [2/10], Phase: train, Batch: [698/730], Loss: 0.2456\n",
      "Epoch [2/10], Phase: train, Batch: [699/730], Loss: 0.2176\n",
      "Epoch [2/10], Phase: train, Batch: [700/730], Loss: 0.1859\n",
      "Epoch [2/10], Phase: train, Batch: [701/730], Loss: 0.1414\n",
      "Epoch [2/10], Phase: train, Batch: [702/730], Loss: 0.3304\n",
      "Epoch [2/10], Phase: train, Batch: [703/730], Loss: 0.3178\n",
      "Epoch [2/10], Phase: train, Batch: [704/730], Loss: 0.3794\n",
      "Epoch [2/10], Phase: train, Batch: [705/730], Loss: 0.2913\n",
      "Epoch [2/10], Phase: train, Batch: [706/730], Loss: 0.2531\n",
      "Epoch [2/10], Phase: train, Batch: [707/730], Loss: 0.2504\n",
      "Epoch [2/10], Phase: train, Batch: [708/730], Loss: 0.3934\n",
      "Epoch [2/10], Phase: train, Batch: [709/730], Loss: 0.4517\n",
      "Epoch [2/10], Phase: train, Batch: [710/730], Loss: 0.3556\n",
      "Epoch [2/10], Phase: train, Batch: [711/730], Loss: 0.2478\n",
      "Epoch [2/10], Phase: train, Batch: [712/730], Loss: 0.5010\n",
      "Epoch [2/10], Phase: train, Batch: [713/730], Loss: 0.2163\n",
      "Epoch [2/10], Phase: train, Batch: [714/730], Loss: 0.2776\n",
      "Epoch [2/10], Phase: train, Batch: [715/730], Loss: 0.4065\n",
      "Epoch [2/10], Phase: train, Batch: [716/730], Loss: 0.3336\n",
      "Epoch [2/10], Phase: train, Batch: [717/730], Loss: 0.2419\n",
      "Epoch [2/10], Phase: train, Batch: [718/730], Loss: 0.2156\n",
      "Epoch [2/10], Phase: train, Batch: [719/730], Loss: 0.2749\n",
      "Epoch [2/10], Phase: train, Batch: [720/730], Loss: 0.2091\n",
      "Epoch [2/10], Phase: train, Batch: [721/730], Loss: 0.3345\n",
      "Epoch [2/10], Phase: train, Batch: [722/730], Loss: 0.2408\n",
      "Epoch [2/10], Phase: train, Batch: [723/730], Loss: 0.2288\n",
      "Epoch [2/10], Phase: train, Batch: [724/730], Loss: 0.2210\n",
      "Epoch [2/10], Phase: train, Batch: [725/730], Loss: 0.3395\n",
      "Epoch [2/10], Phase: train, Batch: [726/730], Loss: 0.3221\n",
      "Epoch [2/10], Phase: train, Batch: [727/730], Loss: 0.4652\n",
      "Epoch [2/10], Phase: train, Batch: [728/730], Loss: 0.2090\n",
      "Epoch [2/10], Phase: train, Batch: [729/730], Loss: 0.2934\n",
      "Epoch [2/10], Phase: train, Batch: [730/730], Loss: 0.1475\n",
      "train Loss: 0.2932 Acc: 0.8805\n",
      "Epoch [2/10], Phase: val, Batch: [1/182], Loss: 0.3327\n",
      "Epoch [2/10], Phase: val, Batch: [2/182], Loss: 0.2376\n",
      "Epoch [2/10], Phase: val, Batch: [3/182], Loss: 0.1763\n",
      "Epoch [2/10], Phase: val, Batch: [4/182], Loss: 0.2684\n",
      "Epoch [2/10], Phase: val, Batch: [5/182], Loss: 0.2198\n",
      "Epoch [2/10], Phase: val, Batch: [6/182], Loss: 0.1865\n",
      "Epoch [2/10], Phase: val, Batch: [7/182], Loss: 0.1064\n",
      "Epoch [2/10], Phase: val, Batch: [8/182], Loss: 0.2593\n",
      "Epoch [2/10], Phase: val, Batch: [9/182], Loss: 0.2142\n",
      "Epoch [2/10], Phase: val, Batch: [10/182], Loss: 0.1746\n",
      "Epoch [2/10], Phase: val, Batch: [11/182], Loss: 0.1518\n",
      "Epoch [2/10], Phase: val, Batch: [12/182], Loss: 0.2422\n",
      "Epoch [2/10], Phase: val, Batch: [13/182], Loss: 0.1831\n",
      "Epoch [2/10], Phase: val, Batch: [14/182], Loss: 0.1388\n",
      "Epoch [2/10], Phase: val, Batch: [15/182], Loss: 0.1997\n",
      "Epoch [2/10], Phase: val, Batch: [16/182], Loss: 0.2490\n",
      "Epoch [2/10], Phase: val, Batch: [17/182], Loss: 0.2323\n",
      "Epoch [2/10], Phase: val, Batch: [18/182], Loss: 0.2111\n",
      "Epoch [2/10], Phase: val, Batch: [19/182], Loss: 0.3302\n",
      "Epoch [2/10], Phase: val, Batch: [20/182], Loss: 0.3476\n",
      "Epoch [2/10], Phase: val, Batch: [21/182], Loss: 0.3292\n",
      "Epoch [2/10], Phase: val, Batch: [22/182], Loss: 0.3306\n",
      "Epoch [2/10], Phase: val, Batch: [23/182], Loss: 0.1726\n",
      "Epoch [2/10], Phase: val, Batch: [24/182], Loss: 0.3489\n",
      "Epoch [2/10], Phase: val, Batch: [25/182], Loss: 0.2571\n",
      "Epoch [2/10], Phase: val, Batch: [26/182], Loss: 0.1567\n",
      "Epoch [2/10], Phase: val, Batch: [27/182], Loss: 0.2066\n",
      "Epoch [2/10], Phase: val, Batch: [28/182], Loss: 0.3457\n",
      "Epoch [2/10], Phase: val, Batch: [29/182], Loss: 0.2792\n",
      "Epoch [2/10], Phase: val, Batch: [30/182], Loss: 0.2804\n",
      "Epoch [2/10], Phase: val, Batch: [31/182], Loss: 0.3404\n",
      "Epoch [2/10], Phase: val, Batch: [32/182], Loss: 0.1364\n",
      "Epoch [2/10], Phase: val, Batch: [33/182], Loss: 0.2557\n",
      "Epoch [2/10], Phase: val, Batch: [34/182], Loss: 0.2552\n",
      "Epoch [2/10], Phase: val, Batch: [35/182], Loss: 0.1561\n",
      "Epoch [2/10], Phase: val, Batch: [36/182], Loss: 0.2299\n",
      "Epoch [2/10], Phase: val, Batch: [37/182], Loss: 0.1582\n",
      "Epoch [2/10], Phase: val, Batch: [38/182], Loss: 0.1744\n",
      "Epoch [2/10], Phase: val, Batch: [39/182], Loss: 0.2831\n",
      "Epoch [2/10], Phase: val, Batch: [40/182], Loss: 0.2241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: val, Batch: [41/182], Loss: 0.2137\n",
      "Epoch [2/10], Phase: val, Batch: [42/182], Loss: 0.2621\n",
      "Epoch [2/10], Phase: val, Batch: [43/182], Loss: 0.1876\n",
      "Epoch [2/10], Phase: val, Batch: [44/182], Loss: 0.2998\n",
      "Epoch [2/10], Phase: val, Batch: [45/182], Loss: 0.2762\n",
      "Epoch [2/10], Phase: val, Batch: [46/182], Loss: 0.1979\n",
      "Epoch [2/10], Phase: val, Batch: [47/182], Loss: 0.2780\n",
      "Epoch [2/10], Phase: val, Batch: [48/182], Loss: 0.1188\n",
      "Epoch [2/10], Phase: val, Batch: [49/182], Loss: 0.2667\n",
      "Epoch [2/10], Phase: val, Batch: [50/182], Loss: 0.3286\n",
      "Epoch [2/10], Phase: val, Batch: [51/182], Loss: 0.3627\n",
      "Epoch [2/10], Phase: val, Batch: [52/182], Loss: 0.2227\n",
      "Epoch [2/10], Phase: val, Batch: [53/182], Loss: 0.2225\n",
      "Epoch [2/10], Phase: val, Batch: [54/182], Loss: 0.2818\n",
      "Epoch [2/10], Phase: val, Batch: [55/182], Loss: 0.1741\n",
      "Epoch [2/10], Phase: val, Batch: [56/182], Loss: 0.1793\n",
      "Epoch [2/10], Phase: val, Batch: [57/182], Loss: 0.2234\n",
      "Epoch [2/10], Phase: val, Batch: [58/182], Loss: 0.1987\n",
      "Epoch [2/10], Phase: val, Batch: [59/182], Loss: 0.1763\n",
      "Epoch [2/10], Phase: val, Batch: [60/182], Loss: 0.1554\n",
      "Epoch [2/10], Phase: val, Batch: [61/182], Loss: 0.2859\n",
      "Epoch [2/10], Phase: val, Batch: [62/182], Loss: 0.3589\n",
      "Epoch [2/10], Phase: val, Batch: [63/182], Loss: 0.1753\n",
      "Epoch [2/10], Phase: val, Batch: [64/182], Loss: 0.2721\n",
      "Epoch [2/10], Phase: val, Batch: [65/182], Loss: 0.1843\n",
      "Epoch [2/10], Phase: val, Batch: [66/182], Loss: 0.2610\n",
      "Epoch [2/10], Phase: val, Batch: [67/182], Loss: 0.2089\n",
      "Epoch [2/10], Phase: val, Batch: [68/182], Loss: 0.2062\n",
      "Epoch [2/10], Phase: val, Batch: [69/182], Loss: 0.2619\n",
      "Epoch [2/10], Phase: val, Batch: [70/182], Loss: 0.2297\n",
      "Epoch [2/10], Phase: val, Batch: [71/182], Loss: 0.3414\n",
      "Epoch [2/10], Phase: val, Batch: [72/182], Loss: 0.2028\n",
      "Epoch [2/10], Phase: val, Batch: [73/182], Loss: 0.1713\n",
      "Epoch [2/10], Phase: val, Batch: [74/182], Loss: 0.3424\n",
      "Epoch [2/10], Phase: val, Batch: [75/182], Loss: 0.2174\n",
      "Epoch [2/10], Phase: val, Batch: [76/182], Loss: 0.1684\n",
      "Epoch [2/10], Phase: val, Batch: [77/182], Loss: 0.1572\n",
      "Epoch [2/10], Phase: val, Batch: [78/182], Loss: 0.1502\n",
      "Epoch [2/10], Phase: val, Batch: [79/182], Loss: 0.2180\n",
      "Epoch [2/10], Phase: val, Batch: [80/182], Loss: 0.1856\n",
      "Epoch [2/10], Phase: val, Batch: [81/182], Loss: 0.1291\n",
      "Epoch [2/10], Phase: val, Batch: [82/182], Loss: 0.1860\n",
      "Epoch [2/10], Phase: val, Batch: [83/182], Loss: 0.2036\n",
      "Epoch [2/10], Phase: val, Batch: [84/182], Loss: 0.2131\n",
      "Epoch [2/10], Phase: val, Batch: [85/182], Loss: 0.1962\n",
      "Epoch [2/10], Phase: val, Batch: [86/182], Loss: 0.2688\n",
      "Epoch [2/10], Phase: val, Batch: [87/182], Loss: 0.3667\n",
      "Epoch [2/10], Phase: val, Batch: [88/182], Loss: 0.2657\n",
      "Epoch [2/10], Phase: val, Batch: [89/182], Loss: 0.2368\n",
      "Epoch [2/10], Phase: val, Batch: [90/182], Loss: 0.2819\n",
      "Epoch [2/10], Phase: val, Batch: [91/182], Loss: 0.2757\n",
      "Epoch [2/10], Phase: val, Batch: [92/182], Loss: 0.2284\n",
      "Epoch [2/10], Phase: val, Batch: [93/182], Loss: 0.1764\n",
      "Epoch [2/10], Phase: val, Batch: [94/182], Loss: 0.1894\n",
      "Epoch [2/10], Phase: val, Batch: [95/182], Loss: 0.2610\n",
      "Epoch [2/10], Phase: val, Batch: [96/182], Loss: 0.2136\n",
      "Epoch [2/10], Phase: val, Batch: [97/182], Loss: 0.2331\n",
      "Epoch [2/10], Phase: val, Batch: [98/182], Loss: 0.2133\n",
      "Epoch [2/10], Phase: val, Batch: [99/182], Loss: 0.2548\n",
      "Epoch [2/10], Phase: val, Batch: [100/182], Loss: 0.2750\n",
      "Epoch [2/10], Phase: val, Batch: [101/182], Loss: 0.3325\n",
      "Epoch [2/10], Phase: val, Batch: [102/182], Loss: 0.1979\n",
      "Epoch [2/10], Phase: val, Batch: [103/182], Loss: 0.2312\n",
      "Epoch [2/10], Phase: val, Batch: [104/182], Loss: 0.2347\n",
      "Epoch [2/10], Phase: val, Batch: [105/182], Loss: 0.1760\n",
      "Epoch [2/10], Phase: val, Batch: [106/182], Loss: 0.3757\n",
      "Epoch [2/10], Phase: val, Batch: [107/182], Loss: 0.2534\n",
      "Epoch [2/10], Phase: val, Batch: [108/182], Loss: 0.2173\n",
      "Epoch [2/10], Phase: val, Batch: [109/182], Loss: 0.2317\n",
      "Epoch [2/10], Phase: val, Batch: [110/182], Loss: 0.1902\n",
      "Epoch [2/10], Phase: val, Batch: [111/182], Loss: 0.1216\n",
      "Epoch [2/10], Phase: val, Batch: [112/182], Loss: 0.1724\n",
      "Epoch [2/10], Phase: val, Batch: [113/182], Loss: 0.1507\n",
      "Epoch [2/10], Phase: val, Batch: [114/182], Loss: 0.2574\n",
      "Epoch [2/10], Phase: val, Batch: [115/182], Loss: 0.1854\n",
      "Epoch [2/10], Phase: val, Batch: [116/182], Loss: 0.2679\n",
      "Epoch [2/10], Phase: val, Batch: [117/182], Loss: 0.1357\n",
      "Epoch [2/10], Phase: val, Batch: [118/182], Loss: 0.2302\n",
      "Epoch [2/10], Phase: val, Batch: [119/182], Loss: 0.1731\n",
      "Epoch [2/10], Phase: val, Batch: [120/182], Loss: 0.2018\n",
      "Epoch [2/10], Phase: val, Batch: [121/182], Loss: 0.2309\n",
      "Epoch [2/10], Phase: val, Batch: [122/182], Loss: 0.1955\n",
      "Epoch [2/10], Phase: val, Batch: [123/182], Loss: 0.2803\n",
      "Epoch [2/10], Phase: val, Batch: [124/182], Loss: 0.1606\n",
      "Epoch [2/10], Phase: val, Batch: [125/182], Loss: 0.1729\n",
      "Epoch [2/10], Phase: val, Batch: [126/182], Loss: 0.2181\n",
      "Epoch [2/10], Phase: val, Batch: [127/182], Loss: 0.1972\n",
      "Epoch [2/10], Phase: val, Batch: [128/182], Loss: 0.1962\n",
      "Epoch [2/10], Phase: val, Batch: [129/182], Loss: 0.2340\n",
      "Epoch [2/10], Phase: val, Batch: [130/182], Loss: 0.1595\n",
      "Epoch [2/10], Phase: val, Batch: [131/182], Loss: 0.2444\n",
      "Epoch [2/10], Phase: val, Batch: [132/182], Loss: 0.2451\n",
      "Epoch [2/10], Phase: val, Batch: [133/182], Loss: 0.3426\n",
      "Epoch [2/10], Phase: val, Batch: [134/182], Loss: 0.1143\n",
      "Epoch [2/10], Phase: val, Batch: [135/182], Loss: 0.1960\n",
      "Epoch [2/10], Phase: val, Batch: [136/182], Loss: 0.2655\n",
      "Epoch [2/10], Phase: val, Batch: [137/182], Loss: 0.2190\n",
      "Epoch [2/10], Phase: val, Batch: [138/182], Loss: 0.2495\n",
      "Epoch [2/10], Phase: val, Batch: [139/182], Loss: 0.1426\n",
      "Epoch [2/10], Phase: val, Batch: [140/182], Loss: 0.2391\n",
      "Epoch [2/10], Phase: val, Batch: [141/182], Loss: 0.2117\n",
      "Epoch [2/10], Phase: val, Batch: [142/182], Loss: 0.1883\n",
      "Epoch [2/10], Phase: val, Batch: [143/182], Loss: 0.2565\n",
      "Epoch [2/10], Phase: val, Batch: [144/182], Loss: 0.2695\n",
      "Epoch [2/10], Phase: val, Batch: [145/182], Loss: 0.1327\n",
      "Epoch [2/10], Phase: val, Batch: [146/182], Loss: 0.1980\n",
      "Epoch [2/10], Phase: val, Batch: [147/182], Loss: 0.2451\n",
      "Epoch [2/10], Phase: val, Batch: [148/182], Loss: 0.1773\n",
      "Epoch [2/10], Phase: val, Batch: [149/182], Loss: 0.2524\n",
      "Epoch [2/10], Phase: val, Batch: [150/182], Loss: 0.2642\n",
      "Epoch [2/10], Phase: val, Batch: [151/182], Loss: 0.2513\n",
      "Epoch [2/10], Phase: val, Batch: [152/182], Loss: 0.2831\n",
      "Epoch [2/10], Phase: val, Batch: [153/182], Loss: 0.2552\n",
      "Epoch [2/10], Phase: val, Batch: [154/182], Loss: 0.2360\n",
      "Epoch [2/10], Phase: val, Batch: [155/182], Loss: 0.1998\n",
      "Epoch [2/10], Phase: val, Batch: [156/182], Loss: 0.3344\n",
      "Epoch [2/10], Phase: val, Batch: [157/182], Loss: 0.2429\n",
      "Epoch [2/10], Phase: val, Batch: [158/182], Loss: 0.3726\n",
      "Epoch [2/10], Phase: val, Batch: [159/182], Loss: 0.2531\n",
      "Epoch [2/10], Phase: val, Batch: [160/182], Loss: 0.1898\n",
      "Epoch [2/10], Phase: val, Batch: [161/182], Loss: 0.2452\n",
      "Epoch [2/10], Phase: val, Batch: [162/182], Loss: 0.2812\n",
      "Epoch [2/10], Phase: val, Batch: [163/182], Loss: 0.2878\n",
      "Epoch [2/10], Phase: val, Batch: [164/182], Loss: 0.1849\n",
      "Epoch [2/10], Phase: val, Batch: [165/182], Loss: 0.2394\n",
      "Epoch [2/10], Phase: val, Batch: [166/182], Loss: 0.1365\n",
      "Epoch [2/10], Phase: val, Batch: [167/182], Loss: 0.1849\n",
      "Epoch [2/10], Phase: val, Batch: [168/182], Loss: 0.2038\n",
      "Epoch [2/10], Phase: val, Batch: [169/182], Loss: 0.2453\n",
      "Epoch [2/10], Phase: val, Batch: [170/182], Loss: 0.2534\n",
      "Epoch [2/10], Phase: val, Batch: [171/182], Loss: 0.3088\n",
      "Epoch [2/10], Phase: val, Batch: [172/182], Loss: 0.2228\n",
      "Epoch [2/10], Phase: val, Batch: [173/182], Loss: 0.1149\n",
      "Epoch [2/10], Phase: val, Batch: [174/182], Loss: 0.2677\n",
      "Epoch [2/10], Phase: val, Batch: [175/182], Loss: 0.1474\n",
      "Epoch [2/10], Phase: val, Batch: [176/182], Loss: 0.2135\n",
      "Epoch [2/10], Phase: val, Batch: [177/182], Loss: 0.2532\n",
      "Epoch [2/10], Phase: val, Batch: [178/182], Loss: 0.1249\n",
      "Epoch [2/10], Phase: val, Batch: [179/182], Loss: 0.1890\n",
      "Epoch [2/10], Phase: val, Batch: [180/182], Loss: 0.1985\n",
      "Epoch [2/10], Phase: val, Batch: [181/182], Loss: 0.3166\n",
      "Epoch [2/10], Phase: val, Batch: [182/182], Loss: 0.2330\n",
      "val Loss: 0.2285 Acc: 0.9105\n",
      "Epoch [3/10], Phase: train, Batch: [1/730], Loss: 0.2271\n",
      "Epoch [3/10], Phase: train, Batch: [2/730], Loss: 0.3748\n",
      "Epoch [3/10], Phase: train, Batch: [3/730], Loss: 0.2935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [4/730], Loss: 0.3961\n",
      "Epoch [3/10], Phase: train, Batch: [5/730], Loss: 0.3371\n",
      "Epoch [3/10], Phase: train, Batch: [6/730], Loss: 0.3621\n",
      "Epoch [3/10], Phase: train, Batch: [7/730], Loss: 0.2991\n",
      "Epoch [3/10], Phase: train, Batch: [8/730], Loss: 0.3442\n",
      "Epoch [3/10], Phase: train, Batch: [9/730], Loss: 0.2652\n",
      "Epoch [3/10], Phase: train, Batch: [10/730], Loss: 0.3299\n",
      "Epoch [3/10], Phase: train, Batch: [11/730], Loss: 0.3792\n",
      "Epoch [3/10], Phase: train, Batch: [12/730], Loss: 0.2667\n",
      "Epoch [3/10], Phase: train, Batch: [13/730], Loss: 0.2596\n",
      "Epoch [3/10], Phase: train, Batch: [14/730], Loss: 0.2436\n",
      "Epoch [3/10], Phase: train, Batch: [15/730], Loss: 0.2103\n",
      "Epoch [3/10], Phase: train, Batch: [16/730], Loss: 0.2345\n",
      "Epoch [3/10], Phase: train, Batch: [17/730], Loss: 0.3590\n",
      "Epoch [3/10], Phase: train, Batch: [18/730], Loss: 0.2961\n",
      "Epoch [3/10], Phase: train, Batch: [19/730], Loss: 0.2550\n",
      "Epoch [3/10], Phase: train, Batch: [20/730], Loss: 0.2606\n",
      "Epoch [3/10], Phase: train, Batch: [21/730], Loss: 0.2044\n",
      "Epoch [3/10], Phase: train, Batch: [22/730], Loss: 0.3441\n",
      "Epoch [3/10], Phase: train, Batch: [23/730], Loss: 0.3502\n",
      "Epoch [3/10], Phase: train, Batch: [24/730], Loss: 0.2546\n",
      "Epoch [3/10], Phase: train, Batch: [25/730], Loss: 0.2264\n",
      "Epoch [3/10], Phase: train, Batch: [26/730], Loss: 0.2581\n",
      "Epoch [3/10], Phase: train, Batch: [27/730], Loss: 0.2080\n",
      "Epoch [3/10], Phase: train, Batch: [28/730], Loss: 0.2475\n",
      "Epoch [3/10], Phase: train, Batch: [29/730], Loss: 0.2807\n",
      "Epoch [3/10], Phase: train, Batch: [30/730], Loss: 0.3294\n",
      "Epoch [3/10], Phase: train, Batch: [31/730], Loss: 0.2229\n",
      "Epoch [3/10], Phase: train, Batch: [32/730], Loss: 0.3486\n",
      "Epoch [3/10], Phase: train, Batch: [33/730], Loss: 0.3753\n",
      "Epoch [3/10], Phase: train, Batch: [34/730], Loss: 0.3771\n",
      "Epoch [3/10], Phase: train, Batch: [35/730], Loss: 0.1548\n",
      "Epoch [3/10], Phase: train, Batch: [36/730], Loss: 0.2673\n",
      "Epoch [3/10], Phase: train, Batch: [37/730], Loss: 0.2882\n",
      "Epoch [3/10], Phase: train, Batch: [38/730], Loss: 0.4335\n",
      "Epoch [3/10], Phase: train, Batch: [39/730], Loss: 0.4412\n",
      "Epoch [3/10], Phase: train, Batch: [40/730], Loss: 0.2046\n",
      "Epoch [3/10], Phase: train, Batch: [41/730], Loss: 0.2326\n",
      "Epoch [3/10], Phase: train, Batch: [42/730], Loss: 0.2022\n",
      "Epoch [3/10], Phase: train, Batch: [43/730], Loss: 0.3716\n",
      "Epoch [3/10], Phase: train, Batch: [44/730], Loss: 0.2906\n",
      "Epoch [3/10], Phase: train, Batch: [45/730], Loss: 0.3001\n",
      "Epoch [3/10], Phase: train, Batch: [46/730], Loss: 0.3020\n",
      "Epoch [3/10], Phase: train, Batch: [47/730], Loss: 0.2062\n",
      "Epoch [3/10], Phase: train, Batch: [48/730], Loss: 0.2179\n",
      "Epoch [3/10], Phase: train, Batch: [49/730], Loss: 0.2450\n",
      "Epoch [3/10], Phase: train, Batch: [50/730], Loss: 0.4208\n",
      "Epoch [3/10], Phase: train, Batch: [51/730], Loss: 0.3553\n",
      "Epoch [3/10], Phase: train, Batch: [52/730], Loss: 0.2833\n",
      "Epoch [3/10], Phase: train, Batch: [53/730], Loss: 0.1983\n",
      "Epoch [3/10], Phase: train, Batch: [54/730], Loss: 0.4165\n",
      "Epoch [3/10], Phase: train, Batch: [55/730], Loss: 0.2762\n",
      "Epoch [3/10], Phase: train, Batch: [56/730], Loss: 0.1724\n",
      "Epoch [3/10], Phase: train, Batch: [57/730], Loss: 0.2281\n",
      "Epoch [3/10], Phase: train, Batch: [58/730], Loss: 0.2320\n",
      "Epoch [3/10], Phase: train, Batch: [59/730], Loss: 0.3085\n",
      "Epoch [3/10], Phase: train, Batch: [60/730], Loss: 0.2354\n",
      "Epoch [3/10], Phase: train, Batch: [61/730], Loss: 0.2191\n",
      "Epoch [3/10], Phase: train, Batch: [62/730], Loss: 0.3737\n",
      "Epoch [3/10], Phase: train, Batch: [63/730], Loss: 0.3144\n",
      "Epoch [3/10], Phase: train, Batch: [64/730], Loss: 0.3143\n",
      "Epoch [3/10], Phase: train, Batch: [65/730], Loss: 0.2833\n",
      "Epoch [3/10], Phase: train, Batch: [66/730], Loss: 0.3450\n",
      "Epoch [3/10], Phase: train, Batch: [67/730], Loss: 0.2671\n",
      "Epoch [3/10], Phase: train, Batch: [68/730], Loss: 0.2442\n",
      "Epoch [3/10], Phase: train, Batch: [69/730], Loss: 0.2255\n",
      "Epoch [3/10], Phase: train, Batch: [70/730], Loss: 0.1675\n",
      "Epoch [3/10], Phase: train, Batch: [71/730], Loss: 0.3721\n",
      "Epoch [3/10], Phase: train, Batch: [72/730], Loss: 0.2894\n",
      "Epoch [3/10], Phase: train, Batch: [73/730], Loss: 0.3151\n",
      "Epoch [3/10], Phase: train, Batch: [74/730], Loss: 0.1901\n",
      "Epoch [3/10], Phase: train, Batch: [75/730], Loss: 0.3365\n",
      "Epoch [3/10], Phase: train, Batch: [76/730], Loss: 0.2639\n",
      "Epoch [3/10], Phase: train, Batch: [77/730], Loss: 0.3762\n",
      "Epoch [3/10], Phase: train, Batch: [78/730], Loss: 0.1767\n",
      "Epoch [3/10], Phase: train, Batch: [79/730], Loss: 0.1963\n",
      "Epoch [3/10], Phase: train, Batch: [80/730], Loss: 0.2688\n",
      "Epoch [3/10], Phase: train, Batch: [81/730], Loss: 0.2555\n",
      "Epoch [3/10], Phase: train, Batch: [82/730], Loss: 0.2243\n",
      "Epoch [3/10], Phase: train, Batch: [83/730], Loss: 0.2417\n",
      "Epoch [3/10], Phase: train, Batch: [84/730], Loss: 0.3495\n",
      "Epoch [3/10], Phase: train, Batch: [85/730], Loss: 0.2298\n",
      "Epoch [3/10], Phase: train, Batch: [86/730], Loss: 0.3739\n",
      "Epoch [3/10], Phase: train, Batch: [87/730], Loss: 0.1850\n",
      "Epoch [3/10], Phase: train, Batch: [88/730], Loss: 0.1888\n",
      "Epoch [3/10], Phase: train, Batch: [89/730], Loss: 0.2984\n",
      "Epoch [3/10], Phase: train, Batch: [90/730], Loss: 0.3542\n",
      "Epoch [3/10], Phase: train, Batch: [91/730], Loss: 0.2990\n",
      "Epoch [3/10], Phase: train, Batch: [92/730], Loss: 0.3066\n",
      "Epoch [3/10], Phase: train, Batch: [93/730], Loss: 0.2996\n",
      "Epoch [3/10], Phase: train, Batch: [94/730], Loss: 0.4166\n",
      "Epoch [3/10], Phase: train, Batch: [95/730], Loss: 0.2831\n",
      "Epoch [3/10], Phase: train, Batch: [96/730], Loss: 0.1570\n",
      "Epoch [3/10], Phase: train, Batch: [97/730], Loss: 0.2313\n",
      "Epoch [3/10], Phase: train, Batch: [98/730], Loss: 0.2060\n",
      "Epoch [3/10], Phase: train, Batch: [99/730], Loss: 0.3018\n",
      "Epoch [3/10], Phase: train, Batch: [100/730], Loss: 0.3078\n",
      "Epoch [3/10], Phase: train, Batch: [101/730], Loss: 0.3603\n",
      "Epoch [3/10], Phase: train, Batch: [102/730], Loss: 0.2589\n",
      "Epoch [3/10], Phase: train, Batch: [103/730], Loss: 0.2123\n",
      "Epoch [3/10], Phase: train, Batch: [104/730], Loss: 0.3734\n",
      "Epoch [3/10], Phase: train, Batch: [105/730], Loss: 0.2744\n",
      "Epoch [3/10], Phase: train, Batch: [106/730], Loss: 0.3058\n",
      "Epoch [3/10], Phase: train, Batch: [107/730], Loss: 0.4053\n",
      "Epoch [3/10], Phase: train, Batch: [108/730], Loss: 0.3063\n",
      "Epoch [3/10], Phase: train, Batch: [109/730], Loss: 0.4158\n",
      "Epoch [3/10], Phase: train, Batch: [110/730], Loss: 0.2433\n",
      "Epoch [3/10], Phase: train, Batch: [111/730], Loss: 0.3310\n",
      "Epoch [3/10], Phase: train, Batch: [112/730], Loss: 0.3299\n",
      "Epoch [3/10], Phase: train, Batch: [113/730], Loss: 0.2912\n",
      "Epoch [3/10], Phase: train, Batch: [114/730], Loss: 0.2003\n",
      "Epoch [3/10], Phase: train, Batch: [115/730], Loss: 0.3084\n",
      "Epoch [3/10], Phase: train, Batch: [116/730], Loss: 0.3112\n",
      "Epoch [3/10], Phase: train, Batch: [117/730], Loss: 0.2676\n",
      "Epoch [3/10], Phase: train, Batch: [118/730], Loss: 0.3372\n",
      "Epoch [3/10], Phase: train, Batch: [119/730], Loss: 0.2280\n",
      "Epoch [3/10], Phase: train, Batch: [120/730], Loss: 0.4053\n",
      "Epoch [3/10], Phase: train, Batch: [121/730], Loss: 0.2576\n",
      "Epoch [3/10], Phase: train, Batch: [122/730], Loss: 0.3654\n",
      "Epoch [3/10], Phase: train, Batch: [123/730], Loss: 0.3818\n",
      "Epoch [3/10], Phase: train, Batch: [124/730], Loss: 0.2303\n",
      "Epoch [3/10], Phase: train, Batch: [125/730], Loss: 0.2830\n",
      "Epoch [3/10], Phase: train, Batch: [126/730], Loss: 0.3065\n",
      "Epoch [3/10], Phase: train, Batch: [127/730], Loss: 0.2134\n",
      "Epoch [3/10], Phase: train, Batch: [128/730], Loss: 0.2825\n",
      "Epoch [3/10], Phase: train, Batch: [129/730], Loss: 0.2143\n",
      "Epoch [3/10], Phase: train, Batch: [130/730], Loss: 0.2769\n",
      "Epoch [3/10], Phase: train, Batch: [131/730], Loss: 0.3906\n",
      "Epoch [3/10], Phase: train, Batch: [132/730], Loss: 0.3648\n",
      "Epoch [3/10], Phase: train, Batch: [133/730], Loss: 0.3513\n",
      "Epoch [3/10], Phase: train, Batch: [134/730], Loss: 0.2809\n",
      "Epoch [3/10], Phase: train, Batch: [135/730], Loss: 0.2810\n",
      "Epoch [3/10], Phase: train, Batch: [136/730], Loss: 0.3938\n",
      "Epoch [3/10], Phase: train, Batch: [137/730], Loss: 0.4136\n",
      "Epoch [3/10], Phase: train, Batch: [138/730], Loss: 0.1999\n",
      "Epoch [3/10], Phase: train, Batch: [139/730], Loss: 0.2819\n",
      "Epoch [3/10], Phase: train, Batch: [140/730], Loss: 0.2713\n",
      "Epoch [3/10], Phase: train, Batch: [141/730], Loss: 0.2543\n",
      "Epoch [3/10], Phase: train, Batch: [142/730], Loss: 0.2097\n",
      "Epoch [3/10], Phase: train, Batch: [143/730], Loss: 0.3606\n",
      "Epoch [3/10], Phase: train, Batch: [144/730], Loss: 0.2276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [145/730], Loss: 0.2335\n",
      "Epoch [3/10], Phase: train, Batch: [146/730], Loss: 0.2728\n",
      "Epoch [3/10], Phase: train, Batch: [147/730], Loss: 0.2995\n",
      "Epoch [3/10], Phase: train, Batch: [148/730], Loss: 0.2640\n",
      "Epoch [3/10], Phase: train, Batch: [149/730], Loss: 0.3236\n",
      "Epoch [3/10], Phase: train, Batch: [150/730], Loss: 0.2758\n",
      "Epoch [3/10], Phase: train, Batch: [151/730], Loss: 0.2892\n",
      "Epoch [3/10], Phase: train, Batch: [152/730], Loss: 0.3402\n",
      "Epoch [3/10], Phase: train, Batch: [153/730], Loss: 0.3167\n",
      "Epoch [3/10], Phase: train, Batch: [154/730], Loss: 0.1620\n",
      "Epoch [3/10], Phase: train, Batch: [155/730], Loss: 0.2442\n",
      "Epoch [3/10], Phase: train, Batch: [156/730], Loss: 0.2600\n",
      "Epoch [3/10], Phase: train, Batch: [157/730], Loss: 0.3328\n",
      "Epoch [3/10], Phase: train, Batch: [158/730], Loss: 0.3208\n",
      "Epoch [3/10], Phase: train, Batch: [159/730], Loss: 0.3818\n",
      "Epoch [3/10], Phase: train, Batch: [160/730], Loss: 0.2022\n",
      "Epoch [3/10], Phase: train, Batch: [161/730], Loss: 0.1837\n",
      "Epoch [3/10], Phase: train, Batch: [162/730], Loss: 0.4419\n",
      "Epoch [3/10], Phase: train, Batch: [163/730], Loss: 0.1621\n",
      "Epoch [3/10], Phase: train, Batch: [164/730], Loss: 0.2077\n",
      "Epoch [3/10], Phase: train, Batch: [165/730], Loss: 0.3419\n",
      "Epoch [3/10], Phase: train, Batch: [166/730], Loss: 0.4016\n",
      "Epoch [3/10], Phase: train, Batch: [167/730], Loss: 0.1917\n",
      "Epoch [3/10], Phase: train, Batch: [168/730], Loss: 0.1353\n",
      "Epoch [3/10], Phase: train, Batch: [169/730], Loss: 0.2661\n",
      "Epoch [3/10], Phase: train, Batch: [170/730], Loss: 0.3028\n",
      "Epoch [3/10], Phase: train, Batch: [171/730], Loss: 0.3733\n",
      "Epoch [3/10], Phase: train, Batch: [172/730], Loss: 0.2185\n",
      "Epoch [3/10], Phase: train, Batch: [173/730], Loss: 0.3164\n",
      "Epoch [3/10], Phase: train, Batch: [174/730], Loss: 0.3548\n",
      "Epoch [3/10], Phase: train, Batch: [175/730], Loss: 0.3771\n",
      "Epoch [3/10], Phase: train, Batch: [176/730], Loss: 0.4164\n",
      "Epoch [3/10], Phase: train, Batch: [177/730], Loss: 0.3545\n",
      "Epoch [3/10], Phase: train, Batch: [178/730], Loss: 0.2388\n",
      "Epoch [3/10], Phase: train, Batch: [179/730], Loss: 0.3268\n",
      "Epoch [3/10], Phase: train, Batch: [180/730], Loss: 0.2339\n",
      "Epoch [3/10], Phase: train, Batch: [181/730], Loss: 0.2135\n",
      "Epoch [3/10], Phase: train, Batch: [182/730], Loss: 0.3248\n",
      "Epoch [3/10], Phase: train, Batch: [183/730], Loss: 0.3321\n",
      "Epoch [3/10], Phase: train, Batch: [184/730], Loss: 0.3179\n",
      "Epoch [3/10], Phase: train, Batch: [185/730], Loss: 0.3628\n",
      "Epoch [3/10], Phase: train, Batch: [186/730], Loss: 0.3339\n",
      "Epoch [3/10], Phase: train, Batch: [187/730], Loss: 0.2826\n",
      "Epoch [3/10], Phase: train, Batch: [188/730], Loss: 0.2756\n",
      "Epoch [3/10], Phase: train, Batch: [189/730], Loss: 0.3156\n",
      "Epoch [3/10], Phase: train, Batch: [190/730], Loss: 0.2907\n",
      "Epoch [3/10], Phase: train, Batch: [191/730], Loss: 0.4106\n",
      "Epoch [3/10], Phase: train, Batch: [192/730], Loss: 0.1974\n",
      "Epoch [3/10], Phase: train, Batch: [193/730], Loss: 0.2514\n",
      "Epoch [3/10], Phase: train, Batch: [194/730], Loss: 0.2473\n",
      "Epoch [3/10], Phase: train, Batch: [195/730], Loss: 0.2945\n",
      "Epoch [3/10], Phase: train, Batch: [196/730], Loss: 0.2020\n",
      "Epoch [3/10], Phase: train, Batch: [197/730], Loss: 0.2801\n",
      "Epoch [3/10], Phase: train, Batch: [198/730], Loss: 0.4125\n",
      "Epoch [3/10], Phase: train, Batch: [199/730], Loss: 0.2925\n",
      "Epoch [3/10], Phase: train, Batch: [200/730], Loss: 0.1899\n",
      "Epoch [3/10], Phase: train, Batch: [201/730], Loss: 0.1956\n",
      "Epoch [3/10], Phase: train, Batch: [202/730], Loss: 0.3028\n",
      "Epoch [3/10], Phase: train, Batch: [203/730], Loss: 0.2915\n",
      "Epoch [3/10], Phase: train, Batch: [204/730], Loss: 0.1190\n",
      "Epoch [3/10], Phase: train, Batch: [205/730], Loss: 0.2997\n",
      "Epoch [3/10], Phase: train, Batch: [206/730], Loss: 0.2496\n",
      "Epoch [3/10], Phase: train, Batch: [207/730], Loss: 0.2049\n",
      "Epoch [3/10], Phase: train, Batch: [208/730], Loss: 0.3348\n",
      "Epoch [3/10], Phase: train, Batch: [209/730], Loss: 0.2905\n",
      "Epoch [3/10], Phase: train, Batch: [210/730], Loss: 0.4206\n",
      "Epoch [3/10], Phase: train, Batch: [211/730], Loss: 0.3724\n",
      "Epoch [3/10], Phase: train, Batch: [212/730], Loss: 0.2433\n",
      "Epoch [3/10], Phase: train, Batch: [213/730], Loss: 0.2304\n",
      "Epoch [3/10], Phase: train, Batch: [214/730], Loss: 0.3359\n",
      "Epoch [3/10], Phase: train, Batch: [215/730], Loss: 0.2554\n",
      "Epoch [3/10], Phase: train, Batch: [216/730], Loss: 0.2599\n",
      "Epoch [3/10], Phase: train, Batch: [217/730], Loss: 0.2237\n",
      "Epoch [3/10], Phase: train, Batch: [218/730], Loss: 0.2323\n",
      "Epoch [3/10], Phase: train, Batch: [219/730], Loss: 0.1793\n",
      "Epoch [3/10], Phase: train, Batch: [220/730], Loss: 0.1809\n",
      "Epoch [3/10], Phase: train, Batch: [221/730], Loss: 0.3256\n",
      "Epoch [3/10], Phase: train, Batch: [222/730], Loss: 0.2707\n",
      "Epoch [3/10], Phase: train, Batch: [223/730], Loss: 0.2988\n",
      "Epoch [3/10], Phase: train, Batch: [224/730], Loss: 0.3266\n",
      "Epoch [3/10], Phase: train, Batch: [225/730], Loss: 0.2441\n",
      "Epoch [3/10], Phase: train, Batch: [226/730], Loss: 0.2473\n",
      "Epoch [3/10], Phase: train, Batch: [227/730], Loss: 0.2673\n",
      "Epoch [3/10], Phase: train, Batch: [228/730], Loss: 0.2713\n",
      "Epoch [3/10], Phase: train, Batch: [229/730], Loss: 0.2203\n",
      "Epoch [3/10], Phase: train, Batch: [230/730], Loss: 0.3001\n",
      "Epoch [3/10], Phase: train, Batch: [231/730], Loss: 0.3369\n",
      "Epoch [3/10], Phase: train, Batch: [232/730], Loss: 0.2983\n",
      "Epoch [3/10], Phase: train, Batch: [233/730], Loss: 0.1945\n",
      "Epoch [3/10], Phase: train, Batch: [234/730], Loss: 0.2456\n",
      "Epoch [3/10], Phase: train, Batch: [235/730], Loss: 0.3361\n",
      "Epoch [3/10], Phase: train, Batch: [236/730], Loss: 0.3147\n",
      "Epoch [3/10], Phase: train, Batch: [237/730], Loss: 0.2680\n",
      "Epoch [3/10], Phase: train, Batch: [238/730], Loss: 0.2902\n",
      "Epoch [3/10], Phase: train, Batch: [239/730], Loss: 0.2267\n",
      "Epoch [3/10], Phase: train, Batch: [240/730], Loss: 0.3480\n",
      "Epoch [3/10], Phase: train, Batch: [241/730], Loss: 0.1851\n",
      "Epoch [3/10], Phase: train, Batch: [242/730], Loss: 0.2417\n",
      "Epoch [3/10], Phase: train, Batch: [243/730], Loss: 0.3753\n",
      "Epoch [3/10], Phase: train, Batch: [244/730], Loss: 0.2325\n",
      "Epoch [3/10], Phase: train, Batch: [245/730], Loss: 0.3284\n",
      "Epoch [3/10], Phase: train, Batch: [246/730], Loss: 0.2990\n",
      "Epoch [3/10], Phase: train, Batch: [247/730], Loss: 0.2648\n",
      "Epoch [3/10], Phase: train, Batch: [248/730], Loss: 0.3739\n",
      "Epoch [3/10], Phase: train, Batch: [249/730], Loss: 0.4286\n",
      "Epoch [3/10], Phase: train, Batch: [250/730], Loss: 0.2364\n",
      "Epoch [3/10], Phase: train, Batch: [251/730], Loss: 0.3418\n",
      "Epoch [3/10], Phase: train, Batch: [252/730], Loss: 0.1953\n",
      "Epoch [3/10], Phase: train, Batch: [253/730], Loss: 0.3010\n",
      "Epoch [3/10], Phase: train, Batch: [254/730], Loss: 0.2203\n",
      "Epoch [3/10], Phase: train, Batch: [255/730], Loss: 0.2982\n",
      "Epoch [3/10], Phase: train, Batch: [256/730], Loss: 0.4536\n",
      "Epoch [3/10], Phase: train, Batch: [257/730], Loss: 0.2700\n",
      "Epoch [3/10], Phase: train, Batch: [258/730], Loss: 0.2789\n",
      "Epoch [3/10], Phase: train, Batch: [259/730], Loss: 0.2015\n",
      "Epoch [3/10], Phase: train, Batch: [260/730], Loss: 0.3365\n",
      "Epoch [3/10], Phase: train, Batch: [261/730], Loss: 0.2179\n",
      "Epoch [3/10], Phase: train, Batch: [262/730], Loss: 0.2926\n",
      "Epoch [3/10], Phase: train, Batch: [263/730], Loss: 0.3576\n",
      "Epoch [3/10], Phase: train, Batch: [264/730], Loss: 0.1722\n",
      "Epoch [3/10], Phase: train, Batch: [265/730], Loss: 0.3025\n",
      "Epoch [3/10], Phase: train, Batch: [266/730], Loss: 0.3244\n",
      "Epoch [3/10], Phase: train, Batch: [267/730], Loss: 0.1568\n",
      "Epoch [3/10], Phase: train, Batch: [268/730], Loss: 0.2005\n",
      "Epoch [3/10], Phase: train, Batch: [269/730], Loss: 0.2355\n",
      "Epoch [3/10], Phase: train, Batch: [270/730], Loss: 0.1990\n",
      "Epoch [3/10], Phase: train, Batch: [271/730], Loss: 0.2351\n",
      "Epoch [3/10], Phase: train, Batch: [272/730], Loss: 0.4031\n",
      "Epoch [3/10], Phase: train, Batch: [273/730], Loss: 0.3656\n",
      "Epoch [3/10], Phase: train, Batch: [274/730], Loss: 0.2354\n",
      "Epoch [3/10], Phase: train, Batch: [275/730], Loss: 0.3818\n",
      "Epoch [3/10], Phase: train, Batch: [276/730], Loss: 0.2474\n",
      "Epoch [3/10], Phase: train, Batch: [277/730], Loss: 0.2996\n",
      "Epoch [3/10], Phase: train, Batch: [278/730], Loss: 0.3819\n",
      "Epoch [3/10], Phase: train, Batch: [279/730], Loss: 0.1703\n",
      "Epoch [3/10], Phase: train, Batch: [280/730], Loss: 0.2714\n",
      "Epoch [3/10], Phase: train, Batch: [281/730], Loss: 0.1872\n",
      "Epoch [3/10], Phase: train, Batch: [282/730], Loss: 0.2840\n",
      "Epoch [3/10], Phase: train, Batch: [283/730], Loss: 0.3414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [284/730], Loss: 0.2536\n",
      "Epoch [3/10], Phase: train, Batch: [285/730], Loss: 0.4041\n",
      "Epoch [3/10], Phase: train, Batch: [286/730], Loss: 0.3283\n",
      "Epoch [3/10], Phase: train, Batch: [287/730], Loss: 0.2958\n",
      "Epoch [3/10], Phase: train, Batch: [288/730], Loss: 0.3422\n",
      "Epoch [3/10], Phase: train, Batch: [289/730], Loss: 0.2210\n",
      "Epoch [3/10], Phase: train, Batch: [290/730], Loss: 0.2196\n",
      "Epoch [3/10], Phase: train, Batch: [291/730], Loss: 0.3229\n",
      "Epoch [3/10], Phase: train, Batch: [292/730], Loss: 0.2160\n",
      "Epoch [3/10], Phase: train, Batch: [293/730], Loss: 0.3388\n",
      "Epoch [3/10], Phase: train, Batch: [294/730], Loss: 0.2975\n",
      "Epoch [3/10], Phase: train, Batch: [295/730], Loss: 0.2861\n",
      "Epoch [3/10], Phase: train, Batch: [296/730], Loss: 0.3204\n",
      "Epoch [3/10], Phase: train, Batch: [297/730], Loss: 0.2464\n",
      "Epoch [3/10], Phase: train, Batch: [298/730], Loss: 0.2964\n",
      "Epoch [3/10], Phase: train, Batch: [299/730], Loss: 0.3881\n",
      "Epoch [3/10], Phase: train, Batch: [300/730], Loss: 0.3276\n",
      "Epoch [3/10], Phase: train, Batch: [301/730], Loss: 0.4318\n",
      "Epoch [3/10], Phase: train, Batch: [302/730], Loss: 0.3710\n",
      "Epoch [3/10], Phase: train, Batch: [303/730], Loss: 0.2935\n",
      "Epoch [3/10], Phase: train, Batch: [304/730], Loss: 0.2899\n",
      "Epoch [3/10], Phase: train, Batch: [305/730], Loss: 0.4411\n",
      "Epoch [3/10], Phase: train, Batch: [306/730], Loss: 0.3332\n",
      "Epoch [3/10], Phase: train, Batch: [307/730], Loss: 0.2618\n",
      "Epoch [3/10], Phase: train, Batch: [308/730], Loss: 0.2113\n",
      "Epoch [3/10], Phase: train, Batch: [309/730], Loss: 0.2846\n",
      "Epoch [3/10], Phase: train, Batch: [310/730], Loss: 0.4068\n",
      "Epoch [3/10], Phase: train, Batch: [311/730], Loss: 0.2031\n",
      "Epoch [3/10], Phase: train, Batch: [312/730], Loss: 0.2341\n",
      "Epoch [3/10], Phase: train, Batch: [313/730], Loss: 0.4396\n",
      "Epoch [3/10], Phase: train, Batch: [314/730], Loss: 0.2372\n",
      "Epoch [3/10], Phase: train, Batch: [315/730], Loss: 0.2907\n",
      "Epoch [3/10], Phase: train, Batch: [316/730], Loss: 0.2372\n",
      "Epoch [3/10], Phase: train, Batch: [317/730], Loss: 0.1954\n",
      "Epoch [3/10], Phase: train, Batch: [318/730], Loss: 0.1532\n",
      "Epoch [3/10], Phase: train, Batch: [319/730], Loss: 0.3167\n",
      "Epoch [3/10], Phase: train, Batch: [320/730], Loss: 0.4204\n",
      "Epoch [3/10], Phase: train, Batch: [321/730], Loss: 0.3111\n",
      "Epoch [3/10], Phase: train, Batch: [322/730], Loss: 0.5394\n",
      "Epoch [3/10], Phase: train, Batch: [323/730], Loss: 0.2504\n",
      "Epoch [3/10], Phase: train, Batch: [324/730], Loss: 0.2027\n",
      "Epoch [3/10], Phase: train, Batch: [325/730], Loss: 0.4331\n",
      "Epoch [3/10], Phase: train, Batch: [326/730], Loss: 0.2582\n",
      "Epoch [3/10], Phase: train, Batch: [327/730], Loss: 0.3204\n",
      "Epoch [3/10], Phase: train, Batch: [328/730], Loss: 0.2661\n",
      "Epoch [3/10], Phase: train, Batch: [329/730], Loss: 0.3493\n",
      "Epoch [3/10], Phase: train, Batch: [330/730], Loss: 0.2475\n",
      "Epoch [3/10], Phase: train, Batch: [331/730], Loss: 0.3857\n",
      "Epoch [3/10], Phase: train, Batch: [332/730], Loss: 0.2698\n",
      "Epoch [3/10], Phase: train, Batch: [333/730], Loss: 0.2421\n",
      "Epoch [3/10], Phase: train, Batch: [334/730], Loss: 0.1469\n",
      "Epoch [3/10], Phase: train, Batch: [335/730], Loss: 0.3458\n",
      "Epoch [3/10], Phase: train, Batch: [336/730], Loss: 0.2092\n",
      "Epoch [3/10], Phase: train, Batch: [337/730], Loss: 0.2997\n",
      "Epoch [3/10], Phase: train, Batch: [338/730], Loss: 0.1879\n",
      "Epoch [3/10], Phase: train, Batch: [339/730], Loss: 0.2712\n",
      "Epoch [3/10], Phase: train, Batch: [340/730], Loss: 0.3531\n",
      "Epoch [3/10], Phase: train, Batch: [341/730], Loss: 0.2291\n",
      "Epoch [3/10], Phase: train, Batch: [342/730], Loss: 0.2557\n",
      "Epoch [3/10], Phase: train, Batch: [343/730], Loss: 0.2990\n",
      "Epoch [3/10], Phase: train, Batch: [344/730], Loss: 0.2616\n",
      "Epoch [3/10], Phase: train, Batch: [345/730], Loss: 0.2753\n",
      "Epoch [3/10], Phase: train, Batch: [346/730], Loss: 0.2722\n",
      "Epoch [3/10], Phase: train, Batch: [347/730], Loss: 0.3494\n",
      "Epoch [3/10], Phase: train, Batch: [348/730], Loss: 0.2888\n",
      "Epoch [3/10], Phase: train, Batch: [349/730], Loss: 0.3686\n",
      "Epoch [3/10], Phase: train, Batch: [350/730], Loss: 0.3556\n",
      "Epoch [3/10], Phase: train, Batch: [351/730], Loss: 0.1494\n",
      "Epoch [3/10], Phase: train, Batch: [352/730], Loss: 0.1850\n",
      "Epoch [3/10], Phase: train, Batch: [353/730], Loss: 0.3384\n",
      "Epoch [3/10], Phase: train, Batch: [354/730], Loss: 0.2958\n",
      "Epoch [3/10], Phase: train, Batch: [355/730], Loss: 0.1617\n",
      "Epoch [3/10], Phase: train, Batch: [356/730], Loss: 0.2576\n",
      "Epoch [3/10], Phase: train, Batch: [357/730], Loss: 0.1817\n",
      "Epoch [3/10], Phase: train, Batch: [358/730], Loss: 0.2293\n",
      "Epoch [3/10], Phase: train, Batch: [359/730], Loss: 0.2399\n",
      "Epoch [3/10], Phase: train, Batch: [360/730], Loss: 0.1858\n",
      "Epoch [3/10], Phase: train, Batch: [361/730], Loss: 0.2842\n",
      "Epoch [3/10], Phase: train, Batch: [362/730], Loss: 0.3593\n",
      "Epoch [3/10], Phase: train, Batch: [363/730], Loss: 0.3381\n",
      "Epoch [3/10], Phase: train, Batch: [364/730], Loss: 0.2354\n",
      "Epoch [3/10], Phase: train, Batch: [365/730], Loss: 0.2245\n",
      "Epoch [3/10], Phase: train, Batch: [366/730], Loss: 0.2515\n",
      "Epoch [3/10], Phase: train, Batch: [367/730], Loss: 0.2221\n",
      "Epoch [3/10], Phase: train, Batch: [368/730], Loss: 0.2397\n",
      "Epoch [3/10], Phase: train, Batch: [369/730], Loss: 0.2798\n",
      "Epoch [3/10], Phase: train, Batch: [370/730], Loss: 0.3348\n",
      "Epoch [3/10], Phase: train, Batch: [371/730], Loss: 0.2663\n",
      "Epoch [3/10], Phase: train, Batch: [372/730], Loss: 0.3067\n",
      "Epoch [3/10], Phase: train, Batch: [373/730], Loss: 0.3328\n",
      "Epoch [3/10], Phase: train, Batch: [374/730], Loss: 0.2259\n",
      "Epoch [3/10], Phase: train, Batch: [375/730], Loss: 0.2399\n",
      "Epoch [3/10], Phase: train, Batch: [376/730], Loss: 0.2348\n",
      "Epoch [3/10], Phase: train, Batch: [377/730], Loss: 0.2442\n",
      "Epoch [3/10], Phase: train, Batch: [378/730], Loss: 0.2750\n",
      "Epoch [3/10], Phase: train, Batch: [379/730], Loss: 0.2739\n",
      "Epoch [3/10], Phase: train, Batch: [380/730], Loss: 0.3520\n",
      "Epoch [3/10], Phase: train, Batch: [381/730], Loss: 0.2022\n",
      "Epoch [3/10], Phase: train, Batch: [382/730], Loss: 0.3042\n",
      "Epoch [3/10], Phase: train, Batch: [383/730], Loss: 0.3198\n",
      "Epoch [3/10], Phase: train, Batch: [384/730], Loss: 0.2918\n",
      "Epoch [3/10], Phase: train, Batch: [385/730], Loss: 0.4222\n",
      "Epoch [3/10], Phase: train, Batch: [386/730], Loss: 0.3306\n",
      "Epoch [3/10], Phase: train, Batch: [387/730], Loss: 0.1792\n",
      "Epoch [3/10], Phase: train, Batch: [388/730], Loss: 0.2212\n",
      "Epoch [3/10], Phase: train, Batch: [389/730], Loss: 0.2911\n",
      "Epoch [3/10], Phase: train, Batch: [390/730], Loss: 0.2810\n",
      "Epoch [3/10], Phase: train, Batch: [391/730], Loss: 0.2569\n",
      "Epoch [3/10], Phase: train, Batch: [392/730], Loss: 0.3031\n",
      "Epoch [3/10], Phase: train, Batch: [393/730], Loss: 0.3285\n",
      "Epoch [3/10], Phase: train, Batch: [394/730], Loss: 0.1724\n",
      "Epoch [3/10], Phase: train, Batch: [395/730], Loss: 0.3530\n",
      "Epoch [3/10], Phase: train, Batch: [396/730], Loss: 0.3503\n",
      "Epoch [3/10], Phase: train, Batch: [397/730], Loss: 0.2443\n",
      "Epoch [3/10], Phase: train, Batch: [398/730], Loss: 0.3484\n",
      "Epoch [3/10], Phase: train, Batch: [399/730], Loss: 0.3847\n",
      "Epoch [3/10], Phase: train, Batch: [400/730], Loss: 0.4994\n",
      "Epoch [3/10], Phase: train, Batch: [401/730], Loss: 0.1770\n",
      "Epoch [3/10], Phase: train, Batch: [402/730], Loss: 0.2794\n",
      "Epoch [3/10], Phase: train, Batch: [403/730], Loss: 0.2369\n",
      "Epoch [3/10], Phase: train, Batch: [404/730], Loss: 0.3806\n",
      "Epoch [3/10], Phase: train, Batch: [405/730], Loss: 0.4704\n",
      "Epoch [3/10], Phase: train, Batch: [406/730], Loss: 0.1439\n",
      "Epoch [3/10], Phase: train, Batch: [407/730], Loss: 0.3857\n",
      "Epoch [3/10], Phase: train, Batch: [408/730], Loss: 0.2201\n",
      "Epoch [3/10], Phase: train, Batch: [409/730], Loss: 0.1937\n",
      "Epoch [3/10], Phase: train, Batch: [410/730], Loss: 0.2787\n",
      "Epoch [3/10], Phase: train, Batch: [411/730], Loss: 0.4115\n",
      "Epoch [3/10], Phase: train, Batch: [412/730], Loss: 0.2497\n",
      "Epoch [3/10], Phase: train, Batch: [413/730], Loss: 0.2658\n",
      "Epoch [3/10], Phase: train, Batch: [414/730], Loss: 0.3942\n",
      "Epoch [3/10], Phase: train, Batch: [415/730], Loss: 0.1801\n",
      "Epoch [3/10], Phase: train, Batch: [416/730], Loss: 0.3254\n",
      "Epoch [3/10], Phase: train, Batch: [417/730], Loss: 0.2327\n",
      "Epoch [3/10], Phase: train, Batch: [418/730], Loss: 0.3064\n",
      "Epoch [3/10], Phase: train, Batch: [419/730], Loss: 0.2982\n",
      "Epoch [3/10], Phase: train, Batch: [420/730], Loss: 0.3912\n",
      "Epoch [3/10], Phase: train, Batch: [421/730], Loss: 0.2825\n",
      "Epoch [3/10], Phase: train, Batch: [422/730], Loss: 0.3196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [423/730], Loss: 0.2095\n",
      "Epoch [3/10], Phase: train, Batch: [424/730], Loss: 0.2437\n",
      "Epoch [3/10], Phase: train, Batch: [425/730], Loss: 0.2733\n",
      "Epoch [3/10], Phase: train, Batch: [426/730], Loss: 0.2874\n",
      "Epoch [3/10], Phase: train, Batch: [427/730], Loss: 0.2170\n",
      "Epoch [3/10], Phase: train, Batch: [428/730], Loss: 0.3751\n",
      "Epoch [3/10], Phase: train, Batch: [429/730], Loss: 0.3294\n",
      "Epoch [3/10], Phase: train, Batch: [430/730], Loss: 0.2757\n",
      "Epoch [3/10], Phase: train, Batch: [431/730], Loss: 0.2879\n",
      "Epoch [3/10], Phase: train, Batch: [432/730], Loss: 0.2711\n",
      "Epoch [3/10], Phase: train, Batch: [433/730], Loss: 0.1824\n",
      "Epoch [3/10], Phase: train, Batch: [434/730], Loss: 0.3420\n",
      "Epoch [3/10], Phase: train, Batch: [435/730], Loss: 0.3340\n",
      "Epoch [3/10], Phase: train, Batch: [436/730], Loss: 0.2477\n",
      "Epoch [3/10], Phase: train, Batch: [437/730], Loss: 0.3021\n",
      "Epoch [3/10], Phase: train, Batch: [438/730], Loss: 0.2340\n",
      "Epoch [3/10], Phase: train, Batch: [439/730], Loss: 0.2444\n",
      "Epoch [3/10], Phase: train, Batch: [440/730], Loss: 0.4379\n",
      "Epoch [3/10], Phase: train, Batch: [441/730], Loss: 0.2718\n",
      "Epoch [3/10], Phase: train, Batch: [442/730], Loss: 0.3773\n",
      "Epoch [3/10], Phase: train, Batch: [443/730], Loss: 0.1940\n",
      "Epoch [3/10], Phase: train, Batch: [444/730], Loss: 0.3391\n",
      "Epoch [3/10], Phase: train, Batch: [445/730], Loss: 0.1953\n",
      "Epoch [3/10], Phase: train, Batch: [446/730], Loss: 0.2114\n",
      "Epoch [3/10], Phase: train, Batch: [447/730], Loss: 0.2112\n",
      "Epoch [3/10], Phase: train, Batch: [448/730], Loss: 0.2725\n",
      "Epoch [3/10], Phase: train, Batch: [449/730], Loss: 0.2984\n",
      "Epoch [3/10], Phase: train, Batch: [450/730], Loss: 0.2806\n",
      "Epoch [3/10], Phase: train, Batch: [451/730], Loss: 0.4172\n",
      "Epoch [3/10], Phase: train, Batch: [452/730], Loss: 0.4766\n",
      "Epoch [3/10], Phase: train, Batch: [453/730], Loss: 0.1771\n",
      "Epoch [3/10], Phase: train, Batch: [454/730], Loss: 0.4240\n",
      "Epoch [3/10], Phase: train, Batch: [455/730], Loss: 0.3272\n",
      "Epoch [3/10], Phase: train, Batch: [456/730], Loss: 0.2275\n",
      "Epoch [3/10], Phase: train, Batch: [457/730], Loss: 0.3680\n",
      "Epoch [3/10], Phase: train, Batch: [458/730], Loss: 0.2239\n",
      "Epoch [3/10], Phase: train, Batch: [459/730], Loss: 0.2610\n",
      "Epoch [3/10], Phase: train, Batch: [460/730], Loss: 0.2569\n",
      "Epoch [3/10], Phase: train, Batch: [461/730], Loss: 0.2662\n",
      "Epoch [3/10], Phase: train, Batch: [462/730], Loss: 0.2443\n",
      "Epoch [3/10], Phase: train, Batch: [463/730], Loss: 0.3834\n",
      "Epoch [3/10], Phase: train, Batch: [464/730], Loss: 0.2461\n",
      "Epoch [3/10], Phase: train, Batch: [465/730], Loss: 0.3782\n",
      "Epoch [3/10], Phase: train, Batch: [466/730], Loss: 0.3522\n",
      "Epoch [3/10], Phase: train, Batch: [467/730], Loss: 0.2758\n",
      "Epoch [3/10], Phase: train, Batch: [468/730], Loss: 0.3830\n",
      "Epoch [3/10], Phase: train, Batch: [469/730], Loss: 0.3202\n",
      "Epoch [3/10], Phase: train, Batch: [470/730], Loss: 0.1849\n",
      "Epoch [3/10], Phase: train, Batch: [471/730], Loss: 0.3529\n",
      "Epoch [3/10], Phase: train, Batch: [472/730], Loss: 0.3176\n",
      "Epoch [3/10], Phase: train, Batch: [473/730], Loss: 0.2732\n",
      "Epoch [3/10], Phase: train, Batch: [474/730], Loss: 0.1532\n",
      "Epoch [3/10], Phase: train, Batch: [475/730], Loss: 0.3010\n",
      "Epoch [3/10], Phase: train, Batch: [476/730], Loss: 0.4384\n",
      "Epoch [3/10], Phase: train, Batch: [477/730], Loss: 0.4059\n",
      "Epoch [3/10], Phase: train, Batch: [478/730], Loss: 0.3673\n",
      "Epoch [3/10], Phase: train, Batch: [479/730], Loss: 0.2133\n",
      "Epoch [3/10], Phase: train, Batch: [480/730], Loss: 0.1859\n",
      "Epoch [3/10], Phase: train, Batch: [481/730], Loss: 0.3290\n",
      "Epoch [3/10], Phase: train, Batch: [482/730], Loss: 0.2774\n",
      "Epoch [3/10], Phase: train, Batch: [483/730], Loss: 0.2939\n",
      "Epoch [3/10], Phase: train, Batch: [484/730], Loss: 0.1745\n",
      "Epoch [3/10], Phase: train, Batch: [485/730], Loss: 0.1823\n",
      "Epoch [3/10], Phase: train, Batch: [486/730], Loss: 0.3799\n",
      "Epoch [3/10], Phase: train, Batch: [487/730], Loss: 0.4066\n",
      "Epoch [3/10], Phase: train, Batch: [488/730], Loss: 0.1993\n",
      "Epoch [3/10], Phase: train, Batch: [489/730], Loss: 0.2713\n",
      "Epoch [3/10], Phase: train, Batch: [490/730], Loss: 0.3259\n",
      "Epoch [3/10], Phase: train, Batch: [491/730], Loss: 0.1870\n",
      "Epoch [3/10], Phase: train, Batch: [492/730], Loss: 0.2323\n",
      "Epoch [3/10], Phase: train, Batch: [493/730], Loss: 0.2799\n",
      "Epoch [3/10], Phase: train, Batch: [494/730], Loss: 0.2594\n",
      "Epoch [3/10], Phase: train, Batch: [495/730], Loss: 0.2362\n",
      "Epoch [3/10], Phase: train, Batch: [496/730], Loss: 0.2591\n",
      "Epoch [3/10], Phase: train, Batch: [497/730], Loss: 0.2450\n",
      "Epoch [3/10], Phase: train, Batch: [498/730], Loss: 0.3206\n",
      "Epoch [3/10], Phase: train, Batch: [499/730], Loss: 0.3216\n",
      "Epoch [3/10], Phase: train, Batch: [500/730], Loss: 0.2159\n",
      "Epoch [3/10], Phase: train, Batch: [501/730], Loss: 0.2650\n",
      "Epoch [3/10], Phase: train, Batch: [502/730], Loss: 0.3463\n",
      "Epoch [3/10], Phase: train, Batch: [503/730], Loss: 0.3656\n",
      "Epoch [3/10], Phase: train, Batch: [504/730], Loss: 0.2620\n",
      "Epoch [3/10], Phase: train, Batch: [505/730], Loss: 0.3706\n",
      "Epoch [3/10], Phase: train, Batch: [506/730], Loss: 0.3372\n",
      "Epoch [3/10], Phase: train, Batch: [507/730], Loss: 0.4012\n",
      "Epoch [3/10], Phase: train, Batch: [508/730], Loss: 0.2339\n",
      "Epoch [3/10], Phase: train, Batch: [509/730], Loss: 0.2912\n",
      "Epoch [3/10], Phase: train, Batch: [510/730], Loss: 0.3809\n",
      "Epoch [3/10], Phase: train, Batch: [511/730], Loss: 0.1516\n",
      "Epoch [3/10], Phase: train, Batch: [512/730], Loss: 0.2241\n",
      "Epoch [3/10], Phase: train, Batch: [513/730], Loss: 0.3193\n",
      "Epoch [3/10], Phase: train, Batch: [514/730], Loss: 0.3151\n",
      "Epoch [3/10], Phase: train, Batch: [515/730], Loss: 0.2592\n",
      "Epoch [3/10], Phase: train, Batch: [516/730], Loss: 0.2438\n",
      "Epoch [3/10], Phase: train, Batch: [517/730], Loss: 0.1622\n",
      "Epoch [3/10], Phase: train, Batch: [518/730], Loss: 0.2855\n",
      "Epoch [3/10], Phase: train, Batch: [519/730], Loss: 0.2726\n",
      "Epoch [3/10], Phase: train, Batch: [520/730], Loss: 0.2567\n",
      "Epoch [3/10], Phase: train, Batch: [521/730], Loss: 0.2246\n",
      "Epoch [3/10], Phase: train, Batch: [522/730], Loss: 0.3223\n",
      "Epoch [3/10], Phase: train, Batch: [523/730], Loss: 0.4045\n",
      "Epoch [3/10], Phase: train, Batch: [524/730], Loss: 0.2399\n",
      "Epoch [3/10], Phase: train, Batch: [525/730], Loss: 0.3406\n",
      "Epoch [3/10], Phase: train, Batch: [526/730], Loss: 0.2304\n",
      "Epoch [3/10], Phase: train, Batch: [527/730], Loss: 0.2392\n",
      "Epoch [3/10], Phase: train, Batch: [528/730], Loss: 0.4016\n",
      "Epoch [3/10], Phase: train, Batch: [529/730], Loss: 0.1852\n",
      "Epoch [3/10], Phase: train, Batch: [530/730], Loss: 0.2599\n",
      "Epoch [3/10], Phase: train, Batch: [531/730], Loss: 0.3164\n",
      "Epoch [3/10], Phase: train, Batch: [532/730], Loss: 0.1973\n",
      "Epoch [3/10], Phase: train, Batch: [533/730], Loss: 0.2315\n",
      "Epoch [3/10], Phase: train, Batch: [534/730], Loss: 0.2593\n",
      "Epoch [3/10], Phase: train, Batch: [535/730], Loss: 0.3046\n",
      "Epoch [3/10], Phase: train, Batch: [536/730], Loss: 0.1625\n",
      "Epoch [3/10], Phase: train, Batch: [537/730], Loss: 0.2371\n",
      "Epoch [3/10], Phase: train, Batch: [538/730], Loss: 0.2636\n",
      "Epoch [3/10], Phase: train, Batch: [539/730], Loss: 0.2833\n",
      "Epoch [3/10], Phase: train, Batch: [540/730], Loss: 0.2401\n",
      "Epoch [3/10], Phase: train, Batch: [541/730], Loss: 0.4204\n",
      "Epoch [3/10], Phase: train, Batch: [542/730], Loss: 0.3369\n",
      "Epoch [3/10], Phase: train, Batch: [543/730], Loss: 0.2556\n",
      "Epoch [3/10], Phase: train, Batch: [544/730], Loss: 0.1759\n",
      "Epoch [3/10], Phase: train, Batch: [545/730], Loss: 0.3507\n",
      "Epoch [3/10], Phase: train, Batch: [546/730], Loss: 0.1553\n",
      "Epoch [3/10], Phase: train, Batch: [547/730], Loss: 0.1424\n",
      "Epoch [3/10], Phase: train, Batch: [548/730], Loss: 0.3003\n",
      "Epoch [3/10], Phase: train, Batch: [549/730], Loss: 0.3805\n",
      "Epoch [3/10], Phase: train, Batch: [550/730], Loss: 0.3106\n",
      "Epoch [3/10], Phase: train, Batch: [551/730], Loss: 0.3893\n",
      "Epoch [3/10], Phase: train, Batch: [552/730], Loss: 0.4024\n",
      "Epoch [3/10], Phase: train, Batch: [553/730], Loss: 0.3023\n",
      "Epoch [3/10], Phase: train, Batch: [554/730], Loss: 0.1910\n",
      "Epoch [3/10], Phase: train, Batch: [555/730], Loss: 0.2176\n",
      "Epoch [3/10], Phase: train, Batch: [556/730], Loss: 0.2408\n",
      "Epoch [3/10], Phase: train, Batch: [557/730], Loss: 0.2421\n",
      "Epoch [3/10], Phase: train, Batch: [558/730], Loss: 0.1890\n",
      "Epoch [3/10], Phase: train, Batch: [559/730], Loss: 0.3309\n",
      "Epoch [3/10], Phase: train, Batch: [560/730], Loss: 0.2840\n",
      "Epoch [3/10], Phase: train, Batch: [561/730], Loss: 0.1912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [562/730], Loss: 0.2129\n",
      "Epoch [3/10], Phase: train, Batch: [563/730], Loss: 0.2974\n",
      "Epoch [3/10], Phase: train, Batch: [564/730], Loss: 0.1574\n",
      "Epoch [3/10], Phase: train, Batch: [565/730], Loss: 0.2117\n",
      "Epoch [3/10], Phase: train, Batch: [566/730], Loss: 0.1640\n",
      "Epoch [3/10], Phase: train, Batch: [567/730], Loss: 0.3254\n",
      "Epoch [3/10], Phase: train, Batch: [568/730], Loss: 0.3010\n",
      "Epoch [3/10], Phase: train, Batch: [569/730], Loss: 0.2825\n",
      "Epoch [3/10], Phase: train, Batch: [570/730], Loss: 0.1430\n",
      "Epoch [3/10], Phase: train, Batch: [571/730], Loss: 0.2299\n",
      "Epoch [3/10], Phase: train, Batch: [572/730], Loss: 0.2266\n",
      "Epoch [3/10], Phase: train, Batch: [573/730], Loss: 0.3109\n",
      "Epoch [3/10], Phase: train, Batch: [574/730], Loss: 0.4517\n",
      "Epoch [3/10], Phase: train, Batch: [575/730], Loss: 0.3310\n",
      "Epoch [3/10], Phase: train, Batch: [576/730], Loss: 0.2858\n",
      "Epoch [3/10], Phase: train, Batch: [577/730], Loss: 0.2769\n",
      "Epoch [3/10], Phase: train, Batch: [578/730], Loss: 0.2830\n",
      "Epoch [3/10], Phase: train, Batch: [579/730], Loss: 0.2984\n",
      "Epoch [3/10], Phase: train, Batch: [580/730], Loss: 0.3632\n",
      "Epoch [3/10], Phase: train, Batch: [581/730], Loss: 0.2212\n",
      "Epoch [3/10], Phase: train, Batch: [582/730], Loss: 0.3478\n",
      "Epoch [3/10], Phase: train, Batch: [583/730], Loss: 0.2082\n",
      "Epoch [3/10], Phase: train, Batch: [584/730], Loss: 0.2197\n",
      "Epoch [3/10], Phase: train, Batch: [585/730], Loss: 0.2128\n",
      "Epoch [3/10], Phase: train, Batch: [586/730], Loss: 0.3266\n",
      "Epoch [3/10], Phase: train, Batch: [587/730], Loss: 0.2488\n",
      "Epoch [3/10], Phase: train, Batch: [588/730], Loss: 0.2370\n",
      "Epoch [3/10], Phase: train, Batch: [589/730], Loss: 0.2777\n",
      "Epoch [3/10], Phase: train, Batch: [590/730], Loss: 0.2079\n",
      "Epoch [3/10], Phase: train, Batch: [591/730], Loss: 0.2578\n",
      "Epoch [3/10], Phase: train, Batch: [592/730], Loss: 0.2934\n",
      "Epoch [3/10], Phase: train, Batch: [593/730], Loss: 0.2396\n",
      "Epoch [3/10], Phase: train, Batch: [594/730], Loss: 0.1153\n",
      "Epoch [3/10], Phase: train, Batch: [595/730], Loss: 0.2605\n",
      "Epoch [3/10], Phase: train, Batch: [596/730], Loss: 0.3174\n",
      "Epoch [3/10], Phase: train, Batch: [597/730], Loss: 0.1744\n",
      "Epoch [3/10], Phase: train, Batch: [598/730], Loss: 0.3355\n",
      "Epoch [3/10], Phase: train, Batch: [599/730], Loss: 0.2719\n",
      "Epoch [3/10], Phase: train, Batch: [600/730], Loss: 0.2717\n",
      "Epoch [3/10], Phase: train, Batch: [601/730], Loss: 0.4637\n",
      "Epoch [3/10], Phase: train, Batch: [602/730], Loss: 0.3133\n",
      "Epoch [3/10], Phase: train, Batch: [603/730], Loss: 0.2740\n",
      "Epoch [3/10], Phase: train, Batch: [604/730], Loss: 0.3758\n",
      "Epoch [3/10], Phase: train, Batch: [605/730], Loss: 0.2778\n",
      "Epoch [3/10], Phase: train, Batch: [606/730], Loss: 0.2725\n",
      "Epoch [3/10], Phase: train, Batch: [607/730], Loss: 0.3576\n",
      "Epoch [3/10], Phase: train, Batch: [608/730], Loss: 0.2147\n",
      "Epoch [3/10], Phase: train, Batch: [609/730], Loss: 0.2783\n",
      "Epoch [3/10], Phase: train, Batch: [610/730], Loss: 0.4605\n",
      "Epoch [3/10], Phase: train, Batch: [611/730], Loss: 0.3333\n",
      "Epoch [3/10], Phase: train, Batch: [612/730], Loss: 0.3701\n",
      "Epoch [3/10], Phase: train, Batch: [613/730], Loss: 0.2097\n",
      "Epoch [3/10], Phase: train, Batch: [614/730], Loss: 0.3403\n",
      "Epoch [3/10], Phase: train, Batch: [615/730], Loss: 0.3683\n",
      "Epoch [3/10], Phase: train, Batch: [616/730], Loss: 0.3591\n",
      "Epoch [3/10], Phase: train, Batch: [617/730], Loss: 0.2872\n",
      "Epoch [3/10], Phase: train, Batch: [618/730], Loss: 0.2274\n",
      "Epoch [3/10], Phase: train, Batch: [619/730], Loss: 0.2500\n",
      "Epoch [3/10], Phase: train, Batch: [620/730], Loss: 0.3039\n",
      "Epoch [3/10], Phase: train, Batch: [621/730], Loss: 0.3020\n",
      "Epoch [3/10], Phase: train, Batch: [622/730], Loss: 0.2766\n",
      "Epoch [3/10], Phase: train, Batch: [623/730], Loss: 0.2775\n",
      "Epoch [3/10], Phase: train, Batch: [624/730], Loss: 0.2762\n",
      "Epoch [3/10], Phase: train, Batch: [625/730], Loss: 0.3179\n",
      "Epoch [3/10], Phase: train, Batch: [626/730], Loss: 0.2326\n",
      "Epoch [3/10], Phase: train, Batch: [627/730], Loss: 0.2475\n",
      "Epoch [3/10], Phase: train, Batch: [628/730], Loss: 0.2837\n",
      "Epoch [3/10], Phase: train, Batch: [629/730], Loss: 0.3438\n",
      "Epoch [3/10], Phase: train, Batch: [630/730], Loss: 0.3610\n",
      "Epoch [3/10], Phase: train, Batch: [631/730], Loss: 0.2183\n",
      "Epoch [3/10], Phase: train, Batch: [632/730], Loss: 0.4711\n",
      "Epoch [3/10], Phase: train, Batch: [633/730], Loss: 0.2840\n",
      "Epoch [3/10], Phase: train, Batch: [634/730], Loss: 0.2751\n",
      "Epoch [3/10], Phase: train, Batch: [635/730], Loss: 0.3399\n",
      "Epoch [3/10], Phase: train, Batch: [636/730], Loss: 0.1497\n",
      "Epoch [3/10], Phase: train, Batch: [637/730], Loss: 0.2763\n",
      "Epoch [3/10], Phase: train, Batch: [638/730], Loss: 0.3295\n",
      "Epoch [3/10], Phase: train, Batch: [639/730], Loss: 0.1945\n",
      "Epoch [3/10], Phase: train, Batch: [640/730], Loss: 0.3311\n",
      "Epoch [3/10], Phase: train, Batch: [641/730], Loss: 0.4283\n",
      "Epoch [3/10], Phase: train, Batch: [642/730], Loss: 0.2417\n",
      "Epoch [3/10], Phase: train, Batch: [643/730], Loss: 0.2686\n",
      "Epoch [3/10], Phase: train, Batch: [644/730], Loss: 0.3087\n",
      "Epoch [3/10], Phase: train, Batch: [645/730], Loss: 0.3756\n",
      "Epoch [3/10], Phase: train, Batch: [646/730], Loss: 0.2326\n",
      "Epoch [3/10], Phase: train, Batch: [647/730], Loss: 0.1785\n",
      "Epoch [3/10], Phase: train, Batch: [648/730], Loss: 0.2526\n",
      "Epoch [3/10], Phase: train, Batch: [649/730], Loss: 0.2712\n",
      "Epoch [3/10], Phase: train, Batch: [650/730], Loss: 0.2121\n",
      "Epoch [3/10], Phase: train, Batch: [651/730], Loss: 0.2046\n",
      "Epoch [3/10], Phase: train, Batch: [652/730], Loss: 0.2693\n",
      "Epoch [3/10], Phase: train, Batch: [653/730], Loss: 0.2704\n",
      "Epoch [3/10], Phase: train, Batch: [654/730], Loss: 0.3271\n",
      "Epoch [3/10], Phase: train, Batch: [655/730], Loss: 0.1960\n",
      "Epoch [3/10], Phase: train, Batch: [656/730], Loss: 0.3438\n",
      "Epoch [3/10], Phase: train, Batch: [657/730], Loss: 0.2905\n",
      "Epoch [3/10], Phase: train, Batch: [658/730], Loss: 0.3100\n",
      "Epoch [3/10], Phase: train, Batch: [659/730], Loss: 0.4114\n",
      "Epoch [3/10], Phase: train, Batch: [660/730], Loss: 0.2978\n",
      "Epoch [3/10], Phase: train, Batch: [661/730], Loss: 0.2255\n",
      "Epoch [3/10], Phase: train, Batch: [662/730], Loss: 0.4140\n",
      "Epoch [3/10], Phase: train, Batch: [663/730], Loss: 0.2467\n",
      "Epoch [3/10], Phase: train, Batch: [664/730], Loss: 0.3445\n",
      "Epoch [3/10], Phase: train, Batch: [665/730], Loss: 0.3280\n",
      "Epoch [3/10], Phase: train, Batch: [666/730], Loss: 0.2563\n",
      "Epoch [3/10], Phase: train, Batch: [667/730], Loss: 0.3243\n",
      "Epoch [3/10], Phase: train, Batch: [668/730], Loss: 0.2462\n",
      "Epoch [3/10], Phase: train, Batch: [669/730], Loss: 0.3178\n",
      "Epoch [3/10], Phase: train, Batch: [670/730], Loss: 0.2122\n",
      "Epoch [3/10], Phase: train, Batch: [671/730], Loss: 0.2971\n",
      "Epoch [3/10], Phase: train, Batch: [672/730], Loss: 0.3418\n",
      "Epoch [3/10], Phase: train, Batch: [673/730], Loss: 0.2808\n",
      "Epoch [3/10], Phase: train, Batch: [674/730], Loss: 0.3375\n",
      "Epoch [3/10], Phase: train, Batch: [675/730], Loss: 0.2956\n",
      "Epoch [3/10], Phase: train, Batch: [676/730], Loss: 0.3323\n",
      "Epoch [3/10], Phase: train, Batch: [677/730], Loss: 0.2823\n",
      "Epoch [3/10], Phase: train, Batch: [678/730], Loss: 0.2640\n",
      "Epoch [3/10], Phase: train, Batch: [679/730], Loss: 0.2905\n",
      "Epoch [3/10], Phase: train, Batch: [680/730], Loss: 0.3384\n",
      "Epoch [3/10], Phase: train, Batch: [681/730], Loss: 0.2661\n",
      "Epoch [3/10], Phase: train, Batch: [682/730], Loss: 0.3514\n",
      "Epoch [3/10], Phase: train, Batch: [683/730], Loss: 0.4092\n",
      "Epoch [3/10], Phase: train, Batch: [684/730], Loss: 0.4403\n",
      "Epoch [3/10], Phase: train, Batch: [685/730], Loss: 0.3331\n",
      "Epoch [3/10], Phase: train, Batch: [686/730], Loss: 0.3879\n",
      "Epoch [3/10], Phase: train, Batch: [687/730], Loss: 0.3562\n",
      "Epoch [3/10], Phase: train, Batch: [688/730], Loss: 0.2300\n",
      "Epoch [3/10], Phase: train, Batch: [689/730], Loss: 0.2845\n",
      "Epoch [3/10], Phase: train, Batch: [690/730], Loss: 0.2376\n",
      "Epoch [3/10], Phase: train, Batch: [691/730], Loss: 0.3907\n",
      "Epoch [3/10], Phase: train, Batch: [692/730], Loss: 0.4626\n",
      "Epoch [3/10], Phase: train, Batch: [693/730], Loss: 0.4338\n",
      "Epoch [3/10], Phase: train, Batch: [694/730], Loss: 0.4138\n",
      "Epoch [3/10], Phase: train, Batch: [695/730], Loss: 0.2589\n",
      "Epoch [3/10], Phase: train, Batch: [696/730], Loss: 0.2759\n",
      "Epoch [3/10], Phase: train, Batch: [697/730], Loss: 0.2226\n",
      "Epoch [3/10], Phase: train, Batch: [698/730], Loss: 0.2261\n",
      "Epoch [3/10], Phase: train, Batch: [699/730], Loss: 0.1745\n",
      "Epoch [3/10], Phase: train, Batch: [700/730], Loss: 0.2619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [701/730], Loss: 0.3216\n",
      "Epoch [3/10], Phase: train, Batch: [702/730], Loss: 0.3367\n",
      "Epoch [3/10], Phase: train, Batch: [703/730], Loss: 0.2089\n",
      "Epoch [3/10], Phase: train, Batch: [704/730], Loss: 0.2643\n",
      "Epoch [3/10], Phase: train, Batch: [705/730], Loss: 0.3874\n",
      "Epoch [3/10], Phase: train, Batch: [706/730], Loss: 0.2501\n",
      "Epoch [3/10], Phase: train, Batch: [707/730], Loss: 0.2378\n",
      "Epoch [3/10], Phase: train, Batch: [708/730], Loss: 0.2970\n",
      "Epoch [3/10], Phase: train, Batch: [709/730], Loss: 0.2530\n",
      "Epoch [3/10], Phase: train, Batch: [710/730], Loss: 0.1709\n",
      "Epoch [3/10], Phase: train, Batch: [711/730], Loss: 0.2999\n",
      "Epoch [3/10], Phase: train, Batch: [712/730], Loss: 0.1718\n",
      "Epoch [3/10], Phase: train, Batch: [713/730], Loss: 0.3694\n",
      "Epoch [3/10], Phase: train, Batch: [714/730], Loss: 0.3308\n",
      "Epoch [3/10], Phase: train, Batch: [715/730], Loss: 0.3120\n",
      "Epoch [3/10], Phase: train, Batch: [716/730], Loss: 0.2443\n",
      "Epoch [3/10], Phase: train, Batch: [717/730], Loss: 0.2848\n",
      "Epoch [3/10], Phase: train, Batch: [718/730], Loss: 0.1323\n",
      "Epoch [3/10], Phase: train, Batch: [719/730], Loss: 0.2822\n",
      "Epoch [3/10], Phase: train, Batch: [720/730], Loss: 0.3135\n",
      "Epoch [3/10], Phase: train, Batch: [721/730], Loss: 0.2862\n",
      "Epoch [3/10], Phase: train, Batch: [722/730], Loss: 0.3656\n",
      "Epoch [3/10], Phase: train, Batch: [723/730], Loss: 0.3474\n",
      "Epoch [3/10], Phase: train, Batch: [724/730], Loss: 0.2921\n",
      "Epoch [3/10], Phase: train, Batch: [725/730], Loss: 0.3242\n",
      "Epoch [3/10], Phase: train, Batch: [726/730], Loss: 0.1725\n",
      "Epoch [3/10], Phase: train, Batch: [727/730], Loss: 0.4105\n",
      "Epoch [3/10], Phase: train, Batch: [728/730], Loss: 0.4120\n",
      "Epoch [3/10], Phase: train, Batch: [729/730], Loss: 0.3801\n",
      "Epoch [3/10], Phase: train, Batch: [730/730], Loss: 0.4352\n",
      "train Loss: 0.2869 Acc: 0.8844\n",
      "Epoch [3/10], Phase: val, Batch: [1/182], Loss: 0.3055\n",
      "Epoch [3/10], Phase: val, Batch: [2/182], Loss: 0.2192\n",
      "Epoch [3/10], Phase: val, Batch: [3/182], Loss: 0.1586\n",
      "Epoch [3/10], Phase: val, Batch: [4/182], Loss: 0.2477\n",
      "Epoch [3/10], Phase: val, Batch: [5/182], Loss: 0.1985\n",
      "Epoch [3/10], Phase: val, Batch: [6/182], Loss: 0.1671\n",
      "Epoch [3/10], Phase: val, Batch: [7/182], Loss: 0.0962\n",
      "Epoch [3/10], Phase: val, Batch: [8/182], Loss: 0.2370\n",
      "Epoch [3/10], Phase: val, Batch: [9/182], Loss: 0.1976\n",
      "Epoch [3/10], Phase: val, Batch: [10/182], Loss: 0.1604\n",
      "Epoch [3/10], Phase: val, Batch: [11/182], Loss: 0.1371\n",
      "Epoch [3/10], Phase: val, Batch: [12/182], Loss: 0.2197\n",
      "Epoch [3/10], Phase: val, Batch: [13/182], Loss: 0.1683\n",
      "Epoch [3/10], Phase: val, Batch: [14/182], Loss: 0.1244\n",
      "Epoch [3/10], Phase: val, Batch: [15/182], Loss: 0.1808\n",
      "Epoch [3/10], Phase: val, Batch: [16/182], Loss: 0.2294\n",
      "Epoch [3/10], Phase: val, Batch: [17/182], Loss: 0.2138\n",
      "Epoch [3/10], Phase: val, Batch: [18/182], Loss: 0.1959\n",
      "Epoch [3/10], Phase: val, Batch: [19/182], Loss: 0.3011\n",
      "Epoch [3/10], Phase: val, Batch: [20/182], Loss: 0.3156\n",
      "Epoch [3/10], Phase: val, Batch: [21/182], Loss: 0.3033\n",
      "Epoch [3/10], Phase: val, Batch: [22/182], Loss: 0.2988\n",
      "Epoch [3/10], Phase: val, Batch: [23/182], Loss: 0.1574\n",
      "Epoch [3/10], Phase: val, Batch: [24/182], Loss: 0.3206\n",
      "Epoch [3/10], Phase: val, Batch: [25/182], Loss: 0.2357\n",
      "Epoch [3/10], Phase: val, Batch: [26/182], Loss: 0.1457\n",
      "Epoch [3/10], Phase: val, Batch: [27/182], Loss: 0.1877\n",
      "Epoch [3/10], Phase: val, Batch: [28/182], Loss: 0.3177\n",
      "Epoch [3/10], Phase: val, Batch: [29/182], Loss: 0.2557\n",
      "Epoch [3/10], Phase: val, Batch: [30/182], Loss: 0.2538\n",
      "Epoch [3/10], Phase: val, Batch: [31/182], Loss: 0.3100\n",
      "Epoch [3/10], Phase: val, Batch: [32/182], Loss: 0.1262\n",
      "Epoch [3/10], Phase: val, Batch: [33/182], Loss: 0.2332\n",
      "Epoch [3/10], Phase: val, Batch: [34/182], Loss: 0.2343\n",
      "Epoch [3/10], Phase: val, Batch: [35/182], Loss: 0.1406\n",
      "Epoch [3/10], Phase: val, Batch: [36/182], Loss: 0.2121\n",
      "Epoch [3/10], Phase: val, Batch: [37/182], Loss: 0.1449\n",
      "Epoch [3/10], Phase: val, Batch: [38/182], Loss: 0.1577\n",
      "Epoch [3/10], Phase: val, Batch: [39/182], Loss: 0.2609\n",
      "Epoch [3/10], Phase: val, Batch: [40/182], Loss: 0.2086\n",
      "Epoch [3/10], Phase: val, Batch: [41/182], Loss: 0.1916\n",
      "Epoch [3/10], Phase: val, Batch: [42/182], Loss: 0.2389\n",
      "Epoch [3/10], Phase: val, Batch: [43/182], Loss: 0.1765\n",
      "Epoch [3/10], Phase: val, Batch: [44/182], Loss: 0.2792\n",
      "Epoch [3/10], Phase: val, Batch: [45/182], Loss: 0.2552\n",
      "Epoch [3/10], Phase: val, Batch: [46/182], Loss: 0.1801\n",
      "Epoch [3/10], Phase: val, Batch: [47/182], Loss: 0.2546\n",
      "Epoch [3/10], Phase: val, Batch: [48/182], Loss: 0.1085\n",
      "Epoch [3/10], Phase: val, Batch: [49/182], Loss: 0.2437\n",
      "Epoch [3/10], Phase: val, Batch: [50/182], Loss: 0.3059\n",
      "Epoch [3/10], Phase: val, Batch: [51/182], Loss: 0.3356\n",
      "Epoch [3/10], Phase: val, Batch: [52/182], Loss: 0.2043\n",
      "Epoch [3/10], Phase: val, Batch: [53/182], Loss: 0.2038\n",
      "Epoch [3/10], Phase: val, Batch: [54/182], Loss: 0.2581\n",
      "Epoch [3/10], Phase: val, Batch: [55/182], Loss: 0.1594\n",
      "Epoch [3/10], Phase: val, Batch: [56/182], Loss: 0.1630\n",
      "Epoch [3/10], Phase: val, Batch: [57/182], Loss: 0.2027\n",
      "Epoch [3/10], Phase: val, Batch: [58/182], Loss: 0.1821\n",
      "Epoch [3/10], Phase: val, Batch: [59/182], Loss: 0.1611\n",
      "Epoch [3/10], Phase: val, Batch: [60/182], Loss: 0.1445\n",
      "Epoch [3/10], Phase: val, Batch: [61/182], Loss: 0.2614\n",
      "Epoch [3/10], Phase: val, Batch: [62/182], Loss: 0.3270\n",
      "Epoch [3/10], Phase: val, Batch: [63/182], Loss: 0.1621\n",
      "Epoch [3/10], Phase: val, Batch: [64/182], Loss: 0.2523\n",
      "Epoch [3/10], Phase: val, Batch: [65/182], Loss: 0.1692\n",
      "Epoch [3/10], Phase: val, Batch: [66/182], Loss: 0.2369\n",
      "Epoch [3/10], Phase: val, Batch: [67/182], Loss: 0.1907\n",
      "Epoch [3/10], Phase: val, Batch: [68/182], Loss: 0.1903\n",
      "Epoch [3/10], Phase: val, Batch: [69/182], Loss: 0.2402\n",
      "Epoch [3/10], Phase: val, Batch: [70/182], Loss: 0.2081\n",
      "Epoch [3/10], Phase: val, Batch: [71/182], Loss: 0.3189\n",
      "Epoch [3/10], Phase: val, Batch: [72/182], Loss: 0.1870\n",
      "Epoch [3/10], Phase: val, Batch: [73/182], Loss: 0.1528\n",
      "Epoch [3/10], Phase: val, Batch: [74/182], Loss: 0.3197\n",
      "Epoch [3/10], Phase: val, Batch: [75/182], Loss: 0.1978\n",
      "Epoch [3/10], Phase: val, Batch: [76/182], Loss: 0.1515\n",
      "Epoch [3/10], Phase: val, Batch: [77/182], Loss: 0.1455\n",
      "Epoch [3/10], Phase: val, Batch: [78/182], Loss: 0.1393\n",
      "Epoch [3/10], Phase: val, Batch: [79/182], Loss: 0.2017\n",
      "Epoch [3/10], Phase: val, Batch: [80/182], Loss: 0.1669\n",
      "Epoch [3/10], Phase: val, Batch: [81/182], Loss: 0.1171\n",
      "Epoch [3/10], Phase: val, Batch: [82/182], Loss: 0.1743\n",
      "Epoch [3/10], Phase: val, Batch: [83/182], Loss: 0.1854\n",
      "Epoch [3/10], Phase: val, Batch: [84/182], Loss: 0.1944\n",
      "Epoch [3/10], Phase: val, Batch: [85/182], Loss: 0.1793\n",
      "Epoch [3/10], Phase: val, Batch: [86/182], Loss: 0.2460\n",
      "Epoch [3/10], Phase: val, Batch: [87/182], Loss: 0.3334\n",
      "Epoch [3/10], Phase: val, Batch: [88/182], Loss: 0.2392\n",
      "Epoch [3/10], Phase: val, Batch: [89/182], Loss: 0.2145\n",
      "Epoch [3/10], Phase: val, Batch: [90/182], Loss: 0.2613\n",
      "Epoch [3/10], Phase: val, Batch: [91/182], Loss: 0.2528\n",
      "Epoch [3/10], Phase: val, Batch: [92/182], Loss: 0.2385\n",
      "Epoch [3/10], Phase: val, Batch: [93/182], Loss: 0.1953\n",
      "Epoch [3/10], Phase: val, Batch: [94/182], Loss: 0.2112\n",
      "Epoch [3/10], Phase: val, Batch: [95/182], Loss: 0.2847\n",
      "Epoch [3/10], Phase: val, Batch: [96/182], Loss: 0.2378\n",
      "Epoch [3/10], Phase: val, Batch: [97/182], Loss: 0.2562\n",
      "Epoch [3/10], Phase: val, Batch: [98/182], Loss: 0.2369\n",
      "Epoch [3/10], Phase: val, Batch: [99/182], Loss: 0.2806\n",
      "Epoch [3/10], Phase: val, Batch: [100/182], Loss: 0.3046\n",
      "Epoch [3/10], Phase: val, Batch: [101/182], Loss: 0.3579\n",
      "Epoch [3/10], Phase: val, Batch: [102/182], Loss: 0.2191\n",
      "Epoch [3/10], Phase: val, Batch: [103/182], Loss: 0.2529\n",
      "Epoch [3/10], Phase: val, Batch: [104/182], Loss: 0.2562\n",
      "Epoch [3/10], Phase: val, Batch: [105/182], Loss: 0.1996\n",
      "Epoch [3/10], Phase: val, Batch: [106/182], Loss: 0.4010\n",
      "Epoch [3/10], Phase: val, Batch: [107/182], Loss: 0.2765\n",
      "Epoch [3/10], Phase: val, Batch: [108/182], Loss: 0.2436\n",
      "Epoch [3/10], Phase: val, Batch: [109/182], Loss: 0.2538\n",
      "Epoch [3/10], Phase: val, Batch: [110/182], Loss: 0.2082\n",
      "Epoch [3/10], Phase: val, Batch: [111/182], Loss: 0.1412\n",
      "Epoch [3/10], Phase: val, Batch: [112/182], Loss: 0.1916\n",
      "Epoch [3/10], Phase: val, Batch: [113/182], Loss: 0.1717\n",
      "Epoch [3/10], Phase: val, Batch: [114/182], Loss: 0.2771\n",
      "Epoch [3/10], Phase: val, Batch: [115/182], Loss: 0.2047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: val, Batch: [116/182], Loss: 0.2880\n",
      "Epoch [3/10], Phase: val, Batch: [117/182], Loss: 0.1562\n",
      "Epoch [3/10], Phase: val, Batch: [118/182], Loss: 0.2535\n",
      "Epoch [3/10], Phase: val, Batch: [119/182], Loss: 0.1954\n",
      "Epoch [3/10], Phase: val, Batch: [120/182], Loss: 0.2271\n",
      "Epoch [3/10], Phase: val, Batch: [121/182], Loss: 0.2489\n",
      "Epoch [3/10], Phase: val, Batch: [122/182], Loss: 0.2206\n",
      "Epoch [3/10], Phase: val, Batch: [123/182], Loss: 0.3067\n",
      "Epoch [3/10], Phase: val, Batch: [124/182], Loss: 0.1782\n",
      "Epoch [3/10], Phase: val, Batch: [125/182], Loss: 0.1946\n",
      "Epoch [3/10], Phase: val, Batch: [126/182], Loss: 0.2388\n",
      "Epoch [3/10], Phase: val, Batch: [127/182], Loss: 0.2194\n",
      "Epoch [3/10], Phase: val, Batch: [128/182], Loss: 0.2180\n",
      "Epoch [3/10], Phase: val, Batch: [129/182], Loss: 0.2542\n",
      "Epoch [3/10], Phase: val, Batch: [130/182], Loss: 0.1817\n",
      "Epoch [3/10], Phase: val, Batch: [131/182], Loss: 0.2684\n",
      "Epoch [3/10], Phase: val, Batch: [132/182], Loss: 0.2663\n",
      "Epoch [3/10], Phase: val, Batch: [133/182], Loss: 0.3667\n",
      "Epoch [3/10], Phase: val, Batch: [134/182], Loss: 0.1340\n",
      "Epoch [3/10], Phase: val, Batch: [135/182], Loss: 0.2146\n",
      "Epoch [3/10], Phase: val, Batch: [136/182], Loss: 0.2907\n",
      "Epoch [3/10], Phase: val, Batch: [137/182], Loss: 0.2446\n",
      "Epoch [3/10], Phase: val, Batch: [138/182], Loss: 0.2687\n",
      "Epoch [3/10], Phase: val, Batch: [139/182], Loss: 0.1648\n",
      "Epoch [3/10], Phase: val, Batch: [140/182], Loss: 0.2587\n",
      "Epoch [3/10], Phase: val, Batch: [141/182], Loss: 0.2350\n",
      "Epoch [3/10], Phase: val, Batch: [142/182], Loss: 0.2123\n",
      "Epoch [3/10], Phase: val, Batch: [143/182], Loss: 0.2801\n",
      "Epoch [3/10], Phase: val, Batch: [144/182], Loss: 0.2878\n",
      "Epoch [3/10], Phase: val, Batch: [145/182], Loss: 0.1508\n",
      "Epoch [3/10], Phase: val, Batch: [146/182], Loss: 0.2222\n",
      "Epoch [3/10], Phase: val, Batch: [147/182], Loss: 0.2676\n",
      "Epoch [3/10], Phase: val, Batch: [148/182], Loss: 0.1997\n",
      "Epoch [3/10], Phase: val, Batch: [149/182], Loss: 0.2765\n",
      "Epoch [3/10], Phase: val, Batch: [150/182], Loss: 0.2851\n",
      "Epoch [3/10], Phase: val, Batch: [151/182], Loss: 0.2729\n",
      "Epoch [3/10], Phase: val, Batch: [152/182], Loss: 0.3051\n",
      "Epoch [3/10], Phase: val, Batch: [153/182], Loss: 0.2813\n",
      "Epoch [3/10], Phase: val, Batch: [154/182], Loss: 0.2587\n",
      "Epoch [3/10], Phase: val, Batch: [155/182], Loss: 0.2210\n",
      "Epoch [3/10], Phase: val, Batch: [156/182], Loss: 0.3591\n",
      "Epoch [3/10], Phase: val, Batch: [157/182], Loss: 0.2653\n",
      "Epoch [3/10], Phase: val, Batch: [158/182], Loss: 0.3970\n",
      "Epoch [3/10], Phase: val, Batch: [159/182], Loss: 0.2765\n",
      "Epoch [3/10], Phase: val, Batch: [160/182], Loss: 0.2111\n",
      "Epoch [3/10], Phase: val, Batch: [161/182], Loss: 0.2676\n",
      "Epoch [3/10], Phase: val, Batch: [162/182], Loss: 0.3127\n",
      "Epoch [3/10], Phase: val, Batch: [163/182], Loss: 0.3249\n",
      "Epoch [3/10], Phase: val, Batch: [164/182], Loss: 0.2050\n",
      "Epoch [3/10], Phase: val, Batch: [165/182], Loss: 0.2654\n",
      "Epoch [3/10], Phase: val, Batch: [166/182], Loss: 0.1579\n",
      "Epoch [3/10], Phase: val, Batch: [167/182], Loss: 0.2061\n",
      "Epoch [3/10], Phase: val, Batch: [168/182], Loss: 0.2257\n",
      "Epoch [3/10], Phase: val, Batch: [169/182], Loss: 0.2685\n",
      "Epoch [3/10], Phase: val, Batch: [170/182], Loss: 0.2756\n",
      "Epoch [3/10], Phase: val, Batch: [171/182], Loss: 0.3353\n",
      "Epoch [3/10], Phase: val, Batch: [172/182], Loss: 0.2438\n",
      "Epoch [3/10], Phase: val, Batch: [173/182], Loss: 0.1343\n",
      "Epoch [3/10], Phase: val, Batch: [174/182], Loss: 0.2929\n",
      "Epoch [3/10], Phase: val, Batch: [175/182], Loss: 0.1662\n",
      "Epoch [3/10], Phase: val, Batch: [176/182], Loss: 0.2368\n",
      "Epoch [3/10], Phase: val, Batch: [177/182], Loss: 0.2798\n",
      "Epoch [3/10], Phase: val, Batch: [178/182], Loss: 0.1425\n",
      "Epoch [3/10], Phase: val, Batch: [179/182], Loss: 0.2093\n",
      "Epoch [3/10], Phase: val, Batch: [180/182], Loss: 0.2205\n",
      "Epoch [3/10], Phase: val, Batch: [181/182], Loss: 0.3412\n",
      "Epoch [3/10], Phase: val, Batch: [182/182], Loss: 0.2516\n",
      "val Loss: 0.2299 Acc: 0.9096\n",
      "Epoch [4/10], Phase: train, Batch: [1/730], Loss: 0.2306\n",
      "Epoch [4/10], Phase: train, Batch: [2/730], Loss: 0.1790\n",
      "Epoch [4/10], Phase: train, Batch: [3/730], Loss: 0.3806\n",
      "Epoch [4/10], Phase: train, Batch: [4/730], Loss: 0.2568\n",
      "Epoch [4/10], Phase: train, Batch: [5/730], Loss: 0.3941\n",
      "Epoch [4/10], Phase: train, Batch: [6/730], Loss: 0.2794\n",
      "Epoch [4/10], Phase: train, Batch: [7/730], Loss: 0.2542\n",
      "Epoch [4/10], Phase: train, Batch: [8/730], Loss: 0.2150\n",
      "Epoch [4/10], Phase: train, Batch: [9/730], Loss: 0.3253\n",
      "Epoch [4/10], Phase: train, Batch: [10/730], Loss: 0.2459\n",
      "Epoch [4/10], Phase: train, Batch: [11/730], Loss: 0.2657\n",
      "Epoch [4/10], Phase: train, Batch: [12/730], Loss: 0.3424\n",
      "Epoch [4/10], Phase: train, Batch: [13/730], Loss: 0.4576\n",
      "Epoch [4/10], Phase: train, Batch: [14/730], Loss: 0.4157\n",
      "Epoch [4/10], Phase: train, Batch: [15/730], Loss: 0.3137\n",
      "Epoch [4/10], Phase: train, Batch: [16/730], Loss: 0.3937\n",
      "Epoch [4/10], Phase: train, Batch: [17/730], Loss: 0.2798\n",
      "Epoch [4/10], Phase: train, Batch: [18/730], Loss: 0.1974\n",
      "Epoch [4/10], Phase: train, Batch: [19/730], Loss: 0.2202\n",
      "Epoch [4/10], Phase: train, Batch: [20/730], Loss: 0.2471\n",
      "Epoch [4/10], Phase: train, Batch: [21/730], Loss: 0.3880\n",
      "Epoch [4/10], Phase: train, Batch: [22/730], Loss: 0.1858\n",
      "Epoch [4/10], Phase: train, Batch: [23/730], Loss: 0.3040\n",
      "Epoch [4/10], Phase: train, Batch: [24/730], Loss: 0.2992\n",
      "Epoch [4/10], Phase: train, Batch: [25/730], Loss: 0.3279\n",
      "Epoch [4/10], Phase: train, Batch: [26/730], Loss: 0.3868\n",
      "Epoch [4/10], Phase: train, Batch: [27/730], Loss: 0.2406\n",
      "Epoch [4/10], Phase: train, Batch: [28/730], Loss: 0.2838\n",
      "Epoch [4/10], Phase: train, Batch: [29/730], Loss: 0.2717\n",
      "Epoch [4/10], Phase: train, Batch: [30/730], Loss: 0.2282\n",
      "Epoch [4/10], Phase: train, Batch: [31/730], Loss: 0.3853\n",
      "Epoch [4/10], Phase: train, Batch: [32/730], Loss: 0.2169\n",
      "Epoch [4/10], Phase: train, Batch: [33/730], Loss: 0.4086\n",
      "Epoch [4/10], Phase: train, Batch: [34/730], Loss: 0.3336\n",
      "Epoch [4/10], Phase: train, Batch: [35/730], Loss: 0.2569\n",
      "Epoch [4/10], Phase: train, Batch: [36/730], Loss: 0.2041\n",
      "Epoch [4/10], Phase: train, Batch: [37/730], Loss: 0.2011\n",
      "Epoch [4/10], Phase: train, Batch: [38/730], Loss: 0.2559\n",
      "Epoch [4/10], Phase: train, Batch: [39/730], Loss: 0.2307\n",
      "Epoch [4/10], Phase: train, Batch: [40/730], Loss: 0.2589\n",
      "Epoch [4/10], Phase: train, Batch: [41/730], Loss: 0.2414\n",
      "Epoch [4/10], Phase: train, Batch: [42/730], Loss: 0.4138\n",
      "Epoch [4/10], Phase: train, Batch: [43/730], Loss: 0.2422\n",
      "Epoch [4/10], Phase: train, Batch: [44/730], Loss: 0.2834\n",
      "Epoch [4/10], Phase: train, Batch: [45/730], Loss: 0.4064\n",
      "Epoch [4/10], Phase: train, Batch: [46/730], Loss: 0.2591\n",
      "Epoch [4/10], Phase: train, Batch: [47/730], Loss: 0.2956\n",
      "Epoch [4/10], Phase: train, Batch: [48/730], Loss: 0.2337\n",
      "Epoch [4/10], Phase: train, Batch: [49/730], Loss: 0.3475\n",
      "Epoch [4/10], Phase: train, Batch: [50/730], Loss: 0.3955\n",
      "Epoch [4/10], Phase: train, Batch: [51/730], Loss: 0.2483\n",
      "Epoch [4/10], Phase: train, Batch: [52/730], Loss: 0.1965\n",
      "Epoch [4/10], Phase: train, Batch: [53/730], Loss: 0.2573\n",
      "Epoch [4/10], Phase: train, Batch: [54/730], Loss: 0.3251\n",
      "Epoch [4/10], Phase: train, Batch: [55/730], Loss: 0.2550\n",
      "Epoch [4/10], Phase: train, Batch: [56/730], Loss: 0.2484\n",
      "Epoch [4/10], Phase: train, Batch: [57/730], Loss: 0.2951\n",
      "Epoch [4/10], Phase: train, Batch: [58/730], Loss: 0.2111\n",
      "Epoch [4/10], Phase: train, Batch: [59/730], Loss: 0.3256\n",
      "Epoch [4/10], Phase: train, Batch: [60/730], Loss: 0.3154\n",
      "Epoch [4/10], Phase: train, Batch: [61/730], Loss: 0.2812\n",
      "Epoch [4/10], Phase: train, Batch: [62/730], Loss: 0.2495\n",
      "Epoch [4/10], Phase: train, Batch: [63/730], Loss: 0.3490\n",
      "Epoch [4/10], Phase: train, Batch: [64/730], Loss: 0.4382\n",
      "Epoch [4/10], Phase: train, Batch: [65/730], Loss: 0.2787\n",
      "Epoch [4/10], Phase: train, Batch: [66/730], Loss: 0.2809\n",
      "Epoch [4/10], Phase: train, Batch: [67/730], Loss: 0.2150\n",
      "Epoch [4/10], Phase: train, Batch: [68/730], Loss: 0.2847\n",
      "Epoch [4/10], Phase: train, Batch: [69/730], Loss: 0.3222\n",
      "Epoch [4/10], Phase: train, Batch: [70/730], Loss: 0.5007\n",
      "Epoch [4/10], Phase: train, Batch: [71/730], Loss: 0.2829\n",
      "Epoch [4/10], Phase: train, Batch: [72/730], Loss: 0.2556\n",
      "Epoch [4/10], Phase: train, Batch: [73/730], Loss: 0.2258\n",
      "Epoch [4/10], Phase: train, Batch: [74/730], Loss: 0.2841\n",
      "Epoch [4/10], Phase: train, Batch: [75/730], Loss: 0.3323\n",
      "Epoch [4/10], Phase: train, Batch: [76/730], Loss: 0.2669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [77/730], Loss: 0.2581\n",
      "Epoch [4/10], Phase: train, Batch: [78/730], Loss: 0.2511\n",
      "Epoch [4/10], Phase: train, Batch: [79/730], Loss: 0.3852\n",
      "Epoch [4/10], Phase: train, Batch: [80/730], Loss: 0.3034\n",
      "Epoch [4/10], Phase: train, Batch: [81/730], Loss: 0.2451\n",
      "Epoch [4/10], Phase: train, Batch: [82/730], Loss: 0.2914\n",
      "Epoch [4/10], Phase: train, Batch: [83/730], Loss: 0.2888\n",
      "Epoch [4/10], Phase: train, Batch: [84/730], Loss: 0.1517\n",
      "Epoch [4/10], Phase: train, Batch: [85/730], Loss: 0.2939\n",
      "Epoch [4/10], Phase: train, Batch: [86/730], Loss: 0.2095\n",
      "Epoch [4/10], Phase: train, Batch: [87/730], Loss: 0.2213\n",
      "Epoch [4/10], Phase: train, Batch: [88/730], Loss: 0.2643\n",
      "Epoch [4/10], Phase: train, Batch: [89/730], Loss: 0.2963\n",
      "Epoch [4/10], Phase: train, Batch: [90/730], Loss: 0.2726\n",
      "Epoch [4/10], Phase: train, Batch: [91/730], Loss: 0.2968\n",
      "Epoch [4/10], Phase: train, Batch: [92/730], Loss: 0.3427\n",
      "Epoch [4/10], Phase: train, Batch: [93/730], Loss: 0.2384\n",
      "Epoch [4/10], Phase: train, Batch: [94/730], Loss: 0.3085\n",
      "Epoch [4/10], Phase: train, Batch: [95/730], Loss: 0.2446\n",
      "Epoch [4/10], Phase: train, Batch: [96/730], Loss: 0.3300\n",
      "Epoch [4/10], Phase: train, Batch: [97/730], Loss: 0.3353\n",
      "Epoch [4/10], Phase: train, Batch: [98/730], Loss: 0.2765\n",
      "Epoch [4/10], Phase: train, Batch: [99/730], Loss: 0.1678\n",
      "Epoch [4/10], Phase: train, Batch: [100/730], Loss: 0.3319\n",
      "Epoch [4/10], Phase: train, Batch: [101/730], Loss: 0.2318\n",
      "Epoch [4/10], Phase: train, Batch: [102/730], Loss: 0.2754\n",
      "Epoch [4/10], Phase: train, Batch: [103/730], Loss: 0.4017\n",
      "Epoch [4/10], Phase: train, Batch: [104/730], Loss: 0.2014\n",
      "Epoch [4/10], Phase: train, Batch: [105/730], Loss: 0.2636\n",
      "Epoch [4/10], Phase: train, Batch: [106/730], Loss: 0.2410\n",
      "Epoch [4/10], Phase: train, Batch: [107/730], Loss: 0.2946\n",
      "Epoch [4/10], Phase: train, Batch: [108/730], Loss: 0.2562\n",
      "Epoch [4/10], Phase: train, Batch: [109/730], Loss: 0.5093\n",
      "Epoch [4/10], Phase: train, Batch: [110/730], Loss: 0.2938\n",
      "Epoch [4/10], Phase: train, Batch: [111/730], Loss: 0.2571\n",
      "Epoch [4/10], Phase: train, Batch: [112/730], Loss: 0.2141\n",
      "Epoch [4/10], Phase: train, Batch: [113/730], Loss: 0.2250\n",
      "Epoch [4/10], Phase: train, Batch: [114/730], Loss: 0.2942\n",
      "Epoch [4/10], Phase: train, Batch: [115/730], Loss: 0.2686\n",
      "Epoch [4/10], Phase: train, Batch: [116/730], Loss: 0.2565\n",
      "Epoch [4/10], Phase: train, Batch: [117/730], Loss: 0.3006\n",
      "Epoch [4/10], Phase: train, Batch: [118/730], Loss: 0.2788\n",
      "Epoch [4/10], Phase: train, Batch: [119/730], Loss: 0.3164\n",
      "Epoch [4/10], Phase: train, Batch: [120/730], Loss: 0.3564\n",
      "Epoch [4/10], Phase: train, Batch: [121/730], Loss: 0.2300\n",
      "Epoch [4/10], Phase: train, Batch: [122/730], Loss: 0.3457\n",
      "Epoch [4/10], Phase: train, Batch: [123/730], Loss: 0.3982\n",
      "Epoch [4/10], Phase: train, Batch: [124/730], Loss: 0.3019\n",
      "Epoch [4/10], Phase: train, Batch: [125/730], Loss: 0.3147\n",
      "Epoch [4/10], Phase: train, Batch: [126/730], Loss: 0.2705\n",
      "Epoch [4/10], Phase: train, Batch: [127/730], Loss: 0.3049\n",
      "Epoch [4/10], Phase: train, Batch: [128/730], Loss: 0.3005\n",
      "Epoch [4/10], Phase: train, Batch: [129/730], Loss: 0.3439\n",
      "Epoch [4/10], Phase: train, Batch: [130/730], Loss: 0.2454\n",
      "Epoch [4/10], Phase: train, Batch: [131/730], Loss: 0.1858\n",
      "Epoch [4/10], Phase: train, Batch: [132/730], Loss: 0.4298\n",
      "Epoch [4/10], Phase: train, Batch: [133/730], Loss: 0.3284\n",
      "Epoch [4/10], Phase: train, Batch: [134/730], Loss: 0.3367\n",
      "Epoch [4/10], Phase: train, Batch: [135/730], Loss: 0.2891\n",
      "Epoch [4/10], Phase: train, Batch: [136/730], Loss: 0.1890\n",
      "Epoch [4/10], Phase: train, Batch: [137/730], Loss: 0.2690\n",
      "Epoch [4/10], Phase: train, Batch: [138/730], Loss: 0.2051\n",
      "Epoch [4/10], Phase: train, Batch: [139/730], Loss: 0.2637\n",
      "Epoch [4/10], Phase: train, Batch: [140/730], Loss: 0.2857\n",
      "Epoch [4/10], Phase: train, Batch: [141/730], Loss: 0.3377\n",
      "Epoch [4/10], Phase: train, Batch: [142/730], Loss: 0.3652\n",
      "Epoch [4/10], Phase: train, Batch: [143/730], Loss: 0.2502\n",
      "Epoch [4/10], Phase: train, Batch: [144/730], Loss: 0.3599\n",
      "Epoch [4/10], Phase: train, Batch: [145/730], Loss: 0.3542\n",
      "Epoch [4/10], Phase: train, Batch: [146/730], Loss: 0.2895\n",
      "Epoch [4/10], Phase: train, Batch: [147/730], Loss: 0.3353\n",
      "Epoch [4/10], Phase: train, Batch: [148/730], Loss: 0.4076\n",
      "Epoch [4/10], Phase: train, Batch: [149/730], Loss: 0.2662\n",
      "Epoch [4/10], Phase: train, Batch: [150/730], Loss: 0.3865\n",
      "Epoch [4/10], Phase: train, Batch: [151/730], Loss: 0.2149\n",
      "Epoch [4/10], Phase: train, Batch: [152/730], Loss: 0.2858\n",
      "Epoch [4/10], Phase: train, Batch: [153/730], Loss: 0.2461\n",
      "Epoch [4/10], Phase: train, Batch: [154/730], Loss: 0.2748\n",
      "Epoch [4/10], Phase: train, Batch: [155/730], Loss: 0.2435\n",
      "Epoch [4/10], Phase: train, Batch: [156/730], Loss: 0.3366\n",
      "Epoch [4/10], Phase: train, Batch: [157/730], Loss: 0.2612\n",
      "Epoch [4/10], Phase: train, Batch: [158/730], Loss: 0.3542\n",
      "Epoch [4/10], Phase: train, Batch: [159/730], Loss: 0.2810\n",
      "Epoch [4/10], Phase: train, Batch: [160/730], Loss: 0.1974\n",
      "Epoch [4/10], Phase: train, Batch: [161/730], Loss: 0.3222\n",
      "Epoch [4/10], Phase: train, Batch: [162/730], Loss: 0.1958\n",
      "Epoch [4/10], Phase: train, Batch: [163/730], Loss: 0.2872\n",
      "Epoch [4/10], Phase: train, Batch: [164/730], Loss: 0.3306\n",
      "Epoch [4/10], Phase: train, Batch: [165/730], Loss: 0.2991\n",
      "Epoch [4/10], Phase: train, Batch: [166/730], Loss: 0.4459\n",
      "Epoch [4/10], Phase: train, Batch: [167/730], Loss: 0.2356\n",
      "Epoch [4/10], Phase: train, Batch: [168/730], Loss: 0.4016\n",
      "Epoch [4/10], Phase: train, Batch: [169/730], Loss: 0.1785\n",
      "Epoch [4/10], Phase: train, Batch: [170/730], Loss: 0.2192\n",
      "Epoch [4/10], Phase: train, Batch: [171/730], Loss: 0.2479\n",
      "Epoch [4/10], Phase: train, Batch: [172/730], Loss: 0.2891\n",
      "Epoch [4/10], Phase: train, Batch: [173/730], Loss: 0.3212\n",
      "Epoch [4/10], Phase: train, Batch: [174/730], Loss: 0.2152\n",
      "Epoch [4/10], Phase: train, Batch: [175/730], Loss: 0.2766\n",
      "Epoch [4/10], Phase: train, Batch: [176/730], Loss: 0.2324\n",
      "Epoch [4/10], Phase: train, Batch: [177/730], Loss: 0.2725\n",
      "Epoch [4/10], Phase: train, Batch: [178/730], Loss: 0.2286\n",
      "Epoch [4/10], Phase: train, Batch: [179/730], Loss: 0.3098\n",
      "Epoch [4/10], Phase: train, Batch: [180/730], Loss: 0.2838\n",
      "Epoch [4/10], Phase: train, Batch: [181/730], Loss: 0.3378\n",
      "Epoch [4/10], Phase: train, Batch: [182/730], Loss: 0.3425\n",
      "Epoch [4/10], Phase: train, Batch: [183/730], Loss: 0.2352\n",
      "Epoch [4/10], Phase: train, Batch: [184/730], Loss: 0.1703\n",
      "Epoch [4/10], Phase: train, Batch: [185/730], Loss: 0.3021\n",
      "Epoch [4/10], Phase: train, Batch: [186/730], Loss: 0.2668\n",
      "Epoch [4/10], Phase: train, Batch: [187/730], Loss: 0.2971\n",
      "Epoch [4/10], Phase: train, Batch: [188/730], Loss: 0.1669\n",
      "Epoch [4/10], Phase: train, Batch: [189/730], Loss: 0.2574\n",
      "Epoch [4/10], Phase: train, Batch: [190/730], Loss: 0.3325\n",
      "Epoch [4/10], Phase: train, Batch: [191/730], Loss: 0.2278\n",
      "Epoch [4/10], Phase: train, Batch: [192/730], Loss: 0.2357\n",
      "Epoch [4/10], Phase: train, Batch: [193/730], Loss: 0.2072\n",
      "Epoch [4/10], Phase: train, Batch: [194/730], Loss: 0.3225\n",
      "Epoch [4/10], Phase: train, Batch: [195/730], Loss: 0.3868\n",
      "Epoch [4/10], Phase: train, Batch: [196/730], Loss: 0.2722\n",
      "Epoch [4/10], Phase: train, Batch: [197/730], Loss: 0.3341\n",
      "Epoch [4/10], Phase: train, Batch: [198/730], Loss: 0.2201\n",
      "Epoch [4/10], Phase: train, Batch: [199/730], Loss: 0.1701\n",
      "Epoch [4/10], Phase: train, Batch: [200/730], Loss: 0.3197\n",
      "Epoch [4/10], Phase: train, Batch: [201/730], Loss: 0.1873\n",
      "Epoch [4/10], Phase: train, Batch: [202/730], Loss: 0.2893\n",
      "Epoch [4/10], Phase: train, Batch: [203/730], Loss: 0.3626\n",
      "Epoch [4/10], Phase: train, Batch: [204/730], Loss: 0.3453\n",
      "Epoch [4/10], Phase: train, Batch: [205/730], Loss: 0.3183\n",
      "Epoch [4/10], Phase: train, Batch: [206/730], Loss: 0.2965\n",
      "Epoch [4/10], Phase: train, Batch: [207/730], Loss: 0.2019\n",
      "Epoch [4/10], Phase: train, Batch: [208/730], Loss: 0.2291\n",
      "Epoch [4/10], Phase: train, Batch: [209/730], Loss: 0.1861\n",
      "Epoch [4/10], Phase: train, Batch: [210/730], Loss: 0.3298\n",
      "Epoch [4/10], Phase: train, Batch: [211/730], Loss: 0.2616\n",
      "Epoch [4/10], Phase: train, Batch: [212/730], Loss: 0.3361\n",
      "Epoch [4/10], Phase: train, Batch: [213/730], Loss: 0.2414\n",
      "Epoch [4/10], Phase: train, Batch: [214/730], Loss: 0.3432\n",
      "Epoch [4/10], Phase: train, Batch: [215/730], Loss: 0.2033\n",
      "Epoch [4/10], Phase: train, Batch: [216/730], Loss: 0.2590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [217/730], Loss: 0.2198\n",
      "Epoch [4/10], Phase: train, Batch: [218/730], Loss: 0.4674\n",
      "Epoch [4/10], Phase: train, Batch: [219/730], Loss: 0.2638\n",
      "Epoch [4/10], Phase: train, Batch: [220/730], Loss: 0.2952\n",
      "Epoch [4/10], Phase: train, Batch: [221/730], Loss: 0.4363\n",
      "Epoch [4/10], Phase: train, Batch: [222/730], Loss: 0.3543\n",
      "Epoch [4/10], Phase: train, Batch: [223/730], Loss: 0.3025\n",
      "Epoch [4/10], Phase: train, Batch: [224/730], Loss: 0.3085\n",
      "Epoch [4/10], Phase: train, Batch: [225/730], Loss: 0.1637\n",
      "Epoch [4/10], Phase: train, Batch: [226/730], Loss: 0.2165\n",
      "Epoch [4/10], Phase: train, Batch: [227/730], Loss: 0.2898\n",
      "Epoch [4/10], Phase: train, Batch: [228/730], Loss: 0.1742\n",
      "Epoch [4/10], Phase: train, Batch: [229/730], Loss: 0.3368\n",
      "Epoch [4/10], Phase: train, Batch: [230/730], Loss: 0.2463\n",
      "Epoch [4/10], Phase: train, Batch: [231/730], Loss: 0.4534\n",
      "Epoch [4/10], Phase: train, Batch: [232/730], Loss: 0.1560\n",
      "Epoch [4/10], Phase: train, Batch: [233/730], Loss: 0.2537\n",
      "Epoch [4/10], Phase: train, Batch: [234/730], Loss: 0.2879\n",
      "Epoch [4/10], Phase: train, Batch: [235/730], Loss: 0.3487\n",
      "Epoch [4/10], Phase: train, Batch: [236/730], Loss: 0.2555\n",
      "Epoch [4/10], Phase: train, Batch: [237/730], Loss: 0.2776\n",
      "Epoch [4/10], Phase: train, Batch: [238/730], Loss: 0.3036\n",
      "Epoch [4/10], Phase: train, Batch: [239/730], Loss: 0.1843\n",
      "Epoch [4/10], Phase: train, Batch: [240/730], Loss: 0.5018\n",
      "Epoch [4/10], Phase: train, Batch: [241/730], Loss: 0.2138\n",
      "Epoch [4/10], Phase: train, Batch: [242/730], Loss: 0.3781\n",
      "Epoch [4/10], Phase: train, Batch: [243/730], Loss: 0.3903\n",
      "Epoch [4/10], Phase: train, Batch: [244/730], Loss: 0.2979\n",
      "Epoch [4/10], Phase: train, Batch: [245/730], Loss: 0.2536\n",
      "Epoch [4/10], Phase: train, Batch: [246/730], Loss: 0.4307\n",
      "Epoch [4/10], Phase: train, Batch: [247/730], Loss: 0.2827\n",
      "Epoch [4/10], Phase: train, Batch: [248/730], Loss: 0.2856\n",
      "Epoch [4/10], Phase: train, Batch: [249/730], Loss: 0.3183\n",
      "Epoch [4/10], Phase: train, Batch: [250/730], Loss: 0.2804\n",
      "Epoch [4/10], Phase: train, Batch: [251/730], Loss: 0.3068\n",
      "Epoch [4/10], Phase: train, Batch: [252/730], Loss: 0.2423\n",
      "Epoch [4/10], Phase: train, Batch: [253/730], Loss: 0.3198\n",
      "Epoch [4/10], Phase: train, Batch: [254/730], Loss: 0.2852\n",
      "Epoch [4/10], Phase: train, Batch: [255/730], Loss: 0.1655\n",
      "Epoch [4/10], Phase: train, Batch: [256/730], Loss: 0.2996\n",
      "Epoch [4/10], Phase: train, Batch: [257/730], Loss: 0.3102\n",
      "Epoch [4/10], Phase: train, Batch: [258/730], Loss: 0.3242\n",
      "Epoch [4/10], Phase: train, Batch: [259/730], Loss: 0.2323\n",
      "Epoch [4/10], Phase: train, Batch: [260/730], Loss: 0.2352\n",
      "Epoch [4/10], Phase: train, Batch: [261/730], Loss: 0.3438\n",
      "Epoch [4/10], Phase: train, Batch: [262/730], Loss: 0.3228\n",
      "Epoch [4/10], Phase: train, Batch: [263/730], Loss: 0.3140\n",
      "Epoch [4/10], Phase: train, Batch: [264/730], Loss: 0.3983\n",
      "Epoch [4/10], Phase: train, Batch: [265/730], Loss: 0.2576\n",
      "Epoch [4/10], Phase: train, Batch: [266/730], Loss: 0.2491\n",
      "Epoch [4/10], Phase: train, Batch: [267/730], Loss: 0.4203\n",
      "Epoch [4/10], Phase: train, Batch: [268/730], Loss: 0.3869\n",
      "Epoch [4/10], Phase: train, Batch: [269/730], Loss: 0.2297\n",
      "Epoch [4/10], Phase: train, Batch: [270/730], Loss: 0.3170\n",
      "Epoch [4/10], Phase: train, Batch: [271/730], Loss: 0.3152\n",
      "Epoch [4/10], Phase: train, Batch: [272/730], Loss: 0.1716\n",
      "Epoch [4/10], Phase: train, Batch: [273/730], Loss: 0.3449\n",
      "Epoch [4/10], Phase: train, Batch: [274/730], Loss: 0.2248\n",
      "Epoch [4/10], Phase: train, Batch: [275/730], Loss: 0.5111\n",
      "Epoch [4/10], Phase: train, Batch: [276/730], Loss: 0.3903\n",
      "Epoch [4/10], Phase: train, Batch: [277/730], Loss: 0.2183\n",
      "Epoch [4/10], Phase: train, Batch: [278/730], Loss: 0.2783\n",
      "Epoch [4/10], Phase: train, Batch: [279/730], Loss: 0.2497\n",
      "Epoch [4/10], Phase: train, Batch: [280/730], Loss: 0.3738\n",
      "Epoch [4/10], Phase: train, Batch: [281/730], Loss: 0.2315\n",
      "Epoch [4/10], Phase: train, Batch: [282/730], Loss: 0.2720\n",
      "Epoch [4/10], Phase: train, Batch: [283/730], Loss: 0.4724\n",
      "Epoch [4/10], Phase: train, Batch: [284/730], Loss: 0.2988\n",
      "Epoch [4/10], Phase: train, Batch: [285/730], Loss: 0.1752\n",
      "Epoch [4/10], Phase: train, Batch: [286/730], Loss: 0.2406\n",
      "Epoch [4/10], Phase: train, Batch: [287/730], Loss: 0.3268\n",
      "Epoch [4/10], Phase: train, Batch: [288/730], Loss: 0.2783\n",
      "Epoch [4/10], Phase: train, Batch: [289/730], Loss: 0.2035\n",
      "Epoch [4/10], Phase: train, Batch: [290/730], Loss: 0.2144\n",
      "Epoch [4/10], Phase: train, Batch: [291/730], Loss: 0.3534\n",
      "Epoch [4/10], Phase: train, Batch: [292/730], Loss: 0.2466\n",
      "Epoch [4/10], Phase: train, Batch: [293/730], Loss: 0.2749\n",
      "Epoch [4/10], Phase: train, Batch: [294/730], Loss: 0.2626\n",
      "Epoch [4/10], Phase: train, Batch: [295/730], Loss: 0.3739\n",
      "Epoch [4/10], Phase: train, Batch: [296/730], Loss: 0.2720\n",
      "Epoch [4/10], Phase: train, Batch: [297/730], Loss: 0.2380\n",
      "Epoch [4/10], Phase: train, Batch: [298/730], Loss: 0.2122\n",
      "Epoch [4/10], Phase: train, Batch: [299/730], Loss: 0.2527\n",
      "Epoch [4/10], Phase: train, Batch: [300/730], Loss: 0.3614\n",
      "Epoch [4/10], Phase: train, Batch: [301/730], Loss: 0.2440\n",
      "Epoch [4/10], Phase: train, Batch: [302/730], Loss: 0.2734\n",
      "Epoch [4/10], Phase: train, Batch: [303/730], Loss: 0.2866\n",
      "Epoch [4/10], Phase: train, Batch: [304/730], Loss: 0.1894\n",
      "Epoch [4/10], Phase: train, Batch: [305/730], Loss: 0.3571\n",
      "Epoch [4/10], Phase: train, Batch: [306/730], Loss: 0.3622\n",
      "Epoch [4/10], Phase: train, Batch: [307/730], Loss: 0.2501\n",
      "Epoch [4/10], Phase: train, Batch: [308/730], Loss: 0.2350\n",
      "Epoch [4/10], Phase: train, Batch: [309/730], Loss: 0.2458\n",
      "Epoch [4/10], Phase: train, Batch: [310/730], Loss: 0.3165\n",
      "Epoch [4/10], Phase: train, Batch: [311/730], Loss: 0.3777\n",
      "Epoch [4/10], Phase: train, Batch: [312/730], Loss: 0.2254\n",
      "Epoch [4/10], Phase: train, Batch: [313/730], Loss: 0.3827\n",
      "Epoch [4/10], Phase: train, Batch: [314/730], Loss: 0.2783\n",
      "Epoch [4/10], Phase: train, Batch: [315/730], Loss: 0.1670\n",
      "Epoch [4/10], Phase: train, Batch: [316/730], Loss: 0.2730\n",
      "Epoch [4/10], Phase: train, Batch: [317/730], Loss: 0.3691\n",
      "Epoch [4/10], Phase: train, Batch: [318/730], Loss: 0.3220\n",
      "Epoch [4/10], Phase: train, Batch: [319/730], Loss: 0.3026\n",
      "Epoch [4/10], Phase: train, Batch: [320/730], Loss: 0.2930\n",
      "Epoch [4/10], Phase: train, Batch: [321/730], Loss: 0.2581\n",
      "Epoch [4/10], Phase: train, Batch: [322/730], Loss: 0.2360\n",
      "Epoch [4/10], Phase: train, Batch: [323/730], Loss: 0.2767\n",
      "Epoch [4/10], Phase: train, Batch: [324/730], Loss: 0.3829\n",
      "Epoch [4/10], Phase: train, Batch: [325/730], Loss: 0.2773\n",
      "Epoch [4/10], Phase: train, Batch: [326/730], Loss: 0.2550\n",
      "Epoch [4/10], Phase: train, Batch: [327/730], Loss: 0.2506\n",
      "Epoch [4/10], Phase: train, Batch: [328/730], Loss: 0.2604\n",
      "Epoch [4/10], Phase: train, Batch: [329/730], Loss: 0.2952\n",
      "Epoch [4/10], Phase: train, Batch: [330/730], Loss: 0.1118\n",
      "Epoch [4/10], Phase: train, Batch: [331/730], Loss: 0.2487\n",
      "Epoch [4/10], Phase: train, Batch: [332/730], Loss: 0.2535\n",
      "Epoch [4/10], Phase: train, Batch: [333/730], Loss: 0.3136\n",
      "Epoch [4/10], Phase: train, Batch: [334/730], Loss: 0.3355\n",
      "Epoch [4/10], Phase: train, Batch: [335/730], Loss: 0.2246\n",
      "Epoch [4/10], Phase: train, Batch: [336/730], Loss: 0.2219\n",
      "Epoch [4/10], Phase: train, Batch: [337/730], Loss: 0.1811\n",
      "Epoch [4/10], Phase: train, Batch: [338/730], Loss: 0.2593\n",
      "Epoch [4/10], Phase: train, Batch: [339/730], Loss: 0.3860\n",
      "Epoch [4/10], Phase: train, Batch: [340/730], Loss: 0.3837\n",
      "Epoch [4/10], Phase: train, Batch: [341/730], Loss: 0.3115\n",
      "Epoch [4/10], Phase: train, Batch: [342/730], Loss: 0.3540\n",
      "Epoch [4/10], Phase: train, Batch: [343/730], Loss: 0.1825\n",
      "Epoch [4/10], Phase: train, Batch: [344/730], Loss: 0.2897\n",
      "Epoch [4/10], Phase: train, Batch: [345/730], Loss: 0.4204\n",
      "Epoch [4/10], Phase: train, Batch: [346/730], Loss: 0.2170\n",
      "Epoch [4/10], Phase: train, Batch: [347/730], Loss: 0.2459\n",
      "Epoch [4/10], Phase: train, Batch: [348/730], Loss: 0.2888\n",
      "Epoch [4/10], Phase: train, Batch: [349/730], Loss: 0.2254\n",
      "Epoch [4/10], Phase: train, Batch: [350/730], Loss: 0.3404\n",
      "Epoch [4/10], Phase: train, Batch: [351/730], Loss: 0.2691\n",
      "Epoch [4/10], Phase: train, Batch: [352/730], Loss: 0.3356\n",
      "Epoch [4/10], Phase: train, Batch: [353/730], Loss: 0.3101\n",
      "Epoch [4/10], Phase: train, Batch: [354/730], Loss: 0.2736\n",
      "Epoch [4/10], Phase: train, Batch: [355/730], Loss: 0.2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [356/730], Loss: 0.2107\n",
      "Epoch [4/10], Phase: train, Batch: [357/730], Loss: 0.1563\n",
      "Epoch [4/10], Phase: train, Batch: [358/730], Loss: 0.3399\n",
      "Epoch [4/10], Phase: train, Batch: [359/730], Loss: 0.2857\n",
      "Epoch [4/10], Phase: train, Batch: [360/730], Loss: 0.2550\n",
      "Epoch [4/10], Phase: train, Batch: [361/730], Loss: 0.2776\n",
      "Epoch [4/10], Phase: train, Batch: [362/730], Loss: 0.2213\n",
      "Epoch [4/10], Phase: train, Batch: [363/730], Loss: 0.1278\n",
      "Epoch [4/10], Phase: train, Batch: [364/730], Loss: 0.2885\n",
      "Epoch [4/10], Phase: train, Batch: [365/730], Loss: 0.2779\n",
      "Epoch [4/10], Phase: train, Batch: [366/730], Loss: 0.2472\n",
      "Epoch [4/10], Phase: train, Batch: [367/730], Loss: 0.3747\n",
      "Epoch [4/10], Phase: train, Batch: [368/730], Loss: 0.3835\n",
      "Epoch [4/10], Phase: train, Batch: [369/730], Loss: 0.1889\n",
      "Epoch [4/10], Phase: train, Batch: [370/730], Loss: 0.3008\n",
      "Epoch [4/10], Phase: train, Batch: [371/730], Loss: 0.3161\n",
      "Epoch [4/10], Phase: train, Batch: [372/730], Loss: 0.2209\n",
      "Epoch [4/10], Phase: train, Batch: [373/730], Loss: 0.3058\n",
      "Epoch [4/10], Phase: train, Batch: [374/730], Loss: 0.3752\n",
      "Epoch [4/10], Phase: train, Batch: [375/730], Loss: 0.3282\n",
      "Epoch [4/10], Phase: train, Batch: [376/730], Loss: 0.3230\n",
      "Epoch [4/10], Phase: train, Batch: [377/730], Loss: 0.3015\n",
      "Epoch [4/10], Phase: train, Batch: [378/730], Loss: 0.2709\n",
      "Epoch [4/10], Phase: train, Batch: [379/730], Loss: 0.2376\n",
      "Epoch [4/10], Phase: train, Batch: [380/730], Loss: 0.2437\n",
      "Epoch [4/10], Phase: train, Batch: [381/730], Loss: 0.3855\n",
      "Epoch [4/10], Phase: train, Batch: [382/730], Loss: 0.3120\n",
      "Epoch [4/10], Phase: train, Batch: [383/730], Loss: 0.2433\n",
      "Epoch [4/10], Phase: train, Batch: [384/730], Loss: 0.3528\n",
      "Epoch [4/10], Phase: train, Batch: [385/730], Loss: 0.4129\n",
      "Epoch [4/10], Phase: train, Batch: [386/730], Loss: 0.1861\n",
      "Epoch [4/10], Phase: train, Batch: [387/730], Loss: 0.2662\n",
      "Epoch [4/10], Phase: train, Batch: [388/730], Loss: 0.2442\n",
      "Epoch [4/10], Phase: train, Batch: [389/730], Loss: 0.2543\n",
      "Epoch [4/10], Phase: train, Batch: [390/730], Loss: 0.2541\n",
      "Epoch [4/10], Phase: train, Batch: [391/730], Loss: 0.2993\n",
      "Epoch [4/10], Phase: train, Batch: [392/730], Loss: 0.3046\n",
      "Epoch [4/10], Phase: train, Batch: [393/730], Loss: 0.3659\n",
      "Epoch [4/10], Phase: train, Batch: [394/730], Loss: 0.4009\n",
      "Epoch [4/10], Phase: train, Batch: [395/730], Loss: 0.2981\n",
      "Epoch [4/10], Phase: train, Batch: [396/730], Loss: 0.1966\n",
      "Epoch [4/10], Phase: train, Batch: [397/730], Loss: 0.2583\n",
      "Epoch [4/10], Phase: train, Batch: [398/730], Loss: 0.2649\n",
      "Epoch [4/10], Phase: train, Batch: [399/730], Loss: 0.1497\n",
      "Epoch [4/10], Phase: train, Batch: [400/730], Loss: 0.4132\n",
      "Epoch [4/10], Phase: train, Batch: [401/730], Loss: 0.1821\n",
      "Epoch [4/10], Phase: train, Batch: [402/730], Loss: 0.2092\n",
      "Epoch [4/10], Phase: train, Batch: [403/730], Loss: 0.2172\n",
      "Epoch [4/10], Phase: train, Batch: [404/730], Loss: 0.2623\n",
      "Epoch [4/10], Phase: train, Batch: [405/730], Loss: 0.4802\n",
      "Epoch [4/10], Phase: train, Batch: [406/730], Loss: 0.2743\n",
      "Epoch [4/10], Phase: train, Batch: [407/730], Loss: 0.1796\n",
      "Epoch [4/10], Phase: train, Batch: [408/730], Loss: 0.2028\n",
      "Epoch [4/10], Phase: train, Batch: [409/730], Loss: 0.1805\n",
      "Epoch [4/10], Phase: train, Batch: [410/730], Loss: 0.2530\n",
      "Epoch [4/10], Phase: train, Batch: [411/730], Loss: 0.2969\n",
      "Epoch [4/10], Phase: train, Batch: [412/730], Loss: 0.3209\n",
      "Epoch [4/10], Phase: train, Batch: [413/730], Loss: 0.3709\n",
      "Epoch [4/10], Phase: train, Batch: [414/730], Loss: 0.2546\n",
      "Epoch [4/10], Phase: train, Batch: [415/730], Loss: 0.3682\n",
      "Epoch [4/10], Phase: train, Batch: [416/730], Loss: 0.1855\n",
      "Epoch [4/10], Phase: train, Batch: [417/730], Loss: 0.3521\n",
      "Epoch [4/10], Phase: train, Batch: [418/730], Loss: 0.3388\n",
      "Epoch [4/10], Phase: train, Batch: [419/730], Loss: 0.2637\n",
      "Epoch [4/10], Phase: train, Batch: [420/730], Loss: 0.2512\n",
      "Epoch [4/10], Phase: train, Batch: [421/730], Loss: 0.2483\n",
      "Epoch [4/10], Phase: train, Batch: [422/730], Loss: 0.2560\n",
      "Epoch [4/10], Phase: train, Batch: [423/730], Loss: 0.3228\n",
      "Epoch [4/10], Phase: train, Batch: [424/730], Loss: 0.3039\n",
      "Epoch [4/10], Phase: train, Batch: [425/730], Loss: 0.2986\n",
      "Epoch [4/10], Phase: train, Batch: [426/730], Loss: 0.2473\n",
      "Epoch [4/10], Phase: train, Batch: [427/730], Loss: 0.2314\n",
      "Epoch [4/10], Phase: train, Batch: [428/730], Loss: 0.4739\n",
      "Epoch [4/10], Phase: train, Batch: [429/730], Loss: 0.2812\n",
      "Epoch [4/10], Phase: train, Batch: [430/730], Loss: 0.2398\n",
      "Epoch [4/10], Phase: train, Batch: [431/730], Loss: 0.2574\n",
      "Epoch [4/10], Phase: train, Batch: [432/730], Loss: 0.2911\n",
      "Epoch [4/10], Phase: train, Batch: [433/730], Loss: 0.2498\n",
      "Epoch [4/10], Phase: train, Batch: [434/730], Loss: 0.2596\n",
      "Epoch [4/10], Phase: train, Batch: [435/730], Loss: 0.2046\n",
      "Epoch [4/10], Phase: train, Batch: [436/730], Loss: 0.2985\n",
      "Epoch [4/10], Phase: train, Batch: [437/730], Loss: 0.2496\n",
      "Epoch [4/10], Phase: train, Batch: [438/730], Loss: 0.2566\n",
      "Epoch [4/10], Phase: train, Batch: [439/730], Loss: 0.3074\n",
      "Epoch [4/10], Phase: train, Batch: [440/730], Loss: 0.2167\n",
      "Epoch [4/10], Phase: train, Batch: [441/730], Loss: 0.3734\n",
      "Epoch [4/10], Phase: train, Batch: [442/730], Loss: 0.1438\n",
      "Epoch [4/10], Phase: train, Batch: [443/730], Loss: 0.3413\n",
      "Epoch [4/10], Phase: train, Batch: [444/730], Loss: 0.2634\n",
      "Epoch [4/10], Phase: train, Batch: [445/730], Loss: 0.2175\n",
      "Epoch [4/10], Phase: train, Batch: [446/730], Loss: 0.2807\n",
      "Epoch [4/10], Phase: train, Batch: [447/730], Loss: 0.3407\n",
      "Epoch [4/10], Phase: train, Batch: [448/730], Loss: 0.3143\n",
      "Epoch [4/10], Phase: train, Batch: [449/730], Loss: 0.3244\n",
      "Epoch [4/10], Phase: train, Batch: [450/730], Loss: 0.3367\n",
      "Epoch [4/10], Phase: train, Batch: [451/730], Loss: 0.3704\n",
      "Epoch [4/10], Phase: train, Batch: [452/730], Loss: 0.2621\n",
      "Epoch [4/10], Phase: train, Batch: [453/730], Loss: 0.3600\n",
      "Epoch [4/10], Phase: train, Batch: [454/730], Loss: 0.2136\n",
      "Epoch [4/10], Phase: train, Batch: [455/730], Loss: 0.3196\n",
      "Epoch [4/10], Phase: train, Batch: [456/730], Loss: 0.3347\n",
      "Epoch [4/10], Phase: train, Batch: [457/730], Loss: 0.2464\n",
      "Epoch [4/10], Phase: train, Batch: [458/730], Loss: 0.4627\n",
      "Epoch [4/10], Phase: train, Batch: [459/730], Loss: 0.3078\n",
      "Epoch [4/10], Phase: train, Batch: [460/730], Loss: 0.2831\n",
      "Epoch [4/10], Phase: train, Batch: [461/730], Loss: 0.2137\n",
      "Epoch [4/10], Phase: train, Batch: [462/730], Loss: 0.2148\n",
      "Epoch [4/10], Phase: train, Batch: [463/730], Loss: 0.3000\n",
      "Epoch [4/10], Phase: train, Batch: [464/730], Loss: 0.3976\n",
      "Epoch [4/10], Phase: train, Batch: [465/730], Loss: 0.1892\n",
      "Epoch [4/10], Phase: train, Batch: [466/730], Loss: 0.2746\n",
      "Epoch [4/10], Phase: train, Batch: [467/730], Loss: 0.4708\n",
      "Epoch [4/10], Phase: train, Batch: [468/730], Loss: 0.4541\n",
      "Epoch [4/10], Phase: train, Batch: [469/730], Loss: 0.2946\n",
      "Epoch [4/10], Phase: train, Batch: [470/730], Loss: 0.4371\n",
      "Epoch [4/10], Phase: train, Batch: [471/730], Loss: 0.4657\n",
      "Epoch [4/10], Phase: train, Batch: [472/730], Loss: 0.2380\n",
      "Epoch [4/10], Phase: train, Batch: [473/730], Loss: 0.3085\n",
      "Epoch [4/10], Phase: train, Batch: [474/730], Loss: 0.2584\n",
      "Epoch [4/10], Phase: train, Batch: [475/730], Loss: 0.4216\n",
      "Epoch [4/10], Phase: train, Batch: [476/730], Loss: 0.2206\n",
      "Epoch [4/10], Phase: train, Batch: [477/730], Loss: 0.2211\n",
      "Epoch [4/10], Phase: train, Batch: [478/730], Loss: 0.3369\n",
      "Epoch [4/10], Phase: train, Batch: [479/730], Loss: 0.2535\n",
      "Epoch [4/10], Phase: train, Batch: [480/730], Loss: 0.1801\n",
      "Epoch [4/10], Phase: train, Batch: [481/730], Loss: 0.3317\n",
      "Epoch [4/10], Phase: train, Batch: [482/730], Loss: 0.2496\n",
      "Epoch [4/10], Phase: train, Batch: [483/730], Loss: 0.4145\n",
      "Epoch [4/10], Phase: train, Batch: [484/730], Loss: 0.3663\n",
      "Epoch [4/10], Phase: train, Batch: [485/730], Loss: 0.2570\n",
      "Epoch [4/10], Phase: train, Batch: [486/730], Loss: 0.2816\n",
      "Epoch [4/10], Phase: train, Batch: [487/730], Loss: 0.2744\n",
      "Epoch [4/10], Phase: train, Batch: [488/730], Loss: 0.3080\n",
      "Epoch [4/10], Phase: train, Batch: [489/730], Loss: 0.3101\n",
      "Epoch [4/10], Phase: train, Batch: [490/730], Loss: 0.3331\n",
      "Epoch [4/10], Phase: train, Batch: [491/730], Loss: 0.1944\n",
      "Epoch [4/10], Phase: train, Batch: [492/730], Loss: 0.2158\n",
      "Epoch [4/10], Phase: train, Batch: [493/730], Loss: 0.2698\n",
      "Epoch [4/10], Phase: train, Batch: [494/730], Loss: 0.2799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [495/730], Loss: 0.3165\n",
      "Epoch [4/10], Phase: train, Batch: [496/730], Loss: 0.2563\n",
      "Epoch [4/10], Phase: train, Batch: [497/730], Loss: 0.3056\n",
      "Epoch [4/10], Phase: train, Batch: [498/730], Loss: 0.2823\n",
      "Epoch [4/10], Phase: train, Batch: [499/730], Loss: 0.2252\n",
      "Epoch [4/10], Phase: train, Batch: [500/730], Loss: 0.1459\n",
      "Epoch [4/10], Phase: train, Batch: [501/730], Loss: 0.4314\n",
      "Epoch [4/10], Phase: train, Batch: [502/730], Loss: 0.3435\n",
      "Epoch [4/10], Phase: train, Batch: [503/730], Loss: 0.2779\n",
      "Epoch [4/10], Phase: train, Batch: [504/730], Loss: 0.2419\n",
      "Epoch [4/10], Phase: train, Batch: [505/730], Loss: 0.2776\n",
      "Epoch [4/10], Phase: train, Batch: [506/730], Loss: 0.2623\n",
      "Epoch [4/10], Phase: train, Batch: [507/730], Loss: 0.3287\n",
      "Epoch [4/10], Phase: train, Batch: [508/730], Loss: 0.3599\n",
      "Epoch [4/10], Phase: train, Batch: [509/730], Loss: 0.4284\n",
      "Epoch [4/10], Phase: train, Batch: [510/730], Loss: 0.2531\n",
      "Epoch [4/10], Phase: train, Batch: [511/730], Loss: 0.3429\n",
      "Epoch [4/10], Phase: train, Batch: [512/730], Loss: 0.4729\n",
      "Epoch [4/10], Phase: train, Batch: [513/730], Loss: 0.2495\n",
      "Epoch [4/10], Phase: train, Batch: [514/730], Loss: 0.2024\n",
      "Epoch [4/10], Phase: train, Batch: [515/730], Loss: 0.3883\n",
      "Epoch [4/10], Phase: train, Batch: [516/730], Loss: 0.1852\n",
      "Epoch [4/10], Phase: train, Batch: [517/730], Loss: 0.1919\n",
      "Epoch [4/10], Phase: train, Batch: [518/730], Loss: 0.2127\n",
      "Epoch [4/10], Phase: train, Batch: [519/730], Loss: 0.2175\n",
      "Epoch [4/10], Phase: train, Batch: [520/730], Loss: 0.3794\n",
      "Epoch [4/10], Phase: train, Batch: [521/730], Loss: 0.3463\n",
      "Epoch [4/10], Phase: train, Batch: [522/730], Loss: 0.3042\n",
      "Epoch [4/10], Phase: train, Batch: [523/730], Loss: 0.2878\n",
      "Epoch [4/10], Phase: train, Batch: [524/730], Loss: 0.3508\n",
      "Epoch [4/10], Phase: train, Batch: [525/730], Loss: 0.4670\n",
      "Epoch [4/10], Phase: train, Batch: [526/730], Loss: 0.4242\n",
      "Epoch [4/10], Phase: train, Batch: [527/730], Loss: 0.3056\n",
      "Epoch [4/10], Phase: train, Batch: [528/730], Loss: 0.2700\n",
      "Epoch [4/10], Phase: train, Batch: [529/730], Loss: 0.3783\n",
      "Epoch [4/10], Phase: train, Batch: [530/730], Loss: 0.2592\n",
      "Epoch [4/10], Phase: train, Batch: [531/730], Loss: 0.2998\n",
      "Epoch [4/10], Phase: train, Batch: [532/730], Loss: 0.4149\n",
      "Epoch [4/10], Phase: train, Batch: [533/730], Loss: 0.2344\n",
      "Epoch [4/10], Phase: train, Batch: [534/730], Loss: 0.3275\n",
      "Epoch [4/10], Phase: train, Batch: [535/730], Loss: 0.2600\n",
      "Epoch [4/10], Phase: train, Batch: [536/730], Loss: 0.2141\n",
      "Epoch [4/10], Phase: train, Batch: [537/730], Loss: 0.2724\n",
      "Epoch [4/10], Phase: train, Batch: [538/730], Loss: 0.2519\n",
      "Epoch [4/10], Phase: train, Batch: [539/730], Loss: 0.2643\n",
      "Epoch [4/10], Phase: train, Batch: [540/730], Loss: 0.3497\n",
      "Epoch [4/10], Phase: train, Batch: [541/730], Loss: 0.4046\n",
      "Epoch [4/10], Phase: train, Batch: [542/730], Loss: 0.2554\n",
      "Epoch [4/10], Phase: train, Batch: [543/730], Loss: 0.3567\n",
      "Epoch [4/10], Phase: train, Batch: [544/730], Loss: 0.2072\n",
      "Epoch [4/10], Phase: train, Batch: [545/730], Loss: 0.3316\n",
      "Epoch [4/10], Phase: train, Batch: [546/730], Loss: 0.3805\n",
      "Epoch [4/10], Phase: train, Batch: [547/730], Loss: 0.2008\n",
      "Epoch [4/10], Phase: train, Batch: [548/730], Loss: 0.1137\n",
      "Epoch [4/10], Phase: train, Batch: [549/730], Loss: 0.2523\n",
      "Epoch [4/10], Phase: train, Batch: [550/730], Loss: 0.3539\n",
      "Epoch [4/10], Phase: train, Batch: [551/730], Loss: 0.2461\n",
      "Epoch [4/10], Phase: train, Batch: [552/730], Loss: 0.3487\n",
      "Epoch [4/10], Phase: train, Batch: [553/730], Loss: 0.2574\n",
      "Epoch [4/10], Phase: train, Batch: [554/730], Loss: 0.3086\n",
      "Epoch [4/10], Phase: train, Batch: [555/730], Loss: 0.3297\n",
      "Epoch [4/10], Phase: train, Batch: [556/730], Loss: 0.2597\n",
      "Epoch [4/10], Phase: train, Batch: [557/730], Loss: 0.2697\n",
      "Epoch [4/10], Phase: train, Batch: [558/730], Loss: 0.3582\n",
      "Epoch [4/10], Phase: train, Batch: [559/730], Loss: 0.3785\n",
      "Epoch [4/10], Phase: train, Batch: [560/730], Loss: 0.2989\n",
      "Epoch [4/10], Phase: train, Batch: [561/730], Loss: 0.3429\n",
      "Epoch [4/10], Phase: train, Batch: [562/730], Loss: 0.3679\n",
      "Epoch [4/10], Phase: train, Batch: [563/730], Loss: 0.3633\n",
      "Epoch [4/10], Phase: train, Batch: [564/730], Loss: 0.1888\n",
      "Epoch [4/10], Phase: train, Batch: [565/730], Loss: 0.3809\n",
      "Epoch [4/10], Phase: train, Batch: [566/730], Loss: 0.3033\n",
      "Epoch [4/10], Phase: train, Batch: [567/730], Loss: 0.1884\n",
      "Epoch [4/10], Phase: train, Batch: [568/730], Loss: 0.3846\n",
      "Epoch [4/10], Phase: train, Batch: [569/730], Loss: 0.3038\n",
      "Epoch [4/10], Phase: train, Batch: [570/730], Loss: 0.3173\n",
      "Epoch [4/10], Phase: train, Batch: [571/730], Loss: 0.2246\n",
      "Epoch [4/10], Phase: train, Batch: [572/730], Loss: 0.4050\n",
      "Epoch [4/10], Phase: train, Batch: [573/730], Loss: 0.2768\n",
      "Epoch [4/10], Phase: train, Batch: [574/730], Loss: 0.1283\n",
      "Epoch [4/10], Phase: train, Batch: [575/730], Loss: 0.2558\n",
      "Epoch [4/10], Phase: train, Batch: [576/730], Loss: 0.2551\n",
      "Epoch [4/10], Phase: train, Batch: [577/730], Loss: 0.2237\n",
      "Epoch [4/10], Phase: train, Batch: [578/730], Loss: 0.2200\n",
      "Epoch [4/10], Phase: train, Batch: [579/730], Loss: 0.3450\n",
      "Epoch [4/10], Phase: train, Batch: [580/730], Loss: 0.4227\n",
      "Epoch [4/10], Phase: train, Batch: [581/730], Loss: 0.3220\n",
      "Epoch [4/10], Phase: train, Batch: [582/730], Loss: 0.2749\n",
      "Epoch [4/10], Phase: train, Batch: [583/730], Loss: 0.3420\n",
      "Epoch [4/10], Phase: train, Batch: [584/730], Loss: 0.2349\n",
      "Epoch [4/10], Phase: train, Batch: [585/730], Loss: 0.2004\n",
      "Epoch [4/10], Phase: train, Batch: [586/730], Loss: 0.2631\n",
      "Epoch [4/10], Phase: train, Batch: [587/730], Loss: 0.2384\n",
      "Epoch [4/10], Phase: train, Batch: [588/730], Loss: 0.2601\n",
      "Epoch [4/10], Phase: train, Batch: [589/730], Loss: 0.4406\n",
      "Epoch [4/10], Phase: train, Batch: [590/730], Loss: 0.3910\n",
      "Epoch [4/10], Phase: train, Batch: [591/730], Loss: 0.2174\n",
      "Epoch [4/10], Phase: train, Batch: [592/730], Loss: 0.2604\n",
      "Epoch [4/10], Phase: train, Batch: [593/730], Loss: 0.2753\n",
      "Epoch [4/10], Phase: train, Batch: [594/730], Loss: 0.2729\n",
      "Epoch [4/10], Phase: train, Batch: [595/730], Loss: 0.3715\n",
      "Epoch [4/10], Phase: train, Batch: [596/730], Loss: 0.2744\n",
      "Epoch [4/10], Phase: train, Batch: [597/730], Loss: 0.3132\n",
      "Epoch [4/10], Phase: train, Batch: [598/730], Loss: 0.1593\n",
      "Epoch [4/10], Phase: train, Batch: [599/730], Loss: 0.2274\n",
      "Epoch [4/10], Phase: train, Batch: [600/730], Loss: 0.1721\n",
      "Epoch [4/10], Phase: train, Batch: [601/730], Loss: 0.3058\n",
      "Epoch [4/10], Phase: train, Batch: [602/730], Loss: 0.2916\n",
      "Epoch [4/10], Phase: train, Batch: [603/730], Loss: 0.2731\n",
      "Epoch [4/10], Phase: train, Batch: [604/730], Loss: 0.2001\n",
      "Epoch [4/10], Phase: train, Batch: [605/730], Loss: 0.2660\n",
      "Epoch [4/10], Phase: train, Batch: [606/730], Loss: 0.3385\n",
      "Epoch [4/10], Phase: train, Batch: [607/730], Loss: 0.2530\n",
      "Epoch [4/10], Phase: train, Batch: [608/730], Loss: 0.2893\n",
      "Epoch [4/10], Phase: train, Batch: [609/730], Loss: 0.2748\n",
      "Epoch [4/10], Phase: train, Batch: [610/730], Loss: 0.4587\n",
      "Epoch [4/10], Phase: train, Batch: [611/730], Loss: 0.2742\n",
      "Epoch [4/10], Phase: train, Batch: [612/730], Loss: 0.4131\n",
      "Epoch [4/10], Phase: train, Batch: [613/730], Loss: 0.2229\n",
      "Epoch [4/10], Phase: train, Batch: [614/730], Loss: 0.2119\n",
      "Epoch [4/10], Phase: train, Batch: [615/730], Loss: 0.2067\n",
      "Epoch [4/10], Phase: train, Batch: [616/730], Loss: 0.2631\n",
      "Epoch [4/10], Phase: train, Batch: [617/730], Loss: 0.2374\n",
      "Epoch [4/10], Phase: train, Batch: [618/730], Loss: 0.3336\n",
      "Epoch [4/10], Phase: train, Batch: [619/730], Loss: 0.3002\n",
      "Epoch [4/10], Phase: train, Batch: [620/730], Loss: 0.3873\n",
      "Epoch [4/10], Phase: train, Batch: [621/730], Loss: 0.2644\n",
      "Epoch [4/10], Phase: train, Batch: [622/730], Loss: 0.2849\n",
      "Epoch [4/10], Phase: train, Batch: [623/730], Loss: 0.1852\n",
      "Epoch [4/10], Phase: train, Batch: [624/730], Loss: 0.3130\n",
      "Epoch [4/10], Phase: train, Batch: [625/730], Loss: 0.3035\n",
      "Epoch [4/10], Phase: train, Batch: [626/730], Loss: 0.3669\n",
      "Epoch [4/10], Phase: train, Batch: [627/730], Loss: 0.3143\n",
      "Epoch [4/10], Phase: train, Batch: [628/730], Loss: 0.3881\n",
      "Epoch [4/10], Phase: train, Batch: [629/730], Loss: 0.2097\n",
      "Epoch [4/10], Phase: train, Batch: [630/730], Loss: 0.2428\n",
      "Epoch [4/10], Phase: train, Batch: [631/730], Loss: 0.2818\n",
      "Epoch [4/10], Phase: train, Batch: [632/730], Loss: 0.5231\n",
      "Epoch [4/10], Phase: train, Batch: [633/730], Loss: 0.3404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [634/730], Loss: 0.4040\n",
      "Epoch [4/10], Phase: train, Batch: [635/730], Loss: 0.2185\n",
      "Epoch [4/10], Phase: train, Batch: [636/730], Loss: 0.4693\n",
      "Epoch [4/10], Phase: train, Batch: [637/730], Loss: 0.2972\n",
      "Epoch [4/10], Phase: train, Batch: [638/730], Loss: 0.3444\n",
      "Epoch [4/10], Phase: train, Batch: [639/730], Loss: 0.3952\n",
      "Epoch [4/10], Phase: train, Batch: [640/730], Loss: 0.2626\n",
      "Epoch [4/10], Phase: train, Batch: [641/730], Loss: 0.2863\n",
      "Epoch [4/10], Phase: train, Batch: [642/730], Loss: 0.3005\n",
      "Epoch [4/10], Phase: train, Batch: [643/730], Loss: 0.2663\n",
      "Epoch [4/10], Phase: train, Batch: [644/730], Loss: 0.2880\n",
      "Epoch [4/10], Phase: train, Batch: [645/730], Loss: 0.2955\n",
      "Epoch [4/10], Phase: train, Batch: [646/730], Loss: 0.2941\n",
      "Epoch [4/10], Phase: train, Batch: [647/730], Loss: 0.2318\n",
      "Epoch [4/10], Phase: train, Batch: [648/730], Loss: 0.3730\n",
      "Epoch [4/10], Phase: train, Batch: [649/730], Loss: 0.2227\n",
      "Epoch [4/10], Phase: train, Batch: [650/730], Loss: 0.3782\n",
      "Epoch [4/10], Phase: train, Batch: [651/730], Loss: 0.2665\n",
      "Epoch [4/10], Phase: train, Batch: [652/730], Loss: 0.4223\n",
      "Epoch [4/10], Phase: train, Batch: [653/730], Loss: 0.1448\n",
      "Epoch [4/10], Phase: train, Batch: [654/730], Loss: 0.3923\n",
      "Epoch [4/10], Phase: train, Batch: [655/730], Loss: 0.3927\n",
      "Epoch [4/10], Phase: train, Batch: [656/730], Loss: 0.4714\n",
      "Epoch [4/10], Phase: train, Batch: [657/730], Loss: 0.1605\n",
      "Epoch [4/10], Phase: train, Batch: [658/730], Loss: 0.2735\n",
      "Epoch [4/10], Phase: train, Batch: [659/730], Loss: 0.1768\n",
      "Epoch [4/10], Phase: train, Batch: [660/730], Loss: 0.1703\n",
      "Epoch [4/10], Phase: train, Batch: [661/730], Loss: 0.2377\n",
      "Epoch [4/10], Phase: train, Batch: [662/730], Loss: 0.1874\n",
      "Epoch [4/10], Phase: train, Batch: [663/730], Loss: 0.2295\n",
      "Epoch [4/10], Phase: train, Batch: [664/730], Loss: 0.2375\n",
      "Epoch [4/10], Phase: train, Batch: [665/730], Loss: 0.3011\n",
      "Epoch [4/10], Phase: train, Batch: [666/730], Loss: 0.2393\n",
      "Epoch [4/10], Phase: train, Batch: [667/730], Loss: 0.2405\n",
      "Epoch [4/10], Phase: train, Batch: [668/730], Loss: 0.2531\n",
      "Epoch [4/10], Phase: train, Batch: [669/730], Loss: 0.1895\n",
      "Epoch [4/10], Phase: train, Batch: [670/730], Loss: 0.2427\n",
      "Epoch [4/10], Phase: train, Batch: [671/730], Loss: 0.3260\n",
      "Epoch [4/10], Phase: train, Batch: [672/730], Loss: 0.2225\n",
      "Epoch [4/10], Phase: train, Batch: [673/730], Loss: 0.2944\n",
      "Epoch [4/10], Phase: train, Batch: [674/730], Loss: 0.3031\n",
      "Epoch [4/10], Phase: train, Batch: [675/730], Loss: 0.4646\n",
      "Epoch [4/10], Phase: train, Batch: [676/730], Loss: 0.2784\n",
      "Epoch [4/10], Phase: train, Batch: [677/730], Loss: 0.2877\n",
      "Epoch [4/10], Phase: train, Batch: [678/730], Loss: 0.2275\n",
      "Epoch [4/10], Phase: train, Batch: [679/730], Loss: 0.1711\n",
      "Epoch [4/10], Phase: train, Batch: [680/730], Loss: 0.3226\n",
      "Epoch [4/10], Phase: train, Batch: [681/730], Loss: 0.3320\n",
      "Epoch [4/10], Phase: train, Batch: [682/730], Loss: 0.2235\n",
      "Epoch [4/10], Phase: train, Batch: [683/730], Loss: 0.1376\n",
      "Epoch [4/10], Phase: train, Batch: [684/730], Loss: 0.2568\n",
      "Epoch [4/10], Phase: train, Batch: [685/730], Loss: 0.2379\n",
      "Epoch [4/10], Phase: train, Batch: [686/730], Loss: 0.3088\n",
      "Epoch [4/10], Phase: train, Batch: [687/730], Loss: 0.2874\n",
      "Epoch [4/10], Phase: train, Batch: [688/730], Loss: 0.1671\n",
      "Epoch [4/10], Phase: train, Batch: [689/730], Loss: 0.2814\n",
      "Epoch [4/10], Phase: train, Batch: [690/730], Loss: 0.2994\n",
      "Epoch [4/10], Phase: train, Batch: [691/730], Loss: 0.3668\n",
      "Epoch [4/10], Phase: train, Batch: [692/730], Loss: 0.3454\n",
      "Epoch [4/10], Phase: train, Batch: [693/730], Loss: 0.2504\n",
      "Epoch [4/10], Phase: train, Batch: [694/730], Loss: 0.1963\n",
      "Epoch [4/10], Phase: train, Batch: [695/730], Loss: 0.2109\n",
      "Epoch [4/10], Phase: train, Batch: [696/730], Loss: 0.1776\n",
      "Epoch [4/10], Phase: train, Batch: [697/730], Loss: 0.2844\n",
      "Epoch [4/10], Phase: train, Batch: [698/730], Loss: 0.2253\n",
      "Epoch [4/10], Phase: train, Batch: [699/730], Loss: 0.3226\n",
      "Epoch [4/10], Phase: train, Batch: [700/730], Loss: 0.3135\n",
      "Epoch [4/10], Phase: train, Batch: [701/730], Loss: 0.2276\n",
      "Epoch [4/10], Phase: train, Batch: [702/730], Loss: 0.3373\n",
      "Epoch [4/10], Phase: train, Batch: [703/730], Loss: 0.3929\n",
      "Epoch [4/10], Phase: train, Batch: [704/730], Loss: 0.2696\n",
      "Epoch [4/10], Phase: train, Batch: [705/730], Loss: 0.2502\n",
      "Epoch [4/10], Phase: train, Batch: [706/730], Loss: 0.2875\n",
      "Epoch [4/10], Phase: train, Batch: [707/730], Loss: 0.3486\n",
      "Epoch [4/10], Phase: train, Batch: [708/730], Loss: 0.2369\n",
      "Epoch [4/10], Phase: train, Batch: [709/730], Loss: 0.2688\n",
      "Epoch [4/10], Phase: train, Batch: [710/730], Loss: 0.2609\n",
      "Epoch [4/10], Phase: train, Batch: [711/730], Loss: 0.1962\n",
      "Epoch [4/10], Phase: train, Batch: [712/730], Loss: 0.3504\n",
      "Epoch [4/10], Phase: train, Batch: [713/730], Loss: 0.2194\n",
      "Epoch [4/10], Phase: train, Batch: [714/730], Loss: 0.3557\n",
      "Epoch [4/10], Phase: train, Batch: [715/730], Loss: 0.2484\n",
      "Epoch [4/10], Phase: train, Batch: [716/730], Loss: 0.2635\n",
      "Epoch [4/10], Phase: train, Batch: [717/730], Loss: 0.2999\n",
      "Epoch [4/10], Phase: train, Batch: [718/730], Loss: 0.2070\n",
      "Epoch [4/10], Phase: train, Batch: [719/730], Loss: 0.3455\n",
      "Epoch [4/10], Phase: train, Batch: [720/730], Loss: 0.2173\n",
      "Epoch [4/10], Phase: train, Batch: [721/730], Loss: 0.1378\n",
      "Epoch [4/10], Phase: train, Batch: [722/730], Loss: 0.2625\n",
      "Epoch [4/10], Phase: train, Batch: [723/730], Loss: 0.2955\n",
      "Epoch [4/10], Phase: train, Batch: [724/730], Loss: 0.3023\n",
      "Epoch [4/10], Phase: train, Batch: [725/730], Loss: 0.2544\n",
      "Epoch [4/10], Phase: train, Batch: [726/730], Loss: 0.3718\n",
      "Epoch [4/10], Phase: train, Batch: [727/730], Loss: 0.2968\n",
      "Epoch [4/10], Phase: train, Batch: [728/730], Loss: 0.3631\n",
      "Epoch [4/10], Phase: train, Batch: [729/730], Loss: 0.2598\n",
      "Epoch [4/10], Phase: train, Batch: [730/730], Loss: 0.2978\n",
      "train Loss: 0.2879 Acc: 0.8834\n",
      "Epoch [4/10], Phase: val, Batch: [1/182], Loss: 0.3031\n",
      "Epoch [4/10], Phase: val, Batch: [2/182], Loss: 0.2174\n",
      "Epoch [4/10], Phase: val, Batch: [3/182], Loss: 0.1567\n",
      "Epoch [4/10], Phase: val, Batch: [4/182], Loss: 0.2458\n",
      "Epoch [4/10], Phase: val, Batch: [5/182], Loss: 0.1963\n",
      "Epoch [4/10], Phase: val, Batch: [6/182], Loss: 0.1650\n",
      "Epoch [4/10], Phase: val, Batch: [7/182], Loss: 0.0949\n",
      "Epoch [4/10], Phase: val, Batch: [8/182], Loss: 0.2348\n",
      "Epoch [4/10], Phase: val, Batch: [9/182], Loss: 0.1961\n",
      "Epoch [4/10], Phase: val, Batch: [10/182], Loss: 0.1587\n",
      "Epoch [4/10], Phase: val, Batch: [11/182], Loss: 0.1353\n",
      "Epoch [4/10], Phase: val, Batch: [12/182], Loss: 0.2177\n",
      "Epoch [4/10], Phase: val, Batch: [13/182], Loss: 0.1668\n",
      "Epoch [4/10], Phase: val, Batch: [14/182], Loss: 0.1228\n",
      "Epoch [4/10], Phase: val, Batch: [15/182], Loss: 0.1791\n",
      "Epoch [4/10], Phase: val, Batch: [16/182], Loss: 0.2273\n",
      "Epoch [4/10], Phase: val, Batch: [17/182], Loss: 0.2119\n",
      "Epoch [4/10], Phase: val, Batch: [18/182], Loss: 0.1941\n",
      "Epoch [4/10], Phase: val, Batch: [19/182], Loss: 0.2985\n",
      "Epoch [4/10], Phase: val, Batch: [20/182], Loss: 0.3127\n",
      "Epoch [4/10], Phase: val, Batch: [21/182], Loss: 0.3012\n",
      "Epoch [4/10], Phase: val, Batch: [22/182], Loss: 0.2957\n",
      "Epoch [4/10], Phase: val, Batch: [23/182], Loss: 0.1557\n",
      "Epoch [4/10], Phase: val, Batch: [24/182], Loss: 0.3181\n",
      "Epoch [4/10], Phase: val, Batch: [25/182], Loss: 0.2332\n",
      "Epoch [4/10], Phase: val, Batch: [26/182], Loss: 0.1444\n",
      "Epoch [4/10], Phase: val, Batch: [27/182], Loss: 0.1858\n",
      "Epoch [4/10], Phase: val, Batch: [28/182], Loss: 0.3154\n",
      "Epoch [4/10], Phase: val, Batch: [29/182], Loss: 0.2537\n",
      "Epoch [4/10], Phase: val, Batch: [30/182], Loss: 0.2513\n",
      "Epoch [4/10], Phase: val, Batch: [31/182], Loss: 0.3073\n",
      "Epoch [4/10], Phase: val, Batch: [32/182], Loss: 0.1248\n",
      "Epoch [4/10], Phase: val, Batch: [33/182], Loss: 0.2309\n",
      "Epoch [4/10], Phase: val, Batch: [34/182], Loss: 0.2322\n",
      "Epoch [4/10], Phase: val, Batch: [35/182], Loss: 0.1388\n",
      "Epoch [4/10], Phase: val, Batch: [36/182], Loss: 0.2106\n",
      "Epoch [4/10], Phase: val, Batch: [37/182], Loss: 0.1434\n",
      "Epoch [4/10], Phase: val, Batch: [38/182], Loss: 0.1559\n",
      "Epoch [4/10], Phase: val, Batch: [39/182], Loss: 0.2589\n",
      "Epoch [4/10], Phase: val, Batch: [40/182], Loss: 0.2068\n",
      "Epoch [4/10], Phase: val, Batch: [41/182], Loss: 0.1893\n",
      "Epoch [4/10], Phase: val, Batch: [42/182], Loss: 0.2365\n",
      "Epoch [4/10], Phase: val, Batch: [43/182], Loss: 0.1754\n",
      "Epoch [4/10], Phase: val, Batch: [44/182], Loss: 0.2773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: val, Batch: [45/182], Loss: 0.2532\n",
      "Epoch [4/10], Phase: val, Batch: [46/182], Loss: 0.1782\n",
      "Epoch [4/10], Phase: val, Batch: [47/182], Loss: 0.2523\n",
      "Epoch [4/10], Phase: val, Batch: [48/182], Loss: 0.1072\n",
      "Epoch [4/10], Phase: val, Batch: [49/182], Loss: 0.2418\n",
      "Epoch [4/10], Phase: val, Batch: [50/182], Loss: 0.3038\n",
      "Epoch [4/10], Phase: val, Batch: [51/182], Loss: 0.3331\n",
      "Epoch [4/10], Phase: val, Batch: [52/182], Loss: 0.2023\n",
      "Epoch [4/10], Phase: val, Batch: [53/182], Loss: 0.2016\n",
      "Epoch [4/10], Phase: val, Batch: [54/182], Loss: 0.2560\n",
      "Epoch [4/10], Phase: val, Batch: [55/182], Loss: 0.1577\n",
      "Epoch [4/10], Phase: val, Batch: [56/182], Loss: 0.1613\n",
      "Epoch [4/10], Phase: val, Batch: [57/182], Loss: 0.2005\n",
      "Epoch [4/10], Phase: val, Batch: [58/182], Loss: 0.1804\n",
      "Epoch [4/10], Phase: val, Batch: [59/182], Loss: 0.1595\n",
      "Epoch [4/10], Phase: val, Batch: [60/182], Loss: 0.1430\n",
      "Epoch [4/10], Phase: val, Batch: [61/182], Loss: 0.2593\n",
      "Epoch [4/10], Phase: val, Batch: [62/182], Loss: 0.3242\n",
      "Epoch [4/10], Phase: val, Batch: [63/182], Loss: 0.1608\n",
      "Epoch [4/10], Phase: val, Batch: [64/182], Loss: 0.2503\n",
      "Epoch [4/10], Phase: val, Batch: [65/182], Loss: 0.1675\n",
      "Epoch [4/10], Phase: val, Batch: [66/182], Loss: 0.2349\n",
      "Epoch [4/10], Phase: val, Batch: [67/182], Loss: 0.1889\n",
      "Epoch [4/10], Phase: val, Batch: [68/182], Loss: 0.1885\n",
      "Epoch [4/10], Phase: val, Batch: [69/182], Loss: 0.2382\n",
      "Epoch [4/10], Phase: val, Batch: [70/182], Loss: 0.2059\n",
      "Epoch [4/10], Phase: val, Batch: [71/182], Loss: 0.3170\n",
      "Epoch [4/10], Phase: val, Batch: [72/182], Loss: 0.1856\n",
      "Epoch [4/10], Phase: val, Batch: [73/182], Loss: 0.1509\n",
      "Epoch [4/10], Phase: val, Batch: [74/182], Loss: 0.3175\n",
      "Epoch [4/10], Phase: val, Batch: [75/182], Loss: 0.1958\n",
      "Epoch [4/10], Phase: val, Batch: [76/182], Loss: 0.1494\n",
      "Epoch [4/10], Phase: val, Batch: [77/182], Loss: 0.1440\n",
      "Epoch [4/10], Phase: val, Batch: [78/182], Loss: 0.1379\n",
      "Epoch [4/10], Phase: val, Batch: [79/182], Loss: 0.2001\n",
      "Epoch [4/10], Phase: val, Batch: [80/182], Loss: 0.1650\n",
      "Epoch [4/10], Phase: val, Batch: [81/182], Loss: 0.1155\n",
      "Epoch [4/10], Phase: val, Batch: [82/182], Loss: 0.1731\n",
      "Epoch [4/10], Phase: val, Batch: [83/182], Loss: 0.1835\n",
      "Epoch [4/10], Phase: val, Batch: [84/182], Loss: 0.1926\n",
      "Epoch [4/10], Phase: val, Batch: [85/182], Loss: 0.1774\n",
      "Epoch [4/10], Phase: val, Batch: [86/182], Loss: 0.2440\n",
      "Epoch [4/10], Phase: val, Batch: [87/182], Loss: 0.3305\n",
      "Epoch [4/10], Phase: val, Batch: [88/182], Loss: 0.2367\n",
      "Epoch [4/10], Phase: val, Batch: [89/182], Loss: 0.2125\n",
      "Epoch [4/10], Phase: val, Batch: [90/182], Loss: 0.2594\n",
      "Epoch [4/10], Phase: val, Batch: [91/182], Loss: 0.2504\n",
      "Epoch [4/10], Phase: val, Batch: [92/182], Loss: 0.2397\n",
      "Epoch [4/10], Phase: val, Batch: [93/182], Loss: 0.1968\n",
      "Epoch [4/10], Phase: val, Batch: [94/182], Loss: 0.2131\n",
      "Epoch [4/10], Phase: val, Batch: [95/182], Loss: 0.2871\n",
      "Epoch [4/10], Phase: val, Batch: [96/182], Loss: 0.2402\n",
      "Epoch [4/10], Phase: val, Batch: [97/182], Loss: 0.2583\n",
      "Epoch [4/10], Phase: val, Batch: [98/182], Loss: 0.2388\n",
      "Epoch [4/10], Phase: val, Batch: [99/182], Loss: 0.2832\n",
      "Epoch [4/10], Phase: val, Batch: [100/182], Loss: 0.3078\n",
      "Epoch [4/10], Phase: val, Batch: [101/182], Loss: 0.3614\n",
      "Epoch [4/10], Phase: val, Batch: [102/182], Loss: 0.2211\n",
      "Epoch [4/10], Phase: val, Batch: [103/182], Loss: 0.2547\n",
      "Epoch [4/10], Phase: val, Batch: [104/182], Loss: 0.2584\n",
      "Epoch [4/10], Phase: val, Batch: [105/182], Loss: 0.2015\n",
      "Epoch [4/10], Phase: val, Batch: [106/182], Loss: 0.4041\n",
      "Epoch [4/10], Phase: val, Batch: [107/182], Loss: 0.2788\n",
      "Epoch [4/10], Phase: val, Batch: [108/182], Loss: 0.2455\n",
      "Epoch [4/10], Phase: val, Batch: [109/182], Loss: 0.2561\n",
      "Epoch [4/10], Phase: val, Batch: [110/182], Loss: 0.2099\n",
      "Epoch [4/10], Phase: val, Batch: [111/182], Loss: 0.1427\n",
      "Epoch [4/10], Phase: val, Batch: [112/182], Loss: 0.1933\n",
      "Epoch [4/10], Phase: val, Batch: [113/182], Loss: 0.1736\n",
      "Epoch [4/10], Phase: val, Batch: [114/182], Loss: 0.2792\n",
      "Epoch [4/10], Phase: val, Batch: [115/182], Loss: 0.2064\n",
      "Epoch [4/10], Phase: val, Batch: [116/182], Loss: 0.2902\n",
      "Epoch [4/10], Phase: val, Batch: [117/182], Loss: 0.1579\n",
      "Epoch [4/10], Phase: val, Batch: [118/182], Loss: 0.2558\n",
      "Epoch [4/10], Phase: val, Batch: [119/182], Loss: 0.1973\n",
      "Epoch [4/10], Phase: val, Batch: [120/182], Loss: 0.2293\n",
      "Epoch [4/10], Phase: val, Batch: [121/182], Loss: 0.2509\n",
      "Epoch [4/10], Phase: val, Batch: [122/182], Loss: 0.2226\n",
      "Epoch [4/10], Phase: val, Batch: [123/182], Loss: 0.3092\n",
      "Epoch [4/10], Phase: val, Batch: [124/182], Loss: 0.1798\n",
      "Epoch [4/10], Phase: val, Batch: [125/182], Loss: 0.1967\n",
      "Epoch [4/10], Phase: val, Batch: [126/182], Loss: 0.2407\n",
      "Epoch [4/10], Phase: val, Batch: [127/182], Loss: 0.2217\n",
      "Epoch [4/10], Phase: val, Batch: [128/182], Loss: 0.2201\n",
      "Epoch [4/10], Phase: val, Batch: [129/182], Loss: 0.2564\n",
      "Epoch [4/10], Phase: val, Batch: [130/182], Loss: 0.1834\n",
      "Epoch [4/10], Phase: val, Batch: [131/182], Loss: 0.2710\n",
      "Epoch [4/10], Phase: val, Batch: [132/182], Loss: 0.2686\n",
      "Epoch [4/10], Phase: val, Batch: [133/182], Loss: 0.3700\n",
      "Epoch [4/10], Phase: val, Batch: [134/182], Loss: 0.1355\n",
      "Epoch [4/10], Phase: val, Batch: [135/182], Loss: 0.2162\n",
      "Epoch [4/10], Phase: val, Batch: [136/182], Loss: 0.2936\n",
      "Epoch [4/10], Phase: val, Batch: [137/182], Loss: 0.2472\n",
      "Epoch [4/10], Phase: val, Batch: [138/182], Loss: 0.2707\n",
      "Epoch [4/10], Phase: val, Batch: [139/182], Loss: 0.1661\n",
      "Epoch [4/10], Phase: val, Batch: [140/182], Loss: 0.2608\n",
      "Epoch [4/10], Phase: val, Batch: [141/182], Loss: 0.2369\n",
      "Epoch [4/10], Phase: val, Batch: [142/182], Loss: 0.2145\n",
      "Epoch [4/10], Phase: val, Batch: [143/182], Loss: 0.2825\n",
      "Epoch [4/10], Phase: val, Batch: [144/182], Loss: 0.2898\n",
      "Epoch [4/10], Phase: val, Batch: [145/182], Loss: 0.1522\n",
      "Epoch [4/10], Phase: val, Batch: [146/182], Loss: 0.2245\n",
      "Epoch [4/10], Phase: val, Batch: [147/182], Loss: 0.2696\n",
      "Epoch [4/10], Phase: val, Batch: [148/182], Loss: 0.2018\n",
      "Epoch [4/10], Phase: val, Batch: [149/182], Loss: 0.2788\n",
      "Epoch [4/10], Phase: val, Batch: [150/182], Loss: 0.2872\n",
      "Epoch [4/10], Phase: val, Batch: [151/182], Loss: 0.2753\n",
      "Epoch [4/10], Phase: val, Batch: [152/182], Loss: 0.3075\n",
      "Epoch [4/10], Phase: val, Batch: [153/182], Loss: 0.2838\n",
      "Epoch [4/10], Phase: val, Batch: [154/182], Loss: 0.2612\n",
      "Epoch [4/10], Phase: val, Batch: [155/182], Loss: 0.2228\n",
      "Epoch [4/10], Phase: val, Batch: [156/182], Loss: 0.3617\n",
      "Epoch [4/10], Phase: val, Batch: [157/182], Loss: 0.2676\n",
      "Epoch [4/10], Phase: val, Batch: [158/182], Loss: 0.3999\n",
      "Epoch [4/10], Phase: val, Batch: [159/182], Loss: 0.2789\n",
      "Epoch [4/10], Phase: val, Batch: [160/182], Loss: 0.2128\n",
      "Epoch [4/10], Phase: val, Batch: [161/182], Loss: 0.2694\n",
      "Epoch [4/10], Phase: val, Batch: [162/182], Loss: 0.3158\n",
      "Epoch [4/10], Phase: val, Batch: [163/182], Loss: 0.3283\n",
      "Epoch [4/10], Phase: val, Batch: [164/182], Loss: 0.2066\n",
      "Epoch [4/10], Phase: val, Batch: [165/182], Loss: 0.2677\n",
      "Epoch [4/10], Phase: val, Batch: [166/182], Loss: 0.1595\n",
      "Epoch [4/10], Phase: val, Batch: [167/182], Loss: 0.2078\n",
      "Epoch [4/10], Phase: val, Batch: [168/182], Loss: 0.2279\n",
      "Epoch [4/10], Phase: val, Batch: [169/182], Loss: 0.2709\n",
      "Epoch [4/10], Phase: val, Batch: [170/182], Loss: 0.2778\n",
      "Epoch [4/10], Phase: val, Batch: [171/182], Loss: 0.3386\n",
      "Epoch [4/10], Phase: val, Batch: [172/182], Loss: 0.2458\n",
      "Epoch [4/10], Phase: val, Batch: [173/182], Loss: 0.1358\n",
      "Epoch [4/10], Phase: val, Batch: [174/182], Loss: 0.2956\n",
      "Epoch [4/10], Phase: val, Batch: [175/182], Loss: 0.1679\n",
      "Epoch [4/10], Phase: val, Batch: [176/182], Loss: 0.2391\n",
      "Epoch [4/10], Phase: val, Batch: [177/182], Loss: 0.2824\n",
      "Epoch [4/10], Phase: val, Batch: [178/182], Loss: 0.1438\n",
      "Epoch [4/10], Phase: val, Batch: [179/182], Loss: 0.2111\n",
      "Epoch [4/10], Phase: val, Batch: [180/182], Loss: 0.2223\n",
      "Epoch [4/10], Phase: val, Batch: [181/182], Loss: 0.3440\n",
      "Epoch [4/10], Phase: val, Batch: [182/182], Loss: 0.2538\n",
      "val Loss: 0.2300 Acc: 0.9093\n",
      "Epoch [5/10], Phase: train, Batch: [1/730], Loss: 0.4347\n",
      "Epoch [5/10], Phase: train, Batch: [2/730], Loss: 0.4525\n",
      "Epoch [5/10], Phase: train, Batch: [3/730], Loss: 0.3516\n",
      "Epoch [5/10], Phase: train, Batch: [4/730], Loss: 0.2199\n",
      "Epoch [5/10], Phase: train, Batch: [5/730], Loss: 0.3177\n",
      "Epoch [5/10], Phase: train, Batch: [6/730], Loss: 0.5098\n",
      "Epoch [5/10], Phase: train, Batch: [7/730], Loss: 0.3624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [8/730], Loss: 0.1978\n",
      "Epoch [5/10], Phase: train, Batch: [9/730], Loss: 0.3833\n",
      "Epoch [5/10], Phase: train, Batch: [10/730], Loss: 0.3622\n",
      "Epoch [5/10], Phase: train, Batch: [11/730], Loss: 0.3334\n",
      "Epoch [5/10], Phase: train, Batch: [12/730], Loss: 0.2437\n",
      "Epoch [5/10], Phase: train, Batch: [13/730], Loss: 0.2518\n",
      "Epoch [5/10], Phase: train, Batch: [14/730], Loss: 0.3813\n",
      "Epoch [5/10], Phase: train, Batch: [15/730], Loss: 0.2886\n",
      "Epoch [5/10], Phase: train, Batch: [16/730], Loss: 0.1978\n",
      "Epoch [5/10], Phase: train, Batch: [17/730], Loss: 0.3214\n",
      "Epoch [5/10], Phase: train, Batch: [18/730], Loss: 0.4243\n",
      "Epoch [5/10], Phase: train, Batch: [19/730], Loss: 0.3155\n",
      "Epoch [5/10], Phase: train, Batch: [20/730], Loss: 0.1984\n",
      "Epoch [5/10], Phase: train, Batch: [21/730], Loss: 0.4480\n",
      "Epoch [5/10], Phase: train, Batch: [22/730], Loss: 0.3542\n",
      "Epoch [5/10], Phase: train, Batch: [23/730], Loss: 0.3741\n",
      "Epoch [5/10], Phase: train, Batch: [24/730], Loss: 0.1561\n",
      "Epoch [5/10], Phase: train, Batch: [25/730], Loss: 0.4273\n",
      "Epoch [5/10], Phase: train, Batch: [26/730], Loss: 0.3008\n",
      "Epoch [5/10], Phase: train, Batch: [27/730], Loss: 0.3246\n",
      "Epoch [5/10], Phase: train, Batch: [28/730], Loss: 0.3157\n",
      "Epoch [5/10], Phase: train, Batch: [29/730], Loss: 0.1789\n",
      "Epoch [5/10], Phase: train, Batch: [30/730], Loss: 0.3160\n",
      "Epoch [5/10], Phase: train, Batch: [31/730], Loss: 0.3310\n",
      "Epoch [5/10], Phase: train, Batch: [32/730], Loss: 0.2592\n",
      "Epoch [5/10], Phase: train, Batch: [33/730], Loss: 0.1904\n",
      "Epoch [5/10], Phase: train, Batch: [34/730], Loss: 0.2929\n",
      "Epoch [5/10], Phase: train, Batch: [35/730], Loss: 0.2623\n",
      "Epoch [5/10], Phase: train, Batch: [36/730], Loss: 0.3602\n",
      "Epoch [5/10], Phase: train, Batch: [37/730], Loss: 0.1838\n",
      "Epoch [5/10], Phase: train, Batch: [38/730], Loss: 0.1236\n",
      "Epoch [5/10], Phase: train, Batch: [39/730], Loss: 0.3809\n",
      "Epoch [5/10], Phase: train, Batch: [40/730], Loss: 0.3149\n",
      "Epoch [5/10], Phase: train, Batch: [41/730], Loss: 0.2555\n",
      "Epoch [5/10], Phase: train, Batch: [42/730], Loss: 0.2131\n",
      "Epoch [5/10], Phase: train, Batch: [43/730], Loss: 0.2168\n",
      "Epoch [5/10], Phase: train, Batch: [44/730], Loss: 0.2592\n",
      "Epoch [5/10], Phase: train, Batch: [45/730], Loss: 0.1667\n",
      "Epoch [5/10], Phase: train, Batch: [46/730], Loss: 0.1656\n",
      "Epoch [5/10], Phase: train, Batch: [47/730], Loss: 0.1917\n",
      "Epoch [5/10], Phase: train, Batch: [48/730], Loss: 0.3477\n",
      "Epoch [5/10], Phase: train, Batch: [49/730], Loss: 0.2559\n",
      "Epoch [5/10], Phase: train, Batch: [50/730], Loss: 0.2840\n",
      "Epoch [5/10], Phase: train, Batch: [51/730], Loss: 0.2970\n",
      "Epoch [5/10], Phase: train, Batch: [52/730], Loss: 0.3443\n",
      "Epoch [5/10], Phase: train, Batch: [53/730], Loss: 0.3602\n",
      "Epoch [5/10], Phase: train, Batch: [54/730], Loss: 0.3000\n",
      "Epoch [5/10], Phase: train, Batch: [55/730], Loss: 0.2909\n",
      "Epoch [5/10], Phase: train, Batch: [56/730], Loss: 0.1941\n",
      "Epoch [5/10], Phase: train, Batch: [57/730], Loss: 0.2681\n",
      "Epoch [5/10], Phase: train, Batch: [58/730], Loss: 0.3956\n",
      "Epoch [5/10], Phase: train, Batch: [59/730], Loss: 0.2401\n",
      "Epoch [5/10], Phase: train, Batch: [60/730], Loss: 0.3315\n",
      "Epoch [5/10], Phase: train, Batch: [61/730], Loss: 0.2060\n",
      "Epoch [5/10], Phase: train, Batch: [62/730], Loss: 0.1841\n",
      "Epoch [5/10], Phase: train, Batch: [63/730], Loss: 0.3017\n",
      "Epoch [5/10], Phase: train, Batch: [64/730], Loss: 0.3257\n",
      "Epoch [5/10], Phase: train, Batch: [65/730], Loss: 0.2328\n",
      "Epoch [5/10], Phase: train, Batch: [66/730], Loss: 0.3625\n",
      "Epoch [5/10], Phase: train, Batch: [67/730], Loss: 0.2186\n",
      "Epoch [5/10], Phase: train, Batch: [68/730], Loss: 0.3717\n",
      "Epoch [5/10], Phase: train, Batch: [69/730], Loss: 0.3409\n",
      "Epoch [5/10], Phase: train, Batch: [70/730], Loss: 0.2850\n",
      "Epoch [5/10], Phase: train, Batch: [71/730], Loss: 0.1903\n",
      "Epoch [5/10], Phase: train, Batch: [72/730], Loss: 0.1925\n",
      "Epoch [5/10], Phase: train, Batch: [73/730], Loss: 0.2669\n",
      "Epoch [5/10], Phase: train, Batch: [74/730], Loss: 0.2734\n",
      "Epoch [5/10], Phase: train, Batch: [75/730], Loss: 0.3750\n",
      "Epoch [5/10], Phase: train, Batch: [76/730], Loss: 0.2792\n",
      "Epoch [5/10], Phase: train, Batch: [77/730], Loss: 0.3516\n",
      "Epoch [5/10], Phase: train, Batch: [78/730], Loss: 0.2305\n",
      "Epoch [5/10], Phase: train, Batch: [79/730], Loss: 0.3599\n",
      "Epoch [5/10], Phase: train, Batch: [80/730], Loss: 0.1319\n",
      "Epoch [5/10], Phase: train, Batch: [81/730], Loss: 0.4076\n",
      "Epoch [5/10], Phase: train, Batch: [82/730], Loss: 0.2958\n",
      "Epoch [5/10], Phase: train, Batch: [83/730], Loss: 0.3476\n",
      "Epoch [5/10], Phase: train, Batch: [84/730], Loss: 0.3329\n",
      "Epoch [5/10], Phase: train, Batch: [85/730], Loss: 0.1776\n",
      "Epoch [5/10], Phase: train, Batch: [86/730], Loss: 0.3204\n",
      "Epoch [5/10], Phase: train, Batch: [87/730], Loss: 0.3419\n",
      "Epoch [5/10], Phase: train, Batch: [88/730], Loss: 0.4361\n",
      "Epoch [5/10], Phase: train, Batch: [89/730], Loss: 0.3544\n",
      "Epoch [5/10], Phase: train, Batch: [90/730], Loss: 0.3454\n",
      "Epoch [5/10], Phase: train, Batch: [91/730], Loss: 0.2100\n",
      "Epoch [5/10], Phase: train, Batch: [92/730], Loss: 0.3288\n",
      "Epoch [5/10], Phase: train, Batch: [93/730], Loss: 0.3250\n",
      "Epoch [5/10], Phase: train, Batch: [94/730], Loss: 0.2365\n",
      "Epoch [5/10], Phase: train, Batch: [95/730], Loss: 0.3162\n",
      "Epoch [5/10], Phase: train, Batch: [96/730], Loss: 0.2123\n",
      "Epoch [5/10], Phase: train, Batch: [97/730], Loss: 0.4507\n",
      "Epoch [5/10], Phase: train, Batch: [98/730], Loss: 0.3229\n",
      "Epoch [5/10], Phase: train, Batch: [99/730], Loss: 0.2721\n",
      "Epoch [5/10], Phase: train, Batch: [100/730], Loss: 0.3122\n",
      "Epoch [5/10], Phase: train, Batch: [101/730], Loss: 0.3898\n",
      "Epoch [5/10], Phase: train, Batch: [102/730], Loss: 0.2720\n",
      "Epoch [5/10], Phase: train, Batch: [103/730], Loss: 0.2885\n",
      "Epoch [5/10], Phase: train, Batch: [104/730], Loss: 0.1649\n",
      "Epoch [5/10], Phase: train, Batch: [105/730], Loss: 0.4069\n",
      "Epoch [5/10], Phase: train, Batch: [106/730], Loss: 0.2343\n",
      "Epoch [5/10], Phase: train, Batch: [107/730], Loss: 0.2655\n",
      "Epoch [5/10], Phase: train, Batch: [108/730], Loss: 0.2796\n",
      "Epoch [5/10], Phase: train, Batch: [109/730], Loss: 0.3212\n",
      "Epoch [5/10], Phase: train, Batch: [110/730], Loss: 0.2924\n",
      "Epoch [5/10], Phase: train, Batch: [111/730], Loss: 0.2902\n",
      "Epoch [5/10], Phase: train, Batch: [112/730], Loss: 0.2577\n",
      "Epoch [5/10], Phase: train, Batch: [113/730], Loss: 0.3067\n",
      "Epoch [5/10], Phase: train, Batch: [114/730], Loss: 0.4029\n",
      "Epoch [5/10], Phase: train, Batch: [115/730], Loss: 0.4335\n",
      "Epoch [5/10], Phase: train, Batch: [116/730], Loss: 0.2426\n",
      "Epoch [5/10], Phase: train, Batch: [117/730], Loss: 0.2655\n",
      "Epoch [5/10], Phase: train, Batch: [118/730], Loss: 0.1246\n",
      "Epoch [5/10], Phase: train, Batch: [119/730], Loss: 0.3974\n",
      "Epoch [5/10], Phase: train, Batch: [120/730], Loss: 0.1702\n",
      "Epoch [5/10], Phase: train, Batch: [121/730], Loss: 0.4391\n",
      "Epoch [5/10], Phase: train, Batch: [122/730], Loss: 0.2188\n",
      "Epoch [5/10], Phase: train, Batch: [123/730], Loss: 0.1635\n",
      "Epoch [5/10], Phase: train, Batch: [124/730], Loss: 0.3424\n",
      "Epoch [5/10], Phase: train, Batch: [125/730], Loss: 0.2886\n",
      "Epoch [5/10], Phase: train, Batch: [126/730], Loss: 0.2152\n",
      "Epoch [5/10], Phase: train, Batch: [127/730], Loss: 0.2194\n",
      "Epoch [5/10], Phase: train, Batch: [128/730], Loss: 0.2357\n",
      "Epoch [5/10], Phase: train, Batch: [129/730], Loss: 0.3679\n",
      "Epoch [5/10], Phase: train, Batch: [130/730], Loss: 0.1808\n",
      "Epoch [5/10], Phase: train, Batch: [131/730], Loss: 0.2027\n",
      "Epoch [5/10], Phase: train, Batch: [132/730], Loss: 0.1468\n",
      "Epoch [5/10], Phase: train, Batch: [133/730], Loss: 0.2819\n",
      "Epoch [5/10], Phase: train, Batch: [134/730], Loss: 0.3498\n",
      "Epoch [5/10], Phase: train, Batch: [135/730], Loss: 0.4333\n",
      "Epoch [5/10], Phase: train, Batch: [136/730], Loss: 0.1656\n",
      "Epoch [5/10], Phase: train, Batch: [137/730], Loss: 0.1852\n",
      "Epoch [5/10], Phase: train, Batch: [138/730], Loss: 0.2285\n",
      "Epoch [5/10], Phase: train, Batch: [139/730], Loss: 0.2281\n",
      "Epoch [5/10], Phase: train, Batch: [140/730], Loss: 0.2629\n",
      "Epoch [5/10], Phase: train, Batch: [141/730], Loss: 0.3867\n",
      "Epoch [5/10], Phase: train, Batch: [142/730], Loss: 0.3759\n",
      "Epoch [5/10], Phase: train, Batch: [143/730], Loss: 0.2516\n",
      "Epoch [5/10], Phase: train, Batch: [144/730], Loss: 0.2747\n",
      "Epoch [5/10], Phase: train, Batch: [145/730], Loss: 0.2201\n",
      "Epoch [5/10], Phase: train, Batch: [146/730], Loss: 0.2021\n",
      "Epoch [5/10], Phase: train, Batch: [147/730], Loss: 0.3281\n",
      "Epoch [5/10], Phase: train, Batch: [148/730], Loss: 0.2118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [149/730], Loss: 0.2897\n",
      "Epoch [5/10], Phase: train, Batch: [150/730], Loss: 0.2963\n",
      "Epoch [5/10], Phase: train, Batch: [151/730], Loss: 0.2202\n",
      "Epoch [5/10], Phase: train, Batch: [152/730], Loss: 0.2131\n",
      "Epoch [5/10], Phase: train, Batch: [153/730], Loss: 0.4060\n",
      "Epoch [5/10], Phase: train, Batch: [154/730], Loss: 0.3085\n",
      "Epoch [5/10], Phase: train, Batch: [155/730], Loss: 0.3875\n",
      "Epoch [5/10], Phase: train, Batch: [156/730], Loss: 0.1698\n",
      "Epoch [5/10], Phase: train, Batch: [157/730], Loss: 0.2111\n",
      "Epoch [5/10], Phase: train, Batch: [158/730], Loss: 0.2861\n",
      "Epoch [5/10], Phase: train, Batch: [159/730], Loss: 0.3124\n",
      "Epoch [5/10], Phase: train, Batch: [160/730], Loss: 0.1888\n",
      "Epoch [5/10], Phase: train, Batch: [161/730], Loss: 0.2860\n",
      "Epoch [5/10], Phase: train, Batch: [162/730], Loss: 0.2383\n",
      "Epoch [5/10], Phase: train, Batch: [163/730], Loss: 0.3294\n",
      "Epoch [5/10], Phase: train, Batch: [164/730], Loss: 0.4990\n",
      "Epoch [5/10], Phase: train, Batch: [165/730], Loss: 0.2510\n",
      "Epoch [5/10], Phase: train, Batch: [166/730], Loss: 0.2545\n",
      "Epoch [5/10], Phase: train, Batch: [167/730], Loss: 0.1944\n",
      "Epoch [5/10], Phase: train, Batch: [168/730], Loss: 0.3476\n",
      "Epoch [5/10], Phase: train, Batch: [169/730], Loss: 0.2724\n",
      "Epoch [5/10], Phase: train, Batch: [170/730], Loss: 0.2222\n",
      "Epoch [5/10], Phase: train, Batch: [171/730], Loss: 0.4453\n",
      "Epoch [5/10], Phase: train, Batch: [172/730], Loss: 0.3826\n",
      "Epoch [5/10], Phase: train, Batch: [173/730], Loss: 0.2120\n",
      "Epoch [5/10], Phase: train, Batch: [174/730], Loss: 0.2333\n",
      "Epoch [5/10], Phase: train, Batch: [175/730], Loss: 0.1783\n",
      "Epoch [5/10], Phase: train, Batch: [176/730], Loss: 0.2919\n",
      "Epoch [5/10], Phase: train, Batch: [177/730], Loss: 0.3576\n",
      "Epoch [5/10], Phase: train, Batch: [178/730], Loss: 0.3871\n",
      "Epoch [5/10], Phase: train, Batch: [179/730], Loss: 0.2073\n",
      "Epoch [5/10], Phase: train, Batch: [180/730], Loss: 0.3681\n",
      "Epoch [5/10], Phase: train, Batch: [181/730], Loss: 0.2927\n",
      "Epoch [5/10], Phase: train, Batch: [182/730], Loss: 0.4476\n",
      "Epoch [5/10], Phase: train, Batch: [183/730], Loss: 0.2257\n",
      "Epoch [5/10], Phase: train, Batch: [184/730], Loss: 0.2522\n",
      "Epoch [5/10], Phase: train, Batch: [185/730], Loss: 0.2453\n",
      "Epoch [5/10], Phase: train, Batch: [186/730], Loss: 0.2388\n",
      "Epoch [5/10], Phase: train, Batch: [187/730], Loss: 0.3820\n",
      "Epoch [5/10], Phase: train, Batch: [188/730], Loss: 0.2164\n",
      "Epoch [5/10], Phase: train, Batch: [189/730], Loss: 0.2813\n",
      "Epoch [5/10], Phase: train, Batch: [190/730], Loss: 0.1668\n",
      "Epoch [5/10], Phase: train, Batch: [191/730], Loss: 0.4205\n",
      "Epoch [5/10], Phase: train, Batch: [192/730], Loss: 0.2386\n",
      "Epoch [5/10], Phase: train, Batch: [193/730], Loss: 0.2987\n",
      "Epoch [5/10], Phase: train, Batch: [194/730], Loss: 0.3236\n",
      "Epoch [5/10], Phase: train, Batch: [195/730], Loss: 0.2504\n",
      "Epoch [5/10], Phase: train, Batch: [196/730], Loss: 0.3335\n",
      "Epoch [5/10], Phase: train, Batch: [197/730], Loss: 0.2799\n",
      "Epoch [5/10], Phase: train, Batch: [198/730], Loss: 0.2975\n",
      "Epoch [5/10], Phase: train, Batch: [199/730], Loss: 0.1808\n",
      "Epoch [5/10], Phase: train, Batch: [200/730], Loss: 0.2793\n",
      "Epoch [5/10], Phase: train, Batch: [201/730], Loss: 0.2447\n",
      "Epoch [5/10], Phase: train, Batch: [202/730], Loss: 0.2333\n",
      "Epoch [5/10], Phase: train, Batch: [203/730], Loss: 0.3950\n",
      "Epoch [5/10], Phase: train, Batch: [204/730], Loss: 0.1772\n",
      "Epoch [5/10], Phase: train, Batch: [205/730], Loss: 0.2174\n",
      "Epoch [5/10], Phase: train, Batch: [206/730], Loss: 0.2072\n",
      "Epoch [5/10], Phase: train, Batch: [207/730], Loss: 0.1965\n",
      "Epoch [5/10], Phase: train, Batch: [208/730], Loss: 0.2869\n",
      "Epoch [5/10], Phase: train, Batch: [209/730], Loss: 0.2802\n",
      "Epoch [5/10], Phase: train, Batch: [210/730], Loss: 0.2608\n",
      "Epoch [5/10], Phase: train, Batch: [211/730], Loss: 0.2148\n",
      "Epoch [5/10], Phase: train, Batch: [212/730], Loss: 0.2359\n",
      "Epoch [5/10], Phase: train, Batch: [213/730], Loss: 0.1980\n",
      "Epoch [5/10], Phase: train, Batch: [214/730], Loss: 0.2726\n",
      "Epoch [5/10], Phase: train, Batch: [215/730], Loss: 0.2578\n",
      "Epoch [5/10], Phase: train, Batch: [216/730], Loss: 0.2917\n",
      "Epoch [5/10], Phase: train, Batch: [217/730], Loss: 0.2350\n",
      "Epoch [5/10], Phase: train, Batch: [218/730], Loss: 0.2852\n",
      "Epoch [5/10], Phase: train, Batch: [219/730], Loss: 0.2263\n",
      "Epoch [5/10], Phase: train, Batch: [220/730], Loss: 0.3834\n",
      "Epoch [5/10], Phase: train, Batch: [221/730], Loss: 0.2270\n",
      "Epoch [5/10], Phase: train, Batch: [222/730], Loss: 0.4049\n",
      "Epoch [5/10], Phase: train, Batch: [223/730], Loss: 0.3311\n",
      "Epoch [5/10], Phase: train, Batch: [224/730], Loss: 0.2849\n",
      "Epoch [5/10], Phase: train, Batch: [225/730], Loss: 0.2568\n",
      "Epoch [5/10], Phase: train, Batch: [226/730], Loss: 0.2781\n",
      "Epoch [5/10], Phase: train, Batch: [227/730], Loss: 0.3119\n",
      "Epoch [5/10], Phase: train, Batch: [228/730], Loss: 0.3549\n",
      "Epoch [5/10], Phase: train, Batch: [229/730], Loss: 0.2196\n",
      "Epoch [5/10], Phase: train, Batch: [230/730], Loss: 0.2092\n",
      "Epoch [5/10], Phase: train, Batch: [231/730], Loss: 0.1523\n",
      "Epoch [5/10], Phase: train, Batch: [232/730], Loss: 0.3552\n",
      "Epoch [5/10], Phase: train, Batch: [233/730], Loss: 0.2037\n",
      "Epoch [5/10], Phase: train, Batch: [234/730], Loss: 0.3319\n",
      "Epoch [5/10], Phase: train, Batch: [235/730], Loss: 0.3630\n",
      "Epoch [5/10], Phase: train, Batch: [236/730], Loss: 0.3433\n",
      "Epoch [5/10], Phase: train, Batch: [237/730], Loss: 0.3797\n",
      "Epoch [5/10], Phase: train, Batch: [238/730], Loss: 0.2286\n",
      "Epoch [5/10], Phase: train, Batch: [239/730], Loss: 0.3059\n",
      "Epoch [5/10], Phase: train, Batch: [240/730], Loss: 0.3045\n",
      "Epoch [5/10], Phase: train, Batch: [241/730], Loss: 0.2348\n",
      "Epoch [5/10], Phase: train, Batch: [242/730], Loss: 0.2313\n",
      "Epoch [5/10], Phase: train, Batch: [243/730], Loss: 0.2212\n",
      "Epoch [5/10], Phase: train, Batch: [244/730], Loss: 0.2569\n",
      "Epoch [5/10], Phase: train, Batch: [245/730], Loss: 0.2539\n",
      "Epoch [5/10], Phase: train, Batch: [246/730], Loss: 0.3463\n",
      "Epoch [5/10], Phase: train, Batch: [247/730], Loss: 0.2436\n",
      "Epoch [5/10], Phase: train, Batch: [248/730], Loss: 0.1881\n",
      "Epoch [5/10], Phase: train, Batch: [249/730], Loss: 0.2716\n",
      "Epoch [5/10], Phase: train, Batch: [250/730], Loss: 0.3316\n",
      "Epoch [5/10], Phase: train, Batch: [251/730], Loss: 0.2251\n",
      "Epoch [5/10], Phase: train, Batch: [252/730], Loss: 0.3129\n",
      "Epoch [5/10], Phase: train, Batch: [253/730], Loss: 0.2600\n",
      "Epoch [5/10], Phase: train, Batch: [254/730], Loss: 0.3986\n",
      "Epoch [5/10], Phase: train, Batch: [255/730], Loss: 0.3000\n",
      "Epoch [5/10], Phase: train, Batch: [256/730], Loss: 0.2336\n",
      "Epoch [5/10], Phase: train, Batch: [257/730], Loss: 0.5060\n",
      "Epoch [5/10], Phase: train, Batch: [258/730], Loss: 0.2404\n",
      "Epoch [5/10], Phase: train, Batch: [259/730], Loss: 0.4413\n",
      "Epoch [5/10], Phase: train, Batch: [260/730], Loss: 0.2424\n",
      "Epoch [5/10], Phase: train, Batch: [261/730], Loss: 0.3648\n",
      "Epoch [5/10], Phase: train, Batch: [262/730], Loss: 0.3145\n",
      "Epoch [5/10], Phase: train, Batch: [263/730], Loss: 0.2460\n",
      "Epoch [5/10], Phase: train, Batch: [264/730], Loss: 0.2278\n",
      "Epoch [5/10], Phase: train, Batch: [265/730], Loss: 0.2816\n",
      "Epoch [5/10], Phase: train, Batch: [266/730], Loss: 0.2921\n",
      "Epoch [5/10], Phase: train, Batch: [267/730], Loss: 0.2050\n",
      "Epoch [5/10], Phase: train, Batch: [268/730], Loss: 0.3472\n",
      "Epoch [5/10], Phase: train, Batch: [269/730], Loss: 0.2356\n",
      "Epoch [5/10], Phase: train, Batch: [270/730], Loss: 0.2455\n",
      "Epoch [5/10], Phase: train, Batch: [271/730], Loss: 0.3864\n",
      "Epoch [5/10], Phase: train, Batch: [272/730], Loss: 0.2201\n",
      "Epoch [5/10], Phase: train, Batch: [273/730], Loss: 0.2963\n",
      "Epoch [5/10], Phase: train, Batch: [274/730], Loss: 0.3368\n",
      "Epoch [5/10], Phase: train, Batch: [275/730], Loss: 0.2598\n",
      "Epoch [5/10], Phase: train, Batch: [276/730], Loss: 0.2841\n",
      "Epoch [5/10], Phase: train, Batch: [277/730], Loss: 0.2489\n",
      "Epoch [5/10], Phase: train, Batch: [278/730], Loss: 0.1920\n",
      "Epoch [5/10], Phase: train, Batch: [279/730], Loss: 0.2351\n",
      "Epoch [5/10], Phase: train, Batch: [280/730], Loss: 0.3074\n",
      "Epoch [5/10], Phase: train, Batch: [281/730], Loss: 0.2710\n",
      "Epoch [5/10], Phase: train, Batch: [282/730], Loss: 0.2088\n",
      "Epoch [5/10], Phase: train, Batch: [283/730], Loss: 0.3089\n",
      "Epoch [5/10], Phase: train, Batch: [284/730], Loss: 0.3002\n",
      "Epoch [5/10], Phase: train, Batch: [285/730], Loss: 0.4106\n",
      "Epoch [5/10], Phase: train, Batch: [286/730], Loss: 0.1909\n",
      "Epoch [5/10], Phase: train, Batch: [287/730], Loss: 0.2936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [288/730], Loss: 0.2401\n",
      "Epoch [5/10], Phase: train, Batch: [289/730], Loss: 0.3365\n",
      "Epoch [5/10], Phase: train, Batch: [290/730], Loss: 0.2699\n",
      "Epoch [5/10], Phase: train, Batch: [291/730], Loss: 0.3885\n",
      "Epoch [5/10], Phase: train, Batch: [292/730], Loss: 0.1878\n",
      "Epoch [5/10], Phase: train, Batch: [293/730], Loss: 0.3381\n",
      "Epoch [5/10], Phase: train, Batch: [294/730], Loss: 0.2993\n",
      "Epoch [5/10], Phase: train, Batch: [295/730], Loss: 0.2724\n",
      "Epoch [5/10], Phase: train, Batch: [296/730], Loss: 0.2434\n",
      "Epoch [5/10], Phase: train, Batch: [297/730], Loss: 0.3243\n",
      "Epoch [5/10], Phase: train, Batch: [298/730], Loss: 0.3580\n",
      "Epoch [5/10], Phase: train, Batch: [299/730], Loss: 0.2989\n",
      "Epoch [5/10], Phase: train, Batch: [300/730], Loss: 0.3349\n",
      "Epoch [5/10], Phase: train, Batch: [301/730], Loss: 0.5024\n",
      "Epoch [5/10], Phase: train, Batch: [302/730], Loss: 0.2885\n",
      "Epoch [5/10], Phase: train, Batch: [303/730], Loss: 0.2375\n",
      "Epoch [5/10], Phase: train, Batch: [304/730], Loss: 0.2740\n",
      "Epoch [5/10], Phase: train, Batch: [305/730], Loss: 0.1630\n",
      "Epoch [5/10], Phase: train, Batch: [306/730], Loss: 0.4007\n",
      "Epoch [5/10], Phase: train, Batch: [307/730], Loss: 0.2966\n",
      "Epoch [5/10], Phase: train, Batch: [308/730], Loss: 0.2761\n",
      "Epoch [5/10], Phase: train, Batch: [309/730], Loss: 0.3567\n",
      "Epoch [5/10], Phase: train, Batch: [310/730], Loss: 0.1969\n",
      "Epoch [5/10], Phase: train, Batch: [311/730], Loss: 0.2385\n",
      "Epoch [5/10], Phase: train, Batch: [312/730], Loss: 0.3292\n",
      "Epoch [5/10], Phase: train, Batch: [313/730], Loss: 0.2824\n",
      "Epoch [5/10], Phase: train, Batch: [314/730], Loss: 0.3346\n",
      "Epoch [5/10], Phase: train, Batch: [315/730], Loss: 0.3954\n",
      "Epoch [5/10], Phase: train, Batch: [316/730], Loss: 0.3634\n",
      "Epoch [5/10], Phase: train, Batch: [317/730], Loss: 0.2696\n",
      "Epoch [5/10], Phase: train, Batch: [318/730], Loss: 0.2953\n",
      "Epoch [5/10], Phase: train, Batch: [319/730], Loss: 0.4079\n",
      "Epoch [5/10], Phase: train, Batch: [320/730], Loss: 0.2896\n",
      "Epoch [5/10], Phase: train, Batch: [321/730], Loss: 0.3748\n",
      "Epoch [5/10], Phase: train, Batch: [322/730], Loss: 0.2015\n",
      "Epoch [5/10], Phase: train, Batch: [323/730], Loss: 0.1928\n",
      "Epoch [5/10], Phase: train, Batch: [324/730], Loss: 0.3438\n",
      "Epoch [5/10], Phase: train, Batch: [325/730], Loss: 0.2414\n",
      "Epoch [5/10], Phase: train, Batch: [326/730], Loss: 0.2334\n",
      "Epoch [5/10], Phase: train, Batch: [327/730], Loss: 0.2922\n",
      "Epoch [5/10], Phase: train, Batch: [328/730], Loss: 0.2898\n",
      "Epoch [5/10], Phase: train, Batch: [329/730], Loss: 0.3049\n",
      "Epoch [5/10], Phase: train, Batch: [330/730], Loss: 0.3729\n",
      "Epoch [5/10], Phase: train, Batch: [331/730], Loss: 0.3088\n",
      "Epoch [5/10], Phase: train, Batch: [332/730], Loss: 0.3808\n",
      "Epoch [5/10], Phase: train, Batch: [333/730], Loss: 0.2178\n",
      "Epoch [5/10], Phase: train, Batch: [334/730], Loss: 0.3893\n",
      "Epoch [5/10], Phase: train, Batch: [335/730], Loss: 0.4233\n",
      "Epoch [5/10], Phase: train, Batch: [336/730], Loss: 0.1974\n",
      "Epoch [5/10], Phase: train, Batch: [337/730], Loss: 0.1615\n",
      "Epoch [5/10], Phase: train, Batch: [338/730], Loss: 0.2266\n",
      "Epoch [5/10], Phase: train, Batch: [339/730], Loss: 0.3033\n",
      "Epoch [5/10], Phase: train, Batch: [340/730], Loss: 0.2783\n",
      "Epoch [5/10], Phase: train, Batch: [341/730], Loss: 0.2235\n",
      "Epoch [5/10], Phase: train, Batch: [342/730], Loss: 0.2521\n",
      "Epoch [5/10], Phase: train, Batch: [343/730], Loss: 0.2081\n",
      "Epoch [5/10], Phase: train, Batch: [344/730], Loss: 0.2639\n",
      "Epoch [5/10], Phase: train, Batch: [345/730], Loss: 0.3058\n",
      "Epoch [5/10], Phase: train, Batch: [346/730], Loss: 0.2267\n",
      "Epoch [5/10], Phase: train, Batch: [347/730], Loss: 0.2564\n",
      "Epoch [5/10], Phase: train, Batch: [348/730], Loss: 0.2360\n",
      "Epoch [5/10], Phase: train, Batch: [349/730], Loss: 0.1877\n",
      "Epoch [5/10], Phase: train, Batch: [350/730], Loss: 0.2410\n",
      "Epoch [5/10], Phase: train, Batch: [351/730], Loss: 0.3128\n",
      "Epoch [5/10], Phase: train, Batch: [352/730], Loss: 0.2576\n",
      "Epoch [5/10], Phase: train, Batch: [353/730], Loss: 0.2244\n",
      "Epoch [5/10], Phase: train, Batch: [354/730], Loss: 0.3497\n",
      "Epoch [5/10], Phase: train, Batch: [355/730], Loss: 0.3547\n",
      "Epoch [5/10], Phase: train, Batch: [356/730], Loss: 0.3799\n",
      "Epoch [5/10], Phase: train, Batch: [357/730], Loss: 0.3182\n",
      "Epoch [5/10], Phase: train, Batch: [358/730], Loss: 0.2287\n",
      "Epoch [5/10], Phase: train, Batch: [359/730], Loss: 0.1979\n",
      "Epoch [5/10], Phase: train, Batch: [360/730], Loss: 0.4589\n",
      "Epoch [5/10], Phase: train, Batch: [361/730], Loss: 0.1857\n",
      "Epoch [5/10], Phase: train, Batch: [362/730], Loss: 0.4610\n",
      "Epoch [5/10], Phase: train, Batch: [363/730], Loss: 0.4111\n",
      "Epoch [5/10], Phase: train, Batch: [364/730], Loss: 0.3097\n",
      "Epoch [5/10], Phase: train, Batch: [365/730], Loss: 0.3084\n",
      "Epoch [5/10], Phase: train, Batch: [366/730], Loss: 0.2916\n",
      "Epoch [5/10], Phase: train, Batch: [367/730], Loss: 0.2511\n",
      "Epoch [5/10], Phase: train, Batch: [368/730], Loss: 0.2506\n",
      "Epoch [5/10], Phase: train, Batch: [369/730], Loss: 0.2363\n",
      "Epoch [5/10], Phase: train, Batch: [370/730], Loss: 0.2081\n",
      "Epoch [5/10], Phase: train, Batch: [371/730], Loss: 0.2543\n",
      "Epoch [5/10], Phase: train, Batch: [372/730], Loss: 0.3720\n",
      "Epoch [5/10], Phase: train, Batch: [373/730], Loss: 0.3471\n",
      "Epoch [5/10], Phase: train, Batch: [374/730], Loss: 0.2965\n",
      "Epoch [5/10], Phase: train, Batch: [375/730], Loss: 0.3822\n",
      "Epoch [5/10], Phase: train, Batch: [376/730], Loss: 0.1927\n",
      "Epoch [5/10], Phase: train, Batch: [377/730], Loss: 0.2677\n",
      "Epoch [5/10], Phase: train, Batch: [378/730], Loss: 0.2040\n",
      "Epoch [5/10], Phase: train, Batch: [379/730], Loss: 0.3784\n",
      "Epoch [5/10], Phase: train, Batch: [380/730], Loss: 0.3282\n",
      "Epoch [5/10], Phase: train, Batch: [381/730], Loss: 0.2381\n",
      "Epoch [5/10], Phase: train, Batch: [382/730], Loss: 0.2899\n",
      "Epoch [5/10], Phase: train, Batch: [383/730], Loss: 0.2937\n",
      "Epoch [5/10], Phase: train, Batch: [384/730], Loss: 0.1953\n",
      "Epoch [5/10], Phase: train, Batch: [385/730], Loss: 0.3252\n",
      "Epoch [5/10], Phase: train, Batch: [386/730], Loss: 0.4048\n",
      "Epoch [5/10], Phase: train, Batch: [387/730], Loss: 0.2300\n",
      "Epoch [5/10], Phase: train, Batch: [388/730], Loss: 0.2556\n",
      "Epoch [5/10], Phase: train, Batch: [389/730], Loss: 0.2457\n",
      "Epoch [5/10], Phase: train, Batch: [390/730], Loss: 0.3249\n",
      "Epoch [5/10], Phase: train, Batch: [391/730], Loss: 0.5583\n",
      "Epoch [5/10], Phase: train, Batch: [392/730], Loss: 0.2094\n",
      "Epoch [5/10], Phase: train, Batch: [393/730], Loss: 0.2594\n",
      "Epoch [5/10], Phase: train, Batch: [394/730], Loss: 0.3471\n",
      "Epoch [5/10], Phase: train, Batch: [395/730], Loss: 0.3460\n",
      "Epoch [5/10], Phase: train, Batch: [396/730], Loss: 0.3201\n",
      "Epoch [5/10], Phase: train, Batch: [397/730], Loss: 0.1911\n",
      "Epoch [5/10], Phase: train, Batch: [398/730], Loss: 0.3822\n",
      "Epoch [5/10], Phase: train, Batch: [399/730], Loss: 0.3243\n",
      "Epoch [5/10], Phase: train, Batch: [400/730], Loss: 0.2972\n",
      "Epoch [5/10], Phase: train, Batch: [401/730], Loss: 0.3799\n",
      "Epoch [5/10], Phase: train, Batch: [402/730], Loss: 0.2486\n",
      "Epoch [5/10], Phase: train, Batch: [403/730], Loss: 0.2903\n",
      "Epoch [5/10], Phase: train, Batch: [404/730], Loss: 0.2136\n",
      "Epoch [5/10], Phase: train, Batch: [405/730], Loss: 0.3427\n",
      "Epoch [5/10], Phase: train, Batch: [406/730], Loss: 0.4417\n",
      "Epoch [5/10], Phase: train, Batch: [407/730], Loss: 0.2733\n",
      "Epoch [5/10], Phase: train, Batch: [408/730], Loss: 0.3090\n",
      "Epoch [5/10], Phase: train, Batch: [409/730], Loss: 0.2796\n",
      "Epoch [5/10], Phase: train, Batch: [410/730], Loss: 0.2733\n",
      "Epoch [5/10], Phase: train, Batch: [411/730], Loss: 0.2867\n",
      "Epoch [5/10], Phase: train, Batch: [412/730], Loss: 0.3028\n",
      "Epoch [5/10], Phase: train, Batch: [413/730], Loss: 0.2113\n",
      "Epoch [5/10], Phase: train, Batch: [414/730], Loss: 0.1685\n",
      "Epoch [5/10], Phase: train, Batch: [415/730], Loss: 0.3054\n",
      "Epoch [5/10], Phase: train, Batch: [416/730], Loss: 0.3200\n",
      "Epoch [5/10], Phase: train, Batch: [417/730], Loss: 0.2353\n",
      "Epoch [5/10], Phase: train, Batch: [418/730], Loss: 0.2994\n",
      "Epoch [5/10], Phase: train, Batch: [419/730], Loss: 0.1943\n",
      "Epoch [5/10], Phase: train, Batch: [420/730], Loss: 0.3776\n",
      "Epoch [5/10], Phase: train, Batch: [421/730], Loss: 0.1660\n",
      "Epoch [5/10], Phase: train, Batch: [422/730], Loss: 0.3472\n",
      "Epoch [5/10], Phase: train, Batch: [423/730], Loss: 0.3057\n",
      "Epoch [5/10], Phase: train, Batch: [424/730], Loss: 0.3061\n",
      "Epoch [5/10], Phase: train, Batch: [425/730], Loss: 0.1520\n",
      "Epoch [5/10], Phase: train, Batch: [426/730], Loss: 0.3689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [427/730], Loss: 0.2499\n",
      "Epoch [5/10], Phase: train, Batch: [428/730], Loss: 0.2306\n",
      "Epoch [5/10], Phase: train, Batch: [429/730], Loss: 0.3418\n",
      "Epoch [5/10], Phase: train, Batch: [430/730], Loss: 0.1972\n",
      "Epoch [5/10], Phase: train, Batch: [431/730], Loss: 0.3279\n",
      "Epoch [5/10], Phase: train, Batch: [432/730], Loss: 0.2815\n",
      "Epoch [5/10], Phase: train, Batch: [433/730], Loss: 0.1876\n",
      "Epoch [5/10], Phase: train, Batch: [434/730], Loss: 0.2658\n",
      "Epoch [5/10], Phase: train, Batch: [435/730], Loss: 0.1548\n",
      "Epoch [5/10], Phase: train, Batch: [436/730], Loss: 0.2655\n",
      "Epoch [5/10], Phase: train, Batch: [437/730], Loss: 0.2422\n",
      "Epoch [5/10], Phase: train, Batch: [438/730], Loss: 0.2012\n",
      "Epoch [5/10], Phase: train, Batch: [439/730], Loss: 0.2245\n",
      "Epoch [5/10], Phase: train, Batch: [440/730], Loss: 0.3074\n",
      "Epoch [5/10], Phase: train, Batch: [441/730], Loss: 0.1656\n",
      "Epoch [5/10], Phase: train, Batch: [442/730], Loss: 0.2747\n",
      "Epoch [5/10], Phase: train, Batch: [443/730], Loss: 0.1647\n",
      "Epoch [5/10], Phase: train, Batch: [444/730], Loss: 0.2418\n",
      "Epoch [5/10], Phase: train, Batch: [445/730], Loss: 0.4064\n",
      "Epoch [5/10], Phase: train, Batch: [446/730], Loss: 0.2823\n",
      "Epoch [5/10], Phase: train, Batch: [447/730], Loss: 0.2436\n",
      "Epoch [5/10], Phase: train, Batch: [448/730], Loss: 0.2862\n",
      "Epoch [5/10], Phase: train, Batch: [449/730], Loss: 0.3062\n",
      "Epoch [5/10], Phase: train, Batch: [450/730], Loss: 0.2282\n",
      "Epoch [5/10], Phase: train, Batch: [451/730], Loss: 0.2289\n",
      "Epoch [5/10], Phase: train, Batch: [452/730], Loss: 0.2209\n",
      "Epoch [5/10], Phase: train, Batch: [453/730], Loss: 0.2494\n",
      "Epoch [5/10], Phase: train, Batch: [454/730], Loss: 0.4954\n",
      "Epoch [5/10], Phase: train, Batch: [455/730], Loss: 0.2762\n",
      "Epoch [5/10], Phase: train, Batch: [456/730], Loss: 0.3463\n",
      "Epoch [5/10], Phase: train, Batch: [457/730], Loss: 0.2389\n",
      "Epoch [5/10], Phase: train, Batch: [458/730], Loss: 0.3560\n",
      "Epoch [5/10], Phase: train, Batch: [459/730], Loss: 0.3404\n",
      "Epoch [5/10], Phase: train, Batch: [460/730], Loss: 0.2494\n",
      "Epoch [5/10], Phase: train, Batch: [461/730], Loss: 0.2772\n",
      "Epoch [5/10], Phase: train, Batch: [462/730], Loss: 0.1525\n",
      "Epoch [5/10], Phase: train, Batch: [463/730], Loss: 0.2912\n",
      "Epoch [5/10], Phase: train, Batch: [464/730], Loss: 0.2675\n",
      "Epoch [5/10], Phase: train, Batch: [465/730], Loss: 0.4085\n",
      "Epoch [5/10], Phase: train, Batch: [466/730], Loss: 0.2724\n",
      "Epoch [5/10], Phase: train, Batch: [467/730], Loss: 0.3550\n",
      "Epoch [5/10], Phase: train, Batch: [468/730], Loss: 0.1631\n",
      "Epoch [5/10], Phase: train, Batch: [469/730], Loss: 0.2774\n",
      "Epoch [5/10], Phase: train, Batch: [470/730], Loss: 0.3469\n",
      "Epoch [5/10], Phase: train, Batch: [471/730], Loss: 0.2003\n",
      "Epoch [5/10], Phase: train, Batch: [472/730], Loss: 0.2665\n",
      "Epoch [5/10], Phase: train, Batch: [473/730], Loss: 0.1891\n",
      "Epoch [5/10], Phase: train, Batch: [474/730], Loss: 0.3254\n",
      "Epoch [5/10], Phase: train, Batch: [475/730], Loss: 0.1651\n",
      "Epoch [5/10], Phase: train, Batch: [476/730], Loss: 0.1682\n",
      "Epoch [5/10], Phase: train, Batch: [477/730], Loss: 0.4061\n",
      "Epoch [5/10], Phase: train, Batch: [478/730], Loss: 0.1843\n",
      "Epoch [5/10], Phase: train, Batch: [479/730], Loss: 0.3116\n",
      "Epoch [5/10], Phase: train, Batch: [480/730], Loss: 0.4258\n",
      "Epoch [5/10], Phase: train, Batch: [481/730], Loss: 0.1696\n",
      "Epoch [5/10], Phase: train, Batch: [482/730], Loss: 0.3075\n",
      "Epoch [5/10], Phase: train, Batch: [483/730], Loss: 0.2979\n",
      "Epoch [5/10], Phase: train, Batch: [484/730], Loss: 0.2993\n",
      "Epoch [5/10], Phase: train, Batch: [485/730], Loss: 0.2550\n",
      "Epoch [5/10], Phase: train, Batch: [486/730], Loss: 0.2581\n",
      "Epoch [5/10], Phase: train, Batch: [487/730], Loss: 0.2910\n",
      "Epoch [5/10], Phase: train, Batch: [488/730], Loss: 0.2658\n",
      "Epoch [5/10], Phase: train, Batch: [489/730], Loss: 0.2023\n",
      "Epoch [5/10], Phase: train, Batch: [490/730], Loss: 0.3068\n",
      "Epoch [5/10], Phase: train, Batch: [491/730], Loss: 0.2485\n",
      "Epoch [5/10], Phase: train, Batch: [492/730], Loss: 0.2736\n",
      "Epoch [5/10], Phase: train, Batch: [493/730], Loss: 0.2995\n",
      "Epoch [5/10], Phase: train, Batch: [494/730], Loss: 0.1904\n",
      "Epoch [5/10], Phase: train, Batch: [495/730], Loss: 0.1995\n",
      "Epoch [5/10], Phase: train, Batch: [496/730], Loss: 0.2835\n",
      "Epoch [5/10], Phase: train, Batch: [497/730], Loss: 0.3104\n",
      "Epoch [5/10], Phase: train, Batch: [498/730], Loss: 0.3174\n",
      "Epoch [5/10], Phase: train, Batch: [499/730], Loss: 0.2575\n",
      "Epoch [5/10], Phase: train, Batch: [500/730], Loss: 0.2944\n",
      "Epoch [5/10], Phase: train, Batch: [501/730], Loss: 0.3553\n",
      "Epoch [5/10], Phase: train, Batch: [502/730], Loss: 0.3841\n",
      "Epoch [5/10], Phase: train, Batch: [503/730], Loss: 0.2375\n",
      "Epoch [5/10], Phase: train, Batch: [504/730], Loss: 0.2560\n",
      "Epoch [5/10], Phase: train, Batch: [505/730], Loss: 0.2729\n",
      "Epoch [5/10], Phase: train, Batch: [506/730], Loss: 0.2551\n",
      "Epoch [5/10], Phase: train, Batch: [507/730], Loss: 0.2991\n",
      "Epoch [5/10], Phase: train, Batch: [508/730], Loss: 0.2206\n",
      "Epoch [5/10], Phase: train, Batch: [509/730], Loss: 0.2015\n",
      "Epoch [5/10], Phase: train, Batch: [510/730], Loss: 0.4511\n",
      "Epoch [5/10], Phase: train, Batch: [511/730], Loss: 0.4186\n",
      "Epoch [5/10], Phase: train, Batch: [512/730], Loss: 0.2627\n",
      "Epoch [5/10], Phase: train, Batch: [513/730], Loss: 0.4033\n",
      "Epoch [5/10], Phase: train, Batch: [514/730], Loss: 0.3198\n",
      "Epoch [5/10], Phase: train, Batch: [515/730], Loss: 0.2362\n",
      "Epoch [5/10], Phase: train, Batch: [516/730], Loss: 0.2733\n",
      "Epoch [5/10], Phase: train, Batch: [517/730], Loss: 0.3110\n",
      "Epoch [5/10], Phase: train, Batch: [518/730], Loss: 0.3076\n",
      "Epoch [5/10], Phase: train, Batch: [519/730], Loss: 0.1695\n",
      "Epoch [5/10], Phase: train, Batch: [520/730], Loss: 0.2343\n",
      "Epoch [5/10], Phase: train, Batch: [521/730], Loss: 0.1987\n",
      "Epoch [5/10], Phase: train, Batch: [522/730], Loss: 0.1899\n",
      "Epoch [5/10], Phase: train, Batch: [523/730], Loss: 0.2505\n",
      "Epoch [5/10], Phase: train, Batch: [524/730], Loss: 0.3320\n",
      "Epoch [5/10], Phase: train, Batch: [525/730], Loss: 0.2995\n",
      "Epoch [5/10], Phase: train, Batch: [526/730], Loss: 0.3331\n",
      "Epoch [5/10], Phase: train, Batch: [527/730], Loss: 0.3643\n",
      "Epoch [5/10], Phase: train, Batch: [528/730], Loss: 0.1827\n",
      "Epoch [5/10], Phase: train, Batch: [529/730], Loss: 0.2764\n",
      "Epoch [5/10], Phase: train, Batch: [530/730], Loss: 0.2459\n",
      "Epoch [5/10], Phase: train, Batch: [531/730], Loss: 0.2906\n",
      "Epoch [5/10], Phase: train, Batch: [532/730], Loss: 0.2674\n",
      "Epoch [5/10], Phase: train, Batch: [533/730], Loss: 0.2660\n",
      "Epoch [5/10], Phase: train, Batch: [534/730], Loss: 0.2498\n",
      "Epoch [5/10], Phase: train, Batch: [535/730], Loss: 0.2205\n",
      "Epoch [5/10], Phase: train, Batch: [536/730], Loss: 0.3055\n",
      "Epoch [5/10], Phase: train, Batch: [537/730], Loss: 0.2833\n",
      "Epoch [5/10], Phase: train, Batch: [538/730], Loss: 0.2853\n",
      "Epoch [5/10], Phase: train, Batch: [539/730], Loss: 0.2477\n",
      "Epoch [5/10], Phase: train, Batch: [540/730], Loss: 0.2203\n",
      "Epoch [5/10], Phase: train, Batch: [541/730], Loss: 0.3939\n",
      "Epoch [5/10], Phase: train, Batch: [542/730], Loss: 0.1320\n",
      "Epoch [5/10], Phase: train, Batch: [543/730], Loss: 0.3011\n",
      "Epoch [5/10], Phase: train, Batch: [544/730], Loss: 0.2690\n",
      "Epoch [5/10], Phase: train, Batch: [545/730], Loss: 0.2283\n",
      "Epoch [5/10], Phase: train, Batch: [546/730], Loss: 0.2713\n",
      "Epoch [5/10], Phase: train, Batch: [547/730], Loss: 0.4892\n",
      "Epoch [5/10], Phase: train, Batch: [548/730], Loss: 0.1872\n",
      "Epoch [5/10], Phase: train, Batch: [549/730], Loss: 0.2366\n",
      "Epoch [5/10], Phase: train, Batch: [550/730], Loss: 0.3058\n",
      "Epoch [5/10], Phase: train, Batch: [551/730], Loss: 0.2400\n",
      "Epoch [5/10], Phase: train, Batch: [552/730], Loss: 0.2874\n",
      "Epoch [5/10], Phase: train, Batch: [553/730], Loss: 0.2245\n",
      "Epoch [5/10], Phase: train, Batch: [554/730], Loss: 0.2058\n",
      "Epoch [5/10], Phase: train, Batch: [555/730], Loss: 0.2853\n",
      "Epoch [5/10], Phase: train, Batch: [556/730], Loss: 0.2327\n",
      "Epoch [5/10], Phase: train, Batch: [557/730], Loss: 0.2823\n",
      "Epoch [5/10], Phase: train, Batch: [558/730], Loss: 0.2331\n",
      "Epoch [5/10], Phase: train, Batch: [559/730], Loss: 0.3166\n",
      "Epoch [5/10], Phase: train, Batch: [560/730], Loss: 0.3285\n",
      "Epoch [5/10], Phase: train, Batch: [561/730], Loss: 0.2237\n",
      "Epoch [5/10], Phase: train, Batch: [562/730], Loss: 0.3499\n",
      "Epoch [5/10], Phase: train, Batch: [563/730], Loss: 0.2922\n",
      "Epoch [5/10], Phase: train, Batch: [564/730], Loss: 0.3520\n",
      "Epoch [5/10], Phase: train, Batch: [565/730], Loss: 0.3916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [566/730], Loss: 0.2876\n",
      "Epoch [5/10], Phase: train, Batch: [567/730], Loss: 0.3582\n",
      "Epoch [5/10], Phase: train, Batch: [568/730], Loss: 0.3448\n",
      "Epoch [5/10], Phase: train, Batch: [569/730], Loss: 0.3891\n",
      "Epoch [5/10], Phase: train, Batch: [570/730], Loss: 0.4661\n",
      "Epoch [5/10], Phase: train, Batch: [571/730], Loss: 0.3641\n",
      "Epoch [5/10], Phase: train, Batch: [572/730], Loss: 0.3399\n",
      "Epoch [5/10], Phase: train, Batch: [573/730], Loss: 0.2417\n",
      "Epoch [5/10], Phase: train, Batch: [574/730], Loss: 0.1986\n",
      "Epoch [5/10], Phase: train, Batch: [575/730], Loss: 0.3365\n",
      "Epoch [5/10], Phase: train, Batch: [576/730], Loss: 0.2919\n",
      "Epoch [5/10], Phase: train, Batch: [577/730], Loss: 0.2029\n",
      "Epoch [5/10], Phase: train, Batch: [578/730], Loss: 0.3823\n",
      "Epoch [5/10], Phase: train, Batch: [579/730], Loss: 0.2976\n",
      "Epoch [5/10], Phase: train, Batch: [580/730], Loss: 0.3655\n",
      "Epoch [5/10], Phase: train, Batch: [581/730], Loss: 0.3429\n",
      "Epoch [5/10], Phase: train, Batch: [582/730], Loss: 0.2714\n",
      "Epoch [5/10], Phase: train, Batch: [583/730], Loss: 0.2938\n",
      "Epoch [5/10], Phase: train, Batch: [584/730], Loss: 0.2647\n",
      "Epoch [5/10], Phase: train, Batch: [585/730], Loss: 0.2543\n",
      "Epoch [5/10], Phase: train, Batch: [586/730], Loss: 0.3433\n",
      "Epoch [5/10], Phase: train, Batch: [587/730], Loss: 0.2128\n",
      "Epoch [5/10], Phase: train, Batch: [588/730], Loss: 0.3504\n",
      "Epoch [5/10], Phase: train, Batch: [589/730], Loss: 0.2574\n",
      "Epoch [5/10], Phase: train, Batch: [590/730], Loss: 0.3714\n",
      "Epoch [5/10], Phase: train, Batch: [591/730], Loss: 0.3437\n",
      "Epoch [5/10], Phase: train, Batch: [592/730], Loss: 0.2742\n",
      "Epoch [5/10], Phase: train, Batch: [593/730], Loss: 0.3027\n",
      "Epoch [5/10], Phase: train, Batch: [594/730], Loss: 0.3512\n",
      "Epoch [5/10], Phase: train, Batch: [595/730], Loss: 0.3021\n",
      "Epoch [5/10], Phase: train, Batch: [596/730], Loss: 0.2842\n",
      "Epoch [5/10], Phase: train, Batch: [597/730], Loss: 0.3988\n",
      "Epoch [5/10], Phase: train, Batch: [598/730], Loss: 0.2084\n",
      "Epoch [5/10], Phase: train, Batch: [599/730], Loss: 0.3474\n",
      "Epoch [5/10], Phase: train, Batch: [600/730], Loss: 0.2230\n",
      "Epoch [5/10], Phase: train, Batch: [601/730], Loss: 0.2218\n",
      "Epoch [5/10], Phase: train, Batch: [602/730], Loss: 0.2537\n",
      "Epoch [5/10], Phase: train, Batch: [603/730], Loss: 0.1697\n",
      "Epoch [5/10], Phase: train, Batch: [604/730], Loss: 0.2952\n",
      "Epoch [5/10], Phase: train, Batch: [605/730], Loss: 0.2676\n",
      "Epoch [5/10], Phase: train, Batch: [606/730], Loss: 0.2224\n",
      "Epoch [5/10], Phase: train, Batch: [607/730], Loss: 0.2148\n",
      "Epoch [5/10], Phase: train, Batch: [608/730], Loss: 0.2548\n",
      "Epoch [5/10], Phase: train, Batch: [609/730], Loss: 0.2658\n",
      "Epoch [5/10], Phase: train, Batch: [610/730], Loss: 0.2992\n",
      "Epoch [5/10], Phase: train, Batch: [611/730], Loss: 0.2707\n",
      "Epoch [5/10], Phase: train, Batch: [612/730], Loss: 0.1857\n",
      "Epoch [5/10], Phase: train, Batch: [613/730], Loss: 0.3315\n",
      "Epoch [5/10], Phase: train, Batch: [614/730], Loss: 0.3000\n",
      "Epoch [5/10], Phase: train, Batch: [615/730], Loss: 0.2097\n",
      "Epoch [5/10], Phase: train, Batch: [616/730], Loss: 0.1531\n",
      "Epoch [5/10], Phase: train, Batch: [617/730], Loss: 0.2733\n",
      "Epoch [5/10], Phase: train, Batch: [618/730], Loss: 0.3316\n",
      "Epoch [5/10], Phase: train, Batch: [619/730], Loss: 0.3427\n",
      "Epoch [5/10], Phase: train, Batch: [620/730], Loss: 0.1803\n",
      "Epoch [5/10], Phase: train, Batch: [621/730], Loss: 0.3340\n",
      "Epoch [5/10], Phase: train, Batch: [622/730], Loss: 0.2590\n",
      "Epoch [5/10], Phase: train, Batch: [623/730], Loss: 0.3600\n",
      "Epoch [5/10], Phase: train, Batch: [624/730], Loss: 0.3169\n",
      "Epoch [5/10], Phase: train, Batch: [625/730], Loss: 0.2442\n",
      "Epoch [5/10], Phase: train, Batch: [626/730], Loss: 0.2397\n",
      "Epoch [5/10], Phase: train, Batch: [627/730], Loss: 0.2272\n",
      "Epoch [5/10], Phase: train, Batch: [628/730], Loss: 0.3499\n",
      "Epoch [5/10], Phase: train, Batch: [629/730], Loss: 0.3212\n",
      "Epoch [5/10], Phase: train, Batch: [630/730], Loss: 0.2342\n",
      "Epoch [5/10], Phase: train, Batch: [631/730], Loss: 0.2947\n",
      "Epoch [5/10], Phase: train, Batch: [632/730], Loss: 0.3755\n",
      "Epoch [5/10], Phase: train, Batch: [633/730], Loss: 0.1724\n",
      "Epoch [5/10], Phase: train, Batch: [634/730], Loss: 0.3644\n",
      "Epoch [5/10], Phase: train, Batch: [635/730], Loss: 0.2926\n",
      "Epoch [5/10], Phase: train, Batch: [636/730], Loss: 0.3159\n",
      "Epoch [5/10], Phase: train, Batch: [637/730], Loss: 0.3920\n",
      "Epoch [5/10], Phase: train, Batch: [638/730], Loss: 0.2120\n",
      "Epoch [5/10], Phase: train, Batch: [639/730], Loss: 0.2790\n",
      "Epoch [5/10], Phase: train, Batch: [640/730], Loss: 0.2454\n",
      "Epoch [5/10], Phase: train, Batch: [641/730], Loss: 0.2092\n",
      "Epoch [5/10], Phase: train, Batch: [642/730], Loss: 0.3403\n",
      "Epoch [5/10], Phase: train, Batch: [643/730], Loss: 0.2499\n",
      "Epoch [5/10], Phase: train, Batch: [644/730], Loss: 0.2286\n",
      "Epoch [5/10], Phase: train, Batch: [645/730], Loss: 0.2477\n",
      "Epoch [5/10], Phase: train, Batch: [646/730], Loss: 0.2152\n",
      "Epoch [5/10], Phase: train, Batch: [647/730], Loss: 0.3600\n",
      "Epoch [5/10], Phase: train, Batch: [648/730], Loss: 0.2715\n",
      "Epoch [5/10], Phase: train, Batch: [649/730], Loss: 0.2152\n",
      "Epoch [5/10], Phase: train, Batch: [650/730], Loss: 0.4334\n",
      "Epoch [5/10], Phase: train, Batch: [651/730], Loss: 0.1949\n",
      "Epoch [5/10], Phase: train, Batch: [652/730], Loss: 0.3673\n",
      "Epoch [5/10], Phase: train, Batch: [653/730], Loss: 0.2259\n",
      "Epoch [5/10], Phase: train, Batch: [654/730], Loss: 0.2736\n",
      "Epoch [5/10], Phase: train, Batch: [655/730], Loss: 0.3841\n",
      "Epoch [5/10], Phase: train, Batch: [656/730], Loss: 0.3113\n",
      "Epoch [5/10], Phase: train, Batch: [657/730], Loss: 0.2357\n",
      "Epoch [5/10], Phase: train, Batch: [658/730], Loss: 0.3099\n",
      "Epoch [5/10], Phase: train, Batch: [659/730], Loss: 0.3368\n",
      "Epoch [5/10], Phase: train, Batch: [660/730], Loss: 0.2368\n",
      "Epoch [5/10], Phase: train, Batch: [661/730], Loss: 0.2336\n",
      "Epoch [5/10], Phase: train, Batch: [662/730], Loss: 0.2640\n",
      "Epoch [5/10], Phase: train, Batch: [663/730], Loss: 0.2295\n",
      "Epoch [5/10], Phase: train, Batch: [664/730], Loss: 0.2353\n",
      "Epoch [5/10], Phase: train, Batch: [665/730], Loss: 0.1796\n",
      "Epoch [5/10], Phase: train, Batch: [666/730], Loss: 0.3096\n",
      "Epoch [5/10], Phase: train, Batch: [667/730], Loss: 0.2621\n",
      "Epoch [5/10], Phase: train, Batch: [668/730], Loss: 0.1898\n",
      "Epoch [5/10], Phase: train, Batch: [669/730], Loss: 0.2228\n",
      "Epoch [5/10], Phase: train, Batch: [670/730], Loss: 0.2986\n",
      "Epoch [5/10], Phase: train, Batch: [671/730], Loss: 0.2974\n",
      "Epoch [5/10], Phase: train, Batch: [672/730], Loss: 0.3727\n",
      "Epoch [5/10], Phase: train, Batch: [673/730], Loss: 0.3189\n",
      "Epoch [5/10], Phase: train, Batch: [674/730], Loss: 0.2456\n",
      "Epoch [5/10], Phase: train, Batch: [675/730], Loss: 0.2319\n",
      "Epoch [5/10], Phase: train, Batch: [676/730], Loss: 0.3822\n",
      "Epoch [5/10], Phase: train, Batch: [677/730], Loss: 0.2156\n",
      "Epoch [5/10], Phase: train, Batch: [678/730], Loss: 0.4520\n",
      "Epoch [5/10], Phase: train, Batch: [679/730], Loss: 0.2499\n",
      "Epoch [5/10], Phase: train, Batch: [680/730], Loss: 0.3619\n",
      "Epoch [5/10], Phase: train, Batch: [681/730], Loss: 0.2840\n",
      "Epoch [5/10], Phase: train, Batch: [682/730], Loss: 0.3056\n",
      "Epoch [5/10], Phase: train, Batch: [683/730], Loss: 0.1786\n",
      "Epoch [5/10], Phase: train, Batch: [684/730], Loss: 0.1744\n",
      "Epoch [5/10], Phase: train, Batch: [685/730], Loss: 0.2721\n",
      "Epoch [5/10], Phase: train, Batch: [686/730], Loss: 0.3123\n",
      "Epoch [5/10], Phase: train, Batch: [687/730], Loss: 0.1582\n",
      "Epoch [5/10], Phase: train, Batch: [688/730], Loss: 0.2819\n",
      "Epoch [5/10], Phase: train, Batch: [689/730], Loss: 0.2875\n",
      "Epoch [5/10], Phase: train, Batch: [690/730], Loss: 0.1502\n",
      "Epoch [5/10], Phase: train, Batch: [691/730], Loss: 0.3732\n",
      "Epoch [5/10], Phase: train, Batch: [692/730], Loss: 0.3857\n",
      "Epoch [5/10], Phase: train, Batch: [693/730], Loss: 0.2660\n",
      "Epoch [5/10], Phase: train, Batch: [694/730], Loss: 0.3006\n",
      "Epoch [5/10], Phase: train, Batch: [695/730], Loss: 0.2465\n",
      "Epoch [5/10], Phase: train, Batch: [696/730], Loss: 0.2410\n",
      "Epoch [5/10], Phase: train, Batch: [697/730], Loss: 0.2960\n",
      "Epoch [5/10], Phase: train, Batch: [698/730], Loss: 0.4137\n",
      "Epoch [5/10], Phase: train, Batch: [699/730], Loss: 0.3419\n",
      "Epoch [5/10], Phase: train, Batch: [700/730], Loss: 0.2891\n",
      "Epoch [5/10], Phase: train, Batch: [701/730], Loss: 0.3313\n",
      "Epoch [5/10], Phase: train, Batch: [702/730], Loss: 0.2915\n",
      "Epoch [5/10], Phase: train, Batch: [703/730], Loss: 0.1788\n",
      "Epoch [5/10], Phase: train, Batch: [704/730], Loss: 0.4201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [705/730], Loss: 0.1733\n",
      "Epoch [5/10], Phase: train, Batch: [706/730], Loss: 0.3981\n",
      "Epoch [5/10], Phase: train, Batch: [707/730], Loss: 0.2328\n",
      "Epoch [5/10], Phase: train, Batch: [708/730], Loss: 0.1894\n",
      "Epoch [5/10], Phase: train, Batch: [709/730], Loss: 0.1461\n",
      "Epoch [5/10], Phase: train, Batch: [710/730], Loss: 0.2499\n",
      "Epoch [5/10], Phase: train, Batch: [711/730], Loss: 0.3041\n",
      "Epoch [5/10], Phase: train, Batch: [712/730], Loss: 0.2390\n",
      "Epoch [5/10], Phase: train, Batch: [713/730], Loss: 0.2662\n",
      "Epoch [5/10], Phase: train, Batch: [714/730], Loss: 0.2747\n",
      "Epoch [5/10], Phase: train, Batch: [715/730], Loss: 0.2949\n",
      "Epoch [5/10], Phase: train, Batch: [716/730], Loss: 0.2280\n",
      "Epoch [5/10], Phase: train, Batch: [717/730], Loss: 0.3977\n",
      "Epoch [5/10], Phase: train, Batch: [718/730], Loss: 0.2779\n",
      "Epoch [5/10], Phase: train, Batch: [719/730], Loss: 0.1894\n",
      "Epoch [5/10], Phase: train, Batch: [720/730], Loss: 0.2437\n",
      "Epoch [5/10], Phase: train, Batch: [721/730], Loss: 0.2934\n",
      "Epoch [5/10], Phase: train, Batch: [722/730], Loss: 0.3343\n",
      "Epoch [5/10], Phase: train, Batch: [723/730], Loss: 0.1584\n",
      "Epoch [5/10], Phase: train, Batch: [724/730], Loss: 0.1602\n",
      "Epoch [5/10], Phase: train, Batch: [725/730], Loss: 0.2616\n",
      "Epoch [5/10], Phase: train, Batch: [726/730], Loss: 0.3047\n",
      "Epoch [5/10], Phase: train, Batch: [727/730], Loss: 0.2586\n",
      "Epoch [5/10], Phase: train, Batch: [728/730], Loss: 0.3912\n",
      "Epoch [5/10], Phase: train, Batch: [729/730], Loss: 0.3826\n",
      "Epoch [5/10], Phase: train, Batch: [730/730], Loss: 0.2437\n",
      "train Loss: 0.2841 Acc: 0.8853\n",
      "Epoch [5/10], Phase: val, Batch: [1/182], Loss: 0.3035\n",
      "Epoch [5/10], Phase: val, Batch: [2/182], Loss: 0.2176\n",
      "Epoch [5/10], Phase: val, Batch: [3/182], Loss: 0.1568\n",
      "Epoch [5/10], Phase: val, Batch: [4/182], Loss: 0.2461\n",
      "Epoch [5/10], Phase: val, Batch: [5/182], Loss: 0.1965\n",
      "Epoch [5/10], Phase: val, Batch: [6/182], Loss: 0.1651\n",
      "Epoch [5/10], Phase: val, Batch: [7/182], Loss: 0.0948\n",
      "Epoch [5/10], Phase: val, Batch: [8/182], Loss: 0.2351\n",
      "Epoch [5/10], Phase: val, Batch: [9/182], Loss: 0.1962\n",
      "Epoch [5/10], Phase: val, Batch: [10/182], Loss: 0.1587\n",
      "Epoch [5/10], Phase: val, Batch: [11/182], Loss: 0.1353\n",
      "Epoch [5/10], Phase: val, Batch: [12/182], Loss: 0.2180\n",
      "Epoch [5/10], Phase: val, Batch: [13/182], Loss: 0.1669\n",
      "Epoch [5/10], Phase: val, Batch: [14/182], Loss: 0.1228\n",
      "Epoch [5/10], Phase: val, Batch: [15/182], Loss: 0.1792\n",
      "Epoch [5/10], Phase: val, Batch: [16/182], Loss: 0.2275\n",
      "Epoch [5/10], Phase: val, Batch: [17/182], Loss: 0.2120\n",
      "Epoch [5/10], Phase: val, Batch: [18/182], Loss: 0.1941\n",
      "Epoch [5/10], Phase: val, Batch: [19/182], Loss: 0.2990\n",
      "Epoch [5/10], Phase: val, Batch: [20/182], Loss: 0.3131\n",
      "Epoch [5/10], Phase: val, Batch: [21/182], Loss: 0.3016\n",
      "Epoch [5/10], Phase: val, Batch: [22/182], Loss: 0.2960\n",
      "Epoch [5/10], Phase: val, Batch: [23/182], Loss: 0.1558\n",
      "Epoch [5/10], Phase: val, Batch: [24/182], Loss: 0.3184\n",
      "Epoch [5/10], Phase: val, Batch: [25/182], Loss: 0.2335\n",
      "Epoch [5/10], Phase: val, Batch: [26/182], Loss: 0.1444\n",
      "Epoch [5/10], Phase: val, Batch: [27/182], Loss: 0.1859\n",
      "Epoch [5/10], Phase: val, Batch: [28/182], Loss: 0.3158\n",
      "Epoch [5/10], Phase: val, Batch: [29/182], Loss: 0.2540\n",
      "Epoch [5/10], Phase: val, Batch: [30/182], Loss: 0.2516\n",
      "Epoch [5/10], Phase: val, Batch: [31/182], Loss: 0.3076\n",
      "Epoch [5/10], Phase: val, Batch: [32/182], Loss: 0.1247\n",
      "Epoch [5/10], Phase: val, Batch: [33/182], Loss: 0.2311\n",
      "Epoch [5/10], Phase: val, Batch: [34/182], Loss: 0.2324\n",
      "Epoch [5/10], Phase: val, Batch: [35/182], Loss: 0.1388\n",
      "Epoch [5/10], Phase: val, Batch: [36/182], Loss: 0.2107\n",
      "Epoch [5/10], Phase: val, Batch: [37/182], Loss: 0.1435\n",
      "Epoch [5/10], Phase: val, Batch: [38/182], Loss: 0.1560\n",
      "Epoch [5/10], Phase: val, Batch: [39/182], Loss: 0.2591\n",
      "Epoch [5/10], Phase: val, Batch: [40/182], Loss: 0.2068\n",
      "Epoch [5/10], Phase: val, Batch: [41/182], Loss: 0.1894\n",
      "Epoch [5/10], Phase: val, Batch: [42/182], Loss: 0.2368\n",
      "Epoch [5/10], Phase: val, Batch: [43/182], Loss: 0.1756\n",
      "Epoch [5/10], Phase: val, Batch: [44/182], Loss: 0.2776\n",
      "Epoch [5/10], Phase: val, Batch: [45/182], Loss: 0.2535\n",
      "Epoch [5/10], Phase: val, Batch: [46/182], Loss: 0.1782\n",
      "Epoch [5/10], Phase: val, Batch: [47/182], Loss: 0.2526\n",
      "Epoch [5/10], Phase: val, Batch: [48/182], Loss: 0.1071\n",
      "Epoch [5/10], Phase: val, Batch: [49/182], Loss: 0.2421\n",
      "Epoch [5/10], Phase: val, Batch: [50/182], Loss: 0.3042\n",
      "Epoch [5/10], Phase: val, Batch: [51/182], Loss: 0.3335\n",
      "Epoch [5/10], Phase: val, Batch: [52/182], Loss: 0.2024\n",
      "Epoch [5/10], Phase: val, Batch: [53/182], Loss: 0.2017\n",
      "Epoch [5/10], Phase: val, Batch: [54/182], Loss: 0.2562\n",
      "Epoch [5/10], Phase: val, Batch: [55/182], Loss: 0.1577\n",
      "Epoch [5/10], Phase: val, Batch: [56/182], Loss: 0.1614\n",
      "Epoch [5/10], Phase: val, Batch: [57/182], Loss: 0.2006\n",
      "Epoch [5/10], Phase: val, Batch: [58/182], Loss: 0.1805\n",
      "Epoch [5/10], Phase: val, Batch: [59/182], Loss: 0.1595\n",
      "Epoch [5/10], Phase: val, Batch: [60/182], Loss: 0.1430\n",
      "Epoch [5/10], Phase: val, Batch: [61/182], Loss: 0.2595\n",
      "Epoch [5/10], Phase: val, Batch: [62/182], Loss: 0.3246\n",
      "Epoch [5/10], Phase: val, Batch: [63/182], Loss: 0.1609\n",
      "Epoch [5/10], Phase: val, Batch: [64/182], Loss: 0.2505\n",
      "Epoch [5/10], Phase: val, Batch: [65/182], Loss: 0.1676\n",
      "Epoch [5/10], Phase: val, Batch: [66/182], Loss: 0.2351\n",
      "Epoch [5/10], Phase: val, Batch: [67/182], Loss: 0.1891\n",
      "Epoch [5/10], Phase: val, Batch: [68/182], Loss: 0.1885\n",
      "Epoch [5/10], Phase: val, Batch: [69/182], Loss: 0.2383\n",
      "Epoch [5/10], Phase: val, Batch: [70/182], Loss: 0.2059\n",
      "Epoch [5/10], Phase: val, Batch: [71/182], Loss: 0.3175\n",
      "Epoch [5/10], Phase: val, Batch: [72/182], Loss: 0.1858\n",
      "Epoch [5/10], Phase: val, Batch: [73/182], Loss: 0.1510\n",
      "Epoch [5/10], Phase: val, Batch: [74/182], Loss: 0.3179\n",
      "Epoch [5/10], Phase: val, Batch: [75/182], Loss: 0.1959\n",
      "Epoch [5/10], Phase: val, Batch: [76/182], Loss: 0.1493\n",
      "Epoch [5/10], Phase: val, Batch: [77/182], Loss: 0.1440\n",
      "Epoch [5/10], Phase: val, Batch: [78/182], Loss: 0.1379\n",
      "Epoch [5/10], Phase: val, Batch: [79/182], Loss: 0.2003\n",
      "Epoch [5/10], Phase: val, Batch: [80/182], Loss: 0.1651\n",
      "Epoch [5/10], Phase: val, Batch: [81/182], Loss: 0.1155\n",
      "Epoch [5/10], Phase: val, Batch: [82/182], Loss: 0.1732\n",
      "Epoch [5/10], Phase: val, Batch: [83/182], Loss: 0.1836\n",
      "Epoch [5/10], Phase: val, Batch: [84/182], Loss: 0.1927\n",
      "Epoch [5/10], Phase: val, Batch: [85/182], Loss: 0.1775\n",
      "Epoch [5/10], Phase: val, Batch: [86/182], Loss: 0.2443\n",
      "Epoch [5/10], Phase: val, Batch: [87/182], Loss: 0.3309\n",
      "Epoch [5/10], Phase: val, Batch: [88/182], Loss: 0.2368\n",
      "Epoch [5/10], Phase: val, Batch: [89/182], Loss: 0.2126\n",
      "Epoch [5/10], Phase: val, Batch: [90/182], Loss: 0.2597\n",
      "Epoch [5/10], Phase: val, Batch: [91/182], Loss: 0.2506\n",
      "Epoch [5/10], Phase: val, Batch: [92/182], Loss: 0.2395\n",
      "Epoch [5/10], Phase: val, Batch: [93/182], Loss: 0.1964\n",
      "Epoch [5/10], Phase: val, Batch: [94/182], Loss: 0.2127\n",
      "Epoch [5/10], Phase: val, Batch: [95/182], Loss: 0.2867\n",
      "Epoch [5/10], Phase: val, Batch: [96/182], Loss: 0.2399\n",
      "Epoch [5/10], Phase: val, Batch: [97/182], Loss: 0.2579\n",
      "Epoch [5/10], Phase: val, Batch: [98/182], Loss: 0.2384\n",
      "Epoch [5/10], Phase: val, Batch: [99/182], Loss: 0.2828\n",
      "Epoch [5/10], Phase: val, Batch: [100/182], Loss: 0.3076\n",
      "Epoch [5/10], Phase: val, Batch: [101/182], Loss: 0.3612\n",
      "Epoch [5/10], Phase: val, Batch: [102/182], Loss: 0.2207\n",
      "Epoch [5/10], Phase: val, Batch: [103/182], Loss: 0.2544\n",
      "Epoch [5/10], Phase: val, Batch: [104/182], Loss: 0.2580\n",
      "Epoch [5/10], Phase: val, Batch: [105/182], Loss: 0.2011\n",
      "Epoch [5/10], Phase: val, Batch: [106/182], Loss: 0.4038\n",
      "Epoch [5/10], Phase: val, Batch: [107/182], Loss: 0.2785\n",
      "Epoch [5/10], Phase: val, Batch: [108/182], Loss: 0.2451\n",
      "Epoch [5/10], Phase: val, Batch: [109/182], Loss: 0.2558\n",
      "Epoch [5/10], Phase: val, Batch: [110/182], Loss: 0.2096\n",
      "Epoch [5/10], Phase: val, Batch: [111/182], Loss: 0.1423\n",
      "Epoch [5/10], Phase: val, Batch: [112/182], Loss: 0.1929\n",
      "Epoch [5/10], Phase: val, Batch: [113/182], Loss: 0.1731\n",
      "Epoch [5/10], Phase: val, Batch: [114/182], Loss: 0.2790\n",
      "Epoch [5/10], Phase: val, Batch: [115/182], Loss: 0.2061\n",
      "Epoch [5/10], Phase: val, Batch: [116/182], Loss: 0.2900\n",
      "Epoch [5/10], Phase: val, Batch: [117/182], Loss: 0.1574\n",
      "Epoch [5/10], Phase: val, Batch: [118/182], Loss: 0.2553\n",
      "Epoch [5/10], Phase: val, Batch: [119/182], Loss: 0.1968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: val, Batch: [120/182], Loss: 0.2289\n",
      "Epoch [5/10], Phase: val, Batch: [121/182], Loss: 0.2507\n",
      "Epoch [5/10], Phase: val, Batch: [122/182], Loss: 0.2222\n",
      "Epoch [5/10], Phase: val, Batch: [123/182], Loss: 0.3088\n",
      "Epoch [5/10], Phase: val, Batch: [124/182], Loss: 0.1795\n",
      "Epoch [5/10], Phase: val, Batch: [125/182], Loss: 0.1963\n",
      "Epoch [5/10], Phase: val, Batch: [126/182], Loss: 0.2404\n",
      "Epoch [5/10], Phase: val, Batch: [127/182], Loss: 0.2214\n",
      "Epoch [5/10], Phase: val, Batch: [128/182], Loss: 0.2198\n",
      "Epoch [5/10], Phase: val, Batch: [129/182], Loss: 0.2561\n",
      "Epoch [5/10], Phase: val, Batch: [130/182], Loss: 0.1830\n",
      "Epoch [5/10], Phase: val, Batch: [131/182], Loss: 0.2707\n",
      "Epoch [5/10], Phase: val, Batch: [132/182], Loss: 0.2683\n",
      "Epoch [5/10], Phase: val, Batch: [133/182], Loss: 0.3698\n",
      "Epoch [5/10], Phase: val, Batch: [134/182], Loss: 0.1351\n",
      "Epoch [5/10], Phase: val, Batch: [135/182], Loss: 0.2159\n",
      "Epoch [5/10], Phase: val, Batch: [136/182], Loss: 0.2932\n",
      "Epoch [5/10], Phase: val, Batch: [137/182], Loss: 0.2469\n",
      "Epoch [5/10], Phase: val, Batch: [138/182], Loss: 0.2704\n",
      "Epoch [5/10], Phase: val, Batch: [139/182], Loss: 0.1656\n",
      "Epoch [5/10], Phase: val, Batch: [140/182], Loss: 0.2605\n",
      "Epoch [5/10], Phase: val, Batch: [141/182], Loss: 0.2365\n",
      "Epoch [5/10], Phase: val, Batch: [142/182], Loss: 0.2140\n",
      "Epoch [5/10], Phase: val, Batch: [143/182], Loss: 0.2821\n",
      "Epoch [5/10], Phase: val, Batch: [144/182], Loss: 0.2896\n",
      "Epoch [5/10], Phase: val, Batch: [145/182], Loss: 0.1518\n",
      "Epoch [5/10], Phase: val, Batch: [146/182], Loss: 0.2241\n",
      "Epoch [5/10], Phase: val, Batch: [147/182], Loss: 0.2693\n",
      "Epoch [5/10], Phase: val, Batch: [148/182], Loss: 0.2013\n",
      "Epoch [5/10], Phase: val, Batch: [149/182], Loss: 0.2784\n",
      "Epoch [5/10], Phase: val, Batch: [150/182], Loss: 0.2868\n",
      "Epoch [5/10], Phase: val, Batch: [151/182], Loss: 0.2750\n",
      "Epoch [5/10], Phase: val, Batch: [152/182], Loss: 0.3073\n",
      "Epoch [5/10], Phase: val, Batch: [153/182], Loss: 0.2834\n",
      "Epoch [5/10], Phase: val, Batch: [154/182], Loss: 0.2608\n",
      "Epoch [5/10], Phase: val, Batch: [155/182], Loss: 0.2224\n",
      "Epoch [5/10], Phase: val, Batch: [156/182], Loss: 0.3614\n",
      "Epoch [5/10], Phase: val, Batch: [157/182], Loss: 0.2672\n",
      "Epoch [5/10], Phase: val, Batch: [158/182], Loss: 0.3997\n",
      "Epoch [5/10], Phase: val, Batch: [159/182], Loss: 0.2786\n",
      "Epoch [5/10], Phase: val, Batch: [160/182], Loss: 0.2123\n",
      "Epoch [5/10], Phase: val, Batch: [161/182], Loss: 0.2690\n",
      "Epoch [5/10], Phase: val, Batch: [162/182], Loss: 0.3154\n",
      "Epoch [5/10], Phase: val, Batch: [163/182], Loss: 0.3279\n",
      "Epoch [5/10], Phase: val, Batch: [164/182], Loss: 0.2062\n",
      "Epoch [5/10], Phase: val, Batch: [165/182], Loss: 0.2673\n",
      "Epoch [5/10], Phase: val, Batch: [166/182], Loss: 0.1591\n",
      "Epoch [5/10], Phase: val, Batch: [167/182], Loss: 0.2074\n",
      "Epoch [5/10], Phase: val, Batch: [168/182], Loss: 0.2275\n",
      "Epoch [5/10], Phase: val, Batch: [169/182], Loss: 0.2706\n",
      "Epoch [5/10], Phase: val, Batch: [170/182], Loss: 0.2773\n",
      "Epoch [5/10], Phase: val, Batch: [171/182], Loss: 0.3383\n",
      "Epoch [5/10], Phase: val, Batch: [172/182], Loss: 0.2454\n",
      "Epoch [5/10], Phase: val, Batch: [173/182], Loss: 0.1354\n",
      "Epoch [5/10], Phase: val, Batch: [174/182], Loss: 0.2953\n",
      "Epoch [5/10], Phase: val, Batch: [175/182], Loss: 0.1675\n",
      "Epoch [5/10], Phase: val, Batch: [176/182], Loss: 0.2388\n",
      "Epoch [5/10], Phase: val, Batch: [177/182], Loss: 0.2820\n",
      "Epoch [5/10], Phase: val, Batch: [178/182], Loss: 0.1433\n",
      "Epoch [5/10], Phase: val, Batch: [179/182], Loss: 0.2108\n",
      "Epoch [5/10], Phase: val, Batch: [180/182], Loss: 0.2219\n",
      "Epoch [5/10], Phase: val, Batch: [181/182], Loss: 0.3437\n",
      "Epoch [5/10], Phase: val, Batch: [182/182], Loss: 0.2535\n",
      "val Loss: 0.2299 Acc: 0.9093\n",
      "Early stopping in iteration 3 -->> no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    if counter >= patience:\n",
    "        print(f\"Early stopping in iteration {counter} -->> no improvement in validation loss.\")\n",
    "        break\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_batches = len(dataloaders[phase])\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            #all_preds.extend(preds.cpu().numpy())\n",
    "            #all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            batch_loss = loss.item()\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Phase: {phase}, Batch: [{batch_idx+1}/{total_batches}], Loss: {batch_loss:.4f}')\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        scheduler.step()\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "        \n",
    "        if phase == 'val' and epoch_loss < best_val_loss:\n",
    "            best_val_loss = epoch_loss\n",
    "            counter = 0\n",
    "        elif phase == 'val':\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e31279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b33965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9093\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for inputs, labels in dataloaders['val']:\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = np.mean(all_preds == all_labels)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cd48b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[5326  515]\n",
      " [ 541 5265]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "classification_rep = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beea4d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.91      0.91      0.91      5841\n",
      "        male       0.91      0.91      0.91      5806\n",
      "\n",
      "    accuracy                           0.91     11647\n",
      "   macro avg       0.91      0.91      0.91     11647\n",
      "weighted avg       0.91      0.91      0.91     11647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3934cb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = ['Male', 'Female'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9b0ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'vgg_revize_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67b23a68",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Eski Kod! Stop Here! Look at VGGTransferLearning.ipynb",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEski Kod! Stop Here! Look at VGGTransferLearning.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Eski Kod! Stop Here! Look at VGGTransferLearning.ipynb"
     ]
    }
   ],
   "source": [
    "raise Exception(\"Eski Kod! Stop Here! Look at VGGTransferLearning.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d2d1e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c346f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aerol\\env\\facenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aerol\\env\\facenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = models.vgg16(pretrained=False)  # Load a new instance of VGG16\n",
    "num_features = loaded_model.classifier[6].in_features\n",
    "loaded_model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "loaded_model.load_state_dict(torch.load('vgg_model.pth'))\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2bf01f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: harun.jpg, Predicted Gender: male\n",
      "Image: arda.jpg, Predicted Gender: male\n",
      "Image: fatmanur.jpg, Predicted Gender: female\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image.to(device)  # Move the image to GPU if available\n",
    "\n",
    "image_paths = ['harun.jpg', 'arda.jpg', 'fatmanur.jpg']  # Provide paths to the images\n",
    "for image_path in image_paths:\n",
    "    input_image = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(input_image)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        predicted_label = class_names[predicted_class]\n",
    "        print(f\"Image: {image_path}, Predicted Gender: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
