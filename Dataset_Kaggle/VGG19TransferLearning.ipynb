{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb3cc07",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network  - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe92c4b",
   "metadata": {},
   "source": [
    "Dataset in use: https://www.kaggle.com/datasets/cashutosh/gender-classification-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7bba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640d1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./dataset/Training\"\n",
    "test_dir = \"./dataset/Validation\"\n",
    "input_size = (224, 224)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba002f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec86a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a097a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = datasets.ImageFolder(root=train_dir, transform=transform['train'])\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform['test'])\n",
    "\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset,\n",
    "    'test': test_dataset\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False),  # Changed from 'test' to 'val'\n",
    "    'test': DataLoader(image_datasets['test'], batch_size=batch_size, shuffle=False)  # Changed from 'test' to 'val'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcf57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = full_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f79de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aerol\\env\\facenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aerol\\env\\facenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model = models.vgg19(pretrained=True)\n",
    "\n",
    "# Freeze Layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Custom Classifier\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1), # Dropout is applied with probability 0.1 to prevent overfitting\n",
    "    nn.Linear(256, 2)  # Output is 2 dimensional (male and female)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.013) # Adam Optimizer\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7af19a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a3dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After feedback, VGG19 is trained (in presentation, we presented VGG16 model.) with early stop and dynamic learning rate.\n",
    "# Test and Validation sets are seperated btw each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "175d0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07c58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = np.inf\n",
    "patience = 3\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4811a6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [1/657], Loss: 0.7188\n",
      "Epoch [1/10], Phase: train, Batch: [2/657], Loss: 11.8351\n",
      "Epoch [1/10], Phase: train, Batch: [3/657], Loss: 0.2369\n",
      "Epoch [1/10], Phase: train, Batch: [4/657], Loss: 2.5872\n",
      "Epoch [1/10], Phase: train, Batch: [5/657], Loss: 0.6715\n",
      "Epoch [1/10], Phase: train, Batch: [6/657], Loss: 0.5410\n",
      "Epoch [1/10], Phase: train, Batch: [7/657], Loss: 0.5529\n",
      "Epoch [1/10], Phase: train, Batch: [8/657], Loss: 0.5659\n",
      "Epoch [1/10], Phase: train, Batch: [9/657], Loss: 0.4767\n",
      "Epoch [1/10], Phase: train, Batch: [10/657], Loss: 0.2657\n",
      "Epoch [1/10], Phase: train, Batch: [11/657], Loss: 0.3333\n",
      "Epoch [1/10], Phase: train, Batch: [12/657], Loss: 0.4823\n",
      "Epoch [1/10], Phase: train, Batch: [13/657], Loss: 0.3700\n",
      "Epoch [1/10], Phase: train, Batch: [14/657], Loss: 0.3673\n",
      "Epoch [1/10], Phase: train, Batch: [15/657], Loss: 0.2280\n",
      "Epoch [1/10], Phase: train, Batch: [16/657], Loss: 0.6266\n",
      "Epoch [1/10], Phase: train, Batch: [17/657], Loss: 0.3070\n",
      "Epoch [1/10], Phase: train, Batch: [18/657], Loss: 0.3096\n",
      "Epoch [1/10], Phase: train, Batch: [19/657], Loss: 0.3011\n",
      "Epoch [1/10], Phase: train, Batch: [20/657], Loss: 0.2538\n",
      "Epoch [1/10], Phase: train, Batch: [21/657], Loss: 0.4091\n",
      "Epoch [1/10], Phase: train, Batch: [22/657], Loss: 0.5420\n",
      "Epoch [1/10], Phase: train, Batch: [23/657], Loss: 0.3525\n",
      "Epoch [1/10], Phase: train, Batch: [24/657], Loss: 0.4872\n",
      "Epoch [1/10], Phase: train, Batch: [25/657], Loss: 0.2714\n",
      "Epoch [1/10], Phase: train, Batch: [26/657], Loss: 0.4307\n",
      "Epoch [1/10], Phase: train, Batch: [27/657], Loss: 0.2971\n",
      "Epoch [1/10], Phase: train, Batch: [28/657], Loss: 0.3762\n",
      "Epoch [1/10], Phase: train, Batch: [29/657], Loss: 0.3385\n",
      "Epoch [1/10], Phase: train, Batch: [30/657], Loss: 0.3493\n",
      "Epoch [1/10], Phase: train, Batch: [31/657], Loss: 0.3356\n",
      "Epoch [1/10], Phase: train, Batch: [32/657], Loss: 0.3028\n",
      "Epoch [1/10], Phase: train, Batch: [33/657], Loss: 0.2965\n",
      "Epoch [1/10], Phase: train, Batch: [34/657], Loss: 0.3718\n",
      "Epoch [1/10], Phase: train, Batch: [35/657], Loss: 0.2171\n",
      "Epoch [1/10], Phase: train, Batch: [36/657], Loss: 0.3487\n",
      "Epoch [1/10], Phase: train, Batch: [37/657], Loss: 0.4166\n",
      "Epoch [1/10], Phase: train, Batch: [38/657], Loss: 0.3455\n",
      "Epoch [1/10], Phase: train, Batch: [39/657], Loss: 0.4056\n",
      "Epoch [1/10], Phase: train, Batch: [40/657], Loss: 0.5073\n",
      "Epoch [1/10], Phase: train, Batch: [41/657], Loss: 0.3107\n",
      "Epoch [1/10], Phase: train, Batch: [42/657], Loss: 0.2609\n",
      "Epoch [1/10], Phase: train, Batch: [43/657], Loss: 0.3938\n",
      "Epoch [1/10], Phase: train, Batch: [44/657], Loss: 0.3676\n",
      "Epoch [1/10], Phase: train, Batch: [45/657], Loss: 0.3003\n",
      "Epoch [1/10], Phase: train, Batch: [46/657], Loss: 0.3776\n",
      "Epoch [1/10], Phase: train, Batch: [47/657], Loss: 0.3605\n",
      "Epoch [1/10], Phase: train, Batch: [48/657], Loss: 0.3697\n",
      "Epoch [1/10], Phase: train, Batch: [49/657], Loss: 0.2722\n",
      "Epoch [1/10], Phase: train, Batch: [50/657], Loss: 0.3207\n",
      "Epoch [1/10], Phase: train, Batch: [51/657], Loss: 0.3750\n",
      "Epoch [1/10], Phase: train, Batch: [52/657], Loss: 0.3690\n",
      "Epoch [1/10], Phase: train, Batch: [53/657], Loss: 0.3648\n",
      "Epoch [1/10], Phase: train, Batch: [54/657], Loss: 0.3413\n",
      "Epoch [1/10], Phase: train, Batch: [55/657], Loss: 0.3472\n",
      "Epoch [1/10], Phase: train, Batch: [56/657], Loss: 0.3125\n",
      "Epoch [1/10], Phase: train, Batch: [57/657], Loss: 0.2754\n",
      "Epoch [1/10], Phase: train, Batch: [58/657], Loss: 0.4636\n",
      "Epoch [1/10], Phase: train, Batch: [59/657], Loss: 0.3656\n",
      "Epoch [1/10], Phase: train, Batch: [60/657], Loss: 0.2319\n",
      "Epoch [1/10], Phase: train, Batch: [61/657], Loss: 0.1906\n",
      "Epoch [1/10], Phase: train, Batch: [62/657], Loss: 0.3866\n",
      "Epoch [1/10], Phase: train, Batch: [63/657], Loss: 0.2906\n",
      "Epoch [1/10], Phase: train, Batch: [64/657], Loss: 0.3231\n",
      "Epoch [1/10], Phase: train, Batch: [65/657], Loss: 0.3342\n",
      "Epoch [1/10], Phase: train, Batch: [66/657], Loss: 0.4710\n",
      "Epoch [1/10], Phase: train, Batch: [67/657], Loss: 0.3141\n",
      "Epoch [1/10], Phase: train, Batch: [68/657], Loss: 0.4527\n",
      "Epoch [1/10], Phase: train, Batch: [69/657], Loss: 0.3453\n",
      "Epoch [1/10], Phase: train, Batch: [70/657], Loss: 0.3116\n",
      "Epoch [1/10], Phase: train, Batch: [71/657], Loss: 0.3277\n",
      "Epoch [1/10], Phase: train, Batch: [72/657], Loss: 0.4053\n",
      "Epoch [1/10], Phase: train, Batch: [73/657], Loss: 0.2681\n",
      "Epoch [1/10], Phase: train, Batch: [74/657], Loss: 0.2335\n",
      "Epoch [1/10], Phase: train, Batch: [75/657], Loss: 0.2055\n",
      "Epoch [1/10], Phase: train, Batch: [76/657], Loss: 0.2901\n",
      "Epoch [1/10], Phase: train, Batch: [77/657], Loss: 0.2294\n",
      "Epoch [1/10], Phase: train, Batch: [78/657], Loss: 0.2138\n",
      "Epoch [1/10], Phase: train, Batch: [79/657], Loss: 0.2629\n",
      "Epoch [1/10], Phase: train, Batch: [80/657], Loss: 0.3669\n",
      "Epoch [1/10], Phase: train, Batch: [81/657], Loss: 0.1782\n",
      "Epoch [1/10], Phase: train, Batch: [82/657], Loss: 0.3338\n",
      "Epoch [1/10], Phase: train, Batch: [83/657], Loss: 0.3526\n",
      "Epoch [1/10], Phase: train, Batch: [84/657], Loss: 0.2395\n",
      "Epoch [1/10], Phase: train, Batch: [85/657], Loss: 0.3703\n",
      "Epoch [1/10], Phase: train, Batch: [86/657], Loss: 0.3233\n",
      "Epoch [1/10], Phase: train, Batch: [87/657], Loss: 0.2357\n",
      "Epoch [1/10], Phase: train, Batch: [88/657], Loss: 0.3121\n",
      "Epoch [1/10], Phase: train, Batch: [89/657], Loss: 0.4048\n",
      "Epoch [1/10], Phase: train, Batch: [90/657], Loss: 0.1885\n",
      "Epoch [1/10], Phase: train, Batch: [91/657], Loss: 0.2546\n",
      "Epoch [1/10], Phase: train, Batch: [92/657], Loss: 0.2803\n",
      "Epoch [1/10], Phase: train, Batch: [93/657], Loss: 0.3425\n",
      "Epoch [1/10], Phase: train, Batch: [94/657], Loss: 0.2615\n",
      "Epoch [1/10], Phase: train, Batch: [95/657], Loss: 0.2574\n",
      "Epoch [1/10], Phase: train, Batch: [96/657], Loss: 0.3555\n",
      "Epoch [1/10], Phase: train, Batch: [97/657], Loss: 0.2712\n",
      "Epoch [1/10], Phase: train, Batch: [98/657], Loss: 0.2469\n",
      "Epoch [1/10], Phase: train, Batch: [99/657], Loss: 0.3916\n",
      "Epoch [1/10], Phase: train, Batch: [100/657], Loss: 0.4183\n",
      "Epoch [1/10], Phase: train, Batch: [101/657], Loss: 0.3022\n",
      "Epoch [1/10], Phase: train, Batch: [102/657], Loss: 0.3525\n",
      "Epoch [1/10], Phase: train, Batch: [103/657], Loss: 0.2632\n",
      "Epoch [1/10], Phase: train, Batch: [104/657], Loss: 0.2946\n",
      "Epoch [1/10], Phase: train, Batch: [105/657], Loss: 0.3141\n",
      "Epoch [1/10], Phase: train, Batch: [106/657], Loss: 0.3624\n",
      "Epoch [1/10], Phase: train, Batch: [107/657], Loss: 0.2067\n",
      "Epoch [1/10], Phase: train, Batch: [108/657], Loss: 0.3067\n",
      "Epoch [1/10], Phase: train, Batch: [109/657], Loss: 0.3060\n",
      "Epoch [1/10], Phase: train, Batch: [110/657], Loss: 0.2653\n",
      "Epoch [1/10], Phase: train, Batch: [111/657], Loss: 0.2541\n",
      "Epoch [1/10], Phase: train, Batch: [112/657], Loss: 0.2907\n",
      "Epoch [1/10], Phase: train, Batch: [113/657], Loss: 0.4636\n",
      "Epoch [1/10], Phase: train, Batch: [114/657], Loss: 0.3314\n",
      "Epoch [1/10], Phase: train, Batch: [115/657], Loss: 0.5679\n",
      "Epoch [1/10], Phase: train, Batch: [116/657], Loss: 0.3659\n",
      "Epoch [1/10], Phase: train, Batch: [117/657], Loss: 0.4116\n",
      "Epoch [1/10], Phase: train, Batch: [118/657], Loss: 0.4611\n",
      "Epoch [1/10], Phase: train, Batch: [119/657], Loss: 0.4658\n",
      "Epoch [1/10], Phase: train, Batch: [120/657], Loss: 0.3463\n",
      "Epoch [1/10], Phase: train, Batch: [121/657], Loss: 0.3803\n",
      "Epoch [1/10], Phase: train, Batch: [122/657], Loss: 0.2830\n",
      "Epoch [1/10], Phase: train, Batch: [123/657], Loss: 0.4553\n",
      "Epoch [1/10], Phase: train, Batch: [124/657], Loss: 0.2774\n",
      "Epoch [1/10], Phase: train, Batch: [125/657], Loss: 0.3915\n",
      "Epoch [1/10], Phase: train, Batch: [126/657], Loss: 0.2900\n",
      "Epoch [1/10], Phase: train, Batch: [127/657], Loss: 0.3981\n",
      "Epoch [1/10], Phase: train, Batch: [128/657], Loss: 0.3524\n",
      "Epoch [1/10], Phase: train, Batch: [129/657], Loss: 0.2332\n",
      "Epoch [1/10], Phase: train, Batch: [130/657], Loss: 0.3972\n",
      "Epoch [1/10], Phase: train, Batch: [131/657], Loss: 0.4349\n",
      "Epoch [1/10], Phase: train, Batch: [132/657], Loss: 0.4066\n",
      "Epoch [1/10], Phase: train, Batch: [133/657], Loss: 0.2428\n",
      "Epoch [1/10], Phase: train, Batch: [134/657], Loss: 0.4452\n",
      "Epoch [1/10], Phase: train, Batch: [135/657], Loss: 0.3375\n",
      "Epoch [1/10], Phase: train, Batch: [136/657], Loss: 0.2337\n",
      "Epoch [1/10], Phase: train, Batch: [137/657], Loss: 0.4189\n",
      "Epoch [1/10], Phase: train, Batch: [138/657], Loss: 0.1536\n",
      "Epoch [1/10], Phase: train, Batch: [139/657], Loss: 0.3180\n",
      "Epoch [1/10], Phase: train, Batch: [140/657], Loss: 0.3972\n",
      "Epoch [1/10], Phase: train, Batch: [141/657], Loss: 0.2410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [142/657], Loss: 0.2970\n",
      "Epoch [1/10], Phase: train, Batch: [143/657], Loss: 0.5632\n",
      "Epoch [1/10], Phase: train, Batch: [144/657], Loss: 0.3126\n",
      "Epoch [1/10], Phase: train, Batch: [145/657], Loss: 0.1743\n",
      "Epoch [1/10], Phase: train, Batch: [146/657], Loss: 0.1991\n",
      "Epoch [1/10], Phase: train, Batch: [147/657], Loss: 0.3512\n",
      "Epoch [1/10], Phase: train, Batch: [148/657], Loss: 0.2742\n",
      "Epoch [1/10], Phase: train, Batch: [149/657], Loss: 0.3001\n",
      "Epoch [1/10], Phase: train, Batch: [150/657], Loss: 0.2897\n",
      "Epoch [1/10], Phase: train, Batch: [151/657], Loss: 0.3128\n",
      "Epoch [1/10], Phase: train, Batch: [152/657], Loss: 0.2449\n",
      "Epoch [1/10], Phase: train, Batch: [153/657], Loss: 0.3205\n",
      "Epoch [1/10], Phase: train, Batch: [154/657], Loss: 0.3634\n",
      "Epoch [1/10], Phase: train, Batch: [155/657], Loss: 0.2695\n",
      "Epoch [1/10], Phase: train, Batch: [156/657], Loss: 0.2413\n",
      "Epoch [1/10], Phase: train, Batch: [157/657], Loss: 0.4568\n",
      "Epoch [1/10], Phase: train, Batch: [158/657], Loss: 0.2053\n",
      "Epoch [1/10], Phase: train, Batch: [159/657], Loss: 0.4345\n",
      "Epoch [1/10], Phase: train, Batch: [160/657], Loss: 0.2805\n",
      "Epoch [1/10], Phase: train, Batch: [161/657], Loss: 0.2054\n",
      "Epoch [1/10], Phase: train, Batch: [162/657], Loss: 0.3558\n",
      "Epoch [1/10], Phase: train, Batch: [163/657], Loss: 0.2343\n",
      "Epoch [1/10], Phase: train, Batch: [164/657], Loss: 0.2533\n",
      "Epoch [1/10], Phase: train, Batch: [165/657], Loss: 0.3178\n",
      "Epoch [1/10], Phase: train, Batch: [166/657], Loss: 0.2361\n",
      "Epoch [1/10], Phase: train, Batch: [167/657], Loss: 0.3124\n",
      "Epoch [1/10], Phase: train, Batch: [168/657], Loss: 0.2228\n",
      "Epoch [1/10], Phase: train, Batch: [169/657], Loss: 0.3372\n",
      "Epoch [1/10], Phase: train, Batch: [170/657], Loss: 0.3239\n",
      "Epoch [1/10], Phase: train, Batch: [171/657], Loss: 0.2244\n",
      "Epoch [1/10], Phase: train, Batch: [172/657], Loss: 0.3711\n",
      "Epoch [1/10], Phase: train, Batch: [173/657], Loss: 0.2968\n",
      "Epoch [1/10], Phase: train, Batch: [174/657], Loss: 0.3190\n",
      "Epoch [1/10], Phase: train, Batch: [175/657], Loss: 0.2920\n",
      "Epoch [1/10], Phase: train, Batch: [176/657], Loss: 0.2290\n",
      "Epoch [1/10], Phase: train, Batch: [177/657], Loss: 0.2947\n",
      "Epoch [1/10], Phase: train, Batch: [178/657], Loss: 0.2998\n",
      "Epoch [1/10], Phase: train, Batch: [179/657], Loss: 0.3198\n",
      "Epoch [1/10], Phase: train, Batch: [180/657], Loss: 0.1785\n",
      "Epoch [1/10], Phase: train, Batch: [181/657], Loss: 0.2191\n",
      "Epoch [1/10], Phase: train, Batch: [182/657], Loss: 0.5044\n",
      "Epoch [1/10], Phase: train, Batch: [183/657], Loss: 0.4552\n",
      "Epoch [1/10], Phase: train, Batch: [184/657], Loss: 0.2709\n",
      "Epoch [1/10], Phase: train, Batch: [185/657], Loss: 0.4168\n",
      "Epoch [1/10], Phase: train, Batch: [186/657], Loss: 0.2823\n",
      "Epoch [1/10], Phase: train, Batch: [187/657], Loss: 0.2585\n",
      "Epoch [1/10], Phase: train, Batch: [188/657], Loss: 0.3699\n",
      "Epoch [1/10], Phase: train, Batch: [189/657], Loss: 0.2682\n",
      "Epoch [1/10], Phase: train, Batch: [190/657], Loss: 0.2473\n",
      "Epoch [1/10], Phase: train, Batch: [191/657], Loss: 0.2465\n",
      "Epoch [1/10], Phase: train, Batch: [192/657], Loss: 0.2180\n",
      "Epoch [1/10], Phase: train, Batch: [193/657], Loss: 0.3716\n",
      "Epoch [1/10], Phase: train, Batch: [194/657], Loss: 0.1669\n",
      "Epoch [1/10], Phase: train, Batch: [195/657], Loss: 0.1423\n",
      "Epoch [1/10], Phase: train, Batch: [196/657], Loss: 0.4835\n",
      "Epoch [1/10], Phase: train, Batch: [197/657], Loss: 0.2317\n",
      "Epoch [1/10], Phase: train, Batch: [198/657], Loss: 0.2498\n",
      "Epoch [1/10], Phase: train, Batch: [199/657], Loss: 0.2843\n",
      "Epoch [1/10], Phase: train, Batch: [200/657], Loss: 0.2009\n",
      "Epoch [1/10], Phase: train, Batch: [201/657], Loss: 0.2293\n",
      "Epoch [1/10], Phase: train, Batch: [202/657], Loss: 0.3294\n",
      "Epoch [1/10], Phase: train, Batch: [203/657], Loss: 0.4252\n",
      "Epoch [1/10], Phase: train, Batch: [204/657], Loss: 0.3241\n",
      "Epoch [1/10], Phase: train, Batch: [205/657], Loss: 0.3119\n",
      "Epoch [1/10], Phase: train, Batch: [206/657], Loss: 0.3304\n",
      "Epoch [1/10], Phase: train, Batch: [207/657], Loss: 0.2561\n",
      "Epoch [1/10], Phase: train, Batch: [208/657], Loss: 0.2561\n",
      "Epoch [1/10], Phase: train, Batch: [209/657], Loss: 0.4030\n",
      "Epoch [1/10], Phase: train, Batch: [210/657], Loss: 0.1804\n",
      "Epoch [1/10], Phase: train, Batch: [211/657], Loss: 0.4501\n",
      "Epoch [1/10], Phase: train, Batch: [212/657], Loss: 0.3392\n",
      "Epoch [1/10], Phase: train, Batch: [213/657], Loss: 0.3937\n",
      "Epoch [1/10], Phase: train, Batch: [214/657], Loss: 0.3647\n",
      "Epoch [1/10], Phase: train, Batch: [215/657], Loss: 0.2683\n",
      "Epoch [1/10], Phase: train, Batch: [216/657], Loss: 0.2593\n",
      "Epoch [1/10], Phase: train, Batch: [217/657], Loss: 0.4877\n",
      "Epoch [1/10], Phase: train, Batch: [218/657], Loss: 0.3229\n",
      "Epoch [1/10], Phase: train, Batch: [219/657], Loss: 0.3748\n",
      "Epoch [1/10], Phase: train, Batch: [220/657], Loss: 0.4236\n",
      "Epoch [1/10], Phase: train, Batch: [221/657], Loss: 0.3839\n",
      "Epoch [1/10], Phase: train, Batch: [222/657], Loss: 0.4398\n",
      "Epoch [1/10], Phase: train, Batch: [223/657], Loss: 0.2906\n",
      "Epoch [1/10], Phase: train, Batch: [224/657], Loss: 0.2770\n",
      "Epoch [1/10], Phase: train, Batch: [225/657], Loss: 0.3042\n",
      "Epoch [1/10], Phase: train, Batch: [226/657], Loss: 0.2626\n",
      "Epoch [1/10], Phase: train, Batch: [227/657], Loss: 0.3617\n",
      "Epoch [1/10], Phase: train, Batch: [228/657], Loss: 0.2501\n",
      "Epoch [1/10], Phase: train, Batch: [229/657], Loss: 0.2348\n",
      "Epoch [1/10], Phase: train, Batch: [230/657], Loss: 0.2901\n",
      "Epoch [1/10], Phase: train, Batch: [231/657], Loss: 0.2779\n",
      "Epoch [1/10], Phase: train, Batch: [232/657], Loss: 0.4555\n",
      "Epoch [1/10], Phase: train, Batch: [233/657], Loss: 0.1970\n",
      "Epoch [1/10], Phase: train, Batch: [234/657], Loss: 0.6043\n",
      "Epoch [1/10], Phase: train, Batch: [235/657], Loss: 0.3403\n",
      "Epoch [1/10], Phase: train, Batch: [236/657], Loss: 0.3306\n",
      "Epoch [1/10], Phase: train, Batch: [237/657], Loss: 0.2415\n",
      "Epoch [1/10], Phase: train, Batch: [238/657], Loss: 0.4070\n",
      "Epoch [1/10], Phase: train, Batch: [239/657], Loss: 0.3562\n",
      "Epoch [1/10], Phase: train, Batch: [240/657], Loss: 0.3712\n",
      "Epoch [1/10], Phase: train, Batch: [241/657], Loss: 0.3878\n",
      "Epoch [1/10], Phase: train, Batch: [242/657], Loss: 0.3850\n",
      "Epoch [1/10], Phase: train, Batch: [243/657], Loss: 0.3454\n",
      "Epoch [1/10], Phase: train, Batch: [244/657], Loss: 0.3310\n",
      "Epoch [1/10], Phase: train, Batch: [245/657], Loss: 0.2490\n",
      "Epoch [1/10], Phase: train, Batch: [246/657], Loss: 0.4321\n",
      "Epoch [1/10], Phase: train, Batch: [247/657], Loss: 0.3558\n",
      "Epoch [1/10], Phase: train, Batch: [248/657], Loss: 0.2682\n",
      "Epoch [1/10], Phase: train, Batch: [249/657], Loss: 0.1972\n",
      "Epoch [1/10], Phase: train, Batch: [250/657], Loss: 0.1392\n",
      "Epoch [1/10], Phase: train, Batch: [251/657], Loss: 0.2683\n",
      "Epoch [1/10], Phase: train, Batch: [252/657], Loss: 0.3506\n",
      "Epoch [1/10], Phase: train, Batch: [253/657], Loss: 0.4048\n",
      "Epoch [1/10], Phase: train, Batch: [254/657], Loss: 0.2481\n",
      "Epoch [1/10], Phase: train, Batch: [255/657], Loss: 0.4515\n",
      "Epoch [1/10], Phase: train, Batch: [256/657], Loss: 0.4096\n",
      "Epoch [1/10], Phase: train, Batch: [257/657], Loss: 0.2855\n",
      "Epoch [1/10], Phase: train, Batch: [258/657], Loss: 0.4256\n",
      "Epoch [1/10], Phase: train, Batch: [259/657], Loss: 0.3408\n",
      "Epoch [1/10], Phase: train, Batch: [260/657], Loss: 0.3387\n",
      "Epoch [1/10], Phase: train, Batch: [261/657], Loss: 0.4171\n",
      "Epoch [1/10], Phase: train, Batch: [262/657], Loss: 0.2590\n",
      "Epoch [1/10], Phase: train, Batch: [263/657], Loss: 0.3307\n",
      "Epoch [1/10], Phase: train, Batch: [264/657], Loss: 0.3700\n",
      "Epoch [1/10], Phase: train, Batch: [265/657], Loss: 0.3301\n",
      "Epoch [1/10], Phase: train, Batch: [266/657], Loss: 0.4126\n",
      "Epoch [1/10], Phase: train, Batch: [267/657], Loss: 0.4107\n",
      "Epoch [1/10], Phase: train, Batch: [268/657], Loss: 0.3401\n",
      "Epoch [1/10], Phase: train, Batch: [269/657], Loss: 0.3153\n",
      "Epoch [1/10], Phase: train, Batch: [270/657], Loss: 0.3813\n",
      "Epoch [1/10], Phase: train, Batch: [271/657], Loss: 0.3330\n",
      "Epoch [1/10], Phase: train, Batch: [272/657], Loss: 0.3546\n",
      "Epoch [1/10], Phase: train, Batch: [273/657], Loss: 0.2663\n",
      "Epoch [1/10], Phase: train, Batch: [274/657], Loss: 0.2444\n",
      "Epoch [1/10], Phase: train, Batch: [275/657], Loss: 0.2509\n",
      "Epoch [1/10], Phase: train, Batch: [276/657], Loss: 0.2491\n",
      "Epoch [1/10], Phase: train, Batch: [277/657], Loss: 0.2717\n",
      "Epoch [1/10], Phase: train, Batch: [278/657], Loss: 0.2472\n",
      "Epoch [1/10], Phase: train, Batch: [279/657], Loss: 0.2975\n",
      "Epoch [1/10], Phase: train, Batch: [280/657], Loss: 0.2142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [281/657], Loss: 0.3005\n",
      "Epoch [1/10], Phase: train, Batch: [282/657], Loss: 0.5584\n",
      "Epoch [1/10], Phase: train, Batch: [283/657], Loss: 0.2537\n",
      "Epoch [1/10], Phase: train, Batch: [284/657], Loss: 0.3785\n",
      "Epoch [1/10], Phase: train, Batch: [285/657], Loss: 0.3921\n",
      "Epoch [1/10], Phase: train, Batch: [286/657], Loss: 0.1806\n",
      "Epoch [1/10], Phase: train, Batch: [287/657], Loss: 0.3239\n",
      "Epoch [1/10], Phase: train, Batch: [288/657], Loss: 0.2762\n",
      "Epoch [1/10], Phase: train, Batch: [289/657], Loss: 0.2378\n",
      "Epoch [1/10], Phase: train, Batch: [290/657], Loss: 0.1548\n",
      "Epoch [1/10], Phase: train, Batch: [291/657], Loss: 0.2806\n",
      "Epoch [1/10], Phase: train, Batch: [292/657], Loss: 0.2439\n",
      "Epoch [1/10], Phase: train, Batch: [293/657], Loss: 0.2512\n",
      "Epoch [1/10], Phase: train, Batch: [294/657], Loss: 0.3482\n",
      "Epoch [1/10], Phase: train, Batch: [295/657], Loss: 0.1688\n",
      "Epoch [1/10], Phase: train, Batch: [296/657], Loss: 0.2378\n",
      "Epoch [1/10], Phase: train, Batch: [297/657], Loss: 0.3122\n",
      "Epoch [1/10], Phase: train, Batch: [298/657], Loss: 0.3636\n",
      "Epoch [1/10], Phase: train, Batch: [299/657], Loss: 0.3955\n",
      "Epoch [1/10], Phase: train, Batch: [300/657], Loss: 0.3057\n",
      "Epoch [1/10], Phase: train, Batch: [301/657], Loss: 0.3917\n",
      "Epoch [1/10], Phase: train, Batch: [302/657], Loss: 0.2075\n",
      "Epoch [1/10], Phase: train, Batch: [303/657], Loss: 0.3002\n",
      "Epoch [1/10], Phase: train, Batch: [304/657], Loss: 0.3416\n",
      "Epoch [1/10], Phase: train, Batch: [305/657], Loss: 0.4311\n",
      "Epoch [1/10], Phase: train, Batch: [306/657], Loss: 0.2344\n",
      "Epoch [1/10], Phase: train, Batch: [307/657], Loss: 0.2198\n",
      "Epoch [1/10], Phase: train, Batch: [308/657], Loss: 0.2092\n",
      "Epoch [1/10], Phase: train, Batch: [309/657], Loss: 0.3017\n",
      "Epoch [1/10], Phase: train, Batch: [310/657], Loss: 0.2626\n",
      "Epoch [1/10], Phase: train, Batch: [311/657], Loss: 0.1973\n",
      "Epoch [1/10], Phase: train, Batch: [312/657], Loss: 0.4438\n",
      "Epoch [1/10], Phase: train, Batch: [313/657], Loss: 0.3107\n",
      "Epoch [1/10], Phase: train, Batch: [314/657], Loss: 0.3502\n",
      "Epoch [1/10], Phase: train, Batch: [315/657], Loss: 0.3117\n",
      "Epoch [1/10], Phase: train, Batch: [316/657], Loss: 0.3574\n",
      "Epoch [1/10], Phase: train, Batch: [317/657], Loss: 0.3549\n",
      "Epoch [1/10], Phase: train, Batch: [318/657], Loss: 0.3010\n",
      "Epoch [1/10], Phase: train, Batch: [319/657], Loss: 0.3493\n",
      "Epoch [1/10], Phase: train, Batch: [320/657], Loss: 0.3304\n",
      "Epoch [1/10], Phase: train, Batch: [321/657], Loss: 0.3823\n",
      "Epoch [1/10], Phase: train, Batch: [322/657], Loss: 0.2856\n",
      "Epoch [1/10], Phase: train, Batch: [323/657], Loss: 0.4381\n",
      "Epoch [1/10], Phase: train, Batch: [324/657], Loss: 0.2114\n",
      "Epoch [1/10], Phase: train, Batch: [325/657], Loss: 0.2744\n",
      "Epoch [1/10], Phase: train, Batch: [326/657], Loss: 0.2929\n",
      "Epoch [1/10], Phase: train, Batch: [327/657], Loss: 0.2474\n",
      "Epoch [1/10], Phase: train, Batch: [328/657], Loss: 0.3466\n",
      "Epoch [1/10], Phase: train, Batch: [329/657], Loss: 0.3445\n",
      "Epoch [1/10], Phase: train, Batch: [330/657], Loss: 0.4210\n",
      "Epoch [1/10], Phase: train, Batch: [331/657], Loss: 0.2771\n",
      "Epoch [1/10], Phase: train, Batch: [332/657], Loss: 0.2847\n",
      "Epoch [1/10], Phase: train, Batch: [333/657], Loss: 0.2149\n",
      "Epoch [1/10], Phase: train, Batch: [334/657], Loss: 0.2106\n",
      "Epoch [1/10], Phase: train, Batch: [335/657], Loss: 0.2511\n",
      "Epoch [1/10], Phase: train, Batch: [336/657], Loss: 0.3899\n",
      "Epoch [1/10], Phase: train, Batch: [337/657], Loss: 0.3348\n",
      "Epoch [1/10], Phase: train, Batch: [338/657], Loss: 0.1937\n",
      "Epoch [1/10], Phase: train, Batch: [339/657], Loss: 0.1217\n",
      "Epoch [1/10], Phase: train, Batch: [340/657], Loss: 0.3699\n",
      "Epoch [1/10], Phase: train, Batch: [341/657], Loss: 0.1078\n",
      "Epoch [1/10], Phase: train, Batch: [342/657], Loss: 0.3539\n",
      "Epoch [1/10], Phase: train, Batch: [343/657], Loss: 0.2645\n",
      "Epoch [1/10], Phase: train, Batch: [344/657], Loss: 0.1785\n",
      "Epoch [1/10], Phase: train, Batch: [345/657], Loss: 0.3311\n",
      "Epoch [1/10], Phase: train, Batch: [346/657], Loss: 0.3716\n",
      "Epoch [1/10], Phase: train, Batch: [347/657], Loss: 0.2341\n",
      "Epoch [1/10], Phase: train, Batch: [348/657], Loss: 0.3420\n",
      "Epoch [1/10], Phase: train, Batch: [349/657], Loss: 0.3286\n",
      "Epoch [1/10], Phase: train, Batch: [350/657], Loss: 0.3140\n",
      "Epoch [1/10], Phase: train, Batch: [351/657], Loss: 0.2560\n",
      "Epoch [1/10], Phase: train, Batch: [352/657], Loss: 0.3520\n",
      "Epoch [1/10], Phase: train, Batch: [353/657], Loss: 0.2484\n",
      "Epoch [1/10], Phase: train, Batch: [354/657], Loss: 0.3082\n",
      "Epoch [1/10], Phase: train, Batch: [355/657], Loss: 0.2630\n",
      "Epoch [1/10], Phase: train, Batch: [356/657], Loss: 0.1967\n",
      "Epoch [1/10], Phase: train, Batch: [357/657], Loss: 0.2659\n",
      "Epoch [1/10], Phase: train, Batch: [358/657], Loss: 0.2338\n",
      "Epoch [1/10], Phase: train, Batch: [359/657], Loss: 0.3499\n",
      "Epoch [1/10], Phase: train, Batch: [360/657], Loss: 0.2176\n",
      "Epoch [1/10], Phase: train, Batch: [361/657], Loss: 0.2234\n",
      "Epoch [1/10], Phase: train, Batch: [362/657], Loss: 0.3881\n",
      "Epoch [1/10], Phase: train, Batch: [363/657], Loss: 0.3326\n",
      "Epoch [1/10], Phase: train, Batch: [364/657], Loss: 0.3162\n",
      "Epoch [1/10], Phase: train, Batch: [365/657], Loss: 0.2613\n",
      "Epoch [1/10], Phase: train, Batch: [366/657], Loss: 0.4310\n",
      "Epoch [1/10], Phase: train, Batch: [367/657], Loss: 0.2868\n",
      "Epoch [1/10], Phase: train, Batch: [368/657], Loss: 0.4255\n",
      "Epoch [1/10], Phase: train, Batch: [369/657], Loss: 0.2916\n",
      "Epoch [1/10], Phase: train, Batch: [370/657], Loss: 0.3767\n",
      "Epoch [1/10], Phase: train, Batch: [371/657], Loss: 0.2795\n",
      "Epoch [1/10], Phase: train, Batch: [372/657], Loss: 0.2504\n",
      "Epoch [1/10], Phase: train, Batch: [373/657], Loss: 0.3370\n",
      "Epoch [1/10], Phase: train, Batch: [374/657], Loss: 0.3968\n",
      "Epoch [1/10], Phase: train, Batch: [375/657], Loss: 0.2483\n",
      "Epoch [1/10], Phase: train, Batch: [376/657], Loss: 0.1800\n",
      "Epoch [1/10], Phase: train, Batch: [377/657], Loss: 0.2757\n",
      "Epoch [1/10], Phase: train, Batch: [378/657], Loss: 0.4742\n",
      "Epoch [1/10], Phase: train, Batch: [379/657], Loss: 0.1753\n",
      "Epoch [1/10], Phase: train, Batch: [380/657], Loss: 0.2354\n",
      "Epoch [1/10], Phase: train, Batch: [381/657], Loss: 0.2029\n",
      "Epoch [1/10], Phase: train, Batch: [382/657], Loss: 0.3134\n",
      "Epoch [1/10], Phase: train, Batch: [383/657], Loss: 0.3641\n",
      "Epoch [1/10], Phase: train, Batch: [384/657], Loss: 0.2871\n",
      "Epoch [1/10], Phase: train, Batch: [385/657], Loss: 0.2667\n",
      "Epoch [1/10], Phase: train, Batch: [386/657], Loss: 0.4530\n",
      "Epoch [1/10], Phase: train, Batch: [387/657], Loss: 0.2763\n",
      "Epoch [1/10], Phase: train, Batch: [388/657], Loss: 0.3709\n",
      "Epoch [1/10], Phase: train, Batch: [389/657], Loss: 0.2559\n",
      "Epoch [1/10], Phase: train, Batch: [390/657], Loss: 0.4108\n",
      "Epoch [1/10], Phase: train, Batch: [391/657], Loss: 0.2951\n",
      "Epoch [1/10], Phase: train, Batch: [392/657], Loss: 0.2933\n",
      "Epoch [1/10], Phase: train, Batch: [393/657], Loss: 0.2472\n",
      "Epoch [1/10], Phase: train, Batch: [394/657], Loss: 0.3322\n",
      "Epoch [1/10], Phase: train, Batch: [395/657], Loss: 0.2490\n",
      "Epoch [1/10], Phase: train, Batch: [396/657], Loss: 0.3512\n",
      "Epoch [1/10], Phase: train, Batch: [397/657], Loss: 0.4572\n",
      "Epoch [1/10], Phase: train, Batch: [398/657], Loss: 0.1838\n",
      "Epoch [1/10], Phase: train, Batch: [399/657], Loss: 0.3401\n",
      "Epoch [1/10], Phase: train, Batch: [400/657], Loss: 0.1546\n",
      "Epoch [1/10], Phase: train, Batch: [401/657], Loss: 0.3626\n",
      "Epoch [1/10], Phase: train, Batch: [402/657], Loss: 0.2652\n",
      "Epoch [1/10], Phase: train, Batch: [403/657], Loss: 0.1699\n",
      "Epoch [1/10], Phase: train, Batch: [404/657], Loss: 0.1991\n",
      "Epoch [1/10], Phase: train, Batch: [405/657], Loss: 0.3989\n",
      "Epoch [1/10], Phase: train, Batch: [406/657], Loss: 0.4082\n",
      "Epoch [1/10], Phase: train, Batch: [407/657], Loss: 0.2798\n",
      "Epoch [1/10], Phase: train, Batch: [408/657], Loss: 0.3722\n",
      "Epoch [1/10], Phase: train, Batch: [409/657], Loss: 0.3425\n",
      "Epoch [1/10], Phase: train, Batch: [410/657], Loss: 0.2362\n",
      "Epoch [1/10], Phase: train, Batch: [411/657], Loss: 0.3578\n",
      "Epoch [1/10], Phase: train, Batch: [412/657], Loss: 0.2735\n",
      "Epoch [1/10], Phase: train, Batch: [413/657], Loss: 0.2548\n",
      "Epoch [1/10], Phase: train, Batch: [414/657], Loss: 0.2142\n",
      "Epoch [1/10], Phase: train, Batch: [415/657], Loss: 0.2106\n",
      "Epoch [1/10], Phase: train, Batch: [416/657], Loss: 0.2634\n",
      "Epoch [1/10], Phase: train, Batch: [417/657], Loss: 0.3592\n",
      "Epoch [1/10], Phase: train, Batch: [418/657], Loss: 0.2998\n",
      "Epoch [1/10], Phase: train, Batch: [419/657], Loss: 0.4305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [420/657], Loss: 0.2001\n",
      "Epoch [1/10], Phase: train, Batch: [421/657], Loss: 0.2500\n",
      "Epoch [1/10], Phase: train, Batch: [422/657], Loss: 0.3050\n",
      "Epoch [1/10], Phase: train, Batch: [423/657], Loss: 0.2792\n",
      "Epoch [1/10], Phase: train, Batch: [424/657], Loss: 0.2455\n",
      "Epoch [1/10], Phase: train, Batch: [425/657], Loss: 0.3103\n",
      "Epoch [1/10], Phase: train, Batch: [426/657], Loss: 0.2086\n",
      "Epoch [1/10], Phase: train, Batch: [427/657], Loss: 0.2804\n",
      "Epoch [1/10], Phase: train, Batch: [428/657], Loss: 0.3735\n",
      "Epoch [1/10], Phase: train, Batch: [429/657], Loss: 0.3848\n",
      "Epoch [1/10], Phase: train, Batch: [430/657], Loss: 0.3376\n",
      "Epoch [1/10], Phase: train, Batch: [431/657], Loss: 0.6003\n",
      "Epoch [1/10], Phase: train, Batch: [432/657], Loss: 0.3474\n",
      "Epoch [1/10], Phase: train, Batch: [433/657], Loss: 0.1857\n",
      "Epoch [1/10], Phase: train, Batch: [434/657], Loss: 0.3602\n",
      "Epoch [1/10], Phase: train, Batch: [435/657], Loss: 0.2333\n",
      "Epoch [1/10], Phase: train, Batch: [436/657], Loss: 0.3773\n",
      "Epoch [1/10], Phase: train, Batch: [437/657], Loss: 0.2443\n",
      "Epoch [1/10], Phase: train, Batch: [438/657], Loss: 0.2543\n",
      "Epoch [1/10], Phase: train, Batch: [439/657], Loss: 0.3380\n",
      "Epoch [1/10], Phase: train, Batch: [440/657], Loss: 0.4585\n",
      "Epoch [1/10], Phase: train, Batch: [441/657], Loss: 0.3679\n",
      "Epoch [1/10], Phase: train, Batch: [442/657], Loss: 0.2370\n",
      "Epoch [1/10], Phase: train, Batch: [443/657], Loss: 0.4090\n",
      "Epoch [1/10], Phase: train, Batch: [444/657], Loss: 0.4247\n",
      "Epoch [1/10], Phase: train, Batch: [445/657], Loss: 0.3303\n",
      "Epoch [1/10], Phase: train, Batch: [446/657], Loss: 0.3985\n",
      "Epoch [1/10], Phase: train, Batch: [447/657], Loss: 0.2654\n",
      "Epoch [1/10], Phase: train, Batch: [448/657], Loss: 0.4003\n",
      "Epoch [1/10], Phase: train, Batch: [449/657], Loss: 0.2519\n",
      "Epoch [1/10], Phase: train, Batch: [450/657], Loss: 0.2193\n",
      "Epoch [1/10], Phase: train, Batch: [451/657], Loss: 0.5652\n",
      "Epoch [1/10], Phase: train, Batch: [452/657], Loss: 0.2431\n",
      "Epoch [1/10], Phase: train, Batch: [453/657], Loss: 0.4256\n",
      "Epoch [1/10], Phase: train, Batch: [454/657], Loss: 0.3320\n",
      "Epoch [1/10], Phase: train, Batch: [455/657], Loss: 0.2024\n",
      "Epoch [1/10], Phase: train, Batch: [456/657], Loss: 0.3381\n",
      "Epoch [1/10], Phase: train, Batch: [457/657], Loss: 0.4002\n",
      "Epoch [1/10], Phase: train, Batch: [458/657], Loss: 0.2925\n",
      "Epoch [1/10], Phase: train, Batch: [459/657], Loss: 0.3053\n",
      "Epoch [1/10], Phase: train, Batch: [460/657], Loss: 0.2129\n",
      "Epoch [1/10], Phase: train, Batch: [461/657], Loss: 0.3212\n",
      "Epoch [1/10], Phase: train, Batch: [462/657], Loss: 0.4460\n",
      "Epoch [1/10], Phase: train, Batch: [463/657], Loss: 0.1992\n",
      "Epoch [1/10], Phase: train, Batch: [464/657], Loss: 0.2931\n",
      "Epoch [1/10], Phase: train, Batch: [465/657], Loss: 0.5726\n",
      "Epoch [1/10], Phase: train, Batch: [466/657], Loss: 0.2852\n",
      "Epoch [1/10], Phase: train, Batch: [467/657], Loss: 0.3685\n",
      "Epoch [1/10], Phase: train, Batch: [468/657], Loss: 0.2726\n",
      "Epoch [1/10], Phase: train, Batch: [469/657], Loss: 0.4773\n",
      "Epoch [1/10], Phase: train, Batch: [470/657], Loss: 0.2390\n",
      "Epoch [1/10], Phase: train, Batch: [471/657], Loss: 0.2501\n",
      "Epoch [1/10], Phase: train, Batch: [472/657], Loss: 0.3192\n",
      "Epoch [1/10], Phase: train, Batch: [473/657], Loss: 0.2571\n",
      "Epoch [1/10], Phase: train, Batch: [474/657], Loss: 0.2164\n",
      "Epoch [1/10], Phase: train, Batch: [475/657], Loss: 0.3479\n",
      "Epoch [1/10], Phase: train, Batch: [476/657], Loss: 0.1885\n",
      "Epoch [1/10], Phase: train, Batch: [477/657], Loss: 0.3759\n",
      "Epoch [1/10], Phase: train, Batch: [478/657], Loss: 0.1967\n",
      "Epoch [1/10], Phase: train, Batch: [479/657], Loss: 0.2324\n",
      "Epoch [1/10], Phase: train, Batch: [480/657], Loss: 0.3099\n",
      "Epoch [1/10], Phase: train, Batch: [481/657], Loss: 0.5521\n",
      "Epoch [1/10], Phase: train, Batch: [482/657], Loss: 0.1912\n",
      "Epoch [1/10], Phase: train, Batch: [483/657], Loss: 0.1735\n",
      "Epoch [1/10], Phase: train, Batch: [484/657], Loss: 0.5103\n",
      "Epoch [1/10], Phase: train, Batch: [485/657], Loss: 0.4579\n",
      "Epoch [1/10], Phase: train, Batch: [486/657], Loss: 0.3299\n",
      "Epoch [1/10], Phase: train, Batch: [487/657], Loss: 0.2143\n",
      "Epoch [1/10], Phase: train, Batch: [488/657], Loss: 0.3231\n",
      "Epoch [1/10], Phase: train, Batch: [489/657], Loss: 0.3190\n",
      "Epoch [1/10], Phase: train, Batch: [490/657], Loss: 0.2845\n",
      "Epoch [1/10], Phase: train, Batch: [491/657], Loss: 0.3233\n",
      "Epoch [1/10], Phase: train, Batch: [492/657], Loss: 0.3567\n",
      "Epoch [1/10], Phase: train, Batch: [493/657], Loss: 0.2626\n",
      "Epoch [1/10], Phase: train, Batch: [494/657], Loss: 0.2208\n",
      "Epoch [1/10], Phase: train, Batch: [495/657], Loss: 0.2803\n",
      "Epoch [1/10], Phase: train, Batch: [496/657], Loss: 0.1862\n",
      "Epoch [1/10], Phase: train, Batch: [497/657], Loss: 0.2792\n",
      "Epoch [1/10], Phase: train, Batch: [498/657], Loss: 0.0959\n",
      "Epoch [1/10], Phase: train, Batch: [499/657], Loss: 0.4302\n",
      "Epoch [1/10], Phase: train, Batch: [500/657], Loss: 0.2342\n",
      "Epoch [1/10], Phase: train, Batch: [501/657], Loss: 0.2682\n",
      "Epoch [1/10], Phase: train, Batch: [502/657], Loss: 0.4404\n",
      "Epoch [1/10], Phase: train, Batch: [503/657], Loss: 0.2859\n",
      "Epoch [1/10], Phase: train, Batch: [504/657], Loss: 0.3091\n",
      "Epoch [1/10], Phase: train, Batch: [505/657], Loss: 0.2970\n",
      "Epoch [1/10], Phase: train, Batch: [506/657], Loss: 0.3243\n",
      "Epoch [1/10], Phase: train, Batch: [507/657], Loss: 0.3090\n",
      "Epoch [1/10], Phase: train, Batch: [508/657], Loss: 0.2804\n",
      "Epoch [1/10], Phase: train, Batch: [509/657], Loss: 0.2901\n",
      "Epoch [1/10], Phase: train, Batch: [510/657], Loss: 0.4599\n",
      "Epoch [1/10], Phase: train, Batch: [511/657], Loss: 0.2212\n",
      "Epoch [1/10], Phase: train, Batch: [512/657], Loss: 0.3033\n",
      "Epoch [1/10], Phase: train, Batch: [513/657], Loss: 0.3359\n",
      "Epoch [1/10], Phase: train, Batch: [514/657], Loss: 0.3086\n",
      "Epoch [1/10], Phase: train, Batch: [515/657], Loss: 0.3194\n",
      "Epoch [1/10], Phase: train, Batch: [516/657], Loss: 0.3341\n",
      "Epoch [1/10], Phase: train, Batch: [517/657], Loss: 0.2226\n",
      "Epoch [1/10], Phase: train, Batch: [518/657], Loss: 0.3388\n",
      "Epoch [1/10], Phase: train, Batch: [519/657], Loss: 0.3377\n",
      "Epoch [1/10], Phase: train, Batch: [520/657], Loss: 0.2472\n",
      "Epoch [1/10], Phase: train, Batch: [521/657], Loss: 0.3166\n",
      "Epoch [1/10], Phase: train, Batch: [522/657], Loss: 0.2207\n",
      "Epoch [1/10], Phase: train, Batch: [523/657], Loss: 0.4229\n",
      "Epoch [1/10], Phase: train, Batch: [524/657], Loss: 0.2962\n",
      "Epoch [1/10], Phase: train, Batch: [525/657], Loss: 0.2759\n",
      "Epoch [1/10], Phase: train, Batch: [526/657], Loss: 0.3910\n",
      "Epoch [1/10], Phase: train, Batch: [527/657], Loss: 0.2349\n",
      "Epoch [1/10], Phase: train, Batch: [528/657], Loss: 0.2708\n",
      "Epoch [1/10], Phase: train, Batch: [529/657], Loss: 0.4045\n",
      "Epoch [1/10], Phase: train, Batch: [530/657], Loss: 0.3257\n",
      "Epoch [1/10], Phase: train, Batch: [531/657], Loss: 0.2250\n",
      "Epoch [1/10], Phase: train, Batch: [532/657], Loss: 0.3352\n",
      "Epoch [1/10], Phase: train, Batch: [533/657], Loss: 0.2716\n",
      "Epoch [1/10], Phase: train, Batch: [534/657], Loss: 0.1947\n",
      "Epoch [1/10], Phase: train, Batch: [535/657], Loss: 0.1911\n",
      "Epoch [1/10], Phase: train, Batch: [536/657], Loss: 0.3164\n",
      "Epoch [1/10], Phase: train, Batch: [537/657], Loss: 0.4245\n",
      "Epoch [1/10], Phase: train, Batch: [538/657], Loss: 0.2196\n",
      "Epoch [1/10], Phase: train, Batch: [539/657], Loss: 0.2778\n",
      "Epoch [1/10], Phase: train, Batch: [540/657], Loss: 0.2816\n",
      "Epoch [1/10], Phase: train, Batch: [541/657], Loss: 0.4551\n",
      "Epoch [1/10], Phase: train, Batch: [542/657], Loss: 0.1864\n",
      "Epoch [1/10], Phase: train, Batch: [543/657], Loss: 0.2605\n",
      "Epoch [1/10], Phase: train, Batch: [544/657], Loss: 0.2890\n",
      "Epoch [1/10], Phase: train, Batch: [545/657], Loss: 0.2891\n",
      "Epoch [1/10], Phase: train, Batch: [546/657], Loss: 0.4442\n",
      "Epoch [1/10], Phase: train, Batch: [547/657], Loss: 0.4296\n",
      "Epoch [1/10], Phase: train, Batch: [548/657], Loss: 0.2548\n",
      "Epoch [1/10], Phase: train, Batch: [549/657], Loss: 0.2843\n",
      "Epoch [1/10], Phase: train, Batch: [550/657], Loss: 0.3765\n",
      "Epoch [1/10], Phase: train, Batch: [551/657], Loss: 0.2721\n",
      "Epoch [1/10], Phase: train, Batch: [552/657], Loss: 0.3734\n",
      "Epoch [1/10], Phase: train, Batch: [553/657], Loss: 0.2727\n",
      "Epoch [1/10], Phase: train, Batch: [554/657], Loss: 0.4903\n",
      "Epoch [1/10], Phase: train, Batch: [555/657], Loss: 0.2781\n",
      "Epoch [1/10], Phase: train, Batch: [556/657], Loss: 0.2394\n",
      "Epoch [1/10], Phase: train, Batch: [557/657], Loss: 0.2192\n",
      "Epoch [1/10], Phase: train, Batch: [558/657], Loss: 0.3365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: train, Batch: [559/657], Loss: 0.3676\n",
      "Epoch [1/10], Phase: train, Batch: [560/657], Loss: 0.2369\n",
      "Epoch [1/10], Phase: train, Batch: [561/657], Loss: 0.3390\n",
      "Epoch [1/10], Phase: train, Batch: [562/657], Loss: 0.1897\n",
      "Epoch [1/10], Phase: train, Batch: [563/657], Loss: 0.2054\n",
      "Epoch [1/10], Phase: train, Batch: [564/657], Loss: 0.2933\n",
      "Epoch [1/10], Phase: train, Batch: [565/657], Loss: 0.1927\n",
      "Epoch [1/10], Phase: train, Batch: [566/657], Loss: 0.2642\n",
      "Epoch [1/10], Phase: train, Batch: [567/657], Loss: 0.5512\n",
      "Epoch [1/10], Phase: train, Batch: [568/657], Loss: 0.3087\n",
      "Epoch [1/10], Phase: train, Batch: [569/657], Loss: 0.1165\n",
      "Epoch [1/10], Phase: train, Batch: [570/657], Loss: 0.2775\n",
      "Epoch [1/10], Phase: train, Batch: [571/657], Loss: 0.4763\n",
      "Epoch [1/10], Phase: train, Batch: [572/657], Loss: 0.2704\n",
      "Epoch [1/10], Phase: train, Batch: [573/657], Loss: 0.1539\n",
      "Epoch [1/10], Phase: train, Batch: [574/657], Loss: 0.2016\n",
      "Epoch [1/10], Phase: train, Batch: [575/657], Loss: 0.2514\n",
      "Epoch [1/10], Phase: train, Batch: [576/657], Loss: 0.3099\n",
      "Epoch [1/10], Phase: train, Batch: [577/657], Loss: 0.2554\n",
      "Epoch [1/10], Phase: train, Batch: [578/657], Loss: 0.2465\n",
      "Epoch [1/10], Phase: train, Batch: [579/657], Loss: 0.3161\n",
      "Epoch [1/10], Phase: train, Batch: [580/657], Loss: 0.1765\n",
      "Epoch [1/10], Phase: train, Batch: [581/657], Loss: 0.4051\n",
      "Epoch [1/10], Phase: train, Batch: [582/657], Loss: 0.2457\n",
      "Epoch [1/10], Phase: train, Batch: [583/657], Loss: 0.3044\n",
      "Epoch [1/10], Phase: train, Batch: [584/657], Loss: 0.2293\n",
      "Epoch [1/10], Phase: train, Batch: [585/657], Loss: 0.2183\n",
      "Epoch [1/10], Phase: train, Batch: [586/657], Loss: 0.3385\n",
      "Epoch [1/10], Phase: train, Batch: [587/657], Loss: 0.5028\n",
      "Epoch [1/10], Phase: train, Batch: [588/657], Loss: 0.2884\n",
      "Epoch [1/10], Phase: train, Batch: [589/657], Loss: 0.2998\n",
      "Epoch [1/10], Phase: train, Batch: [590/657], Loss: 0.3105\n",
      "Epoch [1/10], Phase: train, Batch: [591/657], Loss: 0.2456\n",
      "Epoch [1/10], Phase: train, Batch: [592/657], Loss: 0.2298\n",
      "Epoch [1/10], Phase: train, Batch: [593/657], Loss: 0.2726\n",
      "Epoch [1/10], Phase: train, Batch: [594/657], Loss: 0.2591\n",
      "Epoch [1/10], Phase: train, Batch: [595/657], Loss: 0.3741\n",
      "Epoch [1/10], Phase: train, Batch: [596/657], Loss: 0.4944\n",
      "Epoch [1/10], Phase: train, Batch: [597/657], Loss: 0.3513\n",
      "Epoch [1/10], Phase: train, Batch: [598/657], Loss: 0.3869\n",
      "Epoch [1/10], Phase: train, Batch: [599/657], Loss: 0.3520\n",
      "Epoch [1/10], Phase: train, Batch: [600/657], Loss: 0.3027\n",
      "Epoch [1/10], Phase: train, Batch: [601/657], Loss: 0.3122\n",
      "Epoch [1/10], Phase: train, Batch: [602/657], Loss: 0.3048\n",
      "Epoch [1/10], Phase: train, Batch: [603/657], Loss: 0.3073\n",
      "Epoch [1/10], Phase: train, Batch: [604/657], Loss: 0.4240\n",
      "Epoch [1/10], Phase: train, Batch: [605/657], Loss: 0.3914\n",
      "Epoch [1/10], Phase: train, Batch: [606/657], Loss: 0.3699\n",
      "Epoch [1/10], Phase: train, Batch: [607/657], Loss: 0.1853\n",
      "Epoch [1/10], Phase: train, Batch: [608/657], Loss: 0.3210\n",
      "Epoch [1/10], Phase: train, Batch: [609/657], Loss: 0.7113\n",
      "Epoch [1/10], Phase: train, Batch: [610/657], Loss: 0.2963\n",
      "Epoch [1/10], Phase: train, Batch: [611/657], Loss: 0.2463\n",
      "Epoch [1/10], Phase: train, Batch: [612/657], Loss: 0.4136\n",
      "Epoch [1/10], Phase: train, Batch: [613/657], Loss: 0.3393\n",
      "Epoch [1/10], Phase: train, Batch: [614/657], Loss: 0.4067\n",
      "Epoch [1/10], Phase: train, Batch: [615/657], Loss: 0.2751\n",
      "Epoch [1/10], Phase: train, Batch: [616/657], Loss: 0.4167\n",
      "Epoch [1/10], Phase: train, Batch: [617/657], Loss: 0.4745\n",
      "Epoch [1/10], Phase: train, Batch: [618/657], Loss: 0.3323\n",
      "Epoch [1/10], Phase: train, Batch: [619/657], Loss: 0.3980\n",
      "Epoch [1/10], Phase: train, Batch: [620/657], Loss: 0.2732\n",
      "Epoch [1/10], Phase: train, Batch: [621/657], Loss: 0.3236\n",
      "Epoch [1/10], Phase: train, Batch: [622/657], Loss: 0.4398\n",
      "Epoch [1/10], Phase: train, Batch: [623/657], Loss: 0.2695\n",
      "Epoch [1/10], Phase: train, Batch: [624/657], Loss: 0.3340\n",
      "Epoch [1/10], Phase: train, Batch: [625/657], Loss: 0.4462\n",
      "Epoch [1/10], Phase: train, Batch: [626/657], Loss: 0.2678\n",
      "Epoch [1/10], Phase: train, Batch: [627/657], Loss: 0.3376\n",
      "Epoch [1/10], Phase: train, Batch: [628/657], Loss: 0.3370\n",
      "Epoch [1/10], Phase: train, Batch: [629/657], Loss: 0.3555\n",
      "Epoch [1/10], Phase: train, Batch: [630/657], Loss: 0.3254\n",
      "Epoch [1/10], Phase: train, Batch: [631/657], Loss: 0.2564\n",
      "Epoch [1/10], Phase: train, Batch: [632/657], Loss: 0.2980\n",
      "Epoch [1/10], Phase: train, Batch: [633/657], Loss: 0.2868\n",
      "Epoch [1/10], Phase: train, Batch: [634/657], Loss: 0.2985\n",
      "Epoch [1/10], Phase: train, Batch: [635/657], Loss: 0.3777\n",
      "Epoch [1/10], Phase: train, Batch: [636/657], Loss: 0.3913\n",
      "Epoch [1/10], Phase: train, Batch: [637/657], Loss: 0.4152\n",
      "Epoch [1/10], Phase: train, Batch: [638/657], Loss: 0.4473\n",
      "Epoch [1/10], Phase: train, Batch: [639/657], Loss: 0.3365\n",
      "Epoch [1/10], Phase: train, Batch: [640/657], Loss: 0.2719\n",
      "Epoch [1/10], Phase: train, Batch: [641/657], Loss: 0.3337\n",
      "Epoch [1/10], Phase: train, Batch: [642/657], Loss: 0.3151\n",
      "Epoch [1/10], Phase: train, Batch: [643/657], Loss: 0.3597\n",
      "Epoch [1/10], Phase: train, Batch: [644/657], Loss: 0.2827\n",
      "Epoch [1/10], Phase: train, Batch: [645/657], Loss: 0.1580\n",
      "Epoch [1/10], Phase: train, Batch: [646/657], Loss: 0.2441\n",
      "Epoch [1/10], Phase: train, Batch: [647/657], Loss: 0.4305\n",
      "Epoch [1/10], Phase: train, Batch: [648/657], Loss: 0.2294\n",
      "Epoch [1/10], Phase: train, Batch: [649/657], Loss: 0.2685\n",
      "Epoch [1/10], Phase: train, Batch: [650/657], Loss: 0.1972\n",
      "Epoch [1/10], Phase: train, Batch: [651/657], Loss: 0.3747\n",
      "Epoch [1/10], Phase: train, Batch: [652/657], Loss: 0.5641\n",
      "Epoch [1/10], Phase: train, Batch: [653/657], Loss: 0.2129\n",
      "Epoch [1/10], Phase: train, Batch: [654/657], Loss: 0.2877\n",
      "Epoch [1/10], Phase: train, Batch: [655/657], Loss: 0.2225\n",
      "Epoch [1/10], Phase: train, Batch: [656/657], Loss: 0.3471\n",
      "Epoch [1/10], Phase: train, Batch: [657/657], Loss: 0.1669\n",
      "train Loss: 0.3388 Acc: 0.8721\n",
      "Epoch [1/10], Phase: val, Batch: [1/73], Loss: 0.3371\n",
      "Epoch [1/10], Phase: val, Batch: [2/73], Loss: 0.2941\n",
      "Epoch [1/10], Phase: val, Batch: [3/73], Loss: 0.1704\n",
      "Epoch [1/10], Phase: val, Batch: [4/73], Loss: 0.3699\n",
      "Epoch [1/10], Phase: val, Batch: [5/73], Loss: 0.2064\n",
      "Epoch [1/10], Phase: val, Batch: [6/73], Loss: 0.2864\n",
      "Epoch [1/10], Phase: val, Batch: [7/73], Loss: 0.1883\n",
      "Epoch [1/10], Phase: val, Batch: [8/73], Loss: 0.2425\n",
      "Epoch [1/10], Phase: val, Batch: [9/73], Loss: 0.0950\n",
      "Epoch [1/10], Phase: val, Batch: [10/73], Loss: 0.2116\n",
      "Epoch [1/10], Phase: val, Batch: [11/73], Loss: 0.1912\n",
      "Epoch [1/10], Phase: val, Batch: [12/73], Loss: 0.2530\n",
      "Epoch [1/10], Phase: val, Batch: [13/73], Loss: 0.1605\n",
      "Epoch [1/10], Phase: val, Batch: [14/73], Loss: 0.2896\n",
      "Epoch [1/10], Phase: val, Batch: [15/73], Loss: 0.2154\n",
      "Epoch [1/10], Phase: val, Batch: [16/73], Loss: 0.3408\n",
      "Epoch [1/10], Phase: val, Batch: [17/73], Loss: 0.1342\n",
      "Epoch [1/10], Phase: val, Batch: [18/73], Loss: 0.3063\n",
      "Epoch [1/10], Phase: val, Batch: [19/73], Loss: 0.3133\n",
      "Epoch [1/10], Phase: val, Batch: [20/73], Loss: 0.1817\n",
      "Epoch [1/10], Phase: val, Batch: [21/73], Loss: 0.3521\n",
      "Epoch [1/10], Phase: val, Batch: [22/73], Loss: 0.2223\n",
      "Epoch [1/10], Phase: val, Batch: [23/73], Loss: 0.2837\n",
      "Epoch [1/10], Phase: val, Batch: [24/73], Loss: 0.2868\n",
      "Epoch [1/10], Phase: val, Batch: [25/73], Loss: 0.1995\n",
      "Epoch [1/10], Phase: val, Batch: [26/73], Loss: 0.2102\n",
      "Epoch [1/10], Phase: val, Batch: [27/73], Loss: 0.2616\n",
      "Epoch [1/10], Phase: val, Batch: [28/73], Loss: 0.2411\n",
      "Epoch [1/10], Phase: val, Batch: [29/73], Loss: 0.3615\n",
      "Epoch [1/10], Phase: val, Batch: [30/73], Loss: 0.3487\n",
      "Epoch [1/10], Phase: val, Batch: [31/73], Loss: 0.1998\n",
      "Epoch [1/10], Phase: val, Batch: [32/73], Loss: 0.2816\n",
      "Epoch [1/10], Phase: val, Batch: [33/73], Loss: 0.4109\n",
      "Epoch [1/10], Phase: val, Batch: [34/73], Loss: 0.2292\n",
      "Epoch [1/10], Phase: val, Batch: [35/73], Loss: 0.1810\n",
      "Epoch [1/10], Phase: val, Batch: [36/73], Loss: 0.3737\n",
      "Epoch [1/10], Phase: val, Batch: [37/73], Loss: 0.2298\n",
      "Epoch [1/10], Phase: val, Batch: [38/73], Loss: 0.1609\n",
      "Epoch [1/10], Phase: val, Batch: [39/73], Loss: 0.2319\n",
      "Epoch [1/10], Phase: val, Batch: [40/73], Loss: 0.2108\n",
      "Epoch [1/10], Phase: val, Batch: [41/73], Loss: 0.2433\n",
      "Epoch [1/10], Phase: val, Batch: [42/73], Loss: 0.2674\n",
      "Epoch [1/10], Phase: val, Batch: [43/73], Loss: 0.2293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Phase: val, Batch: [44/73], Loss: 0.2424\n",
      "Epoch [1/10], Phase: val, Batch: [45/73], Loss: 0.2189\n",
      "Epoch [1/10], Phase: val, Batch: [46/73], Loss: 0.3165\n",
      "Epoch [1/10], Phase: val, Batch: [47/73], Loss: 0.2920\n",
      "Epoch [1/10], Phase: val, Batch: [48/73], Loss: 0.1598\n",
      "Epoch [1/10], Phase: val, Batch: [49/73], Loss: 0.2938\n",
      "Epoch [1/10], Phase: val, Batch: [50/73], Loss: 0.1753\n",
      "Epoch [1/10], Phase: val, Batch: [51/73], Loss: 0.3430\n",
      "Epoch [1/10], Phase: val, Batch: [52/73], Loss: 0.2121\n",
      "Epoch [1/10], Phase: val, Batch: [53/73], Loss: 0.2600\n",
      "Epoch [1/10], Phase: val, Batch: [54/73], Loss: 0.2196\n",
      "Epoch [1/10], Phase: val, Batch: [55/73], Loss: 0.2620\n",
      "Epoch [1/10], Phase: val, Batch: [56/73], Loss: 0.3254\n",
      "Epoch [1/10], Phase: val, Batch: [57/73], Loss: 0.1494\n",
      "Epoch [1/10], Phase: val, Batch: [58/73], Loss: 0.2426\n",
      "Epoch [1/10], Phase: val, Batch: [59/73], Loss: 0.2246\n",
      "Epoch [1/10], Phase: val, Batch: [60/73], Loss: 0.1901\n",
      "Epoch [1/10], Phase: val, Batch: [61/73], Loss: 0.3430\n",
      "Epoch [1/10], Phase: val, Batch: [62/73], Loss: 0.2510\n",
      "Epoch [1/10], Phase: val, Batch: [63/73], Loss: 0.2446\n",
      "Epoch [1/10], Phase: val, Batch: [64/73], Loss: 0.2779\n",
      "Epoch [1/10], Phase: val, Batch: [65/73], Loss: 0.2769\n",
      "Epoch [1/10], Phase: val, Batch: [66/73], Loss: 0.2021\n",
      "Epoch [1/10], Phase: val, Batch: [67/73], Loss: 0.2334\n",
      "Epoch [1/10], Phase: val, Batch: [68/73], Loss: 0.2341\n",
      "Epoch [1/10], Phase: val, Batch: [69/73], Loss: 0.2961\n",
      "Epoch [1/10], Phase: val, Batch: [70/73], Loss: 0.2626\n",
      "Epoch [1/10], Phase: val, Batch: [71/73], Loss: 0.2960\n",
      "Epoch [1/10], Phase: val, Batch: [72/73], Loss: 0.3991\n",
      "Epoch [1/10], Phase: val, Batch: [73/73], Loss: 0.1582\n",
      "val Loss: 0.2523 Acc: 0.8957\n",
      "Epoch [2/10], Phase: train, Batch: [1/657], Loss: 0.1631\n",
      "Epoch [2/10], Phase: train, Batch: [2/657], Loss: 0.2812\n",
      "Epoch [2/10], Phase: train, Batch: [3/657], Loss: 0.4192\n",
      "Epoch [2/10], Phase: train, Batch: [4/657], Loss: 0.2263\n",
      "Epoch [2/10], Phase: train, Batch: [5/657], Loss: 0.2594\n",
      "Epoch [2/10], Phase: train, Batch: [6/657], Loss: 0.3967\n",
      "Epoch [2/10], Phase: train, Batch: [7/657], Loss: 0.3127\n",
      "Epoch [2/10], Phase: train, Batch: [8/657], Loss: 0.3728\n",
      "Epoch [2/10], Phase: train, Batch: [9/657], Loss: 0.3314\n",
      "Epoch [2/10], Phase: train, Batch: [10/657], Loss: 0.2865\n",
      "Epoch [2/10], Phase: train, Batch: [11/657], Loss: 0.2276\n",
      "Epoch [2/10], Phase: train, Batch: [12/657], Loss: 0.1798\n",
      "Epoch [2/10], Phase: train, Batch: [13/657], Loss: 0.2952\n",
      "Epoch [2/10], Phase: train, Batch: [14/657], Loss: 0.3213\n",
      "Epoch [2/10], Phase: train, Batch: [15/657], Loss: 0.2470\n",
      "Epoch [2/10], Phase: train, Batch: [16/657], Loss: 0.2436\n",
      "Epoch [2/10], Phase: train, Batch: [17/657], Loss: 0.1781\n",
      "Epoch [2/10], Phase: train, Batch: [18/657], Loss: 0.2610\n",
      "Epoch [2/10], Phase: train, Batch: [19/657], Loss: 0.1991\n",
      "Epoch [2/10], Phase: train, Batch: [20/657], Loss: 0.1425\n",
      "Epoch [2/10], Phase: train, Batch: [21/657], Loss: 0.3387\n",
      "Epoch [2/10], Phase: train, Batch: [22/657], Loss: 0.3294\n",
      "Epoch [2/10], Phase: train, Batch: [23/657], Loss: 0.4940\n",
      "Epoch [2/10], Phase: train, Batch: [24/657], Loss: 0.4392\n",
      "Epoch [2/10], Phase: train, Batch: [25/657], Loss: 0.2433\n",
      "Epoch [2/10], Phase: train, Batch: [26/657], Loss: 0.5363\n",
      "Epoch [2/10], Phase: train, Batch: [27/657], Loss: 0.2424\n",
      "Epoch [2/10], Phase: train, Batch: [28/657], Loss: 0.2466\n",
      "Epoch [2/10], Phase: train, Batch: [29/657], Loss: 0.2432\n",
      "Epoch [2/10], Phase: train, Batch: [30/657], Loss: 0.2789\n",
      "Epoch [2/10], Phase: train, Batch: [31/657], Loss: 0.3457\n",
      "Epoch [2/10], Phase: train, Batch: [32/657], Loss: 0.1870\n",
      "Epoch [2/10], Phase: train, Batch: [33/657], Loss: 0.3245\n",
      "Epoch [2/10], Phase: train, Batch: [34/657], Loss: 0.2664\n",
      "Epoch [2/10], Phase: train, Batch: [35/657], Loss: 0.3658\n",
      "Epoch [2/10], Phase: train, Batch: [36/657], Loss: 0.3824\n",
      "Epoch [2/10], Phase: train, Batch: [37/657], Loss: 0.2218\n",
      "Epoch [2/10], Phase: train, Batch: [38/657], Loss: 0.5380\n",
      "Epoch [2/10], Phase: train, Batch: [39/657], Loss: 0.2207\n",
      "Epoch [2/10], Phase: train, Batch: [40/657], Loss: 0.2920\n",
      "Epoch [2/10], Phase: train, Batch: [41/657], Loss: 0.4109\n",
      "Epoch [2/10], Phase: train, Batch: [42/657], Loss: 0.3193\n",
      "Epoch [2/10], Phase: train, Batch: [43/657], Loss: 0.3034\n",
      "Epoch [2/10], Phase: train, Batch: [44/657], Loss: 0.3038\n",
      "Epoch [2/10], Phase: train, Batch: [45/657], Loss: 0.1817\n",
      "Epoch [2/10], Phase: train, Batch: [46/657], Loss: 0.2706\n",
      "Epoch [2/10], Phase: train, Batch: [47/657], Loss: 0.3074\n",
      "Epoch [2/10], Phase: train, Batch: [48/657], Loss: 0.2072\n",
      "Epoch [2/10], Phase: train, Batch: [49/657], Loss: 0.2978\n",
      "Epoch [2/10], Phase: train, Batch: [50/657], Loss: 0.2407\n",
      "Epoch [2/10], Phase: train, Batch: [51/657], Loss: 0.2099\n",
      "Epoch [2/10], Phase: train, Batch: [52/657], Loss: 0.2092\n",
      "Epoch [2/10], Phase: train, Batch: [53/657], Loss: 0.2272\n",
      "Epoch [2/10], Phase: train, Batch: [54/657], Loss: 0.5115\n",
      "Epoch [2/10], Phase: train, Batch: [55/657], Loss: 0.1658\n",
      "Epoch [2/10], Phase: train, Batch: [56/657], Loss: 0.3174\n",
      "Epoch [2/10], Phase: train, Batch: [57/657], Loss: 0.2180\n",
      "Epoch [2/10], Phase: train, Batch: [58/657], Loss: 0.3627\n",
      "Epoch [2/10], Phase: train, Batch: [59/657], Loss: 0.3658\n",
      "Epoch [2/10], Phase: train, Batch: [60/657], Loss: 0.2283\n",
      "Epoch [2/10], Phase: train, Batch: [61/657], Loss: 0.1728\n",
      "Epoch [2/10], Phase: train, Batch: [62/657], Loss: 0.5008\n",
      "Epoch [2/10], Phase: train, Batch: [63/657], Loss: 0.3776\n",
      "Epoch [2/10], Phase: train, Batch: [64/657], Loss: 0.4168\n",
      "Epoch [2/10], Phase: train, Batch: [65/657], Loss: 0.2070\n",
      "Epoch [2/10], Phase: train, Batch: [66/657], Loss: 0.2126\n",
      "Epoch [2/10], Phase: train, Batch: [67/657], Loss: 0.3729\n",
      "Epoch [2/10], Phase: train, Batch: [68/657], Loss: 0.2080\n",
      "Epoch [2/10], Phase: train, Batch: [69/657], Loss: 0.3194\n",
      "Epoch [2/10], Phase: train, Batch: [70/657], Loss: 0.1794\n",
      "Epoch [2/10], Phase: train, Batch: [71/657], Loss: 0.3344\n",
      "Epoch [2/10], Phase: train, Batch: [72/657], Loss: 0.3257\n",
      "Epoch [2/10], Phase: train, Batch: [73/657], Loss: 0.4279\n",
      "Epoch [2/10], Phase: train, Batch: [74/657], Loss: 0.4156\n",
      "Epoch [2/10], Phase: train, Batch: [75/657], Loss: 0.3102\n",
      "Epoch [2/10], Phase: train, Batch: [76/657], Loss: 0.2872\n",
      "Epoch [2/10], Phase: train, Batch: [77/657], Loss: 0.2717\n",
      "Epoch [2/10], Phase: train, Batch: [78/657], Loss: 0.3062\n",
      "Epoch [2/10], Phase: train, Batch: [79/657], Loss: 0.2416\n",
      "Epoch [2/10], Phase: train, Batch: [80/657], Loss: 0.3487\n",
      "Epoch [2/10], Phase: train, Batch: [81/657], Loss: 0.2188\n",
      "Epoch [2/10], Phase: train, Batch: [82/657], Loss: 0.2924\n",
      "Epoch [2/10], Phase: train, Batch: [83/657], Loss: 0.2157\n",
      "Epoch [2/10], Phase: train, Batch: [84/657], Loss: 0.2512\n",
      "Epoch [2/10], Phase: train, Batch: [85/657], Loss: 0.3142\n",
      "Epoch [2/10], Phase: train, Batch: [86/657], Loss: 0.2899\n",
      "Epoch [2/10], Phase: train, Batch: [87/657], Loss: 0.3512\n",
      "Epoch [2/10], Phase: train, Batch: [88/657], Loss: 0.5247\n",
      "Epoch [2/10], Phase: train, Batch: [89/657], Loss: 0.2019\n",
      "Epoch [2/10], Phase: train, Batch: [90/657], Loss: 0.2295\n",
      "Epoch [2/10], Phase: train, Batch: [91/657], Loss: 0.4152\n",
      "Epoch [2/10], Phase: train, Batch: [92/657], Loss: 0.4581\n",
      "Epoch [2/10], Phase: train, Batch: [93/657], Loss: 0.2389\n",
      "Epoch [2/10], Phase: train, Batch: [94/657], Loss: 0.3655\n",
      "Epoch [2/10], Phase: train, Batch: [95/657], Loss: 0.2624\n",
      "Epoch [2/10], Phase: train, Batch: [96/657], Loss: 0.2083\n",
      "Epoch [2/10], Phase: train, Batch: [97/657], Loss: 0.3595\n",
      "Epoch [2/10], Phase: train, Batch: [98/657], Loss: 0.2476\n",
      "Epoch [2/10], Phase: train, Batch: [99/657], Loss: 0.1901\n",
      "Epoch [2/10], Phase: train, Batch: [100/657], Loss: 0.3285\n",
      "Epoch [2/10], Phase: train, Batch: [101/657], Loss: 0.2512\n",
      "Epoch [2/10], Phase: train, Batch: [102/657], Loss: 0.2589\n",
      "Epoch [2/10], Phase: train, Batch: [103/657], Loss: 0.2276\n",
      "Epoch [2/10], Phase: train, Batch: [104/657], Loss: 0.3397\n",
      "Epoch [2/10], Phase: train, Batch: [105/657], Loss: 0.2605\n",
      "Epoch [2/10], Phase: train, Batch: [106/657], Loss: 0.3236\n",
      "Epoch [2/10], Phase: train, Batch: [107/657], Loss: 0.2160\n",
      "Epoch [2/10], Phase: train, Batch: [108/657], Loss: 0.2897\n",
      "Epoch [2/10], Phase: train, Batch: [109/657], Loss: 0.1937\n",
      "Epoch [2/10], Phase: train, Batch: [110/657], Loss: 0.2036\n",
      "Epoch [2/10], Phase: train, Batch: [111/657], Loss: 0.3986\n",
      "Epoch [2/10], Phase: train, Batch: [112/657], Loss: 0.2112\n",
      "Epoch [2/10], Phase: train, Batch: [113/657], Loss: 0.4613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [114/657], Loss: 0.2264\n",
      "Epoch [2/10], Phase: train, Batch: [115/657], Loss: 0.3010\n",
      "Epoch [2/10], Phase: train, Batch: [116/657], Loss: 0.3853\n",
      "Epoch [2/10], Phase: train, Batch: [117/657], Loss: 0.3146\n",
      "Epoch [2/10], Phase: train, Batch: [118/657], Loss: 0.4230\n",
      "Epoch [2/10], Phase: train, Batch: [119/657], Loss: 0.6534\n",
      "Epoch [2/10], Phase: train, Batch: [120/657], Loss: 0.5097\n",
      "Epoch [2/10], Phase: train, Batch: [121/657], Loss: 0.3798\n",
      "Epoch [2/10], Phase: train, Batch: [122/657], Loss: 0.2270\n",
      "Epoch [2/10], Phase: train, Batch: [123/657], Loss: 0.1865\n",
      "Epoch [2/10], Phase: train, Batch: [124/657], Loss: 0.2835\n",
      "Epoch [2/10], Phase: train, Batch: [125/657], Loss: 0.3287\n",
      "Epoch [2/10], Phase: train, Batch: [126/657], Loss: 0.2945\n",
      "Epoch [2/10], Phase: train, Batch: [127/657], Loss: 0.1914\n",
      "Epoch [2/10], Phase: train, Batch: [128/657], Loss: 0.4440\n",
      "Epoch [2/10], Phase: train, Batch: [129/657], Loss: 0.3009\n",
      "Epoch [2/10], Phase: train, Batch: [130/657], Loss: 0.3624\n",
      "Epoch [2/10], Phase: train, Batch: [131/657], Loss: 0.2371\n",
      "Epoch [2/10], Phase: train, Batch: [132/657], Loss: 0.2246\n",
      "Epoch [2/10], Phase: train, Batch: [133/657], Loss: 0.2289\n",
      "Epoch [2/10], Phase: train, Batch: [134/657], Loss: 0.2727\n",
      "Epoch [2/10], Phase: train, Batch: [135/657], Loss: 0.3464\n",
      "Epoch [2/10], Phase: train, Batch: [136/657], Loss: 0.4714\n",
      "Epoch [2/10], Phase: train, Batch: [137/657], Loss: 0.2101\n",
      "Epoch [2/10], Phase: train, Batch: [138/657], Loss: 0.3914\n",
      "Epoch [2/10], Phase: train, Batch: [139/657], Loss: 0.2475\n",
      "Epoch [2/10], Phase: train, Batch: [140/657], Loss: 0.3412\n",
      "Epoch [2/10], Phase: train, Batch: [141/657], Loss: 0.2771\n",
      "Epoch [2/10], Phase: train, Batch: [142/657], Loss: 0.2289\n",
      "Epoch [2/10], Phase: train, Batch: [143/657], Loss: 0.2105\n",
      "Epoch [2/10], Phase: train, Batch: [144/657], Loss: 0.2483\n",
      "Epoch [2/10], Phase: train, Batch: [145/657], Loss: 0.3128\n",
      "Epoch [2/10], Phase: train, Batch: [146/657], Loss: 0.3713\n",
      "Epoch [2/10], Phase: train, Batch: [147/657], Loss: 0.2571\n",
      "Epoch [2/10], Phase: train, Batch: [148/657], Loss: 0.3478\n",
      "Epoch [2/10], Phase: train, Batch: [149/657], Loss: 0.2059\n",
      "Epoch [2/10], Phase: train, Batch: [150/657], Loss: 0.2631\n",
      "Epoch [2/10], Phase: train, Batch: [151/657], Loss: 0.4403\n",
      "Epoch [2/10], Phase: train, Batch: [152/657], Loss: 0.1991\n",
      "Epoch [2/10], Phase: train, Batch: [153/657], Loss: 0.1976\n",
      "Epoch [2/10], Phase: train, Batch: [154/657], Loss: 0.1964\n",
      "Epoch [2/10], Phase: train, Batch: [155/657], Loss: 0.1652\n",
      "Epoch [2/10], Phase: train, Batch: [156/657], Loss: 0.4317\n",
      "Epoch [2/10], Phase: train, Batch: [157/657], Loss: 0.2440\n",
      "Epoch [2/10], Phase: train, Batch: [158/657], Loss: 0.3636\n",
      "Epoch [2/10], Phase: train, Batch: [159/657], Loss: 0.2281\n",
      "Epoch [2/10], Phase: train, Batch: [160/657], Loss: 0.2682\n",
      "Epoch [2/10], Phase: train, Batch: [161/657], Loss: 0.3100\n",
      "Epoch [2/10], Phase: train, Batch: [162/657], Loss: 0.3250\n",
      "Epoch [2/10], Phase: train, Batch: [163/657], Loss: 0.3094\n",
      "Epoch [2/10], Phase: train, Batch: [164/657], Loss: 0.2588\n",
      "Epoch [2/10], Phase: train, Batch: [165/657], Loss: 0.1468\n",
      "Epoch [2/10], Phase: train, Batch: [166/657], Loss: 0.3709\n",
      "Epoch [2/10], Phase: train, Batch: [167/657], Loss: 0.2614\n",
      "Epoch [2/10], Phase: train, Batch: [168/657], Loss: 0.4417\n",
      "Epoch [2/10], Phase: train, Batch: [169/657], Loss: 0.2886\n",
      "Epoch [2/10], Phase: train, Batch: [170/657], Loss: 0.2930\n",
      "Epoch [2/10], Phase: train, Batch: [171/657], Loss: 0.4013\n",
      "Epoch [2/10], Phase: train, Batch: [172/657], Loss: 0.2353\n",
      "Epoch [2/10], Phase: train, Batch: [173/657], Loss: 0.2768\n",
      "Epoch [2/10], Phase: train, Batch: [174/657], Loss: 0.2018\n",
      "Epoch [2/10], Phase: train, Batch: [175/657], Loss: 0.2652\n",
      "Epoch [2/10], Phase: train, Batch: [176/657], Loss: 0.3511\n",
      "Epoch [2/10], Phase: train, Batch: [177/657], Loss: 0.4232\n",
      "Epoch [2/10], Phase: train, Batch: [178/657], Loss: 0.2197\n",
      "Epoch [2/10], Phase: train, Batch: [179/657], Loss: 0.1852\n",
      "Epoch [2/10], Phase: train, Batch: [180/657], Loss: 0.1603\n",
      "Epoch [2/10], Phase: train, Batch: [181/657], Loss: 0.3340\n",
      "Epoch [2/10], Phase: train, Batch: [182/657], Loss: 0.2760\n",
      "Epoch [2/10], Phase: train, Batch: [183/657], Loss: 0.3826\n",
      "Epoch [2/10], Phase: train, Batch: [184/657], Loss: 0.3644\n",
      "Epoch [2/10], Phase: train, Batch: [185/657], Loss: 0.3067\n",
      "Epoch [2/10], Phase: train, Batch: [186/657], Loss: 0.2330\n",
      "Epoch [2/10], Phase: train, Batch: [187/657], Loss: 0.2454\n",
      "Epoch [2/10], Phase: train, Batch: [188/657], Loss: 0.2057\n",
      "Epoch [2/10], Phase: train, Batch: [189/657], Loss: 0.2578\n",
      "Epoch [2/10], Phase: train, Batch: [190/657], Loss: 0.3295\n",
      "Epoch [2/10], Phase: train, Batch: [191/657], Loss: 0.2380\n",
      "Epoch [2/10], Phase: train, Batch: [192/657], Loss: 0.1806\n",
      "Epoch [2/10], Phase: train, Batch: [193/657], Loss: 0.1273\n",
      "Epoch [2/10], Phase: train, Batch: [194/657], Loss: 0.3174\n",
      "Epoch [2/10], Phase: train, Batch: [195/657], Loss: 0.2879\n",
      "Epoch [2/10], Phase: train, Batch: [196/657], Loss: 0.2552\n",
      "Epoch [2/10], Phase: train, Batch: [197/657], Loss: 0.2679\n",
      "Epoch [2/10], Phase: train, Batch: [198/657], Loss: 0.2392\n",
      "Epoch [2/10], Phase: train, Batch: [199/657], Loss: 0.3713\n",
      "Epoch [2/10], Phase: train, Batch: [200/657], Loss: 0.2441\n",
      "Epoch [2/10], Phase: train, Batch: [201/657], Loss: 0.3631\n",
      "Epoch [2/10], Phase: train, Batch: [202/657], Loss: 0.1348\n",
      "Epoch [2/10], Phase: train, Batch: [203/657], Loss: 0.2683\n",
      "Epoch [2/10], Phase: train, Batch: [204/657], Loss: 0.4414\n",
      "Epoch [2/10], Phase: train, Batch: [205/657], Loss: 0.2712\n",
      "Epoch [2/10], Phase: train, Batch: [206/657], Loss: 0.2182\n",
      "Epoch [2/10], Phase: train, Batch: [207/657], Loss: 0.1915\n",
      "Epoch [2/10], Phase: train, Batch: [208/657], Loss: 0.3342\n",
      "Epoch [2/10], Phase: train, Batch: [209/657], Loss: 0.4302\n",
      "Epoch [2/10], Phase: train, Batch: [210/657], Loss: 0.3604\n",
      "Epoch [2/10], Phase: train, Batch: [211/657], Loss: 0.2794\n",
      "Epoch [2/10], Phase: train, Batch: [212/657], Loss: 0.2806\n",
      "Epoch [2/10], Phase: train, Batch: [213/657], Loss: 0.2265\n",
      "Epoch [2/10], Phase: train, Batch: [214/657], Loss: 0.2684\n",
      "Epoch [2/10], Phase: train, Batch: [215/657], Loss: 0.4033\n",
      "Epoch [2/10], Phase: train, Batch: [216/657], Loss: 0.3024\n",
      "Epoch [2/10], Phase: train, Batch: [217/657], Loss: 0.3060\n",
      "Epoch [2/10], Phase: train, Batch: [218/657], Loss: 0.3128\n",
      "Epoch [2/10], Phase: train, Batch: [219/657], Loss: 0.2162\n",
      "Epoch [2/10], Phase: train, Batch: [220/657], Loss: 0.3283\n",
      "Epoch [2/10], Phase: train, Batch: [221/657], Loss: 0.1846\n",
      "Epoch [2/10], Phase: train, Batch: [222/657], Loss: 0.2048\n",
      "Epoch [2/10], Phase: train, Batch: [223/657], Loss: 0.2501\n",
      "Epoch [2/10], Phase: train, Batch: [224/657], Loss: 0.3053\n",
      "Epoch [2/10], Phase: train, Batch: [225/657], Loss: 0.3346\n",
      "Epoch [2/10], Phase: train, Batch: [226/657], Loss: 0.2734\n",
      "Epoch [2/10], Phase: train, Batch: [227/657], Loss: 0.3075\n",
      "Epoch [2/10], Phase: train, Batch: [228/657], Loss: 0.2786\n",
      "Epoch [2/10], Phase: train, Batch: [229/657], Loss: 0.3049\n",
      "Epoch [2/10], Phase: train, Batch: [230/657], Loss: 0.2657\n",
      "Epoch [2/10], Phase: train, Batch: [231/657], Loss: 0.2458\n",
      "Epoch [2/10], Phase: train, Batch: [232/657], Loss: 0.4068\n",
      "Epoch [2/10], Phase: train, Batch: [233/657], Loss: 0.2467\n",
      "Epoch [2/10], Phase: train, Batch: [234/657], Loss: 0.3372\n",
      "Epoch [2/10], Phase: train, Batch: [235/657], Loss: 0.2389\n",
      "Epoch [2/10], Phase: train, Batch: [236/657], Loss: 0.2457\n",
      "Epoch [2/10], Phase: train, Batch: [237/657], Loss: 0.3683\n",
      "Epoch [2/10], Phase: train, Batch: [238/657], Loss: 0.3205\n",
      "Epoch [2/10], Phase: train, Batch: [239/657], Loss: 0.2627\n",
      "Epoch [2/10], Phase: train, Batch: [240/657], Loss: 0.2782\n",
      "Epoch [2/10], Phase: train, Batch: [241/657], Loss: 0.3400\n",
      "Epoch [2/10], Phase: train, Batch: [242/657], Loss: 0.4002\n",
      "Epoch [2/10], Phase: train, Batch: [243/657], Loss: 0.2527\n",
      "Epoch [2/10], Phase: train, Batch: [244/657], Loss: 0.4043\n",
      "Epoch [2/10], Phase: train, Batch: [245/657], Loss: 0.1254\n",
      "Epoch [2/10], Phase: train, Batch: [246/657], Loss: 0.2651\n",
      "Epoch [2/10], Phase: train, Batch: [247/657], Loss: 0.2443\n",
      "Epoch [2/10], Phase: train, Batch: [248/657], Loss: 0.2588\n",
      "Epoch [2/10], Phase: train, Batch: [249/657], Loss: 0.1836\n",
      "Epoch [2/10], Phase: train, Batch: [250/657], Loss: 0.3148\n",
      "Epoch [2/10], Phase: train, Batch: [251/657], Loss: 0.3031\n",
      "Epoch [2/10], Phase: train, Batch: [252/657], Loss: 0.2447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [253/657], Loss: 0.2366\n",
      "Epoch [2/10], Phase: train, Batch: [254/657], Loss: 0.1880\n",
      "Epoch [2/10], Phase: train, Batch: [255/657], Loss: 0.1798\n",
      "Epoch [2/10], Phase: train, Batch: [256/657], Loss: 0.2135\n",
      "Epoch [2/10], Phase: train, Batch: [257/657], Loss: 0.1694\n",
      "Epoch [2/10], Phase: train, Batch: [258/657], Loss: 0.2541\n",
      "Epoch [2/10], Phase: train, Batch: [259/657], Loss: 0.3197\n",
      "Epoch [2/10], Phase: train, Batch: [260/657], Loss: 0.2701\n",
      "Epoch [2/10], Phase: train, Batch: [261/657], Loss: 0.3243\n",
      "Epoch [2/10], Phase: train, Batch: [262/657], Loss: 0.5478\n",
      "Epoch [2/10], Phase: train, Batch: [263/657], Loss: 0.2235\n",
      "Epoch [2/10], Phase: train, Batch: [264/657], Loss: 0.5167\n",
      "Epoch [2/10], Phase: train, Batch: [265/657], Loss: 0.2035\n",
      "Epoch [2/10], Phase: train, Batch: [266/657], Loss: 0.3541\n",
      "Epoch [2/10], Phase: train, Batch: [267/657], Loss: 0.2871\n",
      "Epoch [2/10], Phase: train, Batch: [268/657], Loss: 0.2041\n",
      "Epoch [2/10], Phase: train, Batch: [269/657], Loss: 0.1889\n",
      "Epoch [2/10], Phase: train, Batch: [270/657], Loss: 0.3073\n",
      "Epoch [2/10], Phase: train, Batch: [271/657], Loss: 0.2516\n",
      "Epoch [2/10], Phase: train, Batch: [272/657], Loss: 0.2653\n",
      "Epoch [2/10], Phase: train, Batch: [273/657], Loss: 0.3901\n",
      "Epoch [2/10], Phase: train, Batch: [274/657], Loss: 0.2649\n",
      "Epoch [2/10], Phase: train, Batch: [275/657], Loss: 0.3661\n",
      "Epoch [2/10], Phase: train, Batch: [276/657], Loss: 0.2622\n",
      "Epoch [2/10], Phase: train, Batch: [277/657], Loss: 0.2720\n",
      "Epoch [2/10], Phase: train, Batch: [278/657], Loss: 0.3075\n",
      "Epoch [2/10], Phase: train, Batch: [279/657], Loss: 0.2146\n",
      "Epoch [2/10], Phase: train, Batch: [280/657], Loss: 0.3333\n",
      "Epoch [2/10], Phase: train, Batch: [281/657], Loss: 0.3821\n",
      "Epoch [2/10], Phase: train, Batch: [282/657], Loss: 0.1918\n",
      "Epoch [2/10], Phase: train, Batch: [283/657], Loss: 0.2109\n",
      "Epoch [2/10], Phase: train, Batch: [284/657], Loss: 0.2210\n",
      "Epoch [2/10], Phase: train, Batch: [285/657], Loss: 0.2619\n",
      "Epoch [2/10], Phase: train, Batch: [286/657], Loss: 0.3725\n",
      "Epoch [2/10], Phase: train, Batch: [287/657], Loss: 0.2459\n",
      "Epoch [2/10], Phase: train, Batch: [288/657], Loss: 0.2437\n",
      "Epoch [2/10], Phase: train, Batch: [289/657], Loss: 0.1451\n",
      "Epoch [2/10], Phase: train, Batch: [290/657], Loss: 0.1596\n",
      "Epoch [2/10], Phase: train, Batch: [291/657], Loss: 0.3507\n",
      "Epoch [2/10], Phase: train, Batch: [292/657], Loss: 0.3666\n",
      "Epoch [2/10], Phase: train, Batch: [293/657], Loss: 0.2693\n",
      "Epoch [2/10], Phase: train, Batch: [294/657], Loss: 0.2317\n",
      "Epoch [2/10], Phase: train, Batch: [295/657], Loss: 0.4372\n",
      "Epoch [2/10], Phase: train, Batch: [296/657], Loss: 0.3512\n",
      "Epoch [2/10], Phase: train, Batch: [297/657], Loss: 0.3070\n",
      "Epoch [2/10], Phase: train, Batch: [298/657], Loss: 0.3449\n",
      "Epoch [2/10], Phase: train, Batch: [299/657], Loss: 0.3206\n",
      "Epoch [2/10], Phase: train, Batch: [300/657], Loss: 0.2041\n",
      "Epoch [2/10], Phase: train, Batch: [301/657], Loss: 0.3009\n",
      "Epoch [2/10], Phase: train, Batch: [302/657], Loss: 0.3939\n",
      "Epoch [2/10], Phase: train, Batch: [303/657], Loss: 0.2506\n",
      "Epoch [2/10], Phase: train, Batch: [304/657], Loss: 0.2296\n",
      "Epoch [2/10], Phase: train, Batch: [305/657], Loss: 0.3645\n",
      "Epoch [2/10], Phase: train, Batch: [306/657], Loss: 0.3009\n",
      "Epoch [2/10], Phase: train, Batch: [307/657], Loss: 0.3126\n",
      "Epoch [2/10], Phase: train, Batch: [308/657], Loss: 0.3211\n",
      "Epoch [2/10], Phase: train, Batch: [309/657], Loss: 0.3156\n",
      "Epoch [2/10], Phase: train, Batch: [310/657], Loss: 0.3267\n",
      "Epoch [2/10], Phase: train, Batch: [311/657], Loss: 0.2946\n",
      "Epoch [2/10], Phase: train, Batch: [312/657], Loss: 0.2441\n",
      "Epoch [2/10], Phase: train, Batch: [313/657], Loss: 0.2956\n",
      "Epoch [2/10], Phase: train, Batch: [314/657], Loss: 0.3391\n",
      "Epoch [2/10], Phase: train, Batch: [315/657], Loss: 0.2770\n",
      "Epoch [2/10], Phase: train, Batch: [316/657], Loss: 0.2718\n",
      "Epoch [2/10], Phase: train, Batch: [317/657], Loss: 0.2678\n",
      "Epoch [2/10], Phase: train, Batch: [318/657], Loss: 0.2391\n",
      "Epoch [2/10], Phase: train, Batch: [319/657], Loss: 0.3319\n",
      "Epoch [2/10], Phase: train, Batch: [320/657], Loss: 0.2155\n",
      "Epoch [2/10], Phase: train, Batch: [321/657], Loss: 0.2831\n",
      "Epoch [2/10], Phase: train, Batch: [322/657], Loss: 0.2462\n",
      "Epoch [2/10], Phase: train, Batch: [323/657], Loss: 0.2899\n",
      "Epoch [2/10], Phase: train, Batch: [324/657], Loss: 0.2513\n",
      "Epoch [2/10], Phase: train, Batch: [325/657], Loss: 0.2883\n",
      "Epoch [2/10], Phase: train, Batch: [326/657], Loss: 0.4288\n",
      "Epoch [2/10], Phase: train, Batch: [327/657], Loss: 0.2357\n",
      "Epoch [2/10], Phase: train, Batch: [328/657], Loss: 0.2883\n",
      "Epoch [2/10], Phase: train, Batch: [329/657], Loss: 0.2079\n",
      "Epoch [2/10], Phase: train, Batch: [330/657], Loss: 0.2870\n",
      "Epoch [2/10], Phase: train, Batch: [331/657], Loss: 0.4094\n",
      "Epoch [2/10], Phase: train, Batch: [332/657], Loss: 0.3382\n",
      "Epoch [2/10], Phase: train, Batch: [333/657], Loss: 0.2902\n",
      "Epoch [2/10], Phase: train, Batch: [334/657], Loss: 0.2804\n",
      "Epoch [2/10], Phase: train, Batch: [335/657], Loss: 0.3597\n",
      "Epoch [2/10], Phase: train, Batch: [336/657], Loss: 0.1844\n",
      "Epoch [2/10], Phase: train, Batch: [337/657], Loss: 0.2978\n",
      "Epoch [2/10], Phase: train, Batch: [338/657], Loss: 0.2115\n",
      "Epoch [2/10], Phase: train, Batch: [339/657], Loss: 0.2235\n",
      "Epoch [2/10], Phase: train, Batch: [340/657], Loss: 0.3370\n",
      "Epoch [2/10], Phase: train, Batch: [341/657], Loss: 0.3785\n",
      "Epoch [2/10], Phase: train, Batch: [342/657], Loss: 0.3025\n",
      "Epoch [2/10], Phase: train, Batch: [343/657], Loss: 0.3423\n",
      "Epoch [2/10], Phase: train, Batch: [344/657], Loss: 0.1957\n",
      "Epoch [2/10], Phase: train, Batch: [345/657], Loss: 0.3139\n",
      "Epoch [2/10], Phase: train, Batch: [346/657], Loss: 0.2881\n",
      "Epoch [2/10], Phase: train, Batch: [347/657], Loss: 0.2246\n",
      "Epoch [2/10], Phase: train, Batch: [348/657], Loss: 0.3171\n",
      "Epoch [2/10], Phase: train, Batch: [349/657], Loss: 0.1964\n",
      "Epoch [2/10], Phase: train, Batch: [350/657], Loss: 0.2688\n",
      "Epoch [2/10], Phase: train, Batch: [351/657], Loss: 0.3423\n",
      "Epoch [2/10], Phase: train, Batch: [352/657], Loss: 0.3270\n",
      "Epoch [2/10], Phase: train, Batch: [353/657], Loss: 0.2449\n",
      "Epoch [2/10], Phase: train, Batch: [354/657], Loss: 0.2895\n",
      "Epoch [2/10], Phase: train, Batch: [355/657], Loss: 0.1791\n",
      "Epoch [2/10], Phase: train, Batch: [356/657], Loss: 0.3593\n",
      "Epoch [2/10], Phase: train, Batch: [357/657], Loss: 0.2436\n",
      "Epoch [2/10], Phase: train, Batch: [358/657], Loss: 0.4378\n",
      "Epoch [2/10], Phase: train, Batch: [359/657], Loss: 0.3490\n",
      "Epoch [2/10], Phase: train, Batch: [360/657], Loss: 0.2262\n",
      "Epoch [2/10], Phase: train, Batch: [361/657], Loss: 0.2457\n",
      "Epoch [2/10], Phase: train, Batch: [362/657], Loss: 0.3343\n",
      "Epoch [2/10], Phase: train, Batch: [363/657], Loss: 0.2785\n",
      "Epoch [2/10], Phase: train, Batch: [364/657], Loss: 0.3986\n",
      "Epoch [2/10], Phase: train, Batch: [365/657], Loss: 0.2374\n",
      "Epoch [2/10], Phase: train, Batch: [366/657], Loss: 0.2011\n",
      "Epoch [2/10], Phase: train, Batch: [367/657], Loss: 0.2474\n",
      "Epoch [2/10], Phase: train, Batch: [368/657], Loss: 0.3724\n",
      "Epoch [2/10], Phase: train, Batch: [369/657], Loss: 0.3553\n",
      "Epoch [2/10], Phase: train, Batch: [370/657], Loss: 0.5021\n",
      "Epoch [2/10], Phase: train, Batch: [371/657], Loss: 0.3510\n",
      "Epoch [2/10], Phase: train, Batch: [372/657], Loss: 0.2839\n",
      "Epoch [2/10], Phase: train, Batch: [373/657], Loss: 0.2843\n",
      "Epoch [2/10], Phase: train, Batch: [374/657], Loss: 0.2605\n",
      "Epoch [2/10], Phase: train, Batch: [375/657], Loss: 0.2253\n",
      "Epoch [2/10], Phase: train, Batch: [376/657], Loss: 0.3436\n",
      "Epoch [2/10], Phase: train, Batch: [377/657], Loss: 0.2826\n",
      "Epoch [2/10], Phase: train, Batch: [378/657], Loss: 0.3722\n",
      "Epoch [2/10], Phase: train, Batch: [379/657], Loss: 0.1748\n",
      "Epoch [2/10], Phase: train, Batch: [380/657], Loss: 0.2356\n",
      "Epoch [2/10], Phase: train, Batch: [381/657], Loss: 0.2148\n",
      "Epoch [2/10], Phase: train, Batch: [382/657], Loss: 0.2464\n",
      "Epoch [2/10], Phase: train, Batch: [383/657], Loss: 0.3029\n",
      "Epoch [2/10], Phase: train, Batch: [384/657], Loss: 0.3589\n",
      "Epoch [2/10], Phase: train, Batch: [385/657], Loss: 0.2528\n",
      "Epoch [2/10], Phase: train, Batch: [386/657], Loss: 0.1934\n",
      "Epoch [2/10], Phase: train, Batch: [387/657], Loss: 0.1904\n",
      "Epoch [2/10], Phase: train, Batch: [388/657], Loss: 0.2189\n",
      "Epoch [2/10], Phase: train, Batch: [389/657], Loss: 0.2596\n",
      "Epoch [2/10], Phase: train, Batch: [390/657], Loss: 0.2840\n",
      "Epoch [2/10], Phase: train, Batch: [391/657], Loss: 0.2692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [392/657], Loss: 0.3945\n",
      "Epoch [2/10], Phase: train, Batch: [393/657], Loss: 0.1836\n",
      "Epoch [2/10], Phase: train, Batch: [394/657], Loss: 0.2461\n",
      "Epoch [2/10], Phase: train, Batch: [395/657], Loss: 0.3620\n",
      "Epoch [2/10], Phase: train, Batch: [396/657], Loss: 0.2947\n",
      "Epoch [2/10], Phase: train, Batch: [397/657], Loss: 0.3561\n",
      "Epoch [2/10], Phase: train, Batch: [398/657], Loss: 0.2763\n",
      "Epoch [2/10], Phase: train, Batch: [399/657], Loss: 0.3488\n",
      "Epoch [2/10], Phase: train, Batch: [400/657], Loss: 0.2039\n",
      "Epoch [2/10], Phase: train, Batch: [401/657], Loss: 0.3179\n",
      "Epoch [2/10], Phase: train, Batch: [402/657], Loss: 0.1793\n",
      "Epoch [2/10], Phase: train, Batch: [403/657], Loss: 0.3315\n",
      "Epoch [2/10], Phase: train, Batch: [404/657], Loss: 0.1787\n",
      "Epoch [2/10], Phase: train, Batch: [405/657], Loss: 0.2618\n",
      "Epoch [2/10], Phase: train, Batch: [406/657], Loss: 0.2706\n",
      "Epoch [2/10], Phase: train, Batch: [407/657], Loss: 0.2930\n",
      "Epoch [2/10], Phase: train, Batch: [408/657], Loss: 0.3090\n",
      "Epoch [2/10], Phase: train, Batch: [409/657], Loss: 0.2650\n",
      "Epoch [2/10], Phase: train, Batch: [410/657], Loss: 0.1570\n",
      "Epoch [2/10], Phase: train, Batch: [411/657], Loss: 0.2257\n",
      "Epoch [2/10], Phase: train, Batch: [412/657], Loss: 0.1757\n",
      "Epoch [2/10], Phase: train, Batch: [413/657], Loss: 0.2333\n",
      "Epoch [2/10], Phase: train, Batch: [414/657], Loss: 0.3529\n",
      "Epoch [2/10], Phase: train, Batch: [415/657], Loss: 0.2738\n",
      "Epoch [2/10], Phase: train, Batch: [416/657], Loss: 0.2744\n",
      "Epoch [2/10], Phase: train, Batch: [417/657], Loss: 0.2965\n",
      "Epoch [2/10], Phase: train, Batch: [418/657], Loss: 0.2335\n",
      "Epoch [2/10], Phase: train, Batch: [419/657], Loss: 0.3598\n",
      "Epoch [2/10], Phase: train, Batch: [420/657], Loss: 0.1700\n",
      "Epoch [2/10], Phase: train, Batch: [421/657], Loss: 0.2855\n",
      "Epoch [2/10], Phase: train, Batch: [422/657], Loss: 0.1711\n",
      "Epoch [2/10], Phase: train, Batch: [423/657], Loss: 0.2639\n",
      "Epoch [2/10], Phase: train, Batch: [424/657], Loss: 0.3870\n",
      "Epoch [2/10], Phase: train, Batch: [425/657], Loss: 0.2326\n",
      "Epoch [2/10], Phase: train, Batch: [426/657], Loss: 0.2539\n",
      "Epoch [2/10], Phase: train, Batch: [427/657], Loss: 0.2985\n",
      "Epoch [2/10], Phase: train, Batch: [428/657], Loss: 0.2835\n",
      "Epoch [2/10], Phase: train, Batch: [429/657], Loss: 0.1603\n",
      "Epoch [2/10], Phase: train, Batch: [430/657], Loss: 0.3632\n",
      "Epoch [2/10], Phase: train, Batch: [431/657], Loss: 0.2598\n",
      "Epoch [2/10], Phase: train, Batch: [432/657], Loss: 0.3928\n",
      "Epoch [2/10], Phase: train, Batch: [433/657], Loss: 0.1564\n",
      "Epoch [2/10], Phase: train, Batch: [434/657], Loss: 0.2328\n",
      "Epoch [2/10], Phase: train, Batch: [435/657], Loss: 0.3355\n",
      "Epoch [2/10], Phase: train, Batch: [436/657], Loss: 0.2493\n",
      "Epoch [2/10], Phase: train, Batch: [437/657], Loss: 0.2507\n",
      "Epoch [2/10], Phase: train, Batch: [438/657], Loss: 0.2902\n",
      "Epoch [2/10], Phase: train, Batch: [439/657], Loss: 0.1642\n",
      "Epoch [2/10], Phase: train, Batch: [440/657], Loss: 0.2048\n",
      "Epoch [2/10], Phase: train, Batch: [441/657], Loss: 0.1987\n",
      "Epoch [2/10], Phase: train, Batch: [442/657], Loss: 0.2420\n",
      "Epoch [2/10], Phase: train, Batch: [443/657], Loss: 0.3332\n",
      "Epoch [2/10], Phase: train, Batch: [444/657], Loss: 0.2032\n",
      "Epoch [2/10], Phase: train, Batch: [445/657], Loss: 0.1822\n",
      "Epoch [2/10], Phase: train, Batch: [446/657], Loss: 0.2343\n",
      "Epoch [2/10], Phase: train, Batch: [447/657], Loss: 0.2744\n",
      "Epoch [2/10], Phase: train, Batch: [448/657], Loss: 0.2794\n",
      "Epoch [2/10], Phase: train, Batch: [449/657], Loss: 0.4046\n",
      "Epoch [2/10], Phase: train, Batch: [450/657], Loss: 0.3274\n",
      "Epoch [2/10], Phase: train, Batch: [451/657], Loss: 0.2878\n",
      "Epoch [2/10], Phase: train, Batch: [452/657], Loss: 0.3592\n",
      "Epoch [2/10], Phase: train, Batch: [453/657], Loss: 0.2644\n",
      "Epoch [2/10], Phase: train, Batch: [454/657], Loss: 0.4156\n",
      "Epoch [2/10], Phase: train, Batch: [455/657], Loss: 0.2481\n",
      "Epoch [2/10], Phase: train, Batch: [456/657], Loss: 0.4123\n",
      "Epoch [2/10], Phase: train, Batch: [457/657], Loss: 0.3147\n",
      "Epoch [2/10], Phase: train, Batch: [458/657], Loss: 0.3265\n",
      "Epoch [2/10], Phase: train, Batch: [459/657], Loss: 0.2860\n",
      "Epoch [2/10], Phase: train, Batch: [460/657], Loss: 0.4063\n",
      "Epoch [2/10], Phase: train, Batch: [461/657], Loss: 0.3075\n",
      "Epoch [2/10], Phase: train, Batch: [462/657], Loss: 0.1670\n",
      "Epoch [2/10], Phase: train, Batch: [463/657], Loss: 0.2242\n",
      "Epoch [2/10], Phase: train, Batch: [464/657], Loss: 0.2714\n",
      "Epoch [2/10], Phase: train, Batch: [465/657], Loss: 0.3963\n",
      "Epoch [2/10], Phase: train, Batch: [466/657], Loss: 0.2832\n",
      "Epoch [2/10], Phase: train, Batch: [467/657], Loss: 0.2144\n",
      "Epoch [2/10], Phase: train, Batch: [468/657], Loss: 0.2057\n",
      "Epoch [2/10], Phase: train, Batch: [469/657], Loss: 0.2021\n",
      "Epoch [2/10], Phase: train, Batch: [470/657], Loss: 0.2752\n",
      "Epoch [2/10], Phase: train, Batch: [471/657], Loss: 0.1953\n",
      "Epoch [2/10], Phase: train, Batch: [472/657], Loss: 0.3255\n",
      "Epoch [2/10], Phase: train, Batch: [473/657], Loss: 0.2822\n",
      "Epoch [2/10], Phase: train, Batch: [474/657], Loss: 0.2298\n",
      "Epoch [2/10], Phase: train, Batch: [475/657], Loss: 0.2065\n",
      "Epoch [2/10], Phase: train, Batch: [476/657], Loss: 0.3565\n",
      "Epoch [2/10], Phase: train, Batch: [477/657], Loss: 0.2369\n",
      "Epoch [2/10], Phase: train, Batch: [478/657], Loss: 0.1956\n",
      "Epoch [2/10], Phase: train, Batch: [479/657], Loss: 0.3540\n",
      "Epoch [2/10], Phase: train, Batch: [480/657], Loss: 0.2450\n",
      "Epoch [2/10], Phase: train, Batch: [481/657], Loss: 0.4806\n",
      "Epoch [2/10], Phase: train, Batch: [482/657], Loss: 0.2637\n",
      "Epoch [2/10], Phase: train, Batch: [483/657], Loss: 0.2688\n",
      "Epoch [2/10], Phase: train, Batch: [484/657], Loss: 0.2987\n",
      "Epoch [2/10], Phase: train, Batch: [485/657], Loss: 0.3054\n",
      "Epoch [2/10], Phase: train, Batch: [486/657], Loss: 0.2573\n",
      "Epoch [2/10], Phase: train, Batch: [487/657], Loss: 0.2393\n",
      "Epoch [2/10], Phase: train, Batch: [488/657], Loss: 0.3732\n",
      "Epoch [2/10], Phase: train, Batch: [489/657], Loss: 0.2361\n",
      "Epoch [2/10], Phase: train, Batch: [490/657], Loss: 0.3750\n",
      "Epoch [2/10], Phase: train, Batch: [491/657], Loss: 0.3858\n",
      "Epoch [2/10], Phase: train, Batch: [492/657], Loss: 0.5045\n",
      "Epoch [2/10], Phase: train, Batch: [493/657], Loss: 0.1555\n",
      "Epoch [2/10], Phase: train, Batch: [494/657], Loss: 0.3152\n",
      "Epoch [2/10], Phase: train, Batch: [495/657], Loss: 0.2003\n",
      "Epoch [2/10], Phase: train, Batch: [496/657], Loss: 0.2727\n",
      "Epoch [2/10], Phase: train, Batch: [497/657], Loss: 0.2087\n",
      "Epoch [2/10], Phase: train, Batch: [498/657], Loss: 0.2241\n",
      "Epoch [2/10], Phase: train, Batch: [499/657], Loss: 0.2859\n",
      "Epoch [2/10], Phase: train, Batch: [500/657], Loss: 0.2315\n",
      "Epoch [2/10], Phase: train, Batch: [501/657], Loss: 0.2852\n",
      "Epoch [2/10], Phase: train, Batch: [502/657], Loss: 0.3423\n",
      "Epoch [2/10], Phase: train, Batch: [503/657], Loss: 0.2540\n",
      "Epoch [2/10], Phase: train, Batch: [504/657], Loss: 0.3336\n",
      "Epoch [2/10], Phase: train, Batch: [505/657], Loss: 0.1948\n",
      "Epoch [2/10], Phase: train, Batch: [506/657], Loss: 0.3133\n",
      "Epoch [2/10], Phase: train, Batch: [507/657], Loss: 0.2396\n",
      "Epoch [2/10], Phase: train, Batch: [508/657], Loss: 0.2960\n",
      "Epoch [2/10], Phase: train, Batch: [509/657], Loss: 0.3223\n",
      "Epoch [2/10], Phase: train, Batch: [510/657], Loss: 0.3764\n",
      "Epoch [2/10], Phase: train, Batch: [511/657], Loss: 0.4383\n",
      "Epoch [2/10], Phase: train, Batch: [512/657], Loss: 0.1834\n",
      "Epoch [2/10], Phase: train, Batch: [513/657], Loss: 0.2295\n",
      "Epoch [2/10], Phase: train, Batch: [514/657], Loss: 0.1679\n",
      "Epoch [2/10], Phase: train, Batch: [515/657], Loss: 0.2734\n",
      "Epoch [2/10], Phase: train, Batch: [516/657], Loss: 0.2755\n",
      "Epoch [2/10], Phase: train, Batch: [517/657], Loss: 0.2510\n",
      "Epoch [2/10], Phase: train, Batch: [518/657], Loss: 0.3336\n",
      "Epoch [2/10], Phase: train, Batch: [519/657], Loss: 0.2159\n",
      "Epoch [2/10], Phase: train, Batch: [520/657], Loss: 0.2546\n",
      "Epoch [2/10], Phase: train, Batch: [521/657], Loss: 0.2997\n",
      "Epoch [2/10], Phase: train, Batch: [522/657], Loss: 0.3358\n",
      "Epoch [2/10], Phase: train, Batch: [523/657], Loss: 0.1929\n",
      "Epoch [2/10], Phase: train, Batch: [524/657], Loss: 0.2072\n",
      "Epoch [2/10], Phase: train, Batch: [525/657], Loss: 0.2720\n",
      "Epoch [2/10], Phase: train, Batch: [526/657], Loss: 0.2745\n",
      "Epoch [2/10], Phase: train, Batch: [527/657], Loss: 0.1947\n",
      "Epoch [2/10], Phase: train, Batch: [528/657], Loss: 0.3610\n",
      "Epoch [2/10], Phase: train, Batch: [529/657], Loss: 0.2570\n",
      "Epoch [2/10], Phase: train, Batch: [530/657], Loss: 0.1655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: train, Batch: [531/657], Loss: 0.2630\n",
      "Epoch [2/10], Phase: train, Batch: [532/657], Loss: 0.2963\n",
      "Epoch [2/10], Phase: train, Batch: [533/657], Loss: 0.1397\n",
      "Epoch [2/10], Phase: train, Batch: [534/657], Loss: 0.5718\n",
      "Epoch [2/10], Phase: train, Batch: [535/657], Loss: 0.2651\n",
      "Epoch [2/10], Phase: train, Batch: [536/657], Loss: 0.2944\n",
      "Epoch [2/10], Phase: train, Batch: [537/657], Loss: 0.3053\n",
      "Epoch [2/10], Phase: train, Batch: [538/657], Loss: 0.3630\n",
      "Epoch [2/10], Phase: train, Batch: [539/657], Loss: 0.3058\n",
      "Epoch [2/10], Phase: train, Batch: [540/657], Loss: 0.3018\n",
      "Epoch [2/10], Phase: train, Batch: [541/657], Loss: 0.2070\n",
      "Epoch [2/10], Phase: train, Batch: [542/657], Loss: 0.2353\n",
      "Epoch [2/10], Phase: train, Batch: [543/657], Loss: 0.2261\n",
      "Epoch [2/10], Phase: train, Batch: [544/657], Loss: 0.2493\n",
      "Epoch [2/10], Phase: train, Batch: [545/657], Loss: 0.2167\n",
      "Epoch [2/10], Phase: train, Batch: [546/657], Loss: 0.2959\n",
      "Epoch [2/10], Phase: train, Batch: [547/657], Loss: 0.2925\n",
      "Epoch [2/10], Phase: train, Batch: [548/657], Loss: 0.2676\n",
      "Epoch [2/10], Phase: train, Batch: [549/657], Loss: 0.1621\n",
      "Epoch [2/10], Phase: train, Batch: [550/657], Loss: 0.3415\n",
      "Epoch [2/10], Phase: train, Batch: [551/657], Loss: 0.3082\n",
      "Epoch [2/10], Phase: train, Batch: [552/657], Loss: 0.2341\n",
      "Epoch [2/10], Phase: train, Batch: [553/657], Loss: 0.3719\n",
      "Epoch [2/10], Phase: train, Batch: [554/657], Loss: 0.4231\n",
      "Epoch [2/10], Phase: train, Batch: [555/657], Loss: 0.2330\n",
      "Epoch [2/10], Phase: train, Batch: [556/657], Loss: 0.2880\n",
      "Epoch [2/10], Phase: train, Batch: [557/657], Loss: 0.2955\n",
      "Epoch [2/10], Phase: train, Batch: [558/657], Loss: 0.2448\n",
      "Epoch [2/10], Phase: train, Batch: [559/657], Loss: 0.2866\n",
      "Epoch [2/10], Phase: train, Batch: [560/657], Loss: 0.2609\n",
      "Epoch [2/10], Phase: train, Batch: [561/657], Loss: 0.2739\n",
      "Epoch [2/10], Phase: train, Batch: [562/657], Loss: 0.2109\n",
      "Epoch [2/10], Phase: train, Batch: [563/657], Loss: 0.3567\n",
      "Epoch [2/10], Phase: train, Batch: [564/657], Loss: 0.2299\n",
      "Epoch [2/10], Phase: train, Batch: [565/657], Loss: 0.2507\n",
      "Epoch [2/10], Phase: train, Batch: [566/657], Loss: 0.1680\n",
      "Epoch [2/10], Phase: train, Batch: [567/657], Loss: 0.3500\n",
      "Epoch [2/10], Phase: train, Batch: [568/657], Loss: 0.2413\n",
      "Epoch [2/10], Phase: train, Batch: [569/657], Loss: 0.3383\n",
      "Epoch [2/10], Phase: train, Batch: [570/657], Loss: 0.2066\n",
      "Epoch [2/10], Phase: train, Batch: [571/657], Loss: 0.2012\n",
      "Epoch [2/10], Phase: train, Batch: [572/657], Loss: 0.2409\n",
      "Epoch [2/10], Phase: train, Batch: [573/657], Loss: 0.2337\n",
      "Epoch [2/10], Phase: train, Batch: [574/657], Loss: 0.1944\n",
      "Epoch [2/10], Phase: train, Batch: [575/657], Loss: 0.2534\n",
      "Epoch [2/10], Phase: train, Batch: [576/657], Loss: 0.1562\n",
      "Epoch [2/10], Phase: train, Batch: [577/657], Loss: 0.1944\n",
      "Epoch [2/10], Phase: train, Batch: [578/657], Loss: 0.2525\n",
      "Epoch [2/10], Phase: train, Batch: [579/657], Loss: 0.2953\n",
      "Epoch [2/10], Phase: train, Batch: [580/657], Loss: 0.3314\n",
      "Epoch [2/10], Phase: train, Batch: [581/657], Loss: 0.2320\n",
      "Epoch [2/10], Phase: train, Batch: [582/657], Loss: 0.2789\n",
      "Epoch [2/10], Phase: train, Batch: [583/657], Loss: 0.3189\n",
      "Epoch [2/10], Phase: train, Batch: [584/657], Loss: 0.2246\n",
      "Epoch [2/10], Phase: train, Batch: [585/657], Loss: 0.2972\n",
      "Epoch [2/10], Phase: train, Batch: [586/657], Loss: 0.2884\n",
      "Epoch [2/10], Phase: train, Batch: [587/657], Loss: 0.1935\n",
      "Epoch [2/10], Phase: train, Batch: [588/657], Loss: 0.2012\n",
      "Epoch [2/10], Phase: train, Batch: [589/657], Loss: 0.1529\n",
      "Epoch [2/10], Phase: train, Batch: [590/657], Loss: 0.2761\n",
      "Epoch [2/10], Phase: train, Batch: [591/657], Loss: 0.1732\n",
      "Epoch [2/10], Phase: train, Batch: [592/657], Loss: 0.3353\n",
      "Epoch [2/10], Phase: train, Batch: [593/657], Loss: 0.3669\n",
      "Epoch [2/10], Phase: train, Batch: [594/657], Loss: 0.2917\n",
      "Epoch [2/10], Phase: train, Batch: [595/657], Loss: 0.3725\n",
      "Epoch [2/10], Phase: train, Batch: [596/657], Loss: 0.1898\n",
      "Epoch [2/10], Phase: train, Batch: [597/657], Loss: 0.4422\n",
      "Epoch [2/10], Phase: train, Batch: [598/657], Loss: 0.2892\n",
      "Epoch [2/10], Phase: train, Batch: [599/657], Loss: 0.2251\n",
      "Epoch [2/10], Phase: train, Batch: [600/657], Loss: 0.2611\n",
      "Epoch [2/10], Phase: train, Batch: [601/657], Loss: 0.2727\n",
      "Epoch [2/10], Phase: train, Batch: [602/657], Loss: 0.2286\n",
      "Epoch [2/10], Phase: train, Batch: [603/657], Loss: 0.3146\n",
      "Epoch [2/10], Phase: train, Batch: [604/657], Loss: 0.2949\n",
      "Epoch [2/10], Phase: train, Batch: [605/657], Loss: 0.2627\n",
      "Epoch [2/10], Phase: train, Batch: [606/657], Loss: 0.4038\n",
      "Epoch [2/10], Phase: train, Batch: [607/657], Loss: 0.2184\n",
      "Epoch [2/10], Phase: train, Batch: [608/657], Loss: 0.4409\n",
      "Epoch [2/10], Phase: train, Batch: [609/657], Loss: 0.4852\n",
      "Epoch [2/10], Phase: train, Batch: [610/657], Loss: 0.3175\n",
      "Epoch [2/10], Phase: train, Batch: [611/657], Loss: 0.2602\n",
      "Epoch [2/10], Phase: train, Batch: [612/657], Loss: 0.4050\n",
      "Epoch [2/10], Phase: train, Batch: [613/657], Loss: 0.3609\n",
      "Epoch [2/10], Phase: train, Batch: [614/657], Loss: 0.2107\n",
      "Epoch [2/10], Phase: train, Batch: [615/657], Loss: 0.1955\n",
      "Epoch [2/10], Phase: train, Batch: [616/657], Loss: 0.2790\n",
      "Epoch [2/10], Phase: train, Batch: [617/657], Loss: 0.2208\n",
      "Epoch [2/10], Phase: train, Batch: [618/657], Loss: 0.2264\n",
      "Epoch [2/10], Phase: train, Batch: [619/657], Loss: 0.3226\n",
      "Epoch [2/10], Phase: train, Batch: [620/657], Loss: 0.3059\n",
      "Epoch [2/10], Phase: train, Batch: [621/657], Loss: 0.2998\n",
      "Epoch [2/10], Phase: train, Batch: [622/657], Loss: 0.3573\n",
      "Epoch [2/10], Phase: train, Batch: [623/657], Loss: 0.1996\n",
      "Epoch [2/10], Phase: train, Batch: [624/657], Loss: 0.2484\n",
      "Epoch [2/10], Phase: train, Batch: [625/657], Loss: 0.3370\n",
      "Epoch [2/10], Phase: train, Batch: [626/657], Loss: 0.2128\n",
      "Epoch [2/10], Phase: train, Batch: [627/657], Loss: 0.3057\n",
      "Epoch [2/10], Phase: train, Batch: [628/657], Loss: 0.2610\n",
      "Epoch [2/10], Phase: train, Batch: [629/657], Loss: 0.3024\n",
      "Epoch [2/10], Phase: train, Batch: [630/657], Loss: 0.2408\n",
      "Epoch [2/10], Phase: train, Batch: [631/657], Loss: 0.3532\n",
      "Epoch [2/10], Phase: train, Batch: [632/657], Loss: 0.3084\n",
      "Epoch [2/10], Phase: train, Batch: [633/657], Loss: 0.1432\n",
      "Epoch [2/10], Phase: train, Batch: [634/657], Loss: 0.4180\n",
      "Epoch [2/10], Phase: train, Batch: [635/657], Loss: 0.2550\n",
      "Epoch [2/10], Phase: train, Batch: [636/657], Loss: 0.4275\n",
      "Epoch [2/10], Phase: train, Batch: [637/657], Loss: 0.1674\n",
      "Epoch [2/10], Phase: train, Batch: [638/657], Loss: 0.2653\n",
      "Epoch [2/10], Phase: train, Batch: [639/657], Loss: 0.2806\n",
      "Epoch [2/10], Phase: train, Batch: [640/657], Loss: 0.4259\n",
      "Epoch [2/10], Phase: train, Batch: [641/657], Loss: 0.3642\n",
      "Epoch [2/10], Phase: train, Batch: [642/657], Loss: 0.3146\n",
      "Epoch [2/10], Phase: train, Batch: [643/657], Loss: 0.3007\n",
      "Epoch [2/10], Phase: train, Batch: [644/657], Loss: 0.1694\n",
      "Epoch [2/10], Phase: train, Batch: [645/657], Loss: 0.2030\n",
      "Epoch [2/10], Phase: train, Batch: [646/657], Loss: 0.3492\n",
      "Epoch [2/10], Phase: train, Batch: [647/657], Loss: 0.3695\n",
      "Epoch [2/10], Phase: train, Batch: [648/657], Loss: 0.1738\n",
      "Epoch [2/10], Phase: train, Batch: [649/657], Loss: 0.3276\n",
      "Epoch [2/10], Phase: train, Batch: [650/657], Loss: 0.2528\n",
      "Epoch [2/10], Phase: train, Batch: [651/657], Loss: 0.2543\n",
      "Epoch [2/10], Phase: train, Batch: [652/657], Loss: 0.1731\n",
      "Epoch [2/10], Phase: train, Batch: [653/657], Loss: 0.3071\n",
      "Epoch [2/10], Phase: train, Batch: [654/657], Loss: 0.2245\n",
      "Epoch [2/10], Phase: train, Batch: [655/657], Loss: 0.2620\n",
      "Epoch [2/10], Phase: train, Batch: [656/657], Loss: 0.1995\n",
      "Epoch [2/10], Phase: train, Batch: [657/657], Loss: 0.2379\n",
      "train Loss: 0.2847 Acc: 0.8867\n",
      "Epoch [2/10], Phase: val, Batch: [1/73], Loss: 0.3336\n",
      "Epoch [2/10], Phase: val, Batch: [2/73], Loss: 0.2921\n",
      "Epoch [2/10], Phase: val, Batch: [3/73], Loss: 0.1544\n",
      "Epoch [2/10], Phase: val, Batch: [4/73], Loss: 0.3696\n",
      "Epoch [2/10], Phase: val, Batch: [5/73], Loss: 0.2162\n",
      "Epoch [2/10], Phase: val, Batch: [6/73], Loss: 0.2822\n",
      "Epoch [2/10], Phase: val, Batch: [7/73], Loss: 0.1931\n",
      "Epoch [2/10], Phase: val, Batch: [8/73], Loss: 0.2199\n",
      "Epoch [2/10], Phase: val, Batch: [9/73], Loss: 0.0819\n",
      "Epoch [2/10], Phase: val, Batch: [10/73], Loss: 0.1942\n",
      "Epoch [2/10], Phase: val, Batch: [11/73], Loss: 0.1806\n",
      "Epoch [2/10], Phase: val, Batch: [12/73], Loss: 0.2408\n",
      "Epoch [2/10], Phase: val, Batch: [13/73], Loss: 0.1336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Phase: val, Batch: [14/73], Loss: 0.2880\n",
      "Epoch [2/10], Phase: val, Batch: [15/73], Loss: 0.1995\n",
      "Epoch [2/10], Phase: val, Batch: [16/73], Loss: 0.3077\n",
      "Epoch [2/10], Phase: val, Batch: [17/73], Loss: 0.1096\n",
      "Epoch [2/10], Phase: val, Batch: [18/73], Loss: 0.2537\n",
      "Epoch [2/10], Phase: val, Batch: [19/73], Loss: 0.3300\n",
      "Epoch [2/10], Phase: val, Batch: [20/73], Loss: 0.1665\n",
      "Epoch [2/10], Phase: val, Batch: [21/73], Loss: 0.3383\n",
      "Epoch [2/10], Phase: val, Batch: [22/73], Loss: 0.2020\n",
      "Epoch [2/10], Phase: val, Batch: [23/73], Loss: 0.2654\n",
      "Epoch [2/10], Phase: val, Batch: [24/73], Loss: 0.2920\n",
      "Epoch [2/10], Phase: val, Batch: [25/73], Loss: 0.1854\n",
      "Epoch [2/10], Phase: val, Batch: [26/73], Loss: 0.1785\n",
      "Epoch [2/10], Phase: val, Batch: [27/73], Loss: 0.2636\n",
      "Epoch [2/10], Phase: val, Batch: [28/73], Loss: 0.2463\n",
      "Epoch [2/10], Phase: val, Batch: [29/73], Loss: 0.3387\n",
      "Epoch [2/10], Phase: val, Batch: [30/73], Loss: 0.3331\n",
      "Epoch [2/10], Phase: val, Batch: [31/73], Loss: 0.1781\n",
      "Epoch [2/10], Phase: val, Batch: [32/73], Loss: 0.2794\n",
      "Epoch [2/10], Phase: val, Batch: [33/73], Loss: 0.3842\n",
      "Epoch [2/10], Phase: val, Batch: [34/73], Loss: 0.2083\n",
      "Epoch [2/10], Phase: val, Batch: [35/73], Loss: 0.1741\n",
      "Epoch [2/10], Phase: val, Batch: [36/73], Loss: 0.3450\n",
      "Epoch [2/10], Phase: val, Batch: [37/73], Loss: 0.2145\n",
      "Epoch [2/10], Phase: val, Batch: [38/73], Loss: 0.1701\n",
      "Epoch [2/10], Phase: val, Batch: [39/73], Loss: 0.2150\n",
      "Epoch [2/10], Phase: val, Batch: [40/73], Loss: 0.1938\n",
      "Epoch [2/10], Phase: val, Batch: [41/73], Loss: 0.2256\n",
      "Epoch [2/10], Phase: val, Batch: [42/73], Loss: 0.2726\n",
      "Epoch [2/10], Phase: val, Batch: [43/73], Loss: 0.2177\n",
      "Epoch [2/10], Phase: val, Batch: [44/73], Loss: 0.2395\n",
      "Epoch [2/10], Phase: val, Batch: [45/73], Loss: 0.1962\n",
      "Epoch [2/10], Phase: val, Batch: [46/73], Loss: 0.3061\n",
      "Epoch [2/10], Phase: val, Batch: [47/73], Loss: 0.2939\n",
      "Epoch [2/10], Phase: val, Batch: [48/73], Loss: 0.1449\n",
      "Epoch [2/10], Phase: val, Batch: [49/73], Loss: 0.3057\n",
      "Epoch [2/10], Phase: val, Batch: [50/73], Loss: 0.1780\n",
      "Epoch [2/10], Phase: val, Batch: [51/73], Loss: 0.3061\n",
      "Epoch [2/10], Phase: val, Batch: [52/73], Loss: 0.1870\n",
      "Epoch [2/10], Phase: val, Batch: [53/73], Loss: 0.2193\n",
      "Epoch [2/10], Phase: val, Batch: [54/73], Loss: 0.2119\n",
      "Epoch [2/10], Phase: val, Batch: [55/73], Loss: 0.2391\n",
      "Epoch [2/10], Phase: val, Batch: [56/73], Loss: 0.3043\n",
      "Epoch [2/10], Phase: val, Batch: [57/73], Loss: 0.1375\n",
      "Epoch [2/10], Phase: val, Batch: [58/73], Loss: 0.2510\n",
      "Epoch [2/10], Phase: val, Batch: [59/73], Loss: 0.2430\n",
      "Epoch [2/10], Phase: val, Batch: [60/73], Loss: 0.1774\n",
      "Epoch [2/10], Phase: val, Batch: [61/73], Loss: 0.3305\n",
      "Epoch [2/10], Phase: val, Batch: [62/73], Loss: 0.2322\n",
      "Epoch [2/10], Phase: val, Batch: [63/73], Loss: 0.2287\n",
      "Epoch [2/10], Phase: val, Batch: [64/73], Loss: 0.2818\n",
      "Epoch [2/10], Phase: val, Batch: [65/73], Loss: 0.2436\n",
      "Epoch [2/10], Phase: val, Batch: [66/73], Loss: 0.1745\n",
      "Epoch [2/10], Phase: val, Batch: [67/73], Loss: 0.2199\n",
      "Epoch [2/10], Phase: val, Batch: [68/73], Loss: 0.2158\n",
      "Epoch [2/10], Phase: val, Batch: [69/73], Loss: 0.3021\n",
      "Epoch [2/10], Phase: val, Batch: [70/73], Loss: 0.2433\n",
      "Epoch [2/10], Phase: val, Batch: [71/73], Loss: 0.3060\n",
      "Epoch [2/10], Phase: val, Batch: [72/73], Loss: 0.4201\n",
      "Epoch [2/10], Phase: val, Batch: [73/73], Loss: 0.1191\n",
      "val Loss: 0.2402 Acc: 0.9012\n",
      "Epoch [3/10], Phase: train, Batch: [1/657], Loss: 0.3279\n",
      "Epoch [3/10], Phase: train, Batch: [2/657], Loss: 0.2012\n",
      "Epoch [3/10], Phase: train, Batch: [3/657], Loss: 0.3009\n",
      "Epoch [3/10], Phase: train, Batch: [4/657], Loss: 0.2905\n",
      "Epoch [3/10], Phase: train, Batch: [5/657], Loss: 0.2858\n",
      "Epoch [3/10], Phase: train, Batch: [6/657], Loss: 0.2636\n",
      "Epoch [3/10], Phase: train, Batch: [7/657], Loss: 0.1852\n",
      "Epoch [3/10], Phase: train, Batch: [8/657], Loss: 0.3634\n",
      "Epoch [3/10], Phase: train, Batch: [9/657], Loss: 0.2955\n",
      "Epoch [3/10], Phase: train, Batch: [10/657], Loss: 0.2222\n",
      "Epoch [3/10], Phase: train, Batch: [11/657], Loss: 0.1376\n",
      "Epoch [3/10], Phase: train, Batch: [12/657], Loss: 0.2230\n",
      "Epoch [3/10], Phase: train, Batch: [13/657], Loss: 0.2182\n",
      "Epoch [3/10], Phase: train, Batch: [14/657], Loss: 0.3585\n",
      "Epoch [3/10], Phase: train, Batch: [15/657], Loss: 0.2412\n",
      "Epoch [3/10], Phase: train, Batch: [16/657], Loss: 0.3799\n",
      "Epoch [3/10], Phase: train, Batch: [17/657], Loss: 0.3800\n",
      "Epoch [3/10], Phase: train, Batch: [18/657], Loss: 0.2663\n",
      "Epoch [3/10], Phase: train, Batch: [19/657], Loss: 0.2521\n",
      "Epoch [3/10], Phase: train, Batch: [20/657], Loss: 0.2594\n",
      "Epoch [3/10], Phase: train, Batch: [21/657], Loss: 0.1764\n",
      "Epoch [3/10], Phase: train, Batch: [22/657], Loss: 0.2725\n",
      "Epoch [3/10], Phase: train, Batch: [23/657], Loss: 0.1422\n",
      "Epoch [3/10], Phase: train, Batch: [24/657], Loss: 0.1552\n",
      "Epoch [3/10], Phase: train, Batch: [25/657], Loss: 0.2748\n",
      "Epoch [3/10], Phase: train, Batch: [26/657], Loss: 0.2241\n",
      "Epoch [3/10], Phase: train, Batch: [27/657], Loss: 0.3736\n",
      "Epoch [3/10], Phase: train, Batch: [28/657], Loss: 0.3221\n",
      "Epoch [3/10], Phase: train, Batch: [29/657], Loss: 0.2400\n",
      "Epoch [3/10], Phase: train, Batch: [30/657], Loss: 0.3566\n",
      "Epoch [3/10], Phase: train, Batch: [31/657], Loss: 0.2174\n",
      "Epoch [3/10], Phase: train, Batch: [32/657], Loss: 0.2550\n",
      "Epoch [3/10], Phase: train, Batch: [33/657], Loss: 0.1390\n",
      "Epoch [3/10], Phase: train, Batch: [34/657], Loss: 0.2106\n",
      "Epoch [3/10], Phase: train, Batch: [35/657], Loss: 0.1901\n",
      "Epoch [3/10], Phase: train, Batch: [36/657], Loss: 0.2382\n",
      "Epoch [3/10], Phase: train, Batch: [37/657], Loss: 0.2922\n",
      "Epoch [3/10], Phase: train, Batch: [38/657], Loss: 0.2863\n",
      "Epoch [3/10], Phase: train, Batch: [39/657], Loss: 0.1176\n",
      "Epoch [3/10], Phase: train, Batch: [40/657], Loss: 0.3514\n",
      "Epoch [3/10], Phase: train, Batch: [41/657], Loss: 0.3262\n",
      "Epoch [3/10], Phase: train, Batch: [42/657], Loss: 0.1964\n",
      "Epoch [3/10], Phase: train, Batch: [43/657], Loss: 0.2312\n",
      "Epoch [3/10], Phase: train, Batch: [44/657], Loss: 0.2239\n",
      "Epoch [3/10], Phase: train, Batch: [45/657], Loss: 0.3078\n",
      "Epoch [3/10], Phase: train, Batch: [46/657], Loss: 0.1934\n",
      "Epoch [3/10], Phase: train, Batch: [47/657], Loss: 0.2013\n",
      "Epoch [3/10], Phase: train, Batch: [48/657], Loss: 0.2321\n",
      "Epoch [3/10], Phase: train, Batch: [49/657], Loss: 0.2671\n",
      "Epoch [3/10], Phase: train, Batch: [50/657], Loss: 0.2114\n",
      "Epoch [3/10], Phase: train, Batch: [51/657], Loss: 0.2015\n",
      "Epoch [3/10], Phase: train, Batch: [52/657], Loss: 0.2724\n",
      "Epoch [3/10], Phase: train, Batch: [53/657], Loss: 0.2895\n",
      "Epoch [3/10], Phase: train, Batch: [54/657], Loss: 0.1851\n",
      "Epoch [3/10], Phase: train, Batch: [55/657], Loss: 0.1627\n",
      "Epoch [3/10], Phase: train, Batch: [56/657], Loss: 0.1555\n",
      "Epoch [3/10], Phase: train, Batch: [57/657], Loss: 0.2360\n",
      "Epoch [3/10], Phase: train, Batch: [58/657], Loss: 0.2284\n",
      "Epoch [3/10], Phase: train, Batch: [59/657], Loss: 0.2234\n",
      "Epoch [3/10], Phase: train, Batch: [60/657], Loss: 0.1397\n",
      "Epoch [3/10], Phase: train, Batch: [61/657], Loss: 0.2432\n",
      "Epoch [3/10], Phase: train, Batch: [62/657], Loss: 0.2825\n",
      "Epoch [3/10], Phase: train, Batch: [63/657], Loss: 0.2445\n",
      "Epoch [3/10], Phase: train, Batch: [64/657], Loss: 0.2530\n",
      "Epoch [3/10], Phase: train, Batch: [65/657], Loss: 0.2856\n",
      "Epoch [3/10], Phase: train, Batch: [66/657], Loss: 0.4256\n",
      "Epoch [3/10], Phase: train, Batch: [67/657], Loss: 0.2225\n",
      "Epoch [3/10], Phase: train, Batch: [68/657], Loss: 0.2430\n",
      "Epoch [3/10], Phase: train, Batch: [69/657], Loss: 0.1706\n",
      "Epoch [3/10], Phase: train, Batch: [70/657], Loss: 0.3380\n",
      "Epoch [3/10], Phase: train, Batch: [71/657], Loss: 0.2744\n",
      "Epoch [3/10], Phase: train, Batch: [72/657], Loss: 0.3310\n",
      "Epoch [3/10], Phase: train, Batch: [73/657], Loss: 0.2518\n",
      "Epoch [3/10], Phase: train, Batch: [74/657], Loss: 0.3257\n",
      "Epoch [3/10], Phase: train, Batch: [75/657], Loss: 0.3842\n",
      "Epoch [3/10], Phase: train, Batch: [76/657], Loss: 0.3867\n",
      "Epoch [3/10], Phase: train, Batch: [77/657], Loss: 0.3773\n",
      "Epoch [3/10], Phase: train, Batch: [78/657], Loss: 0.3469\n",
      "Epoch [3/10], Phase: train, Batch: [79/657], Loss: 0.4297\n",
      "Epoch [3/10], Phase: train, Batch: [80/657], Loss: 0.1606\n",
      "Epoch [3/10], Phase: train, Batch: [81/657], Loss: 0.2285\n",
      "Epoch [3/10], Phase: train, Batch: [82/657], Loss: 0.2910\n",
      "Epoch [3/10], Phase: train, Batch: [83/657], Loss: 0.2058\n",
      "Epoch [3/10], Phase: train, Batch: [84/657], Loss: 0.1954\n",
      "Epoch [3/10], Phase: train, Batch: [85/657], Loss: 0.2415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [86/657], Loss: 0.1373\n",
      "Epoch [3/10], Phase: train, Batch: [87/657], Loss: 0.2454\n",
      "Epoch [3/10], Phase: train, Batch: [88/657], Loss: 0.2725\n",
      "Epoch [3/10], Phase: train, Batch: [89/657], Loss: 0.2501\n",
      "Epoch [3/10], Phase: train, Batch: [90/657], Loss: 0.2153\n",
      "Epoch [3/10], Phase: train, Batch: [91/657], Loss: 0.3179\n",
      "Epoch [3/10], Phase: train, Batch: [92/657], Loss: 0.4835\n",
      "Epoch [3/10], Phase: train, Batch: [93/657], Loss: 0.4374\n",
      "Epoch [3/10], Phase: train, Batch: [94/657], Loss: 0.2461\n",
      "Epoch [3/10], Phase: train, Batch: [95/657], Loss: 0.2870\n",
      "Epoch [3/10], Phase: train, Batch: [96/657], Loss: 0.3171\n",
      "Epoch [3/10], Phase: train, Batch: [97/657], Loss: 0.4598\n",
      "Epoch [3/10], Phase: train, Batch: [98/657], Loss: 0.1920\n",
      "Epoch [3/10], Phase: train, Batch: [99/657], Loss: 0.2921\n",
      "Epoch [3/10], Phase: train, Batch: [100/657], Loss: 0.2503\n",
      "Epoch [3/10], Phase: train, Batch: [101/657], Loss: 0.3106\n",
      "Epoch [3/10], Phase: train, Batch: [102/657], Loss: 0.2038\n",
      "Epoch [3/10], Phase: train, Batch: [103/657], Loss: 0.1276\n",
      "Epoch [3/10], Phase: train, Batch: [104/657], Loss: 0.2090\n",
      "Epoch [3/10], Phase: train, Batch: [105/657], Loss: 0.2827\n",
      "Epoch [3/10], Phase: train, Batch: [106/657], Loss: 0.2221\n",
      "Epoch [3/10], Phase: train, Batch: [107/657], Loss: 0.2686\n",
      "Epoch [3/10], Phase: train, Batch: [108/657], Loss: 0.1662\n",
      "Epoch [3/10], Phase: train, Batch: [109/657], Loss: 0.2408\n",
      "Epoch [3/10], Phase: train, Batch: [110/657], Loss: 0.3325\n",
      "Epoch [3/10], Phase: train, Batch: [111/657], Loss: 0.2642\n",
      "Epoch [3/10], Phase: train, Batch: [112/657], Loss: 0.2023\n",
      "Epoch [3/10], Phase: train, Batch: [113/657], Loss: 0.2167\n",
      "Epoch [3/10], Phase: train, Batch: [114/657], Loss: 0.2264\n",
      "Epoch [3/10], Phase: train, Batch: [115/657], Loss: 0.3435\n",
      "Epoch [3/10], Phase: train, Batch: [116/657], Loss: 0.4130\n",
      "Epoch [3/10], Phase: train, Batch: [117/657], Loss: 0.2976\n",
      "Epoch [3/10], Phase: train, Batch: [118/657], Loss: 0.2335\n",
      "Epoch [3/10], Phase: train, Batch: [119/657], Loss: 0.2517\n",
      "Epoch [3/10], Phase: train, Batch: [120/657], Loss: 0.2395\n",
      "Epoch [3/10], Phase: train, Batch: [121/657], Loss: 0.3826\n",
      "Epoch [3/10], Phase: train, Batch: [122/657], Loss: 0.2735\n",
      "Epoch [3/10], Phase: train, Batch: [123/657], Loss: 0.5132\n",
      "Epoch [3/10], Phase: train, Batch: [124/657], Loss: 0.2567\n",
      "Epoch [3/10], Phase: train, Batch: [125/657], Loss: 0.2530\n",
      "Epoch [3/10], Phase: train, Batch: [126/657], Loss: 0.3586\n",
      "Epoch [3/10], Phase: train, Batch: [127/657], Loss: 0.2336\n",
      "Epoch [3/10], Phase: train, Batch: [128/657], Loss: 0.2409\n",
      "Epoch [3/10], Phase: train, Batch: [129/657], Loss: 0.2115\n",
      "Epoch [3/10], Phase: train, Batch: [130/657], Loss: 0.1991\n",
      "Epoch [3/10], Phase: train, Batch: [131/657], Loss: 0.2906\n",
      "Epoch [3/10], Phase: train, Batch: [132/657], Loss: 0.2956\n",
      "Epoch [3/10], Phase: train, Batch: [133/657], Loss: 0.2852\n",
      "Epoch [3/10], Phase: train, Batch: [134/657], Loss: 0.3763\n",
      "Epoch [3/10], Phase: train, Batch: [135/657], Loss: 0.2984\n",
      "Epoch [3/10], Phase: train, Batch: [136/657], Loss: 0.2500\n",
      "Epoch [3/10], Phase: train, Batch: [137/657], Loss: 0.2991\n",
      "Epoch [3/10], Phase: train, Batch: [138/657], Loss: 0.3149\n",
      "Epoch [3/10], Phase: train, Batch: [139/657], Loss: 0.4113\n",
      "Epoch [3/10], Phase: train, Batch: [140/657], Loss: 0.4540\n",
      "Epoch [3/10], Phase: train, Batch: [141/657], Loss: 0.2435\n",
      "Epoch [3/10], Phase: train, Batch: [142/657], Loss: 0.2113\n",
      "Epoch [3/10], Phase: train, Batch: [143/657], Loss: 0.3779\n",
      "Epoch [3/10], Phase: train, Batch: [144/657], Loss: 0.2387\n",
      "Epoch [3/10], Phase: train, Batch: [145/657], Loss: 0.1556\n",
      "Epoch [3/10], Phase: train, Batch: [146/657], Loss: 0.4182\n",
      "Epoch [3/10], Phase: train, Batch: [147/657], Loss: 0.2159\n",
      "Epoch [3/10], Phase: train, Batch: [148/657], Loss: 0.2464\n",
      "Epoch [3/10], Phase: train, Batch: [149/657], Loss: 0.3110\n",
      "Epoch [3/10], Phase: train, Batch: [150/657], Loss: 0.4140\n",
      "Epoch [3/10], Phase: train, Batch: [151/657], Loss: 0.4098\n",
      "Epoch [3/10], Phase: train, Batch: [152/657], Loss: 0.3246\n",
      "Epoch [3/10], Phase: train, Batch: [153/657], Loss: 0.2983\n",
      "Epoch [3/10], Phase: train, Batch: [154/657], Loss: 0.2600\n",
      "Epoch [3/10], Phase: train, Batch: [155/657], Loss: 0.1810\n",
      "Epoch [3/10], Phase: train, Batch: [156/657], Loss: 0.1886\n",
      "Epoch [3/10], Phase: train, Batch: [157/657], Loss: 0.3126\n",
      "Epoch [3/10], Phase: train, Batch: [158/657], Loss: 0.2021\n",
      "Epoch [3/10], Phase: train, Batch: [159/657], Loss: 0.2911\n",
      "Epoch [3/10], Phase: train, Batch: [160/657], Loss: 0.2887\n",
      "Epoch [3/10], Phase: train, Batch: [161/657], Loss: 0.2990\n",
      "Epoch [3/10], Phase: train, Batch: [162/657], Loss: 0.3631\n",
      "Epoch [3/10], Phase: train, Batch: [163/657], Loss: 0.3005\n",
      "Epoch [3/10], Phase: train, Batch: [164/657], Loss: 0.2675\n",
      "Epoch [3/10], Phase: train, Batch: [165/657], Loss: 0.3329\n",
      "Epoch [3/10], Phase: train, Batch: [166/657], Loss: 0.2906\n",
      "Epoch [3/10], Phase: train, Batch: [167/657], Loss: 0.2246\n",
      "Epoch [3/10], Phase: train, Batch: [168/657], Loss: 0.2101\n",
      "Epoch [3/10], Phase: train, Batch: [169/657], Loss: 0.3122\n",
      "Epoch [3/10], Phase: train, Batch: [170/657], Loss: 0.2653\n",
      "Epoch [3/10], Phase: train, Batch: [171/657], Loss: 0.3098\n",
      "Epoch [3/10], Phase: train, Batch: [172/657], Loss: 0.3124\n",
      "Epoch [3/10], Phase: train, Batch: [173/657], Loss: 0.2990\n",
      "Epoch [3/10], Phase: train, Batch: [174/657], Loss: 0.2076\n",
      "Epoch [3/10], Phase: train, Batch: [175/657], Loss: 0.3904\n",
      "Epoch [3/10], Phase: train, Batch: [176/657], Loss: 0.3321\n",
      "Epoch [3/10], Phase: train, Batch: [177/657], Loss: 0.2523\n",
      "Epoch [3/10], Phase: train, Batch: [178/657], Loss: 0.1900\n",
      "Epoch [3/10], Phase: train, Batch: [179/657], Loss: 0.3109\n",
      "Epoch [3/10], Phase: train, Batch: [180/657], Loss: 0.2599\n",
      "Epoch [3/10], Phase: train, Batch: [181/657], Loss: 0.2159\n",
      "Epoch [3/10], Phase: train, Batch: [182/657], Loss: 0.2810\n",
      "Epoch [3/10], Phase: train, Batch: [183/657], Loss: 0.2926\n",
      "Epoch [3/10], Phase: train, Batch: [184/657], Loss: 0.3004\n",
      "Epoch [3/10], Phase: train, Batch: [185/657], Loss: 0.3266\n",
      "Epoch [3/10], Phase: train, Batch: [186/657], Loss: 0.3467\n",
      "Epoch [3/10], Phase: train, Batch: [187/657], Loss: 0.2028\n",
      "Epoch [3/10], Phase: train, Batch: [188/657], Loss: 0.2655\n",
      "Epoch [3/10], Phase: train, Batch: [189/657], Loss: 0.4674\n",
      "Epoch [3/10], Phase: train, Batch: [190/657], Loss: 0.2704\n",
      "Epoch [3/10], Phase: train, Batch: [191/657], Loss: 0.2104\n",
      "Epoch [3/10], Phase: train, Batch: [192/657], Loss: 0.2902\n",
      "Epoch [3/10], Phase: train, Batch: [193/657], Loss: 0.3022\n",
      "Epoch [3/10], Phase: train, Batch: [194/657], Loss: 0.2244\n",
      "Epoch [3/10], Phase: train, Batch: [195/657], Loss: 0.3156\n",
      "Epoch [3/10], Phase: train, Batch: [196/657], Loss: 0.3306\n",
      "Epoch [3/10], Phase: train, Batch: [197/657], Loss: 0.2670\n",
      "Epoch [3/10], Phase: train, Batch: [198/657], Loss: 0.3517\n",
      "Epoch [3/10], Phase: train, Batch: [199/657], Loss: 0.2119\n",
      "Epoch [3/10], Phase: train, Batch: [200/657], Loss: 0.3139\n",
      "Epoch [3/10], Phase: train, Batch: [201/657], Loss: 0.1670\n",
      "Epoch [3/10], Phase: train, Batch: [202/657], Loss: 0.3586\n",
      "Epoch [3/10], Phase: train, Batch: [203/657], Loss: 0.3187\n",
      "Epoch [3/10], Phase: train, Batch: [204/657], Loss: 0.3517\n",
      "Epoch [3/10], Phase: train, Batch: [205/657], Loss: 0.3002\n",
      "Epoch [3/10], Phase: train, Batch: [206/657], Loss: 0.3292\n",
      "Epoch [3/10], Phase: train, Batch: [207/657], Loss: 0.2564\n",
      "Epoch [3/10], Phase: train, Batch: [208/657], Loss: 0.2867\n",
      "Epoch [3/10], Phase: train, Batch: [209/657], Loss: 0.2434\n",
      "Epoch [3/10], Phase: train, Batch: [210/657], Loss: 0.2855\n",
      "Epoch [3/10], Phase: train, Batch: [211/657], Loss: 0.2517\n",
      "Epoch [3/10], Phase: train, Batch: [212/657], Loss: 0.2640\n",
      "Epoch [3/10], Phase: train, Batch: [213/657], Loss: 0.2377\n",
      "Epoch [3/10], Phase: train, Batch: [214/657], Loss: 0.3149\n",
      "Epoch [3/10], Phase: train, Batch: [215/657], Loss: 0.1839\n",
      "Epoch [3/10], Phase: train, Batch: [216/657], Loss: 0.3788\n",
      "Epoch [3/10], Phase: train, Batch: [217/657], Loss: 0.3355\n",
      "Epoch [3/10], Phase: train, Batch: [218/657], Loss: 0.3133\n",
      "Epoch [3/10], Phase: train, Batch: [219/657], Loss: 0.3385\n",
      "Epoch [3/10], Phase: train, Batch: [220/657], Loss: 0.3077\n",
      "Epoch [3/10], Phase: train, Batch: [221/657], Loss: 0.2732\n",
      "Epoch [3/10], Phase: train, Batch: [222/657], Loss: 0.3489\n",
      "Epoch [3/10], Phase: train, Batch: [223/657], Loss: 0.1951\n",
      "Epoch [3/10], Phase: train, Batch: [224/657], Loss: 0.1960\n",
      "Epoch [3/10], Phase: train, Batch: [225/657], Loss: 0.2588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [226/657], Loss: 0.2716\n",
      "Epoch [3/10], Phase: train, Batch: [227/657], Loss: 0.1822\n",
      "Epoch [3/10], Phase: train, Batch: [228/657], Loss: 0.2761\n",
      "Epoch [3/10], Phase: train, Batch: [229/657], Loss: 0.2223\n",
      "Epoch [3/10], Phase: train, Batch: [230/657], Loss: 0.2704\n",
      "Epoch [3/10], Phase: train, Batch: [231/657], Loss: 0.2176\n",
      "Epoch [3/10], Phase: train, Batch: [232/657], Loss: 0.3527\n",
      "Epoch [3/10], Phase: train, Batch: [233/657], Loss: 0.3559\n",
      "Epoch [3/10], Phase: train, Batch: [234/657], Loss: 0.1448\n",
      "Epoch [3/10], Phase: train, Batch: [235/657], Loss: 0.2915\n",
      "Epoch [3/10], Phase: train, Batch: [236/657], Loss: 0.3049\n",
      "Epoch [3/10], Phase: train, Batch: [237/657], Loss: 0.4306\n",
      "Epoch [3/10], Phase: train, Batch: [238/657], Loss: 0.2911\n",
      "Epoch [3/10], Phase: train, Batch: [239/657], Loss: 0.3174\n",
      "Epoch [3/10], Phase: train, Batch: [240/657], Loss: 0.2699\n",
      "Epoch [3/10], Phase: train, Batch: [241/657], Loss: 0.3472\n",
      "Epoch [3/10], Phase: train, Batch: [242/657], Loss: 0.2482\n",
      "Epoch [3/10], Phase: train, Batch: [243/657], Loss: 0.2409\n",
      "Epoch [3/10], Phase: train, Batch: [244/657], Loss: 0.2160\n",
      "Epoch [3/10], Phase: train, Batch: [245/657], Loss: 0.1622\n",
      "Epoch [3/10], Phase: train, Batch: [246/657], Loss: 0.2040\n",
      "Epoch [3/10], Phase: train, Batch: [247/657], Loss: 0.3255\n",
      "Epoch [3/10], Phase: train, Batch: [248/657], Loss: 0.1718\n",
      "Epoch [3/10], Phase: train, Batch: [249/657], Loss: 0.3008\n",
      "Epoch [3/10], Phase: train, Batch: [250/657], Loss: 0.2532\n",
      "Epoch [3/10], Phase: train, Batch: [251/657], Loss: 0.2139\n",
      "Epoch [3/10], Phase: train, Batch: [252/657], Loss: 0.1554\n",
      "Epoch [3/10], Phase: train, Batch: [253/657], Loss: 0.3854\n",
      "Epoch [3/10], Phase: train, Batch: [254/657], Loss: 0.4441\n",
      "Epoch [3/10], Phase: train, Batch: [255/657], Loss: 0.2709\n",
      "Epoch [3/10], Phase: train, Batch: [256/657], Loss: 0.3005\n",
      "Epoch [3/10], Phase: train, Batch: [257/657], Loss: 0.3427\n",
      "Epoch [3/10], Phase: train, Batch: [258/657], Loss: 0.2298\n",
      "Epoch [3/10], Phase: train, Batch: [259/657], Loss: 0.3379\n",
      "Epoch [3/10], Phase: train, Batch: [260/657], Loss: 0.3314\n",
      "Epoch [3/10], Phase: train, Batch: [261/657], Loss: 0.3975\n",
      "Epoch [3/10], Phase: train, Batch: [262/657], Loss: 0.4682\n",
      "Epoch [3/10], Phase: train, Batch: [263/657], Loss: 0.2804\n",
      "Epoch [3/10], Phase: train, Batch: [264/657], Loss: 0.1642\n",
      "Epoch [3/10], Phase: train, Batch: [265/657], Loss: 0.1971\n",
      "Epoch [3/10], Phase: train, Batch: [266/657], Loss: 0.2410\n",
      "Epoch [3/10], Phase: train, Batch: [267/657], Loss: 0.1569\n",
      "Epoch [3/10], Phase: train, Batch: [268/657], Loss: 0.2941\n",
      "Epoch [3/10], Phase: train, Batch: [269/657], Loss: 0.3771\n",
      "Epoch [3/10], Phase: train, Batch: [270/657], Loss: 0.1786\n",
      "Epoch [3/10], Phase: train, Batch: [271/657], Loss: 0.2039\n",
      "Epoch [3/10], Phase: train, Batch: [272/657], Loss: 0.3558\n",
      "Epoch [3/10], Phase: train, Batch: [273/657], Loss: 0.2413\n",
      "Epoch [3/10], Phase: train, Batch: [274/657], Loss: 0.2841\n",
      "Epoch [3/10], Phase: train, Batch: [275/657], Loss: 0.2056\n",
      "Epoch [3/10], Phase: train, Batch: [276/657], Loss: 0.2950\n",
      "Epoch [3/10], Phase: train, Batch: [277/657], Loss: 0.2278\n",
      "Epoch [3/10], Phase: train, Batch: [278/657], Loss: 0.2920\n",
      "Epoch [3/10], Phase: train, Batch: [279/657], Loss: 0.3592\n",
      "Epoch [3/10], Phase: train, Batch: [280/657], Loss: 0.3314\n",
      "Epoch [3/10], Phase: train, Batch: [281/657], Loss: 0.1586\n",
      "Epoch [3/10], Phase: train, Batch: [282/657], Loss: 0.2095\n",
      "Epoch [3/10], Phase: train, Batch: [283/657], Loss: 0.2472\n",
      "Epoch [3/10], Phase: train, Batch: [284/657], Loss: 0.1674\n",
      "Epoch [3/10], Phase: train, Batch: [285/657], Loss: 0.3013\n",
      "Epoch [3/10], Phase: train, Batch: [286/657], Loss: 0.2387\n",
      "Epoch [3/10], Phase: train, Batch: [287/657], Loss: 0.2306\n",
      "Epoch [3/10], Phase: train, Batch: [288/657], Loss: 0.2532\n",
      "Epoch [3/10], Phase: train, Batch: [289/657], Loss: 0.3343\n",
      "Epoch [3/10], Phase: train, Batch: [290/657], Loss: 0.3683\n",
      "Epoch [3/10], Phase: train, Batch: [291/657], Loss: 0.2232\n",
      "Epoch [3/10], Phase: train, Batch: [292/657], Loss: 0.2583\n",
      "Epoch [3/10], Phase: train, Batch: [293/657], Loss: 0.2792\n",
      "Epoch [3/10], Phase: train, Batch: [294/657], Loss: 0.1933\n",
      "Epoch [3/10], Phase: train, Batch: [295/657], Loss: 0.2293\n",
      "Epoch [3/10], Phase: train, Batch: [296/657], Loss: 0.3090\n",
      "Epoch [3/10], Phase: train, Batch: [297/657], Loss: 0.2366\n",
      "Epoch [3/10], Phase: train, Batch: [298/657], Loss: 0.1958\n",
      "Epoch [3/10], Phase: train, Batch: [299/657], Loss: 0.2866\n",
      "Epoch [3/10], Phase: train, Batch: [300/657], Loss: 0.3046\n",
      "Epoch [3/10], Phase: train, Batch: [301/657], Loss: 0.3405\n",
      "Epoch [3/10], Phase: train, Batch: [302/657], Loss: 0.1734\n",
      "Epoch [3/10], Phase: train, Batch: [303/657], Loss: 0.1921\n",
      "Epoch [3/10], Phase: train, Batch: [304/657], Loss: 0.1608\n",
      "Epoch [3/10], Phase: train, Batch: [305/657], Loss: 0.2942\n",
      "Epoch [3/10], Phase: train, Batch: [306/657], Loss: 0.2254\n",
      "Epoch [3/10], Phase: train, Batch: [307/657], Loss: 0.2893\n",
      "Epoch [3/10], Phase: train, Batch: [308/657], Loss: 0.2824\n",
      "Epoch [3/10], Phase: train, Batch: [309/657], Loss: 0.2954\n",
      "Epoch [3/10], Phase: train, Batch: [310/657], Loss: 0.5061\n",
      "Epoch [3/10], Phase: train, Batch: [311/657], Loss: 0.3840\n",
      "Epoch [3/10], Phase: train, Batch: [312/657], Loss: 0.1837\n",
      "Epoch [3/10], Phase: train, Batch: [313/657], Loss: 0.3197\n",
      "Epoch [3/10], Phase: train, Batch: [314/657], Loss: 0.2339\n",
      "Epoch [3/10], Phase: train, Batch: [315/657], Loss: 0.2119\n",
      "Epoch [3/10], Phase: train, Batch: [316/657], Loss: 0.1810\n",
      "Epoch [3/10], Phase: train, Batch: [317/657], Loss: 0.2577\n",
      "Epoch [3/10], Phase: train, Batch: [318/657], Loss: 0.2458\n",
      "Epoch [3/10], Phase: train, Batch: [319/657], Loss: 0.3474\n",
      "Epoch [3/10], Phase: train, Batch: [320/657], Loss: 0.2617\n",
      "Epoch [3/10], Phase: train, Batch: [321/657], Loss: 0.2494\n",
      "Epoch [3/10], Phase: train, Batch: [322/657], Loss: 0.2867\n",
      "Epoch [3/10], Phase: train, Batch: [323/657], Loss: 0.2709\n",
      "Epoch [3/10], Phase: train, Batch: [324/657], Loss: 0.1853\n",
      "Epoch [3/10], Phase: train, Batch: [325/657], Loss: 0.2282\n",
      "Epoch [3/10], Phase: train, Batch: [326/657], Loss: 0.3204\n",
      "Epoch [3/10], Phase: train, Batch: [327/657], Loss: 0.3013\n",
      "Epoch [3/10], Phase: train, Batch: [328/657], Loss: 0.3146\n",
      "Epoch [3/10], Phase: train, Batch: [329/657], Loss: 0.1397\n",
      "Epoch [3/10], Phase: train, Batch: [330/657], Loss: 0.3454\n",
      "Epoch [3/10], Phase: train, Batch: [331/657], Loss: 0.1915\n",
      "Epoch [3/10], Phase: train, Batch: [332/657], Loss: 0.2767\n",
      "Epoch [3/10], Phase: train, Batch: [333/657], Loss: 0.3381\n",
      "Epoch [3/10], Phase: train, Batch: [334/657], Loss: 0.2475\n",
      "Epoch [3/10], Phase: train, Batch: [335/657], Loss: 0.1999\n",
      "Epoch [3/10], Phase: train, Batch: [336/657], Loss: 0.1756\n",
      "Epoch [3/10], Phase: train, Batch: [337/657], Loss: 0.1486\n",
      "Epoch [3/10], Phase: train, Batch: [338/657], Loss: 0.2632\n",
      "Epoch [3/10], Phase: train, Batch: [339/657], Loss: 0.3700\n",
      "Epoch [3/10], Phase: train, Batch: [340/657], Loss: 0.2087\n",
      "Epoch [3/10], Phase: train, Batch: [341/657], Loss: 0.2897\n",
      "Epoch [3/10], Phase: train, Batch: [342/657], Loss: 0.2542\n",
      "Epoch [3/10], Phase: train, Batch: [343/657], Loss: 0.2061\n",
      "Epoch [3/10], Phase: train, Batch: [344/657], Loss: 0.2296\n",
      "Epoch [3/10], Phase: train, Batch: [345/657], Loss: 0.3391\n",
      "Epoch [3/10], Phase: train, Batch: [346/657], Loss: 0.4265\n",
      "Epoch [3/10], Phase: train, Batch: [347/657], Loss: 0.3585\n",
      "Epoch [3/10], Phase: train, Batch: [348/657], Loss: 0.2885\n",
      "Epoch [3/10], Phase: train, Batch: [349/657], Loss: 0.2060\n",
      "Epoch [3/10], Phase: train, Batch: [350/657], Loss: 0.1916\n",
      "Epoch [3/10], Phase: train, Batch: [351/657], Loss: 0.3134\n",
      "Epoch [3/10], Phase: train, Batch: [352/657], Loss: 0.2132\n",
      "Epoch [3/10], Phase: train, Batch: [353/657], Loss: 0.3722\n",
      "Epoch [3/10], Phase: train, Batch: [354/657], Loss: 0.1635\n",
      "Epoch [3/10], Phase: train, Batch: [355/657], Loss: 0.3749\n",
      "Epoch [3/10], Phase: train, Batch: [356/657], Loss: 0.1939\n",
      "Epoch [3/10], Phase: train, Batch: [357/657], Loss: 0.3116\n",
      "Epoch [3/10], Phase: train, Batch: [358/657], Loss: 0.3311\n",
      "Epoch [3/10], Phase: train, Batch: [359/657], Loss: 0.1845\n",
      "Epoch [3/10], Phase: train, Batch: [360/657], Loss: 0.2176\n",
      "Epoch [3/10], Phase: train, Batch: [361/657], Loss: 0.2073\n",
      "Epoch [3/10], Phase: train, Batch: [362/657], Loss: 0.2114\n",
      "Epoch [3/10], Phase: train, Batch: [363/657], Loss: 0.4064\n",
      "Epoch [3/10], Phase: train, Batch: [364/657], Loss: 0.2647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [365/657], Loss: 0.2540\n",
      "Epoch [3/10], Phase: train, Batch: [366/657], Loss: 0.2843\n",
      "Epoch [3/10], Phase: train, Batch: [367/657], Loss: 0.2135\n",
      "Epoch [3/10], Phase: train, Batch: [368/657], Loss: 0.2530\n",
      "Epoch [3/10], Phase: train, Batch: [369/657], Loss: 0.1917\n",
      "Epoch [3/10], Phase: train, Batch: [370/657], Loss: 0.3736\n",
      "Epoch [3/10], Phase: train, Batch: [371/657], Loss: 0.4068\n",
      "Epoch [3/10], Phase: train, Batch: [372/657], Loss: 0.3402\n",
      "Epoch [3/10], Phase: train, Batch: [373/657], Loss: 0.1626\n",
      "Epoch [3/10], Phase: train, Batch: [374/657], Loss: 0.2461\n",
      "Epoch [3/10], Phase: train, Batch: [375/657], Loss: 0.3366\n",
      "Epoch [3/10], Phase: train, Batch: [376/657], Loss: 0.3589\n",
      "Epoch [3/10], Phase: train, Batch: [377/657], Loss: 0.4624\n",
      "Epoch [3/10], Phase: train, Batch: [378/657], Loss: 0.3060\n",
      "Epoch [3/10], Phase: train, Batch: [379/657], Loss: 0.2085\n",
      "Epoch [3/10], Phase: train, Batch: [380/657], Loss: 0.5245\n",
      "Epoch [3/10], Phase: train, Batch: [381/657], Loss: 0.2277\n",
      "Epoch [3/10], Phase: train, Batch: [382/657], Loss: 0.4268\n",
      "Epoch [3/10], Phase: train, Batch: [383/657], Loss: 0.2996\n",
      "Epoch [3/10], Phase: train, Batch: [384/657], Loss: 0.4069\n",
      "Epoch [3/10], Phase: train, Batch: [385/657], Loss: 0.2694\n",
      "Epoch [3/10], Phase: train, Batch: [386/657], Loss: 0.3189\n",
      "Epoch [3/10], Phase: train, Batch: [387/657], Loss: 0.2567\n",
      "Epoch [3/10], Phase: train, Batch: [388/657], Loss: 0.2986\n",
      "Epoch [3/10], Phase: train, Batch: [389/657], Loss: 0.3843\n",
      "Epoch [3/10], Phase: train, Batch: [390/657], Loss: 0.2034\n",
      "Epoch [3/10], Phase: train, Batch: [391/657], Loss: 0.2797\n",
      "Epoch [3/10], Phase: train, Batch: [392/657], Loss: 0.2713\n",
      "Epoch [3/10], Phase: train, Batch: [393/657], Loss: 0.4203\n",
      "Epoch [3/10], Phase: train, Batch: [394/657], Loss: 0.2104\n",
      "Epoch [3/10], Phase: train, Batch: [395/657], Loss: 0.3714\n",
      "Epoch [3/10], Phase: train, Batch: [396/657], Loss: 0.3560\n",
      "Epoch [3/10], Phase: train, Batch: [397/657], Loss: 0.2368\n",
      "Epoch [3/10], Phase: train, Batch: [398/657], Loss: 0.2593\n",
      "Epoch [3/10], Phase: train, Batch: [399/657], Loss: 0.3246\n",
      "Epoch [3/10], Phase: train, Batch: [400/657], Loss: 0.3197\n",
      "Epoch [3/10], Phase: train, Batch: [401/657], Loss: 0.3012\n",
      "Epoch [3/10], Phase: train, Batch: [402/657], Loss: 0.2165\n",
      "Epoch [3/10], Phase: train, Batch: [403/657], Loss: 0.2829\n",
      "Epoch [3/10], Phase: train, Batch: [404/657], Loss: 0.2905\n",
      "Epoch [3/10], Phase: train, Batch: [405/657], Loss: 0.3913\n",
      "Epoch [3/10], Phase: train, Batch: [406/657], Loss: 0.1945\n",
      "Epoch [3/10], Phase: train, Batch: [407/657], Loss: 0.1838\n",
      "Epoch [3/10], Phase: train, Batch: [408/657], Loss: 0.3033\n",
      "Epoch [3/10], Phase: train, Batch: [409/657], Loss: 0.2544\n",
      "Epoch [3/10], Phase: train, Batch: [410/657], Loss: 0.3928\n",
      "Epoch [3/10], Phase: train, Batch: [411/657], Loss: 0.3532\n",
      "Epoch [3/10], Phase: train, Batch: [412/657], Loss: 0.3818\n",
      "Epoch [3/10], Phase: train, Batch: [413/657], Loss: 0.4492\n",
      "Epoch [3/10], Phase: train, Batch: [414/657], Loss: 0.2986\n",
      "Epoch [3/10], Phase: train, Batch: [415/657], Loss: 0.6091\n",
      "Epoch [3/10], Phase: train, Batch: [416/657], Loss: 0.4404\n",
      "Epoch [3/10], Phase: train, Batch: [417/657], Loss: 0.3106\n",
      "Epoch [3/10], Phase: train, Batch: [418/657], Loss: 0.1444\n",
      "Epoch [3/10], Phase: train, Batch: [419/657], Loss: 0.2580\n",
      "Epoch [3/10], Phase: train, Batch: [420/657], Loss: 0.2249\n",
      "Epoch [3/10], Phase: train, Batch: [421/657], Loss: 0.2334\n",
      "Epoch [3/10], Phase: train, Batch: [422/657], Loss: 0.3858\n",
      "Epoch [3/10], Phase: train, Batch: [423/657], Loss: 0.3249\n",
      "Epoch [3/10], Phase: train, Batch: [424/657], Loss: 0.2931\n",
      "Epoch [3/10], Phase: train, Batch: [425/657], Loss: 0.3427\n",
      "Epoch [3/10], Phase: train, Batch: [426/657], Loss: 0.2989\n",
      "Epoch [3/10], Phase: train, Batch: [427/657], Loss: 0.2339\n",
      "Epoch [3/10], Phase: train, Batch: [428/657], Loss: 0.2317\n",
      "Epoch [3/10], Phase: train, Batch: [429/657], Loss: 0.3398\n",
      "Epoch [3/10], Phase: train, Batch: [430/657], Loss: 0.2840\n",
      "Epoch [3/10], Phase: train, Batch: [431/657], Loss: 0.2679\n",
      "Epoch [3/10], Phase: train, Batch: [432/657], Loss: 0.2242\n",
      "Epoch [3/10], Phase: train, Batch: [433/657], Loss: 0.2390\n",
      "Epoch [3/10], Phase: train, Batch: [434/657], Loss: 0.2629\n",
      "Epoch [3/10], Phase: train, Batch: [435/657], Loss: 0.2044\n",
      "Epoch [3/10], Phase: train, Batch: [436/657], Loss: 0.2843\n",
      "Epoch [3/10], Phase: train, Batch: [437/657], Loss: 0.2877\n",
      "Epoch [3/10], Phase: train, Batch: [438/657], Loss: 0.2341\n",
      "Epoch [3/10], Phase: train, Batch: [439/657], Loss: 0.3502\n",
      "Epoch [3/10], Phase: train, Batch: [440/657], Loss: 0.3446\n",
      "Epoch [3/10], Phase: train, Batch: [441/657], Loss: 0.2118\n",
      "Epoch [3/10], Phase: train, Batch: [442/657], Loss: 0.3389\n",
      "Epoch [3/10], Phase: train, Batch: [443/657], Loss: 0.2309\n",
      "Epoch [3/10], Phase: train, Batch: [444/657], Loss: 0.1946\n",
      "Epoch [3/10], Phase: train, Batch: [445/657], Loss: 0.2209\n",
      "Epoch [3/10], Phase: train, Batch: [446/657], Loss: 0.2951\n",
      "Epoch [3/10], Phase: train, Batch: [447/657], Loss: 0.3349\n",
      "Epoch [3/10], Phase: train, Batch: [448/657], Loss: 0.2057\n",
      "Epoch [3/10], Phase: train, Batch: [449/657], Loss: 0.2763\n",
      "Epoch [3/10], Phase: train, Batch: [450/657], Loss: 0.2075\n",
      "Epoch [3/10], Phase: train, Batch: [451/657], Loss: 0.2974\n",
      "Epoch [3/10], Phase: train, Batch: [452/657], Loss: 0.2561\n",
      "Epoch [3/10], Phase: train, Batch: [453/657], Loss: 0.2576\n",
      "Epoch [3/10], Phase: train, Batch: [454/657], Loss: 0.2308\n",
      "Epoch [3/10], Phase: train, Batch: [455/657], Loss: 0.3210\n",
      "Epoch [3/10], Phase: train, Batch: [456/657], Loss: 0.2452\n",
      "Epoch [3/10], Phase: train, Batch: [457/657], Loss: 0.2145\n",
      "Epoch [3/10], Phase: train, Batch: [458/657], Loss: 0.3418\n",
      "Epoch [3/10], Phase: train, Batch: [459/657], Loss: 0.1724\n",
      "Epoch [3/10], Phase: train, Batch: [460/657], Loss: 0.3611\n",
      "Epoch [3/10], Phase: train, Batch: [461/657], Loss: 0.2678\n",
      "Epoch [3/10], Phase: train, Batch: [462/657], Loss: 0.1937\n",
      "Epoch [3/10], Phase: train, Batch: [463/657], Loss: 0.2613\n",
      "Epoch [3/10], Phase: train, Batch: [464/657], Loss: 0.2723\n",
      "Epoch [3/10], Phase: train, Batch: [465/657], Loss: 0.3122\n",
      "Epoch [3/10], Phase: train, Batch: [466/657], Loss: 0.2726\n",
      "Epoch [3/10], Phase: train, Batch: [467/657], Loss: 0.2363\n",
      "Epoch [3/10], Phase: train, Batch: [468/657], Loss: 0.3083\n",
      "Epoch [3/10], Phase: train, Batch: [469/657], Loss: 0.2078\n",
      "Epoch [3/10], Phase: train, Batch: [470/657], Loss: 0.2413\n",
      "Epoch [3/10], Phase: train, Batch: [471/657], Loss: 0.4599\n",
      "Epoch [3/10], Phase: train, Batch: [472/657], Loss: 0.2238\n",
      "Epoch [3/10], Phase: train, Batch: [473/657], Loss: 0.3144\n",
      "Epoch [3/10], Phase: train, Batch: [474/657], Loss: 0.3501\n",
      "Epoch [3/10], Phase: train, Batch: [475/657], Loss: 0.3115\n",
      "Epoch [3/10], Phase: train, Batch: [476/657], Loss: 0.1980\n",
      "Epoch [3/10], Phase: train, Batch: [477/657], Loss: 0.3348\n",
      "Epoch [3/10], Phase: train, Batch: [478/657], Loss: 0.2346\n",
      "Epoch [3/10], Phase: train, Batch: [479/657], Loss: 0.2929\n",
      "Epoch [3/10], Phase: train, Batch: [480/657], Loss: 0.1841\n",
      "Epoch [3/10], Phase: train, Batch: [481/657], Loss: 0.2761\n",
      "Epoch [3/10], Phase: train, Batch: [482/657], Loss: 0.4087\n",
      "Epoch [3/10], Phase: train, Batch: [483/657], Loss: 0.2494\n",
      "Epoch [3/10], Phase: train, Batch: [484/657], Loss: 0.2366\n",
      "Epoch [3/10], Phase: train, Batch: [485/657], Loss: 0.1921\n",
      "Epoch [3/10], Phase: train, Batch: [486/657], Loss: 0.3248\n",
      "Epoch [3/10], Phase: train, Batch: [487/657], Loss: 0.4086\n",
      "Epoch [3/10], Phase: train, Batch: [488/657], Loss: 0.2442\n",
      "Epoch [3/10], Phase: train, Batch: [489/657], Loss: 0.1807\n",
      "Epoch [3/10], Phase: train, Batch: [490/657], Loss: 0.2032\n",
      "Epoch [3/10], Phase: train, Batch: [491/657], Loss: 0.2860\n",
      "Epoch [3/10], Phase: train, Batch: [492/657], Loss: 0.2138\n",
      "Epoch [3/10], Phase: train, Batch: [493/657], Loss: 0.2781\n",
      "Epoch [3/10], Phase: train, Batch: [494/657], Loss: 0.1780\n",
      "Epoch [3/10], Phase: train, Batch: [495/657], Loss: 0.3473\n",
      "Epoch [3/10], Phase: train, Batch: [496/657], Loss: 0.3328\n",
      "Epoch [3/10], Phase: train, Batch: [497/657], Loss: 0.2916\n",
      "Epoch [3/10], Phase: train, Batch: [498/657], Loss: 0.2118\n",
      "Epoch [3/10], Phase: train, Batch: [499/657], Loss: 0.2041\n",
      "Epoch [3/10], Phase: train, Batch: [500/657], Loss: 0.3337\n",
      "Epoch [3/10], Phase: train, Batch: [501/657], Loss: 0.2350\n",
      "Epoch [3/10], Phase: train, Batch: [502/657], Loss: 0.1948\n",
      "Epoch [3/10], Phase: train, Batch: [503/657], Loss: 0.3859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [504/657], Loss: 0.2419\n",
      "Epoch [3/10], Phase: train, Batch: [505/657], Loss: 0.2350\n",
      "Epoch [3/10], Phase: train, Batch: [506/657], Loss: 0.2760\n",
      "Epoch [3/10], Phase: train, Batch: [507/657], Loss: 0.2786\n",
      "Epoch [3/10], Phase: train, Batch: [508/657], Loss: 0.1923\n",
      "Epoch [3/10], Phase: train, Batch: [509/657], Loss: 0.2407\n",
      "Epoch [3/10], Phase: train, Batch: [510/657], Loss: 0.2937\n",
      "Epoch [3/10], Phase: train, Batch: [511/657], Loss: 0.2658\n",
      "Epoch [3/10], Phase: train, Batch: [512/657], Loss: 0.4085\n",
      "Epoch [3/10], Phase: train, Batch: [513/657], Loss: 0.1769\n",
      "Epoch [3/10], Phase: train, Batch: [514/657], Loss: 0.2558\n",
      "Epoch [3/10], Phase: train, Batch: [515/657], Loss: 0.5766\n",
      "Epoch [3/10], Phase: train, Batch: [516/657], Loss: 0.2054\n",
      "Epoch [3/10], Phase: train, Batch: [517/657], Loss: 0.3249\n",
      "Epoch [3/10], Phase: train, Batch: [518/657], Loss: 0.3905\n",
      "Epoch [3/10], Phase: train, Batch: [519/657], Loss: 0.3966\n",
      "Epoch [3/10], Phase: train, Batch: [520/657], Loss: 0.1574\n",
      "Epoch [3/10], Phase: train, Batch: [521/657], Loss: 0.2090\n",
      "Epoch [3/10], Phase: train, Batch: [522/657], Loss: 0.2345\n",
      "Epoch [3/10], Phase: train, Batch: [523/657], Loss: 0.2960\n",
      "Epoch [3/10], Phase: train, Batch: [524/657], Loss: 0.2797\n",
      "Epoch [3/10], Phase: train, Batch: [525/657], Loss: 0.3918\n",
      "Epoch [3/10], Phase: train, Batch: [526/657], Loss: 0.3369\n",
      "Epoch [3/10], Phase: train, Batch: [527/657], Loss: 0.1888\n",
      "Epoch [3/10], Phase: train, Batch: [528/657], Loss: 0.3182\n",
      "Epoch [3/10], Phase: train, Batch: [529/657], Loss: 0.3397\n",
      "Epoch [3/10], Phase: train, Batch: [530/657], Loss: 0.3493\n",
      "Epoch [3/10], Phase: train, Batch: [531/657], Loss: 0.3178\n",
      "Epoch [3/10], Phase: train, Batch: [532/657], Loss: 0.2345\n",
      "Epoch [3/10], Phase: train, Batch: [533/657], Loss: 0.3164\n",
      "Epoch [3/10], Phase: train, Batch: [534/657], Loss: 0.2618\n",
      "Epoch [3/10], Phase: train, Batch: [535/657], Loss: 0.1645\n",
      "Epoch [3/10], Phase: train, Batch: [536/657], Loss: 0.2902\n",
      "Epoch [3/10], Phase: train, Batch: [537/657], Loss: 0.3378\n",
      "Epoch [3/10], Phase: train, Batch: [538/657], Loss: 0.1589\n",
      "Epoch [3/10], Phase: train, Batch: [539/657], Loss: 0.3742\n",
      "Epoch [3/10], Phase: train, Batch: [540/657], Loss: 0.2002\n",
      "Epoch [3/10], Phase: train, Batch: [541/657], Loss: 0.2503\n",
      "Epoch [3/10], Phase: train, Batch: [542/657], Loss: 0.1470\n",
      "Epoch [3/10], Phase: train, Batch: [543/657], Loss: 0.1701\n",
      "Epoch [3/10], Phase: train, Batch: [544/657], Loss: 0.4114\n",
      "Epoch [3/10], Phase: train, Batch: [545/657], Loss: 0.2978\n",
      "Epoch [3/10], Phase: train, Batch: [546/657], Loss: 0.2100\n",
      "Epoch [3/10], Phase: train, Batch: [547/657], Loss: 0.2581\n",
      "Epoch [3/10], Phase: train, Batch: [548/657], Loss: 0.3491\n",
      "Epoch [3/10], Phase: train, Batch: [549/657], Loss: 0.2694\n",
      "Epoch [3/10], Phase: train, Batch: [550/657], Loss: 0.1867\n",
      "Epoch [3/10], Phase: train, Batch: [551/657], Loss: 0.2720\n",
      "Epoch [3/10], Phase: train, Batch: [552/657], Loss: 0.3651\n",
      "Epoch [3/10], Phase: train, Batch: [553/657], Loss: 0.3894\n",
      "Epoch [3/10], Phase: train, Batch: [554/657], Loss: 0.4046\n",
      "Epoch [3/10], Phase: train, Batch: [555/657], Loss: 0.3942\n",
      "Epoch [3/10], Phase: train, Batch: [556/657], Loss: 0.3581\n",
      "Epoch [3/10], Phase: train, Batch: [557/657], Loss: 0.3768\n",
      "Epoch [3/10], Phase: train, Batch: [558/657], Loss: 0.3064\n",
      "Epoch [3/10], Phase: train, Batch: [559/657], Loss: 0.4033\n",
      "Epoch [3/10], Phase: train, Batch: [560/657], Loss: 0.2260\n",
      "Epoch [3/10], Phase: train, Batch: [561/657], Loss: 0.2261\n",
      "Epoch [3/10], Phase: train, Batch: [562/657], Loss: 0.1815\n",
      "Epoch [3/10], Phase: train, Batch: [563/657], Loss: 0.2098\n",
      "Epoch [3/10], Phase: train, Batch: [564/657], Loss: 0.1869\n",
      "Epoch [3/10], Phase: train, Batch: [565/657], Loss: 0.2007\n",
      "Epoch [3/10], Phase: train, Batch: [566/657], Loss: 0.2635\n",
      "Epoch [3/10], Phase: train, Batch: [567/657], Loss: 0.1562\n",
      "Epoch [3/10], Phase: train, Batch: [568/657], Loss: 0.3002\n",
      "Epoch [3/10], Phase: train, Batch: [569/657], Loss: 0.3359\n",
      "Epoch [3/10], Phase: train, Batch: [570/657], Loss: 0.2916\n",
      "Epoch [3/10], Phase: train, Batch: [571/657], Loss: 0.1701\n",
      "Epoch [3/10], Phase: train, Batch: [572/657], Loss: 0.3093\n",
      "Epoch [3/10], Phase: train, Batch: [573/657], Loss: 0.3305\n",
      "Epoch [3/10], Phase: train, Batch: [574/657], Loss: 0.2459\n",
      "Epoch [3/10], Phase: train, Batch: [575/657], Loss: 0.2434\n",
      "Epoch [3/10], Phase: train, Batch: [576/657], Loss: 0.2788\n",
      "Epoch [3/10], Phase: train, Batch: [577/657], Loss: 0.2420\n",
      "Epoch [3/10], Phase: train, Batch: [578/657], Loss: 0.3279\n",
      "Epoch [3/10], Phase: train, Batch: [579/657], Loss: 0.3008\n",
      "Epoch [3/10], Phase: train, Batch: [580/657], Loss: 0.3836\n",
      "Epoch [3/10], Phase: train, Batch: [581/657], Loss: 0.2863\n",
      "Epoch [3/10], Phase: train, Batch: [582/657], Loss: 0.1729\n",
      "Epoch [3/10], Phase: train, Batch: [583/657], Loss: 0.2337\n",
      "Epoch [3/10], Phase: train, Batch: [584/657], Loss: 0.2951\n",
      "Epoch [3/10], Phase: train, Batch: [585/657], Loss: 0.2828\n",
      "Epoch [3/10], Phase: train, Batch: [586/657], Loss: 0.2175\n",
      "Epoch [3/10], Phase: train, Batch: [587/657], Loss: 0.1266\n",
      "Epoch [3/10], Phase: train, Batch: [588/657], Loss: 0.2418\n",
      "Epoch [3/10], Phase: train, Batch: [589/657], Loss: 0.2301\n",
      "Epoch [3/10], Phase: train, Batch: [590/657], Loss: 0.3279\n",
      "Epoch [3/10], Phase: train, Batch: [591/657], Loss: 0.1391\n",
      "Epoch [3/10], Phase: train, Batch: [592/657], Loss: 0.2696\n",
      "Epoch [3/10], Phase: train, Batch: [593/657], Loss: 0.3272\n",
      "Epoch [3/10], Phase: train, Batch: [594/657], Loss: 0.3664\n",
      "Epoch [3/10], Phase: train, Batch: [595/657], Loss: 0.2409\n",
      "Epoch [3/10], Phase: train, Batch: [596/657], Loss: 0.4977\n",
      "Epoch [3/10], Phase: train, Batch: [597/657], Loss: 0.2065\n",
      "Epoch [3/10], Phase: train, Batch: [598/657], Loss: 0.2931\n",
      "Epoch [3/10], Phase: train, Batch: [599/657], Loss: 0.3329\n",
      "Epoch [3/10], Phase: train, Batch: [600/657], Loss: 0.3636\n",
      "Epoch [3/10], Phase: train, Batch: [601/657], Loss: 0.3061\n",
      "Epoch [3/10], Phase: train, Batch: [602/657], Loss: 0.3274\n",
      "Epoch [3/10], Phase: train, Batch: [603/657], Loss: 0.1789\n",
      "Epoch [3/10], Phase: train, Batch: [604/657], Loss: 0.1426\n",
      "Epoch [3/10], Phase: train, Batch: [605/657], Loss: 0.2590\n",
      "Epoch [3/10], Phase: train, Batch: [606/657], Loss: 0.2643\n",
      "Epoch [3/10], Phase: train, Batch: [607/657], Loss: 0.2419\n",
      "Epoch [3/10], Phase: train, Batch: [608/657], Loss: 0.3135\n",
      "Epoch [3/10], Phase: train, Batch: [609/657], Loss: 0.3604\n",
      "Epoch [3/10], Phase: train, Batch: [610/657], Loss: 0.2957\n",
      "Epoch [3/10], Phase: train, Batch: [611/657], Loss: 0.1751\n",
      "Epoch [3/10], Phase: train, Batch: [612/657], Loss: 0.3039\n",
      "Epoch [3/10], Phase: train, Batch: [613/657], Loss: 0.2237\n",
      "Epoch [3/10], Phase: train, Batch: [614/657], Loss: 0.3080\n",
      "Epoch [3/10], Phase: train, Batch: [615/657], Loss: 0.2516\n",
      "Epoch [3/10], Phase: train, Batch: [616/657], Loss: 0.3432\n",
      "Epoch [3/10], Phase: train, Batch: [617/657], Loss: 0.2782\n",
      "Epoch [3/10], Phase: train, Batch: [618/657], Loss: 0.2096\n",
      "Epoch [3/10], Phase: train, Batch: [619/657], Loss: 0.2373\n",
      "Epoch [3/10], Phase: train, Batch: [620/657], Loss: 0.2966\n",
      "Epoch [3/10], Phase: train, Batch: [621/657], Loss: 0.2423\n",
      "Epoch [3/10], Phase: train, Batch: [622/657], Loss: 0.3417\n",
      "Epoch [3/10], Phase: train, Batch: [623/657], Loss: 0.3100\n",
      "Epoch [3/10], Phase: train, Batch: [624/657], Loss: 0.2874\n",
      "Epoch [3/10], Phase: train, Batch: [625/657], Loss: 0.3969\n",
      "Epoch [3/10], Phase: train, Batch: [626/657], Loss: 0.2536\n",
      "Epoch [3/10], Phase: train, Batch: [627/657], Loss: 0.3004\n",
      "Epoch [3/10], Phase: train, Batch: [628/657], Loss: 0.2738\n",
      "Epoch [3/10], Phase: train, Batch: [629/657], Loss: 0.2528\n",
      "Epoch [3/10], Phase: train, Batch: [630/657], Loss: 0.3666\n",
      "Epoch [3/10], Phase: train, Batch: [631/657], Loss: 0.2988\n",
      "Epoch [3/10], Phase: train, Batch: [632/657], Loss: 0.3182\n",
      "Epoch [3/10], Phase: train, Batch: [633/657], Loss: 0.3050\n",
      "Epoch [3/10], Phase: train, Batch: [634/657], Loss: 0.2334\n",
      "Epoch [3/10], Phase: train, Batch: [635/657], Loss: 0.2329\n",
      "Epoch [3/10], Phase: train, Batch: [636/657], Loss: 0.2666\n",
      "Epoch [3/10], Phase: train, Batch: [637/657], Loss: 0.3957\n",
      "Epoch [3/10], Phase: train, Batch: [638/657], Loss: 0.3037\n",
      "Epoch [3/10], Phase: train, Batch: [639/657], Loss: 0.3029\n",
      "Epoch [3/10], Phase: train, Batch: [640/657], Loss: 0.3543\n",
      "Epoch [3/10], Phase: train, Batch: [641/657], Loss: 0.3269\n",
      "Epoch [3/10], Phase: train, Batch: [642/657], Loss: 0.2753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Phase: train, Batch: [643/657], Loss: 0.2112\n",
      "Epoch [3/10], Phase: train, Batch: [644/657], Loss: 0.2550\n",
      "Epoch [3/10], Phase: train, Batch: [645/657], Loss: 0.3055\n",
      "Epoch [3/10], Phase: train, Batch: [646/657], Loss: 0.2282\n",
      "Epoch [3/10], Phase: train, Batch: [647/657], Loss: 0.2344\n",
      "Epoch [3/10], Phase: train, Batch: [648/657], Loss: 0.2611\n",
      "Epoch [3/10], Phase: train, Batch: [649/657], Loss: 0.1987\n",
      "Epoch [3/10], Phase: train, Batch: [650/657], Loss: 0.5717\n",
      "Epoch [3/10], Phase: train, Batch: [651/657], Loss: 0.2515\n",
      "Epoch [3/10], Phase: train, Batch: [652/657], Loss: 0.3507\n",
      "Epoch [3/10], Phase: train, Batch: [653/657], Loss: 0.2493\n",
      "Epoch [3/10], Phase: train, Batch: [654/657], Loss: 0.2812\n",
      "Epoch [3/10], Phase: train, Batch: [655/657], Loss: 0.2619\n",
      "Epoch [3/10], Phase: train, Batch: [656/657], Loss: 0.2360\n",
      "Epoch [3/10], Phase: train, Batch: [657/657], Loss: 0.6713\n",
      "train Loss: 0.2776 Acc: 0.8883\n",
      "Epoch [3/10], Phase: val, Batch: [1/73], Loss: 0.3197\n",
      "Epoch [3/10], Phase: val, Batch: [2/73], Loss: 0.2955\n",
      "Epoch [3/10], Phase: val, Batch: [3/73], Loss: 0.1581\n",
      "Epoch [3/10], Phase: val, Batch: [4/73], Loss: 0.3601\n",
      "Epoch [3/10], Phase: val, Batch: [5/73], Loss: 0.2165\n",
      "Epoch [3/10], Phase: val, Batch: [6/73], Loss: 0.2764\n",
      "Epoch [3/10], Phase: val, Batch: [7/73], Loss: 0.1956\n",
      "Epoch [3/10], Phase: val, Batch: [8/73], Loss: 0.2220\n",
      "Epoch [3/10], Phase: val, Batch: [9/73], Loss: 0.0853\n",
      "Epoch [3/10], Phase: val, Batch: [10/73], Loss: 0.1950\n",
      "Epoch [3/10], Phase: val, Batch: [11/73], Loss: 0.1809\n",
      "Epoch [3/10], Phase: val, Batch: [12/73], Loss: 0.2461\n",
      "Epoch [3/10], Phase: val, Batch: [13/73], Loss: 0.1376\n",
      "Epoch [3/10], Phase: val, Batch: [14/73], Loss: 0.2904\n",
      "Epoch [3/10], Phase: val, Batch: [15/73], Loss: 0.2064\n",
      "Epoch [3/10], Phase: val, Batch: [16/73], Loss: 0.3090\n",
      "Epoch [3/10], Phase: val, Batch: [17/73], Loss: 0.1137\n",
      "Epoch [3/10], Phase: val, Batch: [18/73], Loss: 0.2502\n",
      "Epoch [3/10], Phase: val, Batch: [19/73], Loss: 0.3238\n",
      "Epoch [3/10], Phase: val, Batch: [20/73], Loss: 0.1725\n",
      "Epoch [3/10], Phase: val, Batch: [21/73], Loss: 0.3347\n",
      "Epoch [3/10], Phase: val, Batch: [22/73], Loss: 0.2076\n",
      "Epoch [3/10], Phase: val, Batch: [23/73], Loss: 0.2628\n",
      "Epoch [3/10], Phase: val, Batch: [24/73], Loss: 0.2879\n",
      "Epoch [3/10], Phase: val, Batch: [25/73], Loss: 0.1865\n",
      "Epoch [3/10], Phase: val, Batch: [26/73], Loss: 0.1819\n",
      "Epoch [3/10], Phase: val, Batch: [27/73], Loss: 0.2577\n",
      "Epoch [3/10], Phase: val, Batch: [28/73], Loss: 0.2426\n",
      "Epoch [3/10], Phase: val, Batch: [29/73], Loss: 0.3404\n",
      "Epoch [3/10], Phase: val, Batch: [30/73], Loss: 0.3384\n",
      "Epoch [3/10], Phase: val, Batch: [31/73], Loss: 0.1823\n",
      "Epoch [3/10], Phase: val, Batch: [32/73], Loss: 0.2775\n",
      "Epoch [3/10], Phase: val, Batch: [33/73], Loss: 0.3864\n",
      "Epoch [3/10], Phase: val, Batch: [34/73], Loss: 0.2101\n",
      "Epoch [3/10], Phase: val, Batch: [35/73], Loss: 0.1782\n",
      "Epoch [3/10], Phase: val, Batch: [36/73], Loss: 0.3398\n",
      "Epoch [3/10], Phase: val, Batch: [37/73], Loss: 0.2184\n",
      "Epoch [3/10], Phase: val, Batch: [38/73], Loss: 0.1693\n",
      "Epoch [3/10], Phase: val, Batch: [39/73], Loss: 0.2173\n",
      "Epoch [3/10], Phase: val, Batch: [40/73], Loss: 0.1960\n",
      "Epoch [3/10], Phase: val, Batch: [41/73], Loss: 0.2227\n",
      "Epoch [3/10], Phase: val, Batch: [42/73], Loss: 0.2688\n",
      "Epoch [3/10], Phase: val, Batch: [43/73], Loss: 0.2199\n",
      "Epoch [3/10], Phase: val, Batch: [44/73], Loss: 0.2380\n",
      "Epoch [3/10], Phase: val, Batch: [45/73], Loss: 0.1910\n",
      "Epoch [3/10], Phase: val, Batch: [46/73], Loss: 0.3054\n",
      "Epoch [3/10], Phase: val, Batch: [47/73], Loss: 0.2870\n",
      "Epoch [3/10], Phase: val, Batch: [48/73], Loss: 0.1444\n",
      "Epoch [3/10], Phase: val, Batch: [49/73], Loss: 0.2982\n",
      "Epoch [3/10], Phase: val, Batch: [50/73], Loss: 0.1823\n",
      "Epoch [3/10], Phase: val, Batch: [51/73], Loss: 0.3085\n",
      "Epoch [3/10], Phase: val, Batch: [52/73], Loss: 0.1909\n",
      "Epoch [3/10], Phase: val, Batch: [53/73], Loss: 0.2176\n",
      "Epoch [3/10], Phase: val, Batch: [54/73], Loss: 0.2098\n",
      "Epoch [3/10], Phase: val, Batch: [55/73], Loss: 0.2384\n",
      "Epoch [3/10], Phase: val, Batch: [56/73], Loss: 0.3027\n",
      "Epoch [3/10], Phase: val, Batch: [57/73], Loss: 0.1401\n",
      "Epoch [3/10], Phase: val, Batch: [58/73], Loss: 0.2554\n",
      "Epoch [3/10], Phase: val, Batch: [59/73], Loss: 0.2447\n",
      "Epoch [3/10], Phase: val, Batch: [60/73], Loss: 0.1741\n",
      "Epoch [3/10], Phase: val, Batch: [61/73], Loss: 0.3311\n",
      "Epoch [3/10], Phase: val, Batch: [62/73], Loss: 0.2353\n",
      "Epoch [3/10], Phase: val, Batch: [63/73], Loss: 0.2310\n",
      "Epoch [3/10], Phase: val, Batch: [64/73], Loss: 0.2808\n",
      "Epoch [3/10], Phase: val, Batch: [65/73], Loss: 0.2434\n",
      "Epoch [3/10], Phase: val, Batch: [66/73], Loss: 0.1810\n",
      "Epoch [3/10], Phase: val, Batch: [67/73], Loss: 0.2191\n",
      "Epoch [3/10], Phase: val, Batch: [68/73], Loss: 0.2176\n",
      "Epoch [3/10], Phase: val, Batch: [69/73], Loss: 0.2982\n",
      "Epoch [3/10], Phase: val, Batch: [70/73], Loss: 0.2453\n",
      "Epoch [3/10], Phase: val, Batch: [71/73], Loss: 0.3113\n",
      "Epoch [3/10], Phase: val, Batch: [72/73], Loss: 0.4053\n",
      "Epoch [3/10], Phase: val, Batch: [73/73], Loss: 0.1162\n",
      "val Loss: 0.2402 Acc: 0.9023\n",
      "Epoch [4/10], Phase: train, Batch: [1/657], Loss: 0.2307\n",
      "Epoch [4/10], Phase: train, Batch: [2/657], Loss: 0.2235\n",
      "Epoch [4/10], Phase: train, Batch: [3/657], Loss: 0.2227\n",
      "Epoch [4/10], Phase: train, Batch: [4/657], Loss: 0.2378\n",
      "Epoch [4/10], Phase: train, Batch: [5/657], Loss: 0.3411\n",
      "Epoch [4/10], Phase: train, Batch: [6/657], Loss: 0.2619\n",
      "Epoch [4/10], Phase: train, Batch: [7/657], Loss: 0.2908\n",
      "Epoch [4/10], Phase: train, Batch: [8/657], Loss: 0.3078\n",
      "Epoch [4/10], Phase: train, Batch: [9/657], Loss: 0.1892\n",
      "Epoch [4/10], Phase: train, Batch: [10/657], Loss: 0.1493\n",
      "Epoch [4/10], Phase: train, Batch: [11/657], Loss: 0.3487\n",
      "Epoch [4/10], Phase: train, Batch: [12/657], Loss: 0.3525\n",
      "Epoch [4/10], Phase: train, Batch: [13/657], Loss: 0.3473\n",
      "Epoch [4/10], Phase: train, Batch: [14/657], Loss: 0.2679\n",
      "Epoch [4/10], Phase: train, Batch: [15/657], Loss: 0.2046\n",
      "Epoch [4/10], Phase: train, Batch: [16/657], Loss: 0.2068\n",
      "Epoch [4/10], Phase: train, Batch: [17/657], Loss: 0.2421\n",
      "Epoch [4/10], Phase: train, Batch: [18/657], Loss: 0.2852\n",
      "Epoch [4/10], Phase: train, Batch: [19/657], Loss: 0.3495\n",
      "Epoch [4/10], Phase: train, Batch: [20/657], Loss: 0.2500\n",
      "Epoch [4/10], Phase: train, Batch: [21/657], Loss: 0.3090\n",
      "Epoch [4/10], Phase: train, Batch: [22/657], Loss: 0.2679\n",
      "Epoch [4/10], Phase: train, Batch: [23/657], Loss: 0.2711\n",
      "Epoch [4/10], Phase: train, Batch: [24/657], Loss: 0.2588\n",
      "Epoch [4/10], Phase: train, Batch: [25/657], Loss: 0.2624\n",
      "Epoch [4/10], Phase: train, Batch: [26/657], Loss: 0.2874\n",
      "Epoch [4/10], Phase: train, Batch: [27/657], Loss: 0.1837\n",
      "Epoch [4/10], Phase: train, Batch: [28/657], Loss: 0.3990\n",
      "Epoch [4/10], Phase: train, Batch: [29/657], Loss: 0.2052\n",
      "Epoch [4/10], Phase: train, Batch: [30/657], Loss: 0.1857\n",
      "Epoch [4/10], Phase: train, Batch: [31/657], Loss: 0.3317\n",
      "Epoch [4/10], Phase: train, Batch: [32/657], Loss: 0.3502\n",
      "Epoch [4/10], Phase: train, Batch: [33/657], Loss: 0.2527\n",
      "Epoch [4/10], Phase: train, Batch: [34/657], Loss: 0.2786\n",
      "Epoch [4/10], Phase: train, Batch: [35/657], Loss: 0.1993\n",
      "Epoch [4/10], Phase: train, Batch: [36/657], Loss: 0.2389\n",
      "Epoch [4/10], Phase: train, Batch: [37/657], Loss: 0.2220\n",
      "Epoch [4/10], Phase: train, Batch: [38/657], Loss: 0.2335\n",
      "Epoch [4/10], Phase: train, Batch: [39/657], Loss: 0.3340\n",
      "Epoch [4/10], Phase: train, Batch: [40/657], Loss: 0.2290\n",
      "Epoch [4/10], Phase: train, Batch: [41/657], Loss: 0.1672\n",
      "Epoch [4/10], Phase: train, Batch: [42/657], Loss: 0.2863\n",
      "Epoch [4/10], Phase: train, Batch: [43/657], Loss: 0.3530\n",
      "Epoch [4/10], Phase: train, Batch: [44/657], Loss: 0.3062\n",
      "Epoch [4/10], Phase: train, Batch: [45/657], Loss: 0.3248\n",
      "Epoch [4/10], Phase: train, Batch: [46/657], Loss: 0.1959\n",
      "Epoch [4/10], Phase: train, Batch: [47/657], Loss: 0.3105\n",
      "Epoch [4/10], Phase: train, Batch: [48/657], Loss: 0.1151\n",
      "Epoch [4/10], Phase: train, Batch: [49/657], Loss: 0.3187\n",
      "Epoch [4/10], Phase: train, Batch: [50/657], Loss: 0.2786\n",
      "Epoch [4/10], Phase: train, Batch: [51/657], Loss: 0.2456\n",
      "Epoch [4/10], Phase: train, Batch: [52/657], Loss: 0.3373\n",
      "Epoch [4/10], Phase: train, Batch: [53/657], Loss: 0.2829\n",
      "Epoch [4/10], Phase: train, Batch: [54/657], Loss: 0.3658\n",
      "Epoch [4/10], Phase: train, Batch: [55/657], Loss: 0.2385\n",
      "Epoch [4/10], Phase: train, Batch: [56/657], Loss: 0.2938\n",
      "Epoch [4/10], Phase: train, Batch: [57/657], Loss: 0.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [58/657], Loss: 0.3524\n",
      "Epoch [4/10], Phase: train, Batch: [59/657], Loss: 0.3047\n",
      "Epoch [4/10], Phase: train, Batch: [60/657], Loss: 0.2038\n",
      "Epoch [4/10], Phase: train, Batch: [61/657], Loss: 0.2740\n",
      "Epoch [4/10], Phase: train, Batch: [62/657], Loss: 0.2981\n",
      "Epoch [4/10], Phase: train, Batch: [63/657], Loss: 0.2549\n",
      "Epoch [4/10], Phase: train, Batch: [64/657], Loss: 0.3055\n",
      "Epoch [4/10], Phase: train, Batch: [65/657], Loss: 0.2392\n",
      "Epoch [4/10], Phase: train, Batch: [66/657], Loss: 0.3756\n",
      "Epoch [4/10], Phase: train, Batch: [67/657], Loss: 0.2620\n",
      "Epoch [4/10], Phase: train, Batch: [68/657], Loss: 0.2538\n",
      "Epoch [4/10], Phase: train, Batch: [69/657], Loss: 0.2595\n",
      "Epoch [4/10], Phase: train, Batch: [70/657], Loss: 0.3343\n",
      "Epoch [4/10], Phase: train, Batch: [71/657], Loss: 0.2512\n",
      "Epoch [4/10], Phase: train, Batch: [72/657], Loss: 0.3416\n",
      "Epoch [4/10], Phase: train, Batch: [73/657], Loss: 0.2142\n",
      "Epoch [4/10], Phase: train, Batch: [74/657], Loss: 0.2006\n",
      "Epoch [4/10], Phase: train, Batch: [75/657], Loss: 0.2861\n",
      "Epoch [4/10], Phase: train, Batch: [76/657], Loss: 0.2696\n",
      "Epoch [4/10], Phase: train, Batch: [77/657], Loss: 0.2626\n",
      "Epoch [4/10], Phase: train, Batch: [78/657], Loss: 0.2486\n",
      "Epoch [4/10], Phase: train, Batch: [79/657], Loss: 0.3689\n",
      "Epoch [4/10], Phase: train, Batch: [80/657], Loss: 0.2293\n",
      "Epoch [4/10], Phase: train, Batch: [81/657], Loss: 0.3474\n",
      "Epoch [4/10], Phase: train, Batch: [82/657], Loss: 0.1632\n",
      "Epoch [4/10], Phase: train, Batch: [83/657], Loss: 0.3109\n",
      "Epoch [4/10], Phase: train, Batch: [84/657], Loss: 0.2843\n",
      "Epoch [4/10], Phase: train, Batch: [85/657], Loss: 0.2074\n",
      "Epoch [4/10], Phase: train, Batch: [86/657], Loss: 0.2139\n",
      "Epoch [4/10], Phase: train, Batch: [87/657], Loss: 0.2593\n",
      "Epoch [4/10], Phase: train, Batch: [88/657], Loss: 0.3144\n",
      "Epoch [4/10], Phase: train, Batch: [89/657], Loss: 0.2714\n",
      "Epoch [4/10], Phase: train, Batch: [90/657], Loss: 0.2318\n",
      "Epoch [4/10], Phase: train, Batch: [91/657], Loss: 0.1954\n",
      "Epoch [4/10], Phase: train, Batch: [92/657], Loss: 0.2243\n",
      "Epoch [4/10], Phase: train, Batch: [93/657], Loss: 0.3101\n",
      "Epoch [4/10], Phase: train, Batch: [94/657], Loss: 0.3583\n",
      "Epoch [4/10], Phase: train, Batch: [95/657], Loss: 0.2027\n",
      "Epoch [4/10], Phase: train, Batch: [96/657], Loss: 0.2040\n",
      "Epoch [4/10], Phase: train, Batch: [97/657], Loss: 0.2154\n",
      "Epoch [4/10], Phase: train, Batch: [98/657], Loss: 0.3763\n",
      "Epoch [4/10], Phase: train, Batch: [99/657], Loss: 0.2943\n",
      "Epoch [4/10], Phase: train, Batch: [100/657], Loss: 0.2278\n",
      "Epoch [4/10], Phase: train, Batch: [101/657], Loss: 0.2503\n",
      "Epoch [4/10], Phase: train, Batch: [102/657], Loss: 0.1802\n",
      "Epoch [4/10], Phase: train, Batch: [103/657], Loss: 0.3296\n",
      "Epoch [4/10], Phase: train, Batch: [104/657], Loss: 0.3884\n",
      "Epoch [4/10], Phase: train, Batch: [105/657], Loss: 0.3172\n",
      "Epoch [4/10], Phase: train, Batch: [106/657], Loss: 0.1753\n",
      "Epoch [4/10], Phase: train, Batch: [107/657], Loss: 0.2978\n",
      "Epoch [4/10], Phase: train, Batch: [108/657], Loss: 0.2359\n",
      "Epoch [4/10], Phase: train, Batch: [109/657], Loss: 0.2173\n",
      "Epoch [4/10], Phase: train, Batch: [110/657], Loss: 0.1720\n",
      "Epoch [4/10], Phase: train, Batch: [111/657], Loss: 0.2521\n",
      "Epoch [4/10], Phase: train, Batch: [112/657], Loss: 0.2725\n",
      "Epoch [4/10], Phase: train, Batch: [113/657], Loss: 0.2241\n",
      "Epoch [4/10], Phase: train, Batch: [114/657], Loss: 0.1903\n",
      "Epoch [4/10], Phase: train, Batch: [115/657], Loss: 0.1657\n",
      "Epoch [4/10], Phase: train, Batch: [116/657], Loss: 0.3711\n",
      "Epoch [4/10], Phase: train, Batch: [117/657], Loss: 0.2015\n",
      "Epoch [4/10], Phase: train, Batch: [118/657], Loss: 0.3184\n",
      "Epoch [4/10], Phase: train, Batch: [119/657], Loss: 0.3234\n",
      "Epoch [4/10], Phase: train, Batch: [120/657], Loss: 0.2538\n",
      "Epoch [4/10], Phase: train, Batch: [121/657], Loss: 0.3893\n",
      "Epoch [4/10], Phase: train, Batch: [122/657], Loss: 0.2340\n",
      "Epoch [4/10], Phase: train, Batch: [123/657], Loss: 0.2681\n",
      "Epoch [4/10], Phase: train, Batch: [124/657], Loss: 0.2274\n",
      "Epoch [4/10], Phase: train, Batch: [125/657], Loss: 0.2694\n",
      "Epoch [4/10], Phase: train, Batch: [126/657], Loss: 0.1948\n",
      "Epoch [4/10], Phase: train, Batch: [127/657], Loss: 0.3599\n",
      "Epoch [4/10], Phase: train, Batch: [128/657], Loss: 0.2921\n",
      "Epoch [4/10], Phase: train, Batch: [129/657], Loss: 0.2689\n",
      "Epoch [4/10], Phase: train, Batch: [130/657], Loss: 0.3285\n",
      "Epoch [4/10], Phase: train, Batch: [131/657], Loss: 0.3281\n",
      "Epoch [4/10], Phase: train, Batch: [132/657], Loss: 0.3523\n",
      "Epoch [4/10], Phase: train, Batch: [133/657], Loss: 0.1903\n",
      "Epoch [4/10], Phase: train, Batch: [134/657], Loss: 0.3392\n",
      "Epoch [4/10], Phase: train, Batch: [135/657], Loss: 0.4118\n",
      "Epoch [4/10], Phase: train, Batch: [136/657], Loss: 0.2204\n",
      "Epoch [4/10], Phase: train, Batch: [137/657], Loss: 0.5368\n",
      "Epoch [4/10], Phase: train, Batch: [138/657], Loss: 0.2682\n",
      "Epoch [4/10], Phase: train, Batch: [139/657], Loss: 0.2419\n",
      "Epoch [4/10], Phase: train, Batch: [140/657], Loss: 0.1983\n",
      "Epoch [4/10], Phase: train, Batch: [141/657], Loss: 0.3088\n",
      "Epoch [4/10], Phase: train, Batch: [142/657], Loss: 0.2999\n",
      "Epoch [4/10], Phase: train, Batch: [143/657], Loss: 0.3389\n",
      "Epoch [4/10], Phase: train, Batch: [144/657], Loss: 0.3317\n",
      "Epoch [4/10], Phase: train, Batch: [145/657], Loss: 0.3097\n",
      "Epoch [4/10], Phase: train, Batch: [146/657], Loss: 0.1731\n",
      "Epoch [4/10], Phase: train, Batch: [147/657], Loss: 0.1731\n",
      "Epoch [4/10], Phase: train, Batch: [148/657], Loss: 0.2697\n",
      "Epoch [4/10], Phase: train, Batch: [149/657], Loss: 0.2907\n",
      "Epoch [4/10], Phase: train, Batch: [150/657], Loss: 0.3905\n",
      "Epoch [4/10], Phase: train, Batch: [151/657], Loss: 0.1839\n",
      "Epoch [4/10], Phase: train, Batch: [152/657], Loss: 0.2718\n",
      "Epoch [4/10], Phase: train, Batch: [153/657], Loss: 0.3037\n",
      "Epoch [4/10], Phase: train, Batch: [154/657], Loss: 0.2893\n",
      "Epoch [4/10], Phase: train, Batch: [155/657], Loss: 0.3542\n",
      "Epoch [4/10], Phase: train, Batch: [156/657], Loss: 0.3080\n",
      "Epoch [4/10], Phase: train, Batch: [157/657], Loss: 0.2471\n",
      "Epoch [4/10], Phase: train, Batch: [158/657], Loss: 0.2026\n",
      "Epoch [4/10], Phase: train, Batch: [159/657], Loss: 0.3885\n",
      "Epoch [4/10], Phase: train, Batch: [160/657], Loss: 0.4086\n",
      "Epoch [4/10], Phase: train, Batch: [161/657], Loss: 0.4929\n",
      "Epoch [4/10], Phase: train, Batch: [162/657], Loss: 0.1876\n",
      "Epoch [4/10], Phase: train, Batch: [163/657], Loss: 0.2534\n",
      "Epoch [4/10], Phase: train, Batch: [164/657], Loss: 0.3498\n",
      "Epoch [4/10], Phase: train, Batch: [165/657], Loss: 0.3054\n",
      "Epoch [4/10], Phase: train, Batch: [166/657], Loss: 0.3699\n",
      "Epoch [4/10], Phase: train, Batch: [167/657], Loss: 0.1698\n",
      "Epoch [4/10], Phase: train, Batch: [168/657], Loss: 0.3733\n",
      "Epoch [4/10], Phase: train, Batch: [169/657], Loss: 0.2712\n",
      "Epoch [4/10], Phase: train, Batch: [170/657], Loss: 0.2162\n",
      "Epoch [4/10], Phase: train, Batch: [171/657], Loss: 0.2940\n",
      "Epoch [4/10], Phase: train, Batch: [172/657], Loss: 0.3107\n",
      "Epoch [4/10], Phase: train, Batch: [173/657], Loss: 0.2344\n",
      "Epoch [4/10], Phase: train, Batch: [174/657], Loss: 0.2597\n",
      "Epoch [4/10], Phase: train, Batch: [175/657], Loss: 0.3187\n",
      "Epoch [4/10], Phase: train, Batch: [176/657], Loss: 0.2428\n",
      "Epoch [4/10], Phase: train, Batch: [177/657], Loss: 0.1626\n",
      "Epoch [4/10], Phase: train, Batch: [178/657], Loss: 0.1960\n",
      "Epoch [4/10], Phase: train, Batch: [179/657], Loss: 0.1829\n",
      "Epoch [4/10], Phase: train, Batch: [180/657], Loss: 0.2548\n",
      "Epoch [4/10], Phase: train, Batch: [181/657], Loss: 0.2481\n",
      "Epoch [4/10], Phase: train, Batch: [182/657], Loss: 0.3468\n",
      "Epoch [4/10], Phase: train, Batch: [183/657], Loss: 0.3060\n",
      "Epoch [4/10], Phase: train, Batch: [184/657], Loss: 0.2925\n",
      "Epoch [4/10], Phase: train, Batch: [185/657], Loss: 0.3248\n",
      "Epoch [4/10], Phase: train, Batch: [186/657], Loss: 0.2098\n",
      "Epoch [4/10], Phase: train, Batch: [187/657], Loss: 0.2001\n",
      "Epoch [4/10], Phase: train, Batch: [188/657], Loss: 0.2322\n",
      "Epoch [4/10], Phase: train, Batch: [189/657], Loss: 0.3757\n",
      "Epoch [4/10], Phase: train, Batch: [190/657], Loss: 0.2557\n",
      "Epoch [4/10], Phase: train, Batch: [191/657], Loss: 0.2755\n",
      "Epoch [4/10], Phase: train, Batch: [192/657], Loss: 0.2722\n",
      "Epoch [4/10], Phase: train, Batch: [193/657], Loss: 0.3301\n",
      "Epoch [4/10], Phase: train, Batch: [194/657], Loss: 0.2429\n",
      "Epoch [4/10], Phase: train, Batch: [195/657], Loss: 0.3513\n",
      "Epoch [4/10], Phase: train, Batch: [196/657], Loss: 0.2121\n",
      "Epoch [4/10], Phase: train, Batch: [197/657], Loss: 0.4634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [198/657], Loss: 0.2889\n",
      "Epoch [4/10], Phase: train, Batch: [199/657], Loss: 0.1856\n",
      "Epoch [4/10], Phase: train, Batch: [200/657], Loss: 0.3105\n",
      "Epoch [4/10], Phase: train, Batch: [201/657], Loss: 0.2558\n",
      "Epoch [4/10], Phase: train, Batch: [202/657], Loss: 0.4052\n",
      "Epoch [4/10], Phase: train, Batch: [203/657], Loss: 0.1757\n",
      "Epoch [4/10], Phase: train, Batch: [204/657], Loss: 0.3089\n",
      "Epoch [4/10], Phase: train, Batch: [205/657], Loss: 0.2805\n",
      "Epoch [4/10], Phase: train, Batch: [206/657], Loss: 0.3639\n",
      "Epoch [4/10], Phase: train, Batch: [207/657], Loss: 0.2358\n",
      "Epoch [4/10], Phase: train, Batch: [208/657], Loss: 0.3351\n",
      "Epoch [4/10], Phase: train, Batch: [209/657], Loss: 0.2033\n",
      "Epoch [4/10], Phase: train, Batch: [210/657], Loss: 0.2848\n",
      "Epoch [4/10], Phase: train, Batch: [211/657], Loss: 0.2707\n",
      "Epoch [4/10], Phase: train, Batch: [212/657], Loss: 0.2629\n",
      "Epoch [4/10], Phase: train, Batch: [213/657], Loss: 0.1805\n",
      "Epoch [4/10], Phase: train, Batch: [214/657], Loss: 0.4140\n",
      "Epoch [4/10], Phase: train, Batch: [215/657], Loss: 0.1958\n",
      "Epoch [4/10], Phase: train, Batch: [216/657], Loss: 0.1903\n",
      "Epoch [4/10], Phase: train, Batch: [217/657], Loss: 0.5028\n",
      "Epoch [4/10], Phase: train, Batch: [218/657], Loss: 0.1855\n",
      "Epoch [4/10], Phase: train, Batch: [219/657], Loss: 0.3062\n",
      "Epoch [4/10], Phase: train, Batch: [220/657], Loss: 0.2936\n",
      "Epoch [4/10], Phase: train, Batch: [221/657], Loss: 0.3534\n",
      "Epoch [4/10], Phase: train, Batch: [222/657], Loss: 0.2063\n",
      "Epoch [4/10], Phase: train, Batch: [223/657], Loss: 0.2154\n",
      "Epoch [4/10], Phase: train, Batch: [224/657], Loss: 0.2751\n",
      "Epoch [4/10], Phase: train, Batch: [225/657], Loss: 0.2288\n",
      "Epoch [4/10], Phase: train, Batch: [226/657], Loss: 0.3430\n",
      "Epoch [4/10], Phase: train, Batch: [227/657], Loss: 0.4504\n",
      "Epoch [4/10], Phase: train, Batch: [228/657], Loss: 0.1960\n",
      "Epoch [4/10], Phase: train, Batch: [229/657], Loss: 0.2942\n",
      "Epoch [4/10], Phase: train, Batch: [230/657], Loss: 0.3976\n",
      "Epoch [4/10], Phase: train, Batch: [231/657], Loss: 0.3671\n",
      "Epoch [4/10], Phase: train, Batch: [232/657], Loss: 0.2835\n",
      "Epoch [4/10], Phase: train, Batch: [233/657], Loss: 0.3032\n",
      "Epoch [4/10], Phase: train, Batch: [234/657], Loss: 0.3267\n",
      "Epoch [4/10], Phase: train, Batch: [235/657], Loss: 0.1489\n",
      "Epoch [4/10], Phase: train, Batch: [236/657], Loss: 0.3875\n",
      "Epoch [4/10], Phase: train, Batch: [237/657], Loss: 0.1595\n",
      "Epoch [4/10], Phase: train, Batch: [238/657], Loss: 0.2570\n",
      "Epoch [4/10], Phase: train, Batch: [239/657], Loss: 0.2055\n",
      "Epoch [4/10], Phase: train, Batch: [240/657], Loss: 0.1760\n",
      "Epoch [4/10], Phase: train, Batch: [241/657], Loss: 0.2602\n",
      "Epoch [4/10], Phase: train, Batch: [242/657], Loss: 0.2137\n",
      "Epoch [4/10], Phase: train, Batch: [243/657], Loss: 0.2822\n",
      "Epoch [4/10], Phase: train, Batch: [244/657], Loss: 0.2197\n",
      "Epoch [4/10], Phase: train, Batch: [245/657], Loss: 0.2908\n",
      "Epoch [4/10], Phase: train, Batch: [246/657], Loss: 0.2806\n",
      "Epoch [4/10], Phase: train, Batch: [247/657], Loss: 0.2852\n",
      "Epoch [4/10], Phase: train, Batch: [248/657], Loss: 0.2099\n",
      "Epoch [4/10], Phase: train, Batch: [249/657], Loss: 0.4030\n",
      "Epoch [4/10], Phase: train, Batch: [250/657], Loss: 0.3490\n",
      "Epoch [4/10], Phase: train, Batch: [251/657], Loss: 0.3010\n",
      "Epoch [4/10], Phase: train, Batch: [252/657], Loss: 0.2945\n",
      "Epoch [4/10], Phase: train, Batch: [253/657], Loss: 0.3202\n",
      "Epoch [4/10], Phase: train, Batch: [254/657], Loss: 0.2305\n",
      "Epoch [4/10], Phase: train, Batch: [255/657], Loss: 0.2677\n",
      "Epoch [4/10], Phase: train, Batch: [256/657], Loss: 0.2659\n",
      "Epoch [4/10], Phase: train, Batch: [257/657], Loss: 0.2161\n",
      "Epoch [4/10], Phase: train, Batch: [258/657], Loss: 0.3838\n",
      "Epoch [4/10], Phase: train, Batch: [259/657], Loss: 0.2528\n",
      "Epoch [4/10], Phase: train, Batch: [260/657], Loss: 0.2250\n",
      "Epoch [4/10], Phase: train, Batch: [261/657], Loss: 0.2321\n",
      "Epoch [4/10], Phase: train, Batch: [262/657], Loss: 0.1932\n",
      "Epoch [4/10], Phase: train, Batch: [263/657], Loss: 0.3153\n",
      "Epoch [4/10], Phase: train, Batch: [264/657], Loss: 0.2289\n",
      "Epoch [4/10], Phase: train, Batch: [265/657], Loss: 0.3141\n",
      "Epoch [4/10], Phase: train, Batch: [266/657], Loss: 0.3318\n",
      "Epoch [4/10], Phase: train, Batch: [267/657], Loss: 0.3170\n",
      "Epoch [4/10], Phase: train, Batch: [268/657], Loss: 0.2204\n",
      "Epoch [4/10], Phase: train, Batch: [269/657], Loss: 0.3770\n",
      "Epoch [4/10], Phase: train, Batch: [270/657], Loss: 0.2111\n",
      "Epoch [4/10], Phase: train, Batch: [271/657], Loss: 0.2328\n",
      "Epoch [4/10], Phase: train, Batch: [272/657], Loss: 0.1701\n",
      "Epoch [4/10], Phase: train, Batch: [273/657], Loss: 0.2381\n",
      "Epoch [4/10], Phase: train, Batch: [274/657], Loss: 0.2215\n",
      "Epoch [4/10], Phase: train, Batch: [275/657], Loss: 0.2231\n",
      "Epoch [4/10], Phase: train, Batch: [276/657], Loss: 0.2789\n",
      "Epoch [4/10], Phase: train, Batch: [277/657], Loss: 0.2380\n",
      "Epoch [4/10], Phase: train, Batch: [278/657], Loss: 0.2230\n",
      "Epoch [4/10], Phase: train, Batch: [279/657], Loss: 0.2328\n",
      "Epoch [4/10], Phase: train, Batch: [280/657], Loss: 0.3140\n",
      "Epoch [4/10], Phase: train, Batch: [281/657], Loss: 0.2874\n",
      "Epoch [4/10], Phase: train, Batch: [282/657], Loss: 0.3054\n",
      "Epoch [4/10], Phase: train, Batch: [283/657], Loss: 0.2907\n",
      "Epoch [4/10], Phase: train, Batch: [284/657], Loss: 0.2369\n",
      "Epoch [4/10], Phase: train, Batch: [285/657], Loss: 0.1900\n",
      "Epoch [4/10], Phase: train, Batch: [286/657], Loss: 0.3243\n",
      "Epoch [4/10], Phase: train, Batch: [287/657], Loss: 0.3375\n",
      "Epoch [4/10], Phase: train, Batch: [288/657], Loss: 0.3363\n",
      "Epoch [4/10], Phase: train, Batch: [289/657], Loss: 0.2794\n",
      "Epoch [4/10], Phase: train, Batch: [290/657], Loss: 0.2455\n",
      "Epoch [4/10], Phase: train, Batch: [291/657], Loss: 0.3132\n",
      "Epoch [4/10], Phase: train, Batch: [292/657], Loss: 0.2696\n",
      "Epoch [4/10], Phase: train, Batch: [293/657], Loss: 0.3031\n",
      "Epoch [4/10], Phase: train, Batch: [294/657], Loss: 0.4633\n",
      "Epoch [4/10], Phase: train, Batch: [295/657], Loss: 0.2130\n",
      "Epoch [4/10], Phase: train, Batch: [296/657], Loss: 0.2209\n",
      "Epoch [4/10], Phase: train, Batch: [297/657], Loss: 0.3207\n",
      "Epoch [4/10], Phase: train, Batch: [298/657], Loss: 0.1973\n",
      "Epoch [4/10], Phase: train, Batch: [299/657], Loss: 0.3380\n",
      "Epoch [4/10], Phase: train, Batch: [300/657], Loss: 0.2493\n",
      "Epoch [4/10], Phase: train, Batch: [301/657], Loss: 0.3414\n",
      "Epoch [4/10], Phase: train, Batch: [302/657], Loss: 0.1975\n",
      "Epoch [4/10], Phase: train, Batch: [303/657], Loss: 0.3391\n",
      "Epoch [4/10], Phase: train, Batch: [304/657], Loss: 0.3343\n",
      "Epoch [4/10], Phase: train, Batch: [305/657], Loss: 0.2394\n",
      "Epoch [4/10], Phase: train, Batch: [306/657], Loss: 0.3357\n",
      "Epoch [4/10], Phase: train, Batch: [307/657], Loss: 0.1724\n",
      "Epoch [4/10], Phase: train, Batch: [308/657], Loss: 0.3169\n",
      "Epoch [4/10], Phase: train, Batch: [309/657], Loss: 0.1900\n",
      "Epoch [4/10], Phase: train, Batch: [310/657], Loss: 0.3255\n",
      "Epoch [4/10], Phase: train, Batch: [311/657], Loss: 0.2168\n",
      "Epoch [4/10], Phase: train, Batch: [312/657], Loss: 0.2091\n",
      "Epoch [4/10], Phase: train, Batch: [313/657], Loss: 0.2693\n",
      "Epoch [4/10], Phase: train, Batch: [314/657], Loss: 0.2560\n",
      "Epoch [4/10], Phase: train, Batch: [315/657], Loss: 0.2491\n",
      "Epoch [4/10], Phase: train, Batch: [316/657], Loss: 0.3491\n",
      "Epoch [4/10], Phase: train, Batch: [317/657], Loss: 0.1546\n",
      "Epoch [4/10], Phase: train, Batch: [318/657], Loss: 0.2880\n",
      "Epoch [4/10], Phase: train, Batch: [319/657], Loss: 0.2995\n",
      "Epoch [4/10], Phase: train, Batch: [320/657], Loss: 0.2989\n",
      "Epoch [4/10], Phase: train, Batch: [321/657], Loss: 0.4000\n",
      "Epoch [4/10], Phase: train, Batch: [322/657], Loss: 0.2884\n",
      "Epoch [4/10], Phase: train, Batch: [323/657], Loss: 0.2262\n",
      "Epoch [4/10], Phase: train, Batch: [324/657], Loss: 0.2885\n",
      "Epoch [4/10], Phase: train, Batch: [325/657], Loss: 0.2151\n",
      "Epoch [4/10], Phase: train, Batch: [326/657], Loss: 0.2814\n",
      "Epoch [4/10], Phase: train, Batch: [327/657], Loss: 0.3450\n",
      "Epoch [4/10], Phase: train, Batch: [328/657], Loss: 0.2321\n",
      "Epoch [4/10], Phase: train, Batch: [329/657], Loss: 0.3300\n",
      "Epoch [4/10], Phase: train, Batch: [330/657], Loss: 0.1617\n",
      "Epoch [4/10], Phase: train, Batch: [331/657], Loss: 0.2988\n",
      "Epoch [4/10], Phase: train, Batch: [332/657], Loss: 0.1790\n",
      "Epoch [4/10], Phase: train, Batch: [333/657], Loss: 0.3132\n",
      "Epoch [4/10], Phase: train, Batch: [334/657], Loss: 0.2329\n",
      "Epoch [4/10], Phase: train, Batch: [335/657], Loss: 0.3808\n",
      "Epoch [4/10], Phase: train, Batch: [336/657], Loss: 0.1459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [337/657], Loss: 0.2977\n",
      "Epoch [4/10], Phase: train, Batch: [338/657], Loss: 0.2284\n",
      "Epoch [4/10], Phase: train, Batch: [339/657], Loss: 0.3689\n",
      "Epoch [4/10], Phase: train, Batch: [340/657], Loss: 0.2297\n",
      "Epoch [4/10], Phase: train, Batch: [341/657], Loss: 0.2700\n",
      "Epoch [4/10], Phase: train, Batch: [342/657], Loss: 0.2985\n",
      "Epoch [4/10], Phase: train, Batch: [343/657], Loss: 0.2220\n",
      "Epoch [4/10], Phase: train, Batch: [344/657], Loss: 0.2982\n",
      "Epoch [4/10], Phase: train, Batch: [345/657], Loss: 0.2635\n",
      "Epoch [4/10], Phase: train, Batch: [346/657], Loss: 0.2310\n",
      "Epoch [4/10], Phase: train, Batch: [347/657], Loss: 0.3927\n",
      "Epoch [4/10], Phase: train, Batch: [348/657], Loss: 0.2621\n",
      "Epoch [4/10], Phase: train, Batch: [349/657], Loss: 0.2487\n",
      "Epoch [4/10], Phase: train, Batch: [350/657], Loss: 0.2154\n",
      "Epoch [4/10], Phase: train, Batch: [351/657], Loss: 0.2148\n",
      "Epoch [4/10], Phase: train, Batch: [352/657], Loss: 0.2317\n",
      "Epoch [4/10], Phase: train, Batch: [353/657], Loss: 0.2517\n",
      "Epoch [4/10], Phase: train, Batch: [354/657], Loss: 0.1817\n",
      "Epoch [4/10], Phase: train, Batch: [355/657], Loss: 0.4351\n",
      "Epoch [4/10], Phase: train, Batch: [356/657], Loss: 0.2100\n",
      "Epoch [4/10], Phase: train, Batch: [357/657], Loss: 0.2048\n",
      "Epoch [4/10], Phase: train, Batch: [358/657], Loss: 0.2486\n",
      "Epoch [4/10], Phase: train, Batch: [359/657], Loss: 0.1787\n",
      "Epoch [4/10], Phase: train, Batch: [360/657], Loss: 0.2289\n",
      "Epoch [4/10], Phase: train, Batch: [361/657], Loss: 0.2857\n",
      "Epoch [4/10], Phase: train, Batch: [362/657], Loss: 0.3631\n",
      "Epoch [4/10], Phase: train, Batch: [363/657], Loss: 0.1409\n",
      "Epoch [4/10], Phase: train, Batch: [364/657], Loss: 0.3197\n",
      "Epoch [4/10], Phase: train, Batch: [365/657], Loss: 0.4847\n",
      "Epoch [4/10], Phase: train, Batch: [366/657], Loss: 0.3995\n",
      "Epoch [4/10], Phase: train, Batch: [367/657], Loss: 0.2946\n",
      "Epoch [4/10], Phase: train, Batch: [368/657], Loss: 0.2870\n",
      "Epoch [4/10], Phase: train, Batch: [369/657], Loss: 0.2699\n",
      "Epoch [4/10], Phase: train, Batch: [370/657], Loss: 0.2202\n",
      "Epoch [4/10], Phase: train, Batch: [371/657], Loss: 0.3945\n",
      "Epoch [4/10], Phase: train, Batch: [372/657], Loss: 0.3722\n",
      "Epoch [4/10], Phase: train, Batch: [373/657], Loss: 0.3376\n",
      "Epoch [4/10], Phase: train, Batch: [374/657], Loss: 0.2402\n",
      "Epoch [4/10], Phase: train, Batch: [375/657], Loss: 0.2581\n",
      "Epoch [4/10], Phase: train, Batch: [376/657], Loss: 0.3116\n",
      "Epoch [4/10], Phase: train, Batch: [377/657], Loss: 0.2936\n",
      "Epoch [4/10], Phase: train, Batch: [378/657], Loss: 0.3192\n",
      "Epoch [4/10], Phase: train, Batch: [379/657], Loss: 0.1535\n",
      "Epoch [4/10], Phase: train, Batch: [380/657], Loss: 0.1826\n",
      "Epoch [4/10], Phase: train, Batch: [381/657], Loss: 0.2772\n",
      "Epoch [4/10], Phase: train, Batch: [382/657], Loss: 0.1676\n",
      "Epoch [4/10], Phase: train, Batch: [383/657], Loss: 0.2939\n",
      "Epoch [4/10], Phase: train, Batch: [384/657], Loss: 0.1762\n",
      "Epoch [4/10], Phase: train, Batch: [385/657], Loss: 0.2298\n",
      "Epoch [4/10], Phase: train, Batch: [386/657], Loss: 0.2013\n",
      "Epoch [4/10], Phase: train, Batch: [387/657], Loss: 0.2995\n",
      "Epoch [4/10], Phase: train, Batch: [388/657], Loss: 0.2769\n",
      "Epoch [4/10], Phase: train, Batch: [389/657], Loss: 0.3789\n",
      "Epoch [4/10], Phase: train, Batch: [390/657], Loss: 0.2269\n",
      "Epoch [4/10], Phase: train, Batch: [391/657], Loss: 0.2744\n",
      "Epoch [4/10], Phase: train, Batch: [392/657], Loss: 0.2821\n",
      "Epoch [4/10], Phase: train, Batch: [393/657], Loss: 0.3712\n",
      "Epoch [4/10], Phase: train, Batch: [394/657], Loss: 0.1693\n",
      "Epoch [4/10], Phase: train, Batch: [395/657], Loss: 0.3804\n",
      "Epoch [4/10], Phase: train, Batch: [396/657], Loss: 0.2963\n",
      "Epoch [4/10], Phase: train, Batch: [397/657], Loss: 0.1802\n",
      "Epoch [4/10], Phase: train, Batch: [398/657], Loss: 0.2645\n",
      "Epoch [4/10], Phase: train, Batch: [399/657], Loss: 0.2907\n",
      "Epoch [4/10], Phase: train, Batch: [400/657], Loss: 0.2694\n",
      "Epoch [4/10], Phase: train, Batch: [401/657], Loss: 0.4304\n",
      "Epoch [4/10], Phase: train, Batch: [402/657], Loss: 0.3745\n",
      "Epoch [4/10], Phase: train, Batch: [403/657], Loss: 0.2539\n",
      "Epoch [4/10], Phase: train, Batch: [404/657], Loss: 0.2663\n",
      "Epoch [4/10], Phase: train, Batch: [405/657], Loss: 0.1806\n",
      "Epoch [4/10], Phase: train, Batch: [406/657], Loss: 0.1944\n",
      "Epoch [4/10], Phase: train, Batch: [407/657], Loss: 0.3860\n",
      "Epoch [4/10], Phase: train, Batch: [408/657], Loss: 0.3101\n",
      "Epoch [4/10], Phase: train, Batch: [409/657], Loss: 0.2034\n",
      "Epoch [4/10], Phase: train, Batch: [410/657], Loss: 0.1535\n",
      "Epoch [4/10], Phase: train, Batch: [411/657], Loss: 0.3458\n",
      "Epoch [4/10], Phase: train, Batch: [412/657], Loss: 0.3386\n",
      "Epoch [4/10], Phase: train, Batch: [413/657], Loss: 0.3114\n",
      "Epoch [4/10], Phase: train, Batch: [414/657], Loss: 0.1731\n",
      "Epoch [4/10], Phase: train, Batch: [415/657], Loss: 0.4655\n",
      "Epoch [4/10], Phase: train, Batch: [416/657], Loss: 0.2297\n",
      "Epoch [4/10], Phase: train, Batch: [417/657], Loss: 0.2367\n",
      "Epoch [4/10], Phase: train, Batch: [418/657], Loss: 0.2574\n",
      "Epoch [4/10], Phase: train, Batch: [419/657], Loss: 0.2590\n",
      "Epoch [4/10], Phase: train, Batch: [420/657], Loss: 0.1499\n",
      "Epoch [4/10], Phase: train, Batch: [421/657], Loss: 0.2044\n",
      "Epoch [4/10], Phase: train, Batch: [422/657], Loss: 0.3603\n",
      "Epoch [4/10], Phase: train, Batch: [423/657], Loss: 0.3694\n",
      "Epoch [4/10], Phase: train, Batch: [424/657], Loss: 0.3647\n",
      "Epoch [4/10], Phase: train, Batch: [425/657], Loss: 0.1715\n",
      "Epoch [4/10], Phase: train, Batch: [426/657], Loss: 0.3209\n",
      "Epoch [4/10], Phase: train, Batch: [427/657], Loss: 0.2646\n",
      "Epoch [4/10], Phase: train, Batch: [428/657], Loss: 0.1976\n",
      "Epoch [4/10], Phase: train, Batch: [429/657], Loss: 0.1267\n",
      "Epoch [4/10], Phase: train, Batch: [430/657], Loss: 0.3040\n",
      "Epoch [4/10], Phase: train, Batch: [431/657], Loss: 0.1973\n",
      "Epoch [4/10], Phase: train, Batch: [432/657], Loss: 0.2019\n",
      "Epoch [4/10], Phase: train, Batch: [433/657], Loss: 0.3422\n",
      "Epoch [4/10], Phase: train, Batch: [434/657], Loss: 0.2624\n",
      "Epoch [4/10], Phase: train, Batch: [435/657], Loss: 0.2895\n",
      "Epoch [4/10], Phase: train, Batch: [436/657], Loss: 0.1617\n",
      "Epoch [4/10], Phase: train, Batch: [437/657], Loss: 0.3819\n",
      "Epoch [4/10], Phase: train, Batch: [438/657], Loss: 0.4093\n",
      "Epoch [4/10], Phase: train, Batch: [439/657], Loss: 0.2309\n",
      "Epoch [4/10], Phase: train, Batch: [440/657], Loss: 0.1947\n",
      "Epoch [4/10], Phase: train, Batch: [441/657], Loss: 0.2531\n",
      "Epoch [4/10], Phase: train, Batch: [442/657], Loss: 0.2392\n",
      "Epoch [4/10], Phase: train, Batch: [443/657], Loss: 0.1630\n",
      "Epoch [4/10], Phase: train, Batch: [444/657], Loss: 0.2653\n",
      "Epoch [4/10], Phase: train, Batch: [445/657], Loss: 0.4038\n",
      "Epoch [4/10], Phase: train, Batch: [446/657], Loss: 0.3550\n",
      "Epoch [4/10], Phase: train, Batch: [447/657], Loss: 0.2100\n",
      "Epoch [4/10], Phase: train, Batch: [448/657], Loss: 0.2387\n",
      "Epoch [4/10], Phase: train, Batch: [449/657], Loss: 0.2515\n",
      "Epoch [4/10], Phase: train, Batch: [450/657], Loss: 0.1860\n",
      "Epoch [4/10], Phase: train, Batch: [451/657], Loss: 0.3054\n",
      "Epoch [4/10], Phase: train, Batch: [452/657], Loss: 0.2894\n",
      "Epoch [4/10], Phase: train, Batch: [453/657], Loss: 0.4488\n",
      "Epoch [4/10], Phase: train, Batch: [454/657], Loss: 0.2386\n",
      "Epoch [4/10], Phase: train, Batch: [455/657], Loss: 0.2788\n",
      "Epoch [4/10], Phase: train, Batch: [456/657], Loss: 0.2193\n",
      "Epoch [4/10], Phase: train, Batch: [457/657], Loss: 0.4562\n",
      "Epoch [4/10], Phase: train, Batch: [458/657], Loss: 0.1560\n",
      "Epoch [4/10], Phase: train, Batch: [459/657], Loss: 0.3489\n",
      "Epoch [4/10], Phase: train, Batch: [460/657], Loss: 0.2304\n",
      "Epoch [4/10], Phase: train, Batch: [461/657], Loss: 0.1858\n",
      "Epoch [4/10], Phase: train, Batch: [462/657], Loss: 0.2635\n",
      "Epoch [4/10], Phase: train, Batch: [463/657], Loss: 0.4170\n",
      "Epoch [4/10], Phase: train, Batch: [464/657], Loss: 0.3317\n",
      "Epoch [4/10], Phase: train, Batch: [465/657], Loss: 0.3068\n",
      "Epoch [4/10], Phase: train, Batch: [466/657], Loss: 0.2927\n",
      "Epoch [4/10], Phase: train, Batch: [467/657], Loss: 0.1863\n",
      "Epoch [4/10], Phase: train, Batch: [468/657], Loss: 0.2805\n",
      "Epoch [4/10], Phase: train, Batch: [469/657], Loss: 0.3395\n",
      "Epoch [4/10], Phase: train, Batch: [470/657], Loss: 0.1860\n",
      "Epoch [4/10], Phase: train, Batch: [471/657], Loss: 0.1824\n",
      "Epoch [4/10], Phase: train, Batch: [472/657], Loss: 0.1477\n",
      "Epoch [4/10], Phase: train, Batch: [473/657], Loss: 0.2562\n",
      "Epoch [4/10], Phase: train, Batch: [474/657], Loss: 0.1856\n",
      "Epoch [4/10], Phase: train, Batch: [475/657], Loss: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [476/657], Loss: 0.2385\n",
      "Epoch [4/10], Phase: train, Batch: [477/657], Loss: 0.3247\n",
      "Epoch [4/10], Phase: train, Batch: [478/657], Loss: 0.2734\n",
      "Epoch [4/10], Phase: train, Batch: [479/657], Loss: 0.1809\n",
      "Epoch [4/10], Phase: train, Batch: [480/657], Loss: 0.3568\n",
      "Epoch [4/10], Phase: train, Batch: [481/657], Loss: 0.1900\n",
      "Epoch [4/10], Phase: train, Batch: [482/657], Loss: 0.2489\n",
      "Epoch [4/10], Phase: train, Batch: [483/657], Loss: 0.2102\n",
      "Epoch [4/10], Phase: train, Batch: [484/657], Loss: 0.2359\n",
      "Epoch [4/10], Phase: train, Batch: [485/657], Loss: 0.3944\n",
      "Epoch [4/10], Phase: train, Batch: [486/657], Loss: 0.2865\n",
      "Epoch [4/10], Phase: train, Batch: [487/657], Loss: 0.1689\n",
      "Epoch [4/10], Phase: train, Batch: [488/657], Loss: 0.2828\n",
      "Epoch [4/10], Phase: train, Batch: [489/657], Loss: 0.1681\n",
      "Epoch [4/10], Phase: train, Batch: [490/657], Loss: 0.1462\n",
      "Epoch [4/10], Phase: train, Batch: [491/657], Loss: 0.2290\n",
      "Epoch [4/10], Phase: train, Batch: [492/657], Loss: 0.2322\n",
      "Epoch [4/10], Phase: train, Batch: [493/657], Loss: 0.2200\n",
      "Epoch [4/10], Phase: train, Batch: [494/657], Loss: 0.3551\n",
      "Epoch [4/10], Phase: train, Batch: [495/657], Loss: 0.2030\n",
      "Epoch [4/10], Phase: train, Batch: [496/657], Loss: 0.2039\n",
      "Epoch [4/10], Phase: train, Batch: [497/657], Loss: 0.2877\n",
      "Epoch [4/10], Phase: train, Batch: [498/657], Loss: 0.2876\n",
      "Epoch [4/10], Phase: train, Batch: [499/657], Loss: 0.2414\n",
      "Epoch [4/10], Phase: train, Batch: [500/657], Loss: 0.2413\n",
      "Epoch [4/10], Phase: train, Batch: [501/657], Loss: 0.1356\n",
      "Epoch [4/10], Phase: train, Batch: [502/657], Loss: 0.3002\n",
      "Epoch [4/10], Phase: train, Batch: [503/657], Loss: 0.1809\n",
      "Epoch [4/10], Phase: train, Batch: [504/657], Loss: 0.2686\n",
      "Epoch [4/10], Phase: train, Batch: [505/657], Loss: 0.3168\n",
      "Epoch [4/10], Phase: train, Batch: [506/657], Loss: 0.3018\n",
      "Epoch [4/10], Phase: train, Batch: [507/657], Loss: 0.2201\n",
      "Epoch [4/10], Phase: train, Batch: [508/657], Loss: 0.2527\n",
      "Epoch [4/10], Phase: train, Batch: [509/657], Loss: 0.2577\n",
      "Epoch [4/10], Phase: train, Batch: [510/657], Loss: 0.2493\n",
      "Epoch [4/10], Phase: train, Batch: [511/657], Loss: 0.2174\n",
      "Epoch [4/10], Phase: train, Batch: [512/657], Loss: 0.2934\n",
      "Epoch [4/10], Phase: train, Batch: [513/657], Loss: 0.2929\n",
      "Epoch [4/10], Phase: train, Batch: [514/657], Loss: 0.1811\n",
      "Epoch [4/10], Phase: train, Batch: [515/657], Loss: 0.2234\n",
      "Epoch [4/10], Phase: train, Batch: [516/657], Loss: 0.2004\n",
      "Epoch [4/10], Phase: train, Batch: [517/657], Loss: 0.3688\n",
      "Epoch [4/10], Phase: train, Batch: [518/657], Loss: 0.2705\n",
      "Epoch [4/10], Phase: train, Batch: [519/657], Loss: 0.2083\n",
      "Epoch [4/10], Phase: train, Batch: [520/657], Loss: 0.2697\n",
      "Epoch [4/10], Phase: train, Batch: [521/657], Loss: 0.3240\n",
      "Epoch [4/10], Phase: train, Batch: [522/657], Loss: 0.2183\n",
      "Epoch [4/10], Phase: train, Batch: [523/657], Loss: 0.2009\n",
      "Epoch [4/10], Phase: train, Batch: [524/657], Loss: 0.3491\n",
      "Epoch [4/10], Phase: train, Batch: [525/657], Loss: 0.1706\n",
      "Epoch [4/10], Phase: train, Batch: [526/657], Loss: 0.4092\n",
      "Epoch [4/10], Phase: train, Batch: [527/657], Loss: 0.2320\n",
      "Epoch [4/10], Phase: train, Batch: [528/657], Loss: 0.2763\n",
      "Epoch [4/10], Phase: train, Batch: [529/657], Loss: 0.3281\n",
      "Epoch [4/10], Phase: train, Batch: [530/657], Loss: 0.3305\n",
      "Epoch [4/10], Phase: train, Batch: [531/657], Loss: 0.3217\n",
      "Epoch [4/10], Phase: train, Batch: [532/657], Loss: 0.3904\n",
      "Epoch [4/10], Phase: train, Batch: [533/657], Loss: 0.2834\n",
      "Epoch [4/10], Phase: train, Batch: [534/657], Loss: 0.2663\n",
      "Epoch [4/10], Phase: train, Batch: [535/657], Loss: 0.3055\n",
      "Epoch [4/10], Phase: train, Batch: [536/657], Loss: 0.2717\n",
      "Epoch [4/10], Phase: train, Batch: [537/657], Loss: 0.2931\n",
      "Epoch [4/10], Phase: train, Batch: [538/657], Loss: 0.2955\n",
      "Epoch [4/10], Phase: train, Batch: [539/657], Loss: 0.2360\n",
      "Epoch [4/10], Phase: train, Batch: [540/657], Loss: 0.3756\n",
      "Epoch [4/10], Phase: train, Batch: [541/657], Loss: 0.2766\n",
      "Epoch [4/10], Phase: train, Batch: [542/657], Loss: 0.2357\n",
      "Epoch [4/10], Phase: train, Batch: [543/657], Loss: 0.3250\n",
      "Epoch [4/10], Phase: train, Batch: [544/657], Loss: 0.2837\n",
      "Epoch [4/10], Phase: train, Batch: [545/657], Loss: 0.2263\n",
      "Epoch [4/10], Phase: train, Batch: [546/657], Loss: 0.3870\n",
      "Epoch [4/10], Phase: train, Batch: [547/657], Loss: 0.2142\n",
      "Epoch [4/10], Phase: train, Batch: [548/657], Loss: 0.2517\n",
      "Epoch [4/10], Phase: train, Batch: [549/657], Loss: 0.2932\n",
      "Epoch [4/10], Phase: train, Batch: [550/657], Loss: 0.3973\n",
      "Epoch [4/10], Phase: train, Batch: [551/657], Loss: 0.3287\n",
      "Epoch [4/10], Phase: train, Batch: [552/657], Loss: 0.2812\n",
      "Epoch [4/10], Phase: train, Batch: [553/657], Loss: 0.5754\n",
      "Epoch [4/10], Phase: train, Batch: [554/657], Loss: 0.3187\n",
      "Epoch [4/10], Phase: train, Batch: [555/657], Loss: 0.2339\n",
      "Epoch [4/10], Phase: train, Batch: [556/657], Loss: 0.4580\n",
      "Epoch [4/10], Phase: train, Batch: [557/657], Loss: 0.2781\n",
      "Epoch [4/10], Phase: train, Batch: [558/657], Loss: 0.3698\n",
      "Epoch [4/10], Phase: train, Batch: [559/657], Loss: 0.2557\n",
      "Epoch [4/10], Phase: train, Batch: [560/657], Loss: 0.3424\n",
      "Epoch [4/10], Phase: train, Batch: [561/657], Loss: 0.2298\n",
      "Epoch [4/10], Phase: train, Batch: [562/657], Loss: 0.3320\n",
      "Epoch [4/10], Phase: train, Batch: [563/657], Loss: 0.2931\n",
      "Epoch [4/10], Phase: train, Batch: [564/657], Loss: 0.4337\n",
      "Epoch [4/10], Phase: train, Batch: [565/657], Loss: 0.3430\n",
      "Epoch [4/10], Phase: train, Batch: [566/657], Loss: 0.2688\n",
      "Epoch [4/10], Phase: train, Batch: [567/657], Loss: 0.2754\n",
      "Epoch [4/10], Phase: train, Batch: [568/657], Loss: 0.1859\n",
      "Epoch [4/10], Phase: train, Batch: [569/657], Loss: 0.2683\n",
      "Epoch [4/10], Phase: train, Batch: [570/657], Loss: 0.3153\n",
      "Epoch [4/10], Phase: train, Batch: [571/657], Loss: 0.1738\n",
      "Epoch [4/10], Phase: train, Batch: [572/657], Loss: 0.4015\n",
      "Epoch [4/10], Phase: train, Batch: [573/657], Loss: 0.2491\n",
      "Epoch [4/10], Phase: train, Batch: [574/657], Loss: 0.2079\n",
      "Epoch [4/10], Phase: train, Batch: [575/657], Loss: 0.3806\n",
      "Epoch [4/10], Phase: train, Batch: [576/657], Loss: 0.1745\n",
      "Epoch [4/10], Phase: train, Batch: [577/657], Loss: 0.2535\n",
      "Epoch [4/10], Phase: train, Batch: [578/657], Loss: 0.1847\n",
      "Epoch [4/10], Phase: train, Batch: [579/657], Loss: 0.3090\n",
      "Epoch [4/10], Phase: train, Batch: [580/657], Loss: 0.4002\n",
      "Epoch [4/10], Phase: train, Batch: [581/657], Loss: 0.3855\n",
      "Epoch [4/10], Phase: train, Batch: [582/657], Loss: 0.4846\n",
      "Epoch [4/10], Phase: train, Batch: [583/657], Loss: 0.2686\n",
      "Epoch [4/10], Phase: train, Batch: [584/657], Loss: 0.2330\n",
      "Epoch [4/10], Phase: train, Batch: [585/657], Loss: 0.2647\n",
      "Epoch [4/10], Phase: train, Batch: [586/657], Loss: 0.4459\n",
      "Epoch [4/10], Phase: train, Batch: [587/657], Loss: 0.2063\n",
      "Epoch [4/10], Phase: train, Batch: [588/657], Loss: 0.2681\n",
      "Epoch [4/10], Phase: train, Batch: [589/657], Loss: 0.3675\n",
      "Epoch [4/10], Phase: train, Batch: [590/657], Loss: 0.2057\n",
      "Epoch [4/10], Phase: train, Batch: [591/657], Loss: 0.2415\n",
      "Epoch [4/10], Phase: train, Batch: [592/657], Loss: 0.2550\n",
      "Epoch [4/10], Phase: train, Batch: [593/657], Loss: 0.1313\n",
      "Epoch [4/10], Phase: train, Batch: [594/657], Loss: 0.3614\n",
      "Epoch [4/10], Phase: train, Batch: [595/657], Loss: 0.2861\n",
      "Epoch [4/10], Phase: train, Batch: [596/657], Loss: 0.2677\n",
      "Epoch [4/10], Phase: train, Batch: [597/657], Loss: 0.2979\n",
      "Epoch [4/10], Phase: train, Batch: [598/657], Loss: 0.2062\n",
      "Epoch [4/10], Phase: train, Batch: [599/657], Loss: 0.1943\n",
      "Epoch [4/10], Phase: train, Batch: [600/657], Loss: 0.2636\n",
      "Epoch [4/10], Phase: train, Batch: [601/657], Loss: 0.2731\n",
      "Epoch [4/10], Phase: train, Batch: [602/657], Loss: 0.2348\n",
      "Epoch [4/10], Phase: train, Batch: [603/657], Loss: 0.2512\n",
      "Epoch [4/10], Phase: train, Batch: [604/657], Loss: 0.1708\n",
      "Epoch [4/10], Phase: train, Batch: [605/657], Loss: 0.2832\n",
      "Epoch [4/10], Phase: train, Batch: [606/657], Loss: 0.2828\n",
      "Epoch [4/10], Phase: train, Batch: [607/657], Loss: 0.2413\n",
      "Epoch [4/10], Phase: train, Batch: [608/657], Loss: 0.2356\n",
      "Epoch [4/10], Phase: train, Batch: [609/657], Loss: 0.2609\n",
      "Epoch [4/10], Phase: train, Batch: [610/657], Loss: 0.3274\n",
      "Epoch [4/10], Phase: train, Batch: [611/657], Loss: 0.2741\n",
      "Epoch [4/10], Phase: train, Batch: [612/657], Loss: 0.3112\n",
      "Epoch [4/10], Phase: train, Batch: [613/657], Loss: 0.3497\n",
      "Epoch [4/10], Phase: train, Batch: [614/657], Loss: 0.2470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Phase: train, Batch: [615/657], Loss: 0.2207\n",
      "Epoch [4/10], Phase: train, Batch: [616/657], Loss: 0.2729\n",
      "Epoch [4/10], Phase: train, Batch: [617/657], Loss: 0.3834\n",
      "Epoch [4/10], Phase: train, Batch: [618/657], Loss: 0.3069\n",
      "Epoch [4/10], Phase: train, Batch: [619/657], Loss: 0.2459\n",
      "Epoch [4/10], Phase: train, Batch: [620/657], Loss: 0.2079\n",
      "Epoch [4/10], Phase: train, Batch: [621/657], Loss: 0.3554\n",
      "Epoch [4/10], Phase: train, Batch: [622/657], Loss: 0.1854\n",
      "Epoch [4/10], Phase: train, Batch: [623/657], Loss: 0.2534\n",
      "Epoch [4/10], Phase: train, Batch: [624/657], Loss: 0.3146\n",
      "Epoch [4/10], Phase: train, Batch: [625/657], Loss: 0.3020\n",
      "Epoch [4/10], Phase: train, Batch: [626/657], Loss: 0.1250\n",
      "Epoch [4/10], Phase: train, Batch: [627/657], Loss: 0.1904\n",
      "Epoch [4/10], Phase: train, Batch: [628/657], Loss: 0.3246\n",
      "Epoch [4/10], Phase: train, Batch: [629/657], Loss: 0.3095\n",
      "Epoch [4/10], Phase: train, Batch: [630/657], Loss: 0.2953\n",
      "Epoch [4/10], Phase: train, Batch: [631/657], Loss: 0.1965\n",
      "Epoch [4/10], Phase: train, Batch: [632/657], Loss: 0.2021\n",
      "Epoch [4/10], Phase: train, Batch: [633/657], Loss: 0.1972\n",
      "Epoch [4/10], Phase: train, Batch: [634/657], Loss: 0.4182\n",
      "Epoch [4/10], Phase: train, Batch: [635/657], Loss: 0.3259\n",
      "Epoch [4/10], Phase: train, Batch: [636/657], Loss: 0.2093\n",
      "Epoch [4/10], Phase: train, Batch: [637/657], Loss: 0.4312\n",
      "Epoch [4/10], Phase: train, Batch: [638/657], Loss: 0.2767\n",
      "Epoch [4/10], Phase: train, Batch: [639/657], Loss: 0.2252\n",
      "Epoch [4/10], Phase: train, Batch: [640/657], Loss: 0.3350\n",
      "Epoch [4/10], Phase: train, Batch: [641/657], Loss: 0.2693\n",
      "Epoch [4/10], Phase: train, Batch: [642/657], Loss: 0.3839\n",
      "Epoch [4/10], Phase: train, Batch: [643/657], Loss: 0.2833\n",
      "Epoch [4/10], Phase: train, Batch: [644/657], Loss: 0.2189\n",
      "Epoch [4/10], Phase: train, Batch: [645/657], Loss: 0.2803\n",
      "Epoch [4/10], Phase: train, Batch: [646/657], Loss: 0.3861\n",
      "Epoch [4/10], Phase: train, Batch: [647/657], Loss: 0.3756\n",
      "Epoch [4/10], Phase: train, Batch: [648/657], Loss: 0.1664\n",
      "Epoch [4/10], Phase: train, Batch: [649/657], Loss: 0.4254\n",
      "Epoch [4/10], Phase: train, Batch: [650/657], Loss: 0.3441\n",
      "Epoch [4/10], Phase: train, Batch: [651/657], Loss: 0.4845\n",
      "Epoch [4/10], Phase: train, Batch: [652/657], Loss: 0.1633\n",
      "Epoch [4/10], Phase: train, Batch: [653/657], Loss: 0.4239\n",
      "Epoch [4/10], Phase: train, Batch: [654/657], Loss: 0.4369\n",
      "Epoch [4/10], Phase: train, Batch: [655/657], Loss: 0.2247\n",
      "Epoch [4/10], Phase: train, Batch: [656/657], Loss: 0.3413\n",
      "Epoch [4/10], Phase: train, Batch: [657/657], Loss: 0.4069\n",
      "train Loss: 0.2758 Acc: 0.8904\n",
      "Epoch [4/10], Phase: val, Batch: [1/73], Loss: 0.3185\n",
      "Epoch [4/10], Phase: val, Batch: [2/73], Loss: 0.2969\n",
      "Epoch [4/10], Phase: val, Batch: [3/73], Loss: 0.1570\n",
      "Epoch [4/10], Phase: val, Batch: [4/73], Loss: 0.3600\n",
      "Epoch [4/10], Phase: val, Batch: [5/73], Loss: 0.2165\n",
      "Epoch [4/10], Phase: val, Batch: [6/73], Loss: 0.2756\n",
      "Epoch [4/10], Phase: val, Batch: [7/73], Loss: 0.1952\n",
      "Epoch [4/10], Phase: val, Batch: [8/73], Loss: 0.2218\n",
      "Epoch [4/10], Phase: val, Batch: [9/73], Loss: 0.0844\n",
      "Epoch [4/10], Phase: val, Batch: [10/73], Loss: 0.1941\n",
      "Epoch [4/10], Phase: val, Batch: [11/73], Loss: 0.1800\n",
      "Epoch [4/10], Phase: val, Batch: [12/73], Loss: 0.2460\n",
      "Epoch [4/10], Phase: val, Batch: [13/73], Loss: 0.1365\n",
      "Epoch [4/10], Phase: val, Batch: [14/73], Loss: 0.2912\n",
      "Epoch [4/10], Phase: val, Batch: [15/73], Loss: 0.2063\n",
      "Epoch [4/10], Phase: val, Batch: [16/73], Loss: 0.3099\n",
      "Epoch [4/10], Phase: val, Batch: [17/73], Loss: 0.1129\n",
      "Epoch [4/10], Phase: val, Batch: [18/73], Loss: 0.2500\n",
      "Epoch [4/10], Phase: val, Batch: [19/73], Loss: 0.3246\n",
      "Epoch [4/10], Phase: val, Batch: [20/73], Loss: 0.1715\n",
      "Epoch [4/10], Phase: val, Batch: [21/73], Loss: 0.3351\n",
      "Epoch [4/10], Phase: val, Batch: [22/73], Loss: 0.2077\n",
      "Epoch [4/10], Phase: val, Batch: [23/73], Loss: 0.2622\n",
      "Epoch [4/10], Phase: val, Batch: [24/73], Loss: 0.2879\n",
      "Epoch [4/10], Phase: val, Batch: [25/73], Loss: 0.1857\n",
      "Epoch [4/10], Phase: val, Batch: [26/73], Loss: 0.1813\n",
      "Epoch [4/10], Phase: val, Batch: [27/73], Loss: 0.2569\n",
      "Epoch [4/10], Phase: val, Batch: [28/73], Loss: 0.2421\n",
      "Epoch [4/10], Phase: val, Batch: [29/73], Loss: 0.3414\n",
      "Epoch [4/10], Phase: val, Batch: [30/73], Loss: 0.3399\n",
      "Epoch [4/10], Phase: val, Batch: [31/73], Loss: 0.1819\n",
      "Epoch [4/10], Phase: val, Batch: [32/73], Loss: 0.2774\n",
      "Epoch [4/10], Phase: val, Batch: [33/73], Loss: 0.3871\n",
      "Epoch [4/10], Phase: val, Batch: [34/73], Loss: 0.2095\n",
      "Epoch [4/10], Phase: val, Batch: [35/73], Loss: 0.1782\n",
      "Epoch [4/10], Phase: val, Batch: [36/73], Loss: 0.3404\n",
      "Epoch [4/10], Phase: val, Batch: [37/73], Loss: 0.2176\n",
      "Epoch [4/10], Phase: val, Batch: [38/73], Loss: 0.1685\n",
      "Epoch [4/10], Phase: val, Batch: [39/73], Loss: 0.2166\n",
      "Epoch [4/10], Phase: val, Batch: [40/73], Loss: 0.1954\n",
      "Epoch [4/10], Phase: val, Batch: [41/73], Loss: 0.2220\n",
      "Epoch [4/10], Phase: val, Batch: [42/73], Loss: 0.2684\n",
      "Epoch [4/10], Phase: val, Batch: [43/73], Loss: 0.2194\n",
      "Epoch [4/10], Phase: val, Batch: [44/73], Loss: 0.2373\n",
      "Epoch [4/10], Phase: val, Batch: [45/73], Loss: 0.1896\n",
      "Epoch [4/10], Phase: val, Batch: [46/73], Loss: 0.3060\n",
      "Epoch [4/10], Phase: val, Batch: [47/73], Loss: 0.2867\n",
      "Epoch [4/10], Phase: val, Batch: [48/73], Loss: 0.1429\n",
      "Epoch [4/10], Phase: val, Batch: [49/73], Loss: 0.2989\n",
      "Epoch [4/10], Phase: val, Batch: [50/73], Loss: 0.1823\n",
      "Epoch [4/10], Phase: val, Batch: [51/73], Loss: 0.3091\n",
      "Epoch [4/10], Phase: val, Batch: [52/73], Loss: 0.1902\n",
      "Epoch [4/10], Phase: val, Batch: [53/73], Loss: 0.2165\n",
      "Epoch [4/10], Phase: val, Batch: [54/73], Loss: 0.2092\n",
      "Epoch [4/10], Phase: val, Batch: [55/73], Loss: 0.2381\n",
      "Epoch [4/10], Phase: val, Batch: [56/73], Loss: 0.3029\n",
      "Epoch [4/10], Phase: val, Batch: [57/73], Loss: 0.1396\n",
      "Epoch [4/10], Phase: val, Batch: [58/73], Loss: 0.2552\n",
      "Epoch [4/10], Phase: val, Batch: [59/73], Loss: 0.2450\n",
      "Epoch [4/10], Phase: val, Batch: [60/73], Loss: 0.1727\n",
      "Epoch [4/10], Phase: val, Batch: [61/73], Loss: 0.3315\n",
      "Epoch [4/10], Phase: val, Batch: [62/73], Loss: 0.2351\n",
      "Epoch [4/10], Phase: val, Batch: [63/73], Loss: 0.2312\n",
      "Epoch [4/10], Phase: val, Batch: [64/73], Loss: 0.2810\n",
      "Epoch [4/10], Phase: val, Batch: [65/73], Loss: 0.2431\n",
      "Epoch [4/10], Phase: val, Batch: [66/73], Loss: 0.1808\n",
      "Epoch [4/10], Phase: val, Batch: [67/73], Loss: 0.2186\n",
      "Epoch [4/10], Phase: val, Batch: [68/73], Loss: 0.2175\n",
      "Epoch [4/10], Phase: val, Batch: [69/73], Loss: 0.2979\n",
      "Epoch [4/10], Phase: val, Batch: [70/73], Loss: 0.2449\n",
      "Epoch [4/10], Phase: val, Batch: [71/73], Loss: 0.3126\n",
      "Epoch [4/10], Phase: val, Batch: [72/73], Loss: 0.4064\n",
      "Epoch [4/10], Phase: val, Batch: [73/73], Loss: 0.1147\n",
      "val Loss: 0.2400 Acc: 0.9019\n",
      "Epoch [5/10], Phase: train, Batch: [1/657], Loss: 0.2574\n",
      "Epoch [5/10], Phase: train, Batch: [2/657], Loss: 0.2627\n",
      "Epoch [5/10], Phase: train, Batch: [3/657], Loss: 0.3605\n",
      "Epoch [5/10], Phase: train, Batch: [4/657], Loss: 0.2938\n",
      "Epoch [5/10], Phase: train, Batch: [5/657], Loss: 0.2574\n",
      "Epoch [5/10], Phase: train, Batch: [6/657], Loss: 0.2222\n",
      "Epoch [5/10], Phase: train, Batch: [7/657], Loss: 0.2773\n",
      "Epoch [5/10], Phase: train, Batch: [8/657], Loss: 0.4086\n",
      "Epoch [5/10], Phase: train, Batch: [9/657], Loss: 0.2541\n",
      "Epoch [5/10], Phase: train, Batch: [10/657], Loss: 0.2075\n",
      "Epoch [5/10], Phase: train, Batch: [11/657], Loss: 0.2563\n",
      "Epoch [5/10], Phase: train, Batch: [12/657], Loss: 0.1108\n",
      "Epoch [5/10], Phase: train, Batch: [13/657], Loss: 0.2563\n",
      "Epoch [5/10], Phase: train, Batch: [14/657], Loss: 0.3675\n",
      "Epoch [5/10], Phase: train, Batch: [15/657], Loss: 0.3955\n",
      "Epoch [5/10], Phase: train, Batch: [16/657], Loss: 0.2273\n",
      "Epoch [5/10], Phase: train, Batch: [17/657], Loss: 0.2784\n",
      "Epoch [5/10], Phase: train, Batch: [18/657], Loss: 0.2524\n",
      "Epoch [5/10], Phase: train, Batch: [19/657], Loss: 0.2679\n",
      "Epoch [5/10], Phase: train, Batch: [20/657], Loss: 0.1787\n",
      "Epoch [5/10], Phase: train, Batch: [21/657], Loss: 0.1855\n",
      "Epoch [5/10], Phase: train, Batch: [22/657], Loss: 0.2416\n",
      "Epoch [5/10], Phase: train, Batch: [23/657], Loss: 0.2148\n",
      "Epoch [5/10], Phase: train, Batch: [24/657], Loss: 0.3228\n",
      "Epoch [5/10], Phase: train, Batch: [25/657], Loss: 0.2626\n",
      "Epoch [5/10], Phase: train, Batch: [26/657], Loss: 0.2217\n",
      "Epoch [5/10], Phase: train, Batch: [27/657], Loss: 0.3153\n",
      "Epoch [5/10], Phase: train, Batch: [28/657], Loss: 0.2771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [29/657], Loss: 0.2792\n",
      "Epoch [5/10], Phase: train, Batch: [30/657], Loss: 0.2402\n",
      "Epoch [5/10], Phase: train, Batch: [31/657], Loss: 0.3279\n",
      "Epoch [5/10], Phase: train, Batch: [32/657], Loss: 0.5116\n",
      "Epoch [5/10], Phase: train, Batch: [33/657], Loss: 0.1865\n",
      "Epoch [5/10], Phase: train, Batch: [34/657], Loss: 0.2848\n",
      "Epoch [5/10], Phase: train, Batch: [35/657], Loss: 0.2706\n",
      "Epoch [5/10], Phase: train, Batch: [36/657], Loss: 0.4194\n",
      "Epoch [5/10], Phase: train, Batch: [37/657], Loss: 0.3160\n",
      "Epoch [5/10], Phase: train, Batch: [38/657], Loss: 0.2627\n",
      "Epoch [5/10], Phase: train, Batch: [39/657], Loss: 0.2313\n",
      "Epoch [5/10], Phase: train, Batch: [40/657], Loss: 0.3411\n",
      "Epoch [5/10], Phase: train, Batch: [41/657], Loss: 0.3476\n",
      "Epoch [5/10], Phase: train, Batch: [42/657], Loss: 0.2491\n",
      "Epoch [5/10], Phase: train, Batch: [43/657], Loss: 0.2072\n",
      "Epoch [5/10], Phase: train, Batch: [44/657], Loss: 0.2963\n",
      "Epoch [5/10], Phase: train, Batch: [45/657], Loss: 0.1818\n",
      "Epoch [5/10], Phase: train, Batch: [46/657], Loss: 0.4790\n",
      "Epoch [5/10], Phase: train, Batch: [47/657], Loss: 0.3915\n",
      "Epoch [5/10], Phase: train, Batch: [48/657], Loss: 0.2053\n",
      "Epoch [5/10], Phase: train, Batch: [49/657], Loss: 0.2297\n",
      "Epoch [5/10], Phase: train, Batch: [50/657], Loss: 0.2860\n",
      "Epoch [5/10], Phase: train, Batch: [51/657], Loss: 0.2493\n",
      "Epoch [5/10], Phase: train, Batch: [52/657], Loss: 0.2990\n",
      "Epoch [5/10], Phase: train, Batch: [53/657], Loss: 0.1836\n",
      "Epoch [5/10], Phase: train, Batch: [54/657], Loss: 0.1922\n",
      "Epoch [5/10], Phase: train, Batch: [55/657], Loss: 0.2140\n",
      "Epoch [5/10], Phase: train, Batch: [56/657], Loss: 0.2307\n",
      "Epoch [5/10], Phase: train, Batch: [57/657], Loss: 0.2069\n",
      "Epoch [5/10], Phase: train, Batch: [58/657], Loss: 0.2391\n",
      "Epoch [5/10], Phase: train, Batch: [59/657], Loss: 0.3226\n",
      "Epoch [5/10], Phase: train, Batch: [60/657], Loss: 0.3131\n",
      "Epoch [5/10], Phase: train, Batch: [61/657], Loss: 0.4571\n",
      "Epoch [5/10], Phase: train, Batch: [62/657], Loss: 0.2122\n",
      "Epoch [5/10], Phase: train, Batch: [63/657], Loss: 0.2520\n",
      "Epoch [5/10], Phase: train, Batch: [64/657], Loss: 0.1596\n",
      "Epoch [5/10], Phase: train, Batch: [65/657], Loss: 0.2474\n",
      "Epoch [5/10], Phase: train, Batch: [66/657], Loss: 0.2756\n",
      "Epoch [5/10], Phase: train, Batch: [67/657], Loss: 0.3035\n",
      "Epoch [5/10], Phase: train, Batch: [68/657], Loss: 0.3618\n",
      "Epoch [5/10], Phase: train, Batch: [69/657], Loss: 0.2607\n",
      "Epoch [5/10], Phase: train, Batch: [70/657], Loss: 0.3824\n",
      "Epoch [5/10], Phase: train, Batch: [71/657], Loss: 0.2400\n",
      "Epoch [5/10], Phase: train, Batch: [72/657], Loss: 0.1919\n",
      "Epoch [5/10], Phase: train, Batch: [73/657], Loss: 0.1703\n",
      "Epoch [5/10], Phase: train, Batch: [74/657], Loss: 0.3594\n",
      "Epoch [5/10], Phase: train, Batch: [75/657], Loss: 0.3997\n",
      "Epoch [5/10], Phase: train, Batch: [76/657], Loss: 0.4176\n",
      "Epoch [5/10], Phase: train, Batch: [77/657], Loss: 0.2225\n",
      "Epoch [5/10], Phase: train, Batch: [78/657], Loss: 0.2685\n",
      "Epoch [5/10], Phase: train, Batch: [79/657], Loss: 0.2734\n",
      "Epoch [5/10], Phase: train, Batch: [80/657], Loss: 0.2655\n",
      "Epoch [5/10], Phase: train, Batch: [81/657], Loss: 0.2153\n",
      "Epoch [5/10], Phase: train, Batch: [82/657], Loss: 0.2492\n",
      "Epoch [5/10], Phase: train, Batch: [83/657], Loss: 0.1803\n",
      "Epoch [5/10], Phase: train, Batch: [84/657], Loss: 0.2561\n",
      "Epoch [5/10], Phase: train, Batch: [85/657], Loss: 0.2019\n",
      "Epoch [5/10], Phase: train, Batch: [86/657], Loss: 0.1834\n",
      "Epoch [5/10], Phase: train, Batch: [87/657], Loss: 0.2520\n",
      "Epoch [5/10], Phase: train, Batch: [88/657], Loss: 0.2455\n",
      "Epoch [5/10], Phase: train, Batch: [89/657], Loss: 0.3111\n",
      "Epoch [5/10], Phase: train, Batch: [90/657], Loss: 0.2317\n",
      "Epoch [5/10], Phase: train, Batch: [91/657], Loss: 0.2661\n",
      "Epoch [5/10], Phase: train, Batch: [92/657], Loss: 0.2599\n",
      "Epoch [5/10], Phase: train, Batch: [93/657], Loss: 0.2437\n",
      "Epoch [5/10], Phase: train, Batch: [94/657], Loss: 0.3123\n",
      "Epoch [5/10], Phase: train, Batch: [95/657], Loss: 0.2276\n",
      "Epoch [5/10], Phase: train, Batch: [96/657], Loss: 0.4126\n",
      "Epoch [5/10], Phase: train, Batch: [97/657], Loss: 0.2101\n",
      "Epoch [5/10], Phase: train, Batch: [98/657], Loss: 0.1667\n",
      "Epoch [5/10], Phase: train, Batch: [99/657], Loss: 0.2401\n",
      "Epoch [5/10], Phase: train, Batch: [100/657], Loss: 0.2918\n",
      "Epoch [5/10], Phase: train, Batch: [101/657], Loss: 0.2461\n",
      "Epoch [5/10], Phase: train, Batch: [102/657], Loss: 0.2911\n",
      "Epoch [5/10], Phase: train, Batch: [103/657], Loss: 0.3938\n",
      "Epoch [5/10], Phase: train, Batch: [104/657], Loss: 0.2496\n",
      "Epoch [5/10], Phase: train, Batch: [105/657], Loss: 0.2609\n",
      "Epoch [5/10], Phase: train, Batch: [106/657], Loss: 0.4117\n",
      "Epoch [5/10], Phase: train, Batch: [107/657], Loss: 0.3260\n",
      "Epoch [5/10], Phase: train, Batch: [108/657], Loss: 0.3965\n",
      "Epoch [5/10], Phase: train, Batch: [109/657], Loss: 0.3875\n",
      "Epoch [5/10], Phase: train, Batch: [110/657], Loss: 0.2264\n",
      "Epoch [5/10], Phase: train, Batch: [111/657], Loss: 0.1731\n",
      "Epoch [5/10], Phase: train, Batch: [112/657], Loss: 0.2263\n",
      "Epoch [5/10], Phase: train, Batch: [113/657], Loss: 0.4009\n",
      "Epoch [5/10], Phase: train, Batch: [114/657], Loss: 0.2619\n",
      "Epoch [5/10], Phase: train, Batch: [115/657], Loss: 0.2339\n",
      "Epoch [5/10], Phase: train, Batch: [116/657], Loss: 0.2895\n",
      "Epoch [5/10], Phase: train, Batch: [117/657], Loss: 0.3012\n",
      "Epoch [5/10], Phase: train, Batch: [118/657], Loss: 0.3152\n",
      "Epoch [5/10], Phase: train, Batch: [119/657], Loss: 0.3007\n",
      "Epoch [5/10], Phase: train, Batch: [120/657], Loss: 0.2762\n",
      "Epoch [5/10], Phase: train, Batch: [121/657], Loss: 0.3099\n",
      "Epoch [5/10], Phase: train, Batch: [122/657], Loss: 0.3415\n",
      "Epoch [5/10], Phase: train, Batch: [123/657], Loss: 0.2957\n",
      "Epoch [5/10], Phase: train, Batch: [124/657], Loss: 0.1971\n",
      "Epoch [5/10], Phase: train, Batch: [125/657], Loss: 0.3372\n",
      "Epoch [5/10], Phase: train, Batch: [126/657], Loss: 0.1262\n",
      "Epoch [5/10], Phase: train, Batch: [127/657], Loss: 0.3218\n",
      "Epoch [5/10], Phase: train, Batch: [128/657], Loss: 0.2180\n",
      "Epoch [5/10], Phase: train, Batch: [129/657], Loss: 0.3456\n",
      "Epoch [5/10], Phase: train, Batch: [130/657], Loss: 0.1640\n",
      "Epoch [5/10], Phase: train, Batch: [131/657], Loss: 0.2465\n",
      "Epoch [5/10], Phase: train, Batch: [132/657], Loss: 0.2166\n",
      "Epoch [5/10], Phase: train, Batch: [133/657], Loss: 0.2978\n",
      "Epoch [5/10], Phase: train, Batch: [134/657], Loss: 0.3095\n",
      "Epoch [5/10], Phase: train, Batch: [135/657], Loss: 0.3963\n",
      "Epoch [5/10], Phase: train, Batch: [136/657], Loss: 0.3213\n",
      "Epoch [5/10], Phase: train, Batch: [137/657], Loss: 0.2200\n",
      "Epoch [5/10], Phase: train, Batch: [138/657], Loss: 0.3038\n",
      "Epoch [5/10], Phase: train, Batch: [139/657], Loss: 0.2354\n",
      "Epoch [5/10], Phase: train, Batch: [140/657], Loss: 0.2128\n",
      "Epoch [5/10], Phase: train, Batch: [141/657], Loss: 0.2819\n",
      "Epoch [5/10], Phase: train, Batch: [142/657], Loss: 0.2739\n",
      "Epoch [5/10], Phase: train, Batch: [143/657], Loss: 0.2240\n",
      "Epoch [5/10], Phase: train, Batch: [144/657], Loss: 0.2954\n",
      "Epoch [5/10], Phase: train, Batch: [145/657], Loss: 0.4912\n",
      "Epoch [5/10], Phase: train, Batch: [146/657], Loss: 0.1891\n",
      "Epoch [5/10], Phase: train, Batch: [147/657], Loss: 0.1973\n",
      "Epoch [5/10], Phase: train, Batch: [148/657], Loss: 0.3362\n",
      "Epoch [5/10], Phase: train, Batch: [149/657], Loss: 0.2434\n",
      "Epoch [5/10], Phase: train, Batch: [150/657], Loss: 0.2295\n",
      "Epoch [5/10], Phase: train, Batch: [151/657], Loss: 0.2952\n",
      "Epoch [5/10], Phase: train, Batch: [152/657], Loss: 0.2595\n",
      "Epoch [5/10], Phase: train, Batch: [153/657], Loss: 0.3127\n",
      "Epoch [5/10], Phase: train, Batch: [154/657], Loss: 0.3743\n",
      "Epoch [5/10], Phase: train, Batch: [155/657], Loss: 0.3504\n",
      "Epoch [5/10], Phase: train, Batch: [156/657], Loss: 0.2831\n",
      "Epoch [5/10], Phase: train, Batch: [157/657], Loss: 0.3202\n",
      "Epoch [5/10], Phase: train, Batch: [158/657], Loss: 0.2696\n",
      "Epoch [5/10], Phase: train, Batch: [159/657], Loss: 0.2151\n",
      "Epoch [5/10], Phase: train, Batch: [160/657], Loss: 0.2694\n",
      "Epoch [5/10], Phase: train, Batch: [161/657], Loss: 0.2605\n",
      "Epoch [5/10], Phase: train, Batch: [162/657], Loss: 0.2783\n",
      "Epoch [5/10], Phase: train, Batch: [163/657], Loss: 0.3062\n",
      "Epoch [5/10], Phase: train, Batch: [164/657], Loss: 0.3015\n",
      "Epoch [5/10], Phase: train, Batch: [165/657], Loss: 0.2595\n",
      "Epoch [5/10], Phase: train, Batch: [166/657], Loss: 0.1943\n",
      "Epoch [5/10], Phase: train, Batch: [167/657], Loss: 0.2776\n",
      "Epoch [5/10], Phase: train, Batch: [168/657], Loss: 0.4068\n",
      "Epoch [5/10], Phase: train, Batch: [169/657], Loss: 0.3090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [170/657], Loss: 0.4161\n",
      "Epoch [5/10], Phase: train, Batch: [171/657], Loss: 0.3738\n",
      "Epoch [5/10], Phase: train, Batch: [172/657], Loss: 0.2877\n",
      "Epoch [5/10], Phase: train, Batch: [173/657], Loss: 0.2582\n",
      "Epoch [5/10], Phase: train, Batch: [174/657], Loss: 0.2616\n",
      "Epoch [5/10], Phase: train, Batch: [175/657], Loss: 0.1908\n",
      "Epoch [5/10], Phase: train, Batch: [176/657], Loss: 0.2623\n",
      "Epoch [5/10], Phase: train, Batch: [177/657], Loss: 0.2947\n",
      "Epoch [5/10], Phase: train, Batch: [178/657], Loss: 0.4406\n",
      "Epoch [5/10], Phase: train, Batch: [179/657], Loss: 0.3379\n",
      "Epoch [5/10], Phase: train, Batch: [180/657], Loss: 0.2293\n",
      "Epoch [5/10], Phase: train, Batch: [181/657], Loss: 0.2153\n",
      "Epoch [5/10], Phase: train, Batch: [182/657], Loss: 0.3605\n",
      "Epoch [5/10], Phase: train, Batch: [183/657], Loss: 0.2141\n",
      "Epoch [5/10], Phase: train, Batch: [184/657], Loss: 0.2190\n",
      "Epoch [5/10], Phase: train, Batch: [185/657], Loss: 0.2939\n",
      "Epoch [5/10], Phase: train, Batch: [186/657], Loss: 0.3598\n",
      "Epoch [5/10], Phase: train, Batch: [187/657], Loss: 0.3457\n",
      "Epoch [5/10], Phase: train, Batch: [188/657], Loss: 0.2914\n",
      "Epoch [5/10], Phase: train, Batch: [189/657], Loss: 0.2918\n",
      "Epoch [5/10], Phase: train, Batch: [190/657], Loss: 0.3428\n",
      "Epoch [5/10], Phase: train, Batch: [191/657], Loss: 0.3525\n",
      "Epoch [5/10], Phase: train, Batch: [192/657], Loss: 0.1120\n",
      "Epoch [5/10], Phase: train, Batch: [193/657], Loss: 0.2737\n",
      "Epoch [5/10], Phase: train, Batch: [194/657], Loss: 0.2626\n",
      "Epoch [5/10], Phase: train, Batch: [195/657], Loss: 0.5104\n",
      "Epoch [5/10], Phase: train, Batch: [196/657], Loss: 0.3026\n",
      "Epoch [5/10], Phase: train, Batch: [197/657], Loss: 0.4257\n",
      "Epoch [5/10], Phase: train, Batch: [198/657], Loss: 0.2337\n",
      "Epoch [5/10], Phase: train, Batch: [199/657], Loss: 0.3566\n",
      "Epoch [5/10], Phase: train, Batch: [200/657], Loss: 0.3353\n",
      "Epoch [5/10], Phase: train, Batch: [201/657], Loss: 0.2307\n",
      "Epoch [5/10], Phase: train, Batch: [202/657], Loss: 0.3080\n",
      "Epoch [5/10], Phase: train, Batch: [203/657], Loss: 0.2257\n",
      "Epoch [5/10], Phase: train, Batch: [204/657], Loss: 0.3619\n",
      "Epoch [5/10], Phase: train, Batch: [205/657], Loss: 0.2730\n",
      "Epoch [5/10], Phase: train, Batch: [206/657], Loss: 0.4593\n",
      "Epoch [5/10], Phase: train, Batch: [207/657], Loss: 0.4023\n",
      "Epoch [5/10], Phase: train, Batch: [208/657], Loss: 0.1994\n",
      "Epoch [5/10], Phase: train, Batch: [209/657], Loss: 0.3851\n",
      "Epoch [5/10], Phase: train, Batch: [210/657], Loss: 0.2462\n",
      "Epoch [5/10], Phase: train, Batch: [211/657], Loss: 0.2972\n",
      "Epoch [5/10], Phase: train, Batch: [212/657], Loss: 0.2059\n",
      "Epoch [5/10], Phase: train, Batch: [213/657], Loss: 0.3807\n",
      "Epoch [5/10], Phase: train, Batch: [214/657], Loss: 0.1981\n",
      "Epoch [5/10], Phase: train, Batch: [215/657], Loss: 0.2098\n",
      "Epoch [5/10], Phase: train, Batch: [216/657], Loss: 0.3237\n",
      "Epoch [5/10], Phase: train, Batch: [217/657], Loss: 0.2400\n",
      "Epoch [5/10], Phase: train, Batch: [218/657], Loss: 0.2293\n",
      "Epoch [5/10], Phase: train, Batch: [219/657], Loss: 0.3081\n",
      "Epoch [5/10], Phase: train, Batch: [220/657], Loss: 0.3006\n",
      "Epoch [5/10], Phase: train, Batch: [221/657], Loss: 0.2407\n",
      "Epoch [5/10], Phase: train, Batch: [222/657], Loss: 0.3198\n",
      "Epoch [5/10], Phase: train, Batch: [223/657], Loss: 0.2479\n",
      "Epoch [5/10], Phase: train, Batch: [224/657], Loss: 0.1754\n",
      "Epoch [5/10], Phase: train, Batch: [225/657], Loss: 0.4434\n",
      "Epoch [5/10], Phase: train, Batch: [226/657], Loss: 0.3075\n",
      "Epoch [5/10], Phase: train, Batch: [227/657], Loss: 0.2580\n",
      "Epoch [5/10], Phase: train, Batch: [228/657], Loss: 0.1815\n",
      "Epoch [5/10], Phase: train, Batch: [229/657], Loss: 0.2496\n",
      "Epoch [5/10], Phase: train, Batch: [230/657], Loss: 0.2170\n",
      "Epoch [5/10], Phase: train, Batch: [231/657], Loss: 0.2634\n",
      "Epoch [5/10], Phase: train, Batch: [232/657], Loss: 0.2374\n",
      "Epoch [5/10], Phase: train, Batch: [233/657], Loss: 0.2072\n",
      "Epoch [5/10], Phase: train, Batch: [234/657], Loss: 0.2876\n",
      "Epoch [5/10], Phase: train, Batch: [235/657], Loss: 0.3191\n",
      "Epoch [5/10], Phase: train, Batch: [236/657], Loss: 0.2049\n",
      "Epoch [5/10], Phase: train, Batch: [237/657], Loss: 0.4028\n",
      "Epoch [5/10], Phase: train, Batch: [238/657], Loss: 0.2011\n",
      "Epoch [5/10], Phase: train, Batch: [239/657], Loss: 0.3846\n",
      "Epoch [5/10], Phase: train, Batch: [240/657], Loss: 0.3708\n",
      "Epoch [5/10], Phase: train, Batch: [241/657], Loss: 0.1835\n",
      "Epoch [5/10], Phase: train, Batch: [242/657], Loss: 0.1900\n",
      "Epoch [5/10], Phase: train, Batch: [243/657], Loss: 0.2574\n",
      "Epoch [5/10], Phase: train, Batch: [244/657], Loss: 0.2935\n",
      "Epoch [5/10], Phase: train, Batch: [245/657], Loss: 0.3825\n",
      "Epoch [5/10], Phase: train, Batch: [246/657], Loss: 0.2931\n",
      "Epoch [5/10], Phase: train, Batch: [247/657], Loss: 0.3005\n",
      "Epoch [5/10], Phase: train, Batch: [248/657], Loss: 0.2659\n",
      "Epoch [5/10], Phase: train, Batch: [249/657], Loss: 0.2592\n",
      "Epoch [5/10], Phase: train, Batch: [250/657], Loss: 0.3051\n",
      "Epoch [5/10], Phase: train, Batch: [251/657], Loss: 0.4142\n",
      "Epoch [5/10], Phase: train, Batch: [252/657], Loss: 0.3857\n",
      "Epoch [5/10], Phase: train, Batch: [253/657], Loss: 0.2428\n",
      "Epoch [5/10], Phase: train, Batch: [254/657], Loss: 0.3619\n",
      "Epoch [5/10], Phase: train, Batch: [255/657], Loss: 0.3560\n",
      "Epoch [5/10], Phase: train, Batch: [256/657], Loss: 0.4583\n",
      "Epoch [5/10], Phase: train, Batch: [257/657], Loss: 0.2719\n",
      "Epoch [5/10], Phase: train, Batch: [258/657], Loss: 0.1575\n",
      "Epoch [5/10], Phase: train, Batch: [259/657], Loss: 0.2514\n",
      "Epoch [5/10], Phase: train, Batch: [260/657], Loss: 0.2429\n",
      "Epoch [5/10], Phase: train, Batch: [261/657], Loss: 0.1955\n",
      "Epoch [5/10], Phase: train, Batch: [262/657], Loss: 0.1621\n",
      "Epoch [5/10], Phase: train, Batch: [263/657], Loss: 0.2546\n",
      "Epoch [5/10], Phase: train, Batch: [264/657], Loss: 0.1671\n",
      "Epoch [5/10], Phase: train, Batch: [265/657], Loss: 0.2917\n",
      "Epoch [5/10], Phase: train, Batch: [266/657], Loss: 0.2327\n",
      "Epoch [5/10], Phase: train, Batch: [267/657], Loss: 0.1786\n",
      "Epoch [5/10], Phase: train, Batch: [268/657], Loss: 0.2585\n",
      "Epoch [5/10], Phase: train, Batch: [269/657], Loss: 0.2610\n",
      "Epoch [5/10], Phase: train, Batch: [270/657], Loss: 0.2588\n",
      "Epoch [5/10], Phase: train, Batch: [271/657], Loss: 0.2502\n",
      "Epoch [5/10], Phase: train, Batch: [272/657], Loss: 0.2175\n",
      "Epoch [5/10], Phase: train, Batch: [273/657], Loss: 0.3637\n",
      "Epoch [5/10], Phase: train, Batch: [274/657], Loss: 0.3496\n",
      "Epoch [5/10], Phase: train, Batch: [275/657], Loss: 0.2756\n",
      "Epoch [5/10], Phase: train, Batch: [276/657], Loss: 0.2340\n",
      "Epoch [5/10], Phase: train, Batch: [277/657], Loss: 0.2862\n",
      "Epoch [5/10], Phase: train, Batch: [278/657], Loss: 0.3131\n",
      "Epoch [5/10], Phase: train, Batch: [279/657], Loss: 0.1618\n",
      "Epoch [5/10], Phase: train, Batch: [280/657], Loss: 0.2014\n",
      "Epoch [5/10], Phase: train, Batch: [281/657], Loss: 0.2055\n",
      "Epoch [5/10], Phase: train, Batch: [282/657], Loss: 0.4210\n",
      "Epoch [5/10], Phase: train, Batch: [283/657], Loss: 0.2188\n",
      "Epoch [5/10], Phase: train, Batch: [284/657], Loss: 0.2402\n",
      "Epoch [5/10], Phase: train, Batch: [285/657], Loss: 0.2588\n",
      "Epoch [5/10], Phase: train, Batch: [286/657], Loss: 0.1838\n",
      "Epoch [5/10], Phase: train, Batch: [287/657], Loss: 0.2719\n",
      "Epoch [5/10], Phase: train, Batch: [288/657], Loss: 0.2419\n",
      "Epoch [5/10], Phase: train, Batch: [289/657], Loss: 0.2471\n",
      "Epoch [5/10], Phase: train, Batch: [290/657], Loss: 0.3417\n",
      "Epoch [5/10], Phase: train, Batch: [291/657], Loss: 0.2454\n",
      "Epoch [5/10], Phase: train, Batch: [292/657], Loss: 0.1788\n",
      "Epoch [5/10], Phase: train, Batch: [293/657], Loss: 0.2907\n",
      "Epoch [5/10], Phase: train, Batch: [294/657], Loss: 0.2513\n",
      "Epoch [5/10], Phase: train, Batch: [295/657], Loss: 0.2321\n",
      "Epoch [5/10], Phase: train, Batch: [296/657], Loss: 0.1904\n",
      "Epoch [5/10], Phase: train, Batch: [297/657], Loss: 0.5482\n",
      "Epoch [5/10], Phase: train, Batch: [298/657], Loss: 0.2084\n",
      "Epoch [5/10], Phase: train, Batch: [299/657], Loss: 0.2232\n",
      "Epoch [5/10], Phase: train, Batch: [300/657], Loss: 0.1340\n",
      "Epoch [5/10], Phase: train, Batch: [301/657], Loss: 0.3542\n",
      "Epoch [5/10], Phase: train, Batch: [302/657], Loss: 0.3230\n",
      "Epoch [5/10], Phase: train, Batch: [303/657], Loss: 0.2734\n",
      "Epoch [5/10], Phase: train, Batch: [304/657], Loss: 0.2869\n",
      "Epoch [5/10], Phase: train, Batch: [305/657], Loss: 0.2032\n",
      "Epoch [5/10], Phase: train, Batch: [306/657], Loss: 0.2896\n",
      "Epoch [5/10], Phase: train, Batch: [307/657], Loss: 0.1379\n",
      "Epoch [5/10], Phase: train, Batch: [308/657], Loss: 0.1832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [309/657], Loss: 0.2875\n",
      "Epoch [5/10], Phase: train, Batch: [310/657], Loss: 0.2812\n",
      "Epoch [5/10], Phase: train, Batch: [311/657], Loss: 0.2642\n",
      "Epoch [5/10], Phase: train, Batch: [312/657], Loss: 0.2031\n",
      "Epoch [5/10], Phase: train, Batch: [313/657], Loss: 0.2242\n",
      "Epoch [5/10], Phase: train, Batch: [314/657], Loss: 0.2240\n",
      "Epoch [5/10], Phase: train, Batch: [315/657], Loss: 0.3516\n",
      "Epoch [5/10], Phase: train, Batch: [316/657], Loss: 0.2172\n",
      "Epoch [5/10], Phase: train, Batch: [317/657], Loss: 0.2745\n",
      "Epoch [5/10], Phase: train, Batch: [318/657], Loss: 0.2078\n",
      "Epoch [5/10], Phase: train, Batch: [319/657], Loss: 0.3045\n",
      "Epoch [5/10], Phase: train, Batch: [320/657], Loss: 0.3008\n",
      "Epoch [5/10], Phase: train, Batch: [321/657], Loss: 0.3028\n",
      "Epoch [5/10], Phase: train, Batch: [322/657], Loss: 0.2880\n",
      "Epoch [5/10], Phase: train, Batch: [323/657], Loss: 0.2228\n",
      "Epoch [5/10], Phase: train, Batch: [324/657], Loss: 0.2542\n",
      "Epoch [5/10], Phase: train, Batch: [325/657], Loss: 0.2541\n",
      "Epoch [5/10], Phase: train, Batch: [326/657], Loss: 0.2686\n",
      "Epoch [5/10], Phase: train, Batch: [327/657], Loss: 0.2780\n",
      "Epoch [5/10], Phase: train, Batch: [328/657], Loss: 0.1472\n",
      "Epoch [5/10], Phase: train, Batch: [329/657], Loss: 0.2665\n",
      "Epoch [5/10], Phase: train, Batch: [330/657], Loss: 0.3072\n",
      "Epoch [5/10], Phase: train, Batch: [331/657], Loss: 0.2221\n",
      "Epoch [5/10], Phase: train, Batch: [332/657], Loss: 0.3941\n",
      "Epoch [5/10], Phase: train, Batch: [333/657], Loss: 0.2285\n",
      "Epoch [5/10], Phase: train, Batch: [334/657], Loss: 0.1822\n",
      "Epoch [5/10], Phase: train, Batch: [335/657], Loss: 0.2026\n",
      "Epoch [5/10], Phase: train, Batch: [336/657], Loss: 0.3946\n",
      "Epoch [5/10], Phase: train, Batch: [337/657], Loss: 0.2922\n",
      "Epoch [5/10], Phase: train, Batch: [338/657], Loss: 0.2148\n",
      "Epoch [5/10], Phase: train, Batch: [339/657], Loss: 0.2522\n",
      "Epoch [5/10], Phase: train, Batch: [340/657], Loss: 0.3651\n",
      "Epoch [5/10], Phase: train, Batch: [341/657], Loss: 0.3267\n",
      "Epoch [5/10], Phase: train, Batch: [342/657], Loss: 0.4098\n",
      "Epoch [5/10], Phase: train, Batch: [343/657], Loss: 0.2907\n",
      "Epoch [5/10], Phase: train, Batch: [344/657], Loss: 0.3378\n",
      "Epoch [5/10], Phase: train, Batch: [345/657], Loss: 0.1565\n",
      "Epoch [5/10], Phase: train, Batch: [346/657], Loss: 0.2067\n",
      "Epoch [5/10], Phase: train, Batch: [347/657], Loss: 0.1689\n",
      "Epoch [5/10], Phase: train, Batch: [348/657], Loss: 0.2533\n",
      "Epoch [5/10], Phase: train, Batch: [349/657], Loss: 0.2564\n",
      "Epoch [5/10], Phase: train, Batch: [350/657], Loss: 0.3376\n",
      "Epoch [5/10], Phase: train, Batch: [351/657], Loss: 0.2385\n",
      "Epoch [5/10], Phase: train, Batch: [352/657], Loss: 0.3412\n",
      "Epoch [5/10], Phase: train, Batch: [353/657], Loss: 0.3297\n",
      "Epoch [5/10], Phase: train, Batch: [354/657], Loss: 0.3284\n",
      "Epoch [5/10], Phase: train, Batch: [355/657], Loss: 0.2532\n",
      "Epoch [5/10], Phase: train, Batch: [356/657], Loss: 0.2628\n",
      "Epoch [5/10], Phase: train, Batch: [357/657], Loss: 0.1941\n",
      "Epoch [5/10], Phase: train, Batch: [358/657], Loss: 0.1988\n",
      "Epoch [5/10], Phase: train, Batch: [359/657], Loss: 0.2259\n",
      "Epoch [5/10], Phase: train, Batch: [360/657], Loss: 0.2539\n",
      "Epoch [5/10], Phase: train, Batch: [361/657], Loss: 0.2156\n",
      "Epoch [5/10], Phase: train, Batch: [362/657], Loss: 0.4597\n",
      "Epoch [5/10], Phase: train, Batch: [363/657], Loss: 0.3020\n",
      "Epoch [5/10], Phase: train, Batch: [364/657], Loss: 0.2957\n",
      "Epoch [5/10], Phase: train, Batch: [365/657], Loss: 0.2714\n",
      "Epoch [5/10], Phase: train, Batch: [366/657], Loss: 0.3914\n",
      "Epoch [5/10], Phase: train, Batch: [367/657], Loss: 0.2353\n",
      "Epoch [5/10], Phase: train, Batch: [368/657], Loss: 0.1733\n",
      "Epoch [5/10], Phase: train, Batch: [369/657], Loss: 0.2885\n",
      "Epoch [5/10], Phase: train, Batch: [370/657], Loss: 0.3295\n",
      "Epoch [5/10], Phase: train, Batch: [371/657], Loss: 0.3071\n",
      "Epoch [5/10], Phase: train, Batch: [372/657], Loss: 0.2776\n",
      "Epoch [5/10], Phase: train, Batch: [373/657], Loss: 0.3031\n",
      "Epoch [5/10], Phase: train, Batch: [374/657], Loss: 0.3648\n",
      "Epoch [5/10], Phase: train, Batch: [375/657], Loss: 0.3436\n",
      "Epoch [5/10], Phase: train, Batch: [376/657], Loss: 0.1838\n",
      "Epoch [5/10], Phase: train, Batch: [377/657], Loss: 0.2232\n",
      "Epoch [5/10], Phase: train, Batch: [378/657], Loss: 0.3482\n",
      "Epoch [5/10], Phase: train, Batch: [379/657], Loss: 0.4530\n",
      "Epoch [5/10], Phase: train, Batch: [380/657], Loss: 0.3478\n",
      "Epoch [5/10], Phase: train, Batch: [381/657], Loss: 0.2686\n",
      "Epoch [5/10], Phase: train, Batch: [382/657], Loss: 0.3082\n",
      "Epoch [5/10], Phase: train, Batch: [383/657], Loss: 0.3175\n",
      "Epoch [5/10], Phase: train, Batch: [384/657], Loss: 0.3323\n",
      "Epoch [5/10], Phase: train, Batch: [385/657], Loss: 0.3605\n",
      "Epoch [5/10], Phase: train, Batch: [386/657], Loss: 0.1730\n",
      "Epoch [5/10], Phase: train, Batch: [387/657], Loss: 0.3321\n",
      "Epoch [5/10], Phase: train, Batch: [388/657], Loss: 0.1812\n",
      "Epoch [5/10], Phase: train, Batch: [389/657], Loss: 0.2232\n",
      "Epoch [5/10], Phase: train, Batch: [390/657], Loss: 0.2027\n",
      "Epoch [5/10], Phase: train, Batch: [391/657], Loss: 0.3611\n",
      "Epoch [5/10], Phase: train, Batch: [392/657], Loss: 0.2415\n",
      "Epoch [5/10], Phase: train, Batch: [393/657], Loss: 0.3554\n",
      "Epoch [5/10], Phase: train, Batch: [394/657], Loss: 0.2778\n",
      "Epoch [5/10], Phase: train, Batch: [395/657], Loss: 0.1951\n",
      "Epoch [5/10], Phase: train, Batch: [396/657], Loss: 0.1658\n",
      "Epoch [5/10], Phase: train, Batch: [397/657], Loss: 0.2183\n",
      "Epoch [5/10], Phase: train, Batch: [398/657], Loss: 0.3116\n",
      "Epoch [5/10], Phase: train, Batch: [399/657], Loss: 0.4096\n",
      "Epoch [5/10], Phase: train, Batch: [400/657], Loss: 0.2608\n",
      "Epoch [5/10], Phase: train, Batch: [401/657], Loss: 0.2251\n",
      "Epoch [5/10], Phase: train, Batch: [402/657], Loss: 0.2049\n",
      "Epoch [5/10], Phase: train, Batch: [403/657], Loss: 0.1934\n",
      "Epoch [5/10], Phase: train, Batch: [404/657], Loss: 0.1973\n",
      "Epoch [5/10], Phase: train, Batch: [405/657], Loss: 0.2558\n",
      "Epoch [5/10], Phase: train, Batch: [406/657], Loss: 0.2865\n",
      "Epoch [5/10], Phase: train, Batch: [407/657], Loss: 0.2287\n",
      "Epoch [5/10], Phase: train, Batch: [408/657], Loss: 0.3538\n",
      "Epoch [5/10], Phase: train, Batch: [409/657], Loss: 0.2694\n",
      "Epoch [5/10], Phase: train, Batch: [410/657], Loss: 0.3062\n",
      "Epoch [5/10], Phase: train, Batch: [411/657], Loss: 0.2038\n",
      "Epoch [5/10], Phase: train, Batch: [412/657], Loss: 0.3239\n",
      "Epoch [5/10], Phase: train, Batch: [413/657], Loss: 0.2636\n",
      "Epoch [5/10], Phase: train, Batch: [414/657], Loss: 0.2026\n",
      "Epoch [5/10], Phase: train, Batch: [415/657], Loss: 0.3177\n",
      "Epoch [5/10], Phase: train, Batch: [416/657], Loss: 0.4785\n",
      "Epoch [5/10], Phase: train, Batch: [417/657], Loss: 0.1550\n",
      "Epoch [5/10], Phase: train, Batch: [418/657], Loss: 0.2590\n",
      "Epoch [5/10], Phase: train, Batch: [419/657], Loss: 0.2831\n",
      "Epoch [5/10], Phase: train, Batch: [420/657], Loss: 0.2519\n",
      "Epoch [5/10], Phase: train, Batch: [421/657], Loss: 0.2944\n",
      "Epoch [5/10], Phase: train, Batch: [422/657], Loss: 0.2481\n",
      "Epoch [5/10], Phase: train, Batch: [423/657], Loss: 0.2398\n",
      "Epoch [5/10], Phase: train, Batch: [424/657], Loss: 0.3707\n",
      "Epoch [5/10], Phase: train, Batch: [425/657], Loss: 0.3015\n",
      "Epoch [5/10], Phase: train, Batch: [426/657], Loss: 0.3693\n",
      "Epoch [5/10], Phase: train, Batch: [427/657], Loss: 0.3566\n",
      "Epoch [5/10], Phase: train, Batch: [428/657], Loss: 0.1861\n",
      "Epoch [5/10], Phase: train, Batch: [429/657], Loss: 0.1706\n",
      "Epoch [5/10], Phase: train, Batch: [430/657], Loss: 0.3510\n",
      "Epoch [5/10], Phase: train, Batch: [431/657], Loss: 0.3945\n",
      "Epoch [5/10], Phase: train, Batch: [432/657], Loss: 0.3322\n",
      "Epoch [5/10], Phase: train, Batch: [433/657], Loss: 0.3222\n",
      "Epoch [5/10], Phase: train, Batch: [434/657], Loss: 0.2335\n",
      "Epoch [5/10], Phase: train, Batch: [435/657], Loss: 0.1823\n",
      "Epoch [5/10], Phase: train, Batch: [436/657], Loss: 0.3565\n",
      "Epoch [5/10], Phase: train, Batch: [437/657], Loss: 0.2524\n",
      "Epoch [5/10], Phase: train, Batch: [438/657], Loss: 0.2133\n",
      "Epoch [5/10], Phase: train, Batch: [439/657], Loss: 0.2233\n",
      "Epoch [5/10], Phase: train, Batch: [440/657], Loss: 0.4012\n",
      "Epoch [5/10], Phase: train, Batch: [441/657], Loss: 0.2874\n",
      "Epoch [5/10], Phase: train, Batch: [442/657], Loss: 0.2326\n",
      "Epoch [5/10], Phase: train, Batch: [443/657], Loss: 0.2767\n",
      "Epoch [5/10], Phase: train, Batch: [444/657], Loss: 0.3523\n",
      "Epoch [5/10], Phase: train, Batch: [445/657], Loss: 0.2016\n",
      "Epoch [5/10], Phase: train, Batch: [446/657], Loss: 0.3173\n",
      "Epoch [5/10], Phase: train, Batch: [447/657], Loss: 0.3421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [448/657], Loss: 0.1788\n",
      "Epoch [5/10], Phase: train, Batch: [449/657], Loss: 0.2963\n",
      "Epoch [5/10], Phase: train, Batch: [450/657], Loss: 0.3218\n",
      "Epoch [5/10], Phase: train, Batch: [451/657], Loss: 0.3400\n",
      "Epoch [5/10], Phase: train, Batch: [452/657], Loss: 0.3539\n",
      "Epoch [5/10], Phase: train, Batch: [453/657], Loss: 0.3554\n",
      "Epoch [5/10], Phase: train, Batch: [454/657], Loss: 0.1895\n",
      "Epoch [5/10], Phase: train, Batch: [455/657], Loss: 0.2775\n",
      "Epoch [5/10], Phase: train, Batch: [456/657], Loss: 0.1759\n",
      "Epoch [5/10], Phase: train, Batch: [457/657], Loss: 0.2652\n",
      "Epoch [5/10], Phase: train, Batch: [458/657], Loss: 0.2710\n",
      "Epoch [5/10], Phase: train, Batch: [459/657], Loss: 0.2499\n",
      "Epoch [5/10], Phase: train, Batch: [460/657], Loss: 0.2554\n",
      "Epoch [5/10], Phase: train, Batch: [461/657], Loss: 0.3910\n",
      "Epoch [5/10], Phase: train, Batch: [462/657], Loss: 0.3531\n",
      "Epoch [5/10], Phase: train, Batch: [463/657], Loss: 0.2698\n",
      "Epoch [5/10], Phase: train, Batch: [464/657], Loss: 0.2375\n",
      "Epoch [5/10], Phase: train, Batch: [465/657], Loss: 0.4289\n",
      "Epoch [5/10], Phase: train, Batch: [466/657], Loss: 0.3161\n",
      "Epoch [5/10], Phase: train, Batch: [467/657], Loss: 0.3696\n",
      "Epoch [5/10], Phase: train, Batch: [468/657], Loss: 0.3426\n",
      "Epoch [5/10], Phase: train, Batch: [469/657], Loss: 0.2614\n",
      "Epoch [5/10], Phase: train, Batch: [470/657], Loss: 0.3845\n",
      "Epoch [5/10], Phase: train, Batch: [471/657], Loss: 0.3305\n",
      "Epoch [5/10], Phase: train, Batch: [472/657], Loss: 0.2908\n",
      "Epoch [5/10], Phase: train, Batch: [473/657], Loss: 0.3139\n",
      "Epoch [5/10], Phase: train, Batch: [474/657], Loss: 0.2056\n",
      "Epoch [5/10], Phase: train, Batch: [475/657], Loss: 0.2240\n",
      "Epoch [5/10], Phase: train, Batch: [476/657], Loss: 0.2621\n",
      "Epoch [5/10], Phase: train, Batch: [477/657], Loss: 0.3450\n",
      "Epoch [5/10], Phase: train, Batch: [478/657], Loss: 0.2545\n",
      "Epoch [5/10], Phase: train, Batch: [479/657], Loss: 0.2732\n",
      "Epoch [5/10], Phase: train, Batch: [480/657], Loss: 0.2620\n",
      "Epoch [5/10], Phase: train, Batch: [481/657], Loss: 0.1867\n",
      "Epoch [5/10], Phase: train, Batch: [482/657], Loss: 0.4744\n",
      "Epoch [5/10], Phase: train, Batch: [483/657], Loss: 0.3214\n",
      "Epoch [5/10], Phase: train, Batch: [484/657], Loss: 0.3069\n",
      "Epoch [5/10], Phase: train, Batch: [485/657], Loss: 0.2728\n",
      "Epoch [5/10], Phase: train, Batch: [486/657], Loss: 0.2328\n",
      "Epoch [5/10], Phase: train, Batch: [487/657], Loss: 0.2030\n",
      "Epoch [5/10], Phase: train, Batch: [488/657], Loss: 0.1797\n",
      "Epoch [5/10], Phase: train, Batch: [489/657], Loss: 0.3332\n",
      "Epoch [5/10], Phase: train, Batch: [490/657], Loss: 0.3250\n",
      "Epoch [5/10], Phase: train, Batch: [491/657], Loss: 0.2440\n",
      "Epoch [5/10], Phase: train, Batch: [492/657], Loss: 0.2723\n",
      "Epoch [5/10], Phase: train, Batch: [493/657], Loss: 0.3185\n",
      "Epoch [5/10], Phase: train, Batch: [494/657], Loss: 0.3389\n",
      "Epoch [5/10], Phase: train, Batch: [495/657], Loss: 0.2464\n",
      "Epoch [5/10], Phase: train, Batch: [496/657], Loss: 0.1515\n",
      "Epoch [5/10], Phase: train, Batch: [497/657], Loss: 0.3334\n",
      "Epoch [5/10], Phase: train, Batch: [498/657], Loss: 0.3260\n",
      "Epoch [5/10], Phase: train, Batch: [499/657], Loss: 0.1907\n",
      "Epoch [5/10], Phase: train, Batch: [500/657], Loss: 0.2993\n",
      "Epoch [5/10], Phase: train, Batch: [501/657], Loss: 0.3089\n",
      "Epoch [5/10], Phase: train, Batch: [502/657], Loss: 0.3902\n",
      "Epoch [5/10], Phase: train, Batch: [503/657], Loss: 0.2956\n",
      "Epoch [5/10], Phase: train, Batch: [504/657], Loss: 0.2805\n",
      "Epoch [5/10], Phase: train, Batch: [505/657], Loss: 0.2889\n",
      "Epoch [5/10], Phase: train, Batch: [506/657], Loss: 0.1975\n",
      "Epoch [5/10], Phase: train, Batch: [507/657], Loss: 0.2003\n",
      "Epoch [5/10], Phase: train, Batch: [508/657], Loss: 0.3861\n",
      "Epoch [5/10], Phase: train, Batch: [509/657], Loss: 0.2076\n",
      "Epoch [5/10], Phase: train, Batch: [510/657], Loss: 0.2290\n",
      "Epoch [5/10], Phase: train, Batch: [511/657], Loss: 0.2778\n",
      "Epoch [5/10], Phase: train, Batch: [512/657], Loss: 0.1998\n",
      "Epoch [5/10], Phase: train, Batch: [513/657], Loss: 0.3182\n",
      "Epoch [5/10], Phase: train, Batch: [514/657], Loss: 0.1603\n",
      "Epoch [5/10], Phase: train, Batch: [515/657], Loss: 0.2156\n",
      "Epoch [5/10], Phase: train, Batch: [516/657], Loss: 0.1115\n",
      "Epoch [5/10], Phase: train, Batch: [517/657], Loss: 0.1947\n",
      "Epoch [5/10], Phase: train, Batch: [518/657], Loss: 0.3455\n",
      "Epoch [5/10], Phase: train, Batch: [519/657], Loss: 0.4180\n",
      "Epoch [5/10], Phase: train, Batch: [520/657], Loss: 0.3379\n",
      "Epoch [5/10], Phase: train, Batch: [521/657], Loss: 0.2635\n",
      "Epoch [5/10], Phase: train, Batch: [522/657], Loss: 0.2639\n",
      "Epoch [5/10], Phase: train, Batch: [523/657], Loss: 0.2491\n",
      "Epoch [5/10], Phase: train, Batch: [524/657], Loss: 0.1902\n",
      "Epoch [5/10], Phase: train, Batch: [525/657], Loss: 0.2577\n",
      "Epoch [5/10], Phase: train, Batch: [526/657], Loss: 0.2332\n",
      "Epoch [5/10], Phase: train, Batch: [527/657], Loss: 0.3728\n",
      "Epoch [5/10], Phase: train, Batch: [528/657], Loss: 0.3571\n",
      "Epoch [5/10], Phase: train, Batch: [529/657], Loss: 0.3010\n",
      "Epoch [5/10], Phase: train, Batch: [530/657], Loss: 0.3747\n",
      "Epoch [5/10], Phase: train, Batch: [531/657], Loss: 0.2510\n",
      "Epoch [5/10], Phase: train, Batch: [532/657], Loss: 0.3555\n",
      "Epoch [5/10], Phase: train, Batch: [533/657], Loss: 0.2889\n",
      "Epoch [5/10], Phase: train, Batch: [534/657], Loss: 0.2693\n",
      "Epoch [5/10], Phase: train, Batch: [535/657], Loss: 0.3959\n",
      "Epoch [5/10], Phase: train, Batch: [536/657], Loss: 0.2666\n",
      "Epoch [5/10], Phase: train, Batch: [537/657], Loss: 0.3982\n",
      "Epoch [5/10], Phase: train, Batch: [538/657], Loss: 0.2201\n",
      "Epoch [5/10], Phase: train, Batch: [539/657], Loss: 0.2734\n",
      "Epoch [5/10], Phase: train, Batch: [540/657], Loss: 0.2131\n",
      "Epoch [5/10], Phase: train, Batch: [541/657], Loss: 0.2019\n",
      "Epoch [5/10], Phase: train, Batch: [542/657], Loss: 0.1566\n",
      "Epoch [5/10], Phase: train, Batch: [543/657], Loss: 0.2368\n",
      "Epoch [5/10], Phase: train, Batch: [544/657], Loss: 0.2882\n",
      "Epoch [5/10], Phase: train, Batch: [545/657], Loss: 0.3910\n",
      "Epoch [5/10], Phase: train, Batch: [546/657], Loss: 0.2802\n",
      "Epoch [5/10], Phase: train, Batch: [547/657], Loss: 0.3026\n",
      "Epoch [5/10], Phase: train, Batch: [548/657], Loss: 0.2141\n",
      "Epoch [5/10], Phase: train, Batch: [549/657], Loss: 0.1663\n",
      "Epoch [5/10], Phase: train, Batch: [550/657], Loss: 0.2950\n",
      "Epoch [5/10], Phase: train, Batch: [551/657], Loss: 0.2035\n",
      "Epoch [5/10], Phase: train, Batch: [552/657], Loss: 0.3277\n",
      "Epoch [5/10], Phase: train, Batch: [553/657], Loss: 0.2253\n",
      "Epoch [5/10], Phase: train, Batch: [554/657], Loss: 0.3562\n",
      "Epoch [5/10], Phase: train, Batch: [555/657], Loss: 0.2400\n",
      "Epoch [5/10], Phase: train, Batch: [556/657], Loss: 0.1727\n",
      "Epoch [5/10], Phase: train, Batch: [557/657], Loss: 0.3228\n",
      "Epoch [5/10], Phase: train, Batch: [558/657], Loss: 0.2346\n",
      "Epoch [5/10], Phase: train, Batch: [559/657], Loss: 0.3290\n",
      "Epoch [5/10], Phase: train, Batch: [560/657], Loss: 0.2042\n",
      "Epoch [5/10], Phase: train, Batch: [561/657], Loss: 0.2260\n",
      "Epoch [5/10], Phase: train, Batch: [562/657], Loss: 0.2510\n",
      "Epoch [5/10], Phase: train, Batch: [563/657], Loss: 0.2437\n",
      "Epoch [5/10], Phase: train, Batch: [564/657], Loss: 0.3263\n",
      "Epoch [5/10], Phase: train, Batch: [565/657], Loss: 0.2695\n",
      "Epoch [5/10], Phase: train, Batch: [566/657], Loss: 0.3132\n",
      "Epoch [5/10], Phase: train, Batch: [567/657], Loss: 0.2802\n",
      "Epoch [5/10], Phase: train, Batch: [568/657], Loss: 0.4397\n",
      "Epoch [5/10], Phase: train, Batch: [569/657], Loss: 0.3187\n",
      "Epoch [5/10], Phase: train, Batch: [570/657], Loss: 0.2778\n",
      "Epoch [5/10], Phase: train, Batch: [571/657], Loss: 0.4091\n",
      "Epoch [5/10], Phase: train, Batch: [572/657], Loss: 0.2917\n",
      "Epoch [5/10], Phase: train, Batch: [573/657], Loss: 0.3072\n",
      "Epoch [5/10], Phase: train, Batch: [574/657], Loss: 0.2729\n",
      "Epoch [5/10], Phase: train, Batch: [575/657], Loss: 0.3542\n",
      "Epoch [5/10], Phase: train, Batch: [576/657], Loss: 0.2755\n",
      "Epoch [5/10], Phase: train, Batch: [577/657], Loss: 0.3230\n",
      "Epoch [5/10], Phase: train, Batch: [578/657], Loss: 0.2380\n",
      "Epoch [5/10], Phase: train, Batch: [579/657], Loss: 0.2111\n",
      "Epoch [5/10], Phase: train, Batch: [580/657], Loss: 0.2449\n",
      "Epoch [5/10], Phase: train, Batch: [581/657], Loss: 0.2661\n",
      "Epoch [5/10], Phase: train, Batch: [582/657], Loss: 0.1730\n",
      "Epoch [5/10], Phase: train, Batch: [583/657], Loss: 0.2698\n",
      "Epoch [5/10], Phase: train, Batch: [584/657], Loss: 0.2772\n",
      "Epoch [5/10], Phase: train, Batch: [585/657], Loss: 0.1988\n",
      "Epoch [5/10], Phase: train, Batch: [586/657], Loss: 0.1619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Phase: train, Batch: [587/657], Loss: 0.2677\n",
      "Epoch [5/10], Phase: train, Batch: [588/657], Loss: 0.4817\n",
      "Epoch [5/10], Phase: train, Batch: [589/657], Loss: 0.2128\n",
      "Epoch [5/10], Phase: train, Batch: [590/657], Loss: 0.2477\n",
      "Epoch [5/10], Phase: train, Batch: [591/657], Loss: 0.3422\n",
      "Epoch [5/10], Phase: train, Batch: [592/657], Loss: 0.1966\n",
      "Epoch [5/10], Phase: train, Batch: [593/657], Loss: 0.3231\n",
      "Epoch [5/10], Phase: train, Batch: [594/657], Loss: 0.3380\n",
      "Epoch [5/10], Phase: train, Batch: [595/657], Loss: 0.2549\n",
      "Epoch [5/10], Phase: train, Batch: [596/657], Loss: 0.2794\n",
      "Epoch [5/10], Phase: train, Batch: [597/657], Loss: 0.2235\n",
      "Epoch [5/10], Phase: train, Batch: [598/657], Loss: 0.2834\n",
      "Epoch [5/10], Phase: train, Batch: [599/657], Loss: 0.3371\n",
      "Epoch [5/10], Phase: train, Batch: [600/657], Loss: 0.2493\n",
      "Epoch [5/10], Phase: train, Batch: [601/657], Loss: 0.2847\n",
      "Epoch [5/10], Phase: train, Batch: [602/657], Loss: 0.3001\n",
      "Epoch [5/10], Phase: train, Batch: [603/657], Loss: 0.3507\n",
      "Epoch [5/10], Phase: train, Batch: [604/657], Loss: 0.1920\n",
      "Epoch [5/10], Phase: train, Batch: [605/657], Loss: 0.3258\n",
      "Epoch [5/10], Phase: train, Batch: [606/657], Loss: 0.4242\n",
      "Epoch [5/10], Phase: train, Batch: [607/657], Loss: 0.2562\n",
      "Epoch [5/10], Phase: train, Batch: [608/657], Loss: 0.2997\n",
      "Epoch [5/10], Phase: train, Batch: [609/657], Loss: 0.3388\n",
      "Epoch [5/10], Phase: train, Batch: [610/657], Loss: 0.2448\n",
      "Epoch [5/10], Phase: train, Batch: [611/657], Loss: 0.1951\n",
      "Epoch [5/10], Phase: train, Batch: [612/657], Loss: 0.2433\n",
      "Epoch [5/10], Phase: train, Batch: [613/657], Loss: 0.2073\n",
      "Epoch [5/10], Phase: train, Batch: [614/657], Loss: 0.2259\n",
      "Epoch [5/10], Phase: train, Batch: [615/657], Loss: 0.3700\n",
      "Epoch [5/10], Phase: train, Batch: [616/657], Loss: 0.1438\n",
      "Epoch [5/10], Phase: train, Batch: [617/657], Loss: 0.3276\n",
      "Epoch [5/10], Phase: train, Batch: [618/657], Loss: 0.2200\n",
      "Epoch [5/10], Phase: train, Batch: [619/657], Loss: 0.1832\n",
      "Epoch [5/10], Phase: train, Batch: [620/657], Loss: 0.3202\n",
      "Epoch [5/10], Phase: train, Batch: [621/657], Loss: 0.3115\n",
      "Epoch [5/10], Phase: train, Batch: [622/657], Loss: 0.3530\n",
      "Epoch [5/10], Phase: train, Batch: [623/657], Loss: 0.2980\n",
      "Epoch [5/10], Phase: train, Batch: [624/657], Loss: 0.4323\n",
      "Epoch [5/10], Phase: train, Batch: [625/657], Loss: 0.2723\n",
      "Epoch [5/10], Phase: train, Batch: [626/657], Loss: 0.2579\n",
      "Epoch [5/10], Phase: train, Batch: [627/657], Loss: 0.3551\n",
      "Epoch [5/10], Phase: train, Batch: [628/657], Loss: 0.3673\n",
      "Epoch [5/10], Phase: train, Batch: [629/657], Loss: 0.4333\n",
      "Epoch [5/10], Phase: train, Batch: [630/657], Loss: 0.1925\n",
      "Epoch [5/10], Phase: train, Batch: [631/657], Loss: 0.1938\n",
      "Epoch [5/10], Phase: train, Batch: [632/657], Loss: 0.2334\n",
      "Epoch [5/10], Phase: train, Batch: [633/657], Loss: 0.3882\n",
      "Epoch [5/10], Phase: train, Batch: [634/657], Loss: 0.3027\n",
      "Epoch [5/10], Phase: train, Batch: [635/657], Loss: 0.3579\n",
      "Epoch [5/10], Phase: train, Batch: [636/657], Loss: 0.2261\n",
      "Epoch [5/10], Phase: train, Batch: [637/657], Loss: 0.2415\n",
      "Epoch [5/10], Phase: train, Batch: [638/657], Loss: 0.2144\n",
      "Epoch [5/10], Phase: train, Batch: [639/657], Loss: 0.2127\n",
      "Epoch [5/10], Phase: train, Batch: [640/657], Loss: 0.1478\n",
      "Epoch [5/10], Phase: train, Batch: [641/657], Loss: 0.2236\n",
      "Epoch [5/10], Phase: train, Batch: [642/657], Loss: 0.3099\n",
      "Epoch [5/10], Phase: train, Batch: [643/657], Loss: 0.3177\n",
      "Epoch [5/10], Phase: train, Batch: [644/657], Loss: 0.2141\n",
      "Epoch [5/10], Phase: train, Batch: [645/657], Loss: 0.3028\n",
      "Epoch [5/10], Phase: train, Batch: [646/657], Loss: 0.2980\n",
      "Epoch [5/10], Phase: train, Batch: [647/657], Loss: 0.2736\n",
      "Epoch [5/10], Phase: train, Batch: [648/657], Loss: 0.2307\n",
      "Epoch [5/10], Phase: train, Batch: [649/657], Loss: 0.2208\n",
      "Epoch [5/10], Phase: train, Batch: [650/657], Loss: 0.4020\n",
      "Epoch [5/10], Phase: train, Batch: [651/657], Loss: 0.3219\n",
      "Epoch [5/10], Phase: train, Batch: [652/657], Loss: 0.2618\n",
      "Epoch [5/10], Phase: train, Batch: [653/657], Loss: 0.3788\n",
      "Epoch [5/10], Phase: train, Batch: [654/657], Loss: 0.1753\n",
      "Epoch [5/10], Phase: train, Batch: [655/657], Loss: 0.3081\n",
      "Epoch [5/10], Phase: train, Batch: [656/657], Loss: 0.2869\n",
      "Epoch [5/10], Phase: train, Batch: [657/657], Loss: 0.1812\n",
      "train Loss: 0.2783 Acc: 0.8891\n",
      "Epoch [5/10], Phase: val, Batch: [1/73], Loss: 0.3182\n",
      "Epoch [5/10], Phase: val, Batch: [2/73], Loss: 0.2970\n",
      "Epoch [5/10], Phase: val, Batch: [3/73], Loss: 0.1571\n",
      "Epoch [5/10], Phase: val, Batch: [4/73], Loss: 0.3598\n",
      "Epoch [5/10], Phase: val, Batch: [5/73], Loss: 0.2165\n",
      "Epoch [5/10], Phase: val, Batch: [6/73], Loss: 0.2756\n",
      "Epoch [5/10], Phase: val, Batch: [7/73], Loss: 0.1952\n",
      "Epoch [5/10], Phase: val, Batch: [8/73], Loss: 0.2219\n",
      "Epoch [5/10], Phase: val, Batch: [9/73], Loss: 0.0845\n",
      "Epoch [5/10], Phase: val, Batch: [10/73], Loss: 0.1942\n",
      "Epoch [5/10], Phase: val, Batch: [11/73], Loss: 0.1800\n",
      "Epoch [5/10], Phase: val, Batch: [12/73], Loss: 0.2462\n",
      "Epoch [5/10], Phase: val, Batch: [13/73], Loss: 0.1366\n",
      "Epoch [5/10], Phase: val, Batch: [14/73], Loss: 0.2913\n",
      "Epoch [5/10], Phase: val, Batch: [15/73], Loss: 0.2065\n",
      "Epoch [5/10], Phase: val, Batch: [16/73], Loss: 0.3099\n",
      "Epoch [5/10], Phase: val, Batch: [17/73], Loss: 0.1130\n",
      "Epoch [5/10], Phase: val, Batch: [18/73], Loss: 0.2499\n",
      "Epoch [5/10], Phase: val, Batch: [19/73], Loss: 0.3245\n",
      "Epoch [5/10], Phase: val, Batch: [20/73], Loss: 0.1716\n",
      "Epoch [5/10], Phase: val, Batch: [21/73], Loss: 0.3350\n",
      "Epoch [5/10], Phase: val, Batch: [22/73], Loss: 0.2078\n",
      "Epoch [5/10], Phase: val, Batch: [23/73], Loss: 0.2621\n",
      "Epoch [5/10], Phase: val, Batch: [24/73], Loss: 0.2879\n",
      "Epoch [5/10], Phase: val, Batch: [25/73], Loss: 0.1858\n",
      "Epoch [5/10], Phase: val, Batch: [26/73], Loss: 0.1814\n",
      "Epoch [5/10], Phase: val, Batch: [27/73], Loss: 0.2568\n",
      "Epoch [5/10], Phase: val, Batch: [28/73], Loss: 0.2420\n",
      "Epoch [5/10], Phase: val, Batch: [29/73], Loss: 0.3414\n",
      "Epoch [5/10], Phase: val, Batch: [30/73], Loss: 0.3400\n",
      "Epoch [5/10], Phase: val, Batch: [31/73], Loss: 0.1820\n",
      "Epoch [5/10], Phase: val, Batch: [32/73], Loss: 0.2774\n",
      "Epoch [5/10], Phase: val, Batch: [33/73], Loss: 0.3872\n",
      "Epoch [5/10], Phase: val, Batch: [34/73], Loss: 0.2096\n",
      "Epoch [5/10], Phase: val, Batch: [35/73], Loss: 0.1782\n",
      "Epoch [5/10], Phase: val, Batch: [36/73], Loss: 0.3403\n",
      "Epoch [5/10], Phase: val, Batch: [37/73], Loss: 0.2177\n",
      "Epoch [5/10], Phase: val, Batch: [38/73], Loss: 0.1685\n",
      "Epoch [5/10], Phase: val, Batch: [39/73], Loss: 0.2167\n",
      "Epoch [5/10], Phase: val, Batch: [40/73], Loss: 0.1955\n",
      "Epoch [5/10], Phase: val, Batch: [41/73], Loss: 0.2219\n",
      "Epoch [5/10], Phase: val, Batch: [42/73], Loss: 0.2684\n",
      "Epoch [5/10], Phase: val, Batch: [43/73], Loss: 0.2194\n",
      "Epoch [5/10], Phase: val, Batch: [44/73], Loss: 0.2374\n",
      "Epoch [5/10], Phase: val, Batch: [45/73], Loss: 0.1896\n",
      "Epoch [5/10], Phase: val, Batch: [46/73], Loss: 0.3061\n",
      "Epoch [5/10], Phase: val, Batch: [47/73], Loss: 0.2866\n",
      "Epoch [5/10], Phase: val, Batch: [48/73], Loss: 0.1430\n",
      "Epoch [5/10], Phase: val, Batch: [49/73], Loss: 0.2988\n",
      "Epoch [5/10], Phase: val, Batch: [50/73], Loss: 0.1824\n",
      "Epoch [5/10], Phase: val, Batch: [51/73], Loss: 0.3091\n",
      "Epoch [5/10], Phase: val, Batch: [52/73], Loss: 0.1903\n",
      "Epoch [5/10], Phase: val, Batch: [53/73], Loss: 0.2165\n",
      "Epoch [5/10], Phase: val, Batch: [54/73], Loss: 0.2091\n",
      "Epoch [5/10], Phase: val, Batch: [55/73], Loss: 0.2380\n",
      "Epoch [5/10], Phase: val, Batch: [56/73], Loss: 0.3029\n",
      "Epoch [5/10], Phase: val, Batch: [57/73], Loss: 0.1397\n",
      "Epoch [5/10], Phase: val, Batch: [58/73], Loss: 0.2553\n",
      "Epoch [5/10], Phase: val, Batch: [59/73], Loss: 0.2450\n",
      "Epoch [5/10], Phase: val, Batch: [60/73], Loss: 0.1727\n",
      "Epoch [5/10], Phase: val, Batch: [61/73], Loss: 0.3315\n",
      "Epoch [5/10], Phase: val, Batch: [62/73], Loss: 0.2352\n",
      "Epoch [5/10], Phase: val, Batch: [63/73], Loss: 0.2312\n",
      "Epoch [5/10], Phase: val, Batch: [64/73], Loss: 0.2810\n",
      "Epoch [5/10], Phase: val, Batch: [65/73], Loss: 0.2431\n",
      "Epoch [5/10], Phase: val, Batch: [66/73], Loss: 0.1809\n",
      "Epoch [5/10], Phase: val, Batch: [67/73], Loss: 0.2186\n",
      "Epoch [5/10], Phase: val, Batch: [68/73], Loss: 0.2176\n",
      "Epoch [5/10], Phase: val, Batch: [69/73], Loss: 0.2979\n",
      "Epoch [5/10], Phase: val, Batch: [70/73], Loss: 0.2450\n",
      "Epoch [5/10], Phase: val, Batch: [71/73], Loss: 0.3127\n",
      "Epoch [5/10], Phase: val, Batch: [72/73], Loss: 0.4061\n",
      "Epoch [5/10], Phase: val, Batch: [73/73], Loss: 0.1146\n",
      "val Loss: 0.2400 Acc: 0.9023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Phase: train, Batch: [1/657], Loss: 0.3716\n",
      "Epoch [6/10], Phase: train, Batch: [2/657], Loss: 0.4579\n",
      "Epoch [6/10], Phase: train, Batch: [3/657], Loss: 0.2682\n",
      "Epoch [6/10], Phase: train, Batch: [4/657], Loss: 0.1871\n",
      "Epoch [6/10], Phase: train, Batch: [5/657], Loss: 0.2078\n",
      "Epoch [6/10], Phase: train, Batch: [6/657], Loss: 0.3032\n",
      "Epoch [6/10], Phase: train, Batch: [7/657], Loss: 0.2676\n",
      "Epoch [6/10], Phase: train, Batch: [8/657], Loss: 0.2570\n",
      "Epoch [6/10], Phase: train, Batch: [9/657], Loss: 0.2459\n",
      "Epoch [6/10], Phase: train, Batch: [10/657], Loss: 0.2360\n",
      "Epoch [6/10], Phase: train, Batch: [11/657], Loss: 0.2918\n",
      "Epoch [6/10], Phase: train, Batch: [12/657], Loss: 0.4843\n",
      "Epoch [6/10], Phase: train, Batch: [13/657], Loss: 0.4424\n",
      "Epoch [6/10], Phase: train, Batch: [14/657], Loss: 0.2197\n",
      "Epoch [6/10], Phase: train, Batch: [15/657], Loss: 0.2988\n",
      "Epoch [6/10], Phase: train, Batch: [16/657], Loss: 0.2621\n",
      "Epoch [6/10], Phase: train, Batch: [17/657], Loss: 0.2513\n",
      "Epoch [6/10], Phase: train, Batch: [18/657], Loss: 0.3819\n",
      "Epoch [6/10], Phase: train, Batch: [19/657], Loss: 0.3052\n",
      "Epoch [6/10], Phase: train, Batch: [20/657], Loss: 0.2141\n",
      "Epoch [6/10], Phase: train, Batch: [21/657], Loss: 0.2246\n",
      "Epoch [6/10], Phase: train, Batch: [22/657], Loss: 0.4099\n",
      "Epoch [6/10], Phase: train, Batch: [23/657], Loss: 0.2318\n",
      "Epoch [6/10], Phase: train, Batch: [24/657], Loss: 0.4012\n",
      "Epoch [6/10], Phase: train, Batch: [25/657], Loss: 0.3183\n",
      "Epoch [6/10], Phase: train, Batch: [26/657], Loss: 0.3153\n",
      "Epoch [6/10], Phase: train, Batch: [27/657], Loss: 0.2994\n",
      "Epoch [6/10], Phase: train, Batch: [28/657], Loss: 0.2667\n",
      "Epoch [6/10], Phase: train, Batch: [29/657], Loss: 0.2505\n",
      "Epoch [6/10], Phase: train, Batch: [30/657], Loss: 0.3507\n",
      "Epoch [6/10], Phase: train, Batch: [31/657], Loss: 0.4168\n",
      "Epoch [6/10], Phase: train, Batch: [32/657], Loss: 0.2616\n",
      "Epoch [6/10], Phase: train, Batch: [33/657], Loss: 0.2707\n",
      "Epoch [6/10], Phase: train, Batch: [34/657], Loss: 0.1821\n",
      "Epoch [6/10], Phase: train, Batch: [35/657], Loss: 0.4440\n",
      "Epoch [6/10], Phase: train, Batch: [36/657], Loss: 0.3030\n",
      "Epoch [6/10], Phase: train, Batch: [37/657], Loss: 0.2145\n",
      "Epoch [6/10], Phase: train, Batch: [38/657], Loss: 0.2708\n",
      "Epoch [6/10], Phase: train, Batch: [39/657], Loss: 0.2744\n",
      "Epoch [6/10], Phase: train, Batch: [40/657], Loss: 0.2993\n",
      "Epoch [6/10], Phase: train, Batch: [41/657], Loss: 0.2326\n",
      "Epoch [6/10], Phase: train, Batch: [42/657], Loss: 0.2255\n",
      "Epoch [6/10], Phase: train, Batch: [43/657], Loss: 0.1698\n",
      "Epoch [6/10], Phase: train, Batch: [44/657], Loss: 0.2397\n",
      "Epoch [6/10], Phase: train, Batch: [45/657], Loss: 0.2028\n",
      "Epoch [6/10], Phase: train, Batch: [46/657], Loss: 0.2031\n",
      "Epoch [6/10], Phase: train, Batch: [47/657], Loss: 0.2127\n",
      "Epoch [6/10], Phase: train, Batch: [48/657], Loss: 0.3556\n",
      "Epoch [6/10], Phase: train, Batch: [49/657], Loss: 0.2850\n",
      "Epoch [6/10], Phase: train, Batch: [50/657], Loss: 0.2587\n",
      "Epoch [6/10], Phase: train, Batch: [51/657], Loss: 0.2434\n",
      "Epoch [6/10], Phase: train, Batch: [52/657], Loss: 0.2103\n",
      "Epoch [6/10], Phase: train, Batch: [53/657], Loss: 0.2989\n",
      "Epoch [6/10], Phase: train, Batch: [54/657], Loss: 0.3152\n",
      "Epoch [6/10], Phase: train, Batch: [55/657], Loss: 0.3184\n",
      "Epoch [6/10], Phase: train, Batch: [56/657], Loss: 0.2242\n",
      "Epoch [6/10], Phase: train, Batch: [57/657], Loss: 0.2677\n",
      "Epoch [6/10], Phase: train, Batch: [58/657], Loss: 0.2436\n",
      "Epoch [6/10], Phase: train, Batch: [59/657], Loss: 0.2689\n",
      "Epoch [6/10], Phase: train, Batch: [60/657], Loss: 0.1105\n",
      "Epoch [6/10], Phase: train, Batch: [61/657], Loss: 0.2728\n",
      "Epoch [6/10], Phase: train, Batch: [62/657], Loss: 0.2141\n",
      "Epoch [6/10], Phase: train, Batch: [63/657], Loss: 0.2192\n",
      "Epoch [6/10], Phase: train, Batch: [64/657], Loss: 0.3733\n",
      "Epoch [6/10], Phase: train, Batch: [65/657], Loss: 0.3481\n",
      "Epoch [6/10], Phase: train, Batch: [66/657], Loss: 0.2439\n",
      "Epoch [6/10], Phase: train, Batch: [67/657], Loss: 0.2740\n",
      "Epoch [6/10], Phase: train, Batch: [68/657], Loss: 0.2470\n",
      "Epoch [6/10], Phase: train, Batch: [69/657], Loss: 0.3185\n",
      "Epoch [6/10], Phase: train, Batch: [70/657], Loss: 0.2647\n",
      "Epoch [6/10], Phase: train, Batch: [71/657], Loss: 0.2231\n",
      "Epoch [6/10], Phase: train, Batch: [72/657], Loss: 0.3198\n",
      "Epoch [6/10], Phase: train, Batch: [73/657], Loss: 0.2129\n",
      "Epoch [6/10], Phase: train, Batch: [74/657], Loss: 0.2322\n",
      "Epoch [6/10], Phase: train, Batch: [75/657], Loss: 0.2720\n",
      "Epoch [6/10], Phase: train, Batch: [76/657], Loss: 0.2320\n",
      "Epoch [6/10], Phase: train, Batch: [77/657], Loss: 0.2711\n",
      "Epoch [6/10], Phase: train, Batch: [78/657], Loss: 0.3702\n",
      "Epoch [6/10], Phase: train, Batch: [79/657], Loss: 0.2027\n",
      "Epoch [6/10], Phase: train, Batch: [80/657], Loss: 0.3280\n",
      "Epoch [6/10], Phase: train, Batch: [81/657], Loss: 0.3246\n",
      "Epoch [6/10], Phase: train, Batch: [82/657], Loss: 0.2556\n",
      "Epoch [6/10], Phase: train, Batch: [83/657], Loss: 0.2670\n",
      "Epoch [6/10], Phase: train, Batch: [84/657], Loss: 0.2919\n",
      "Epoch [6/10], Phase: train, Batch: [85/657], Loss: 0.3064\n",
      "Epoch [6/10], Phase: train, Batch: [86/657], Loss: 0.3333\n",
      "Epoch [6/10], Phase: train, Batch: [87/657], Loss: 0.1877\n",
      "Epoch [6/10], Phase: train, Batch: [88/657], Loss: 0.2816\n",
      "Epoch [6/10], Phase: train, Batch: [89/657], Loss: 0.1584\n",
      "Epoch [6/10], Phase: train, Batch: [90/657], Loss: 0.2464\n",
      "Epoch [6/10], Phase: train, Batch: [91/657], Loss: 0.5596\n",
      "Epoch [6/10], Phase: train, Batch: [92/657], Loss: 0.2520\n",
      "Epoch [6/10], Phase: train, Batch: [93/657], Loss: 0.2675\n",
      "Epoch [6/10], Phase: train, Batch: [94/657], Loss: 0.2538\n",
      "Epoch [6/10], Phase: train, Batch: [95/657], Loss: 0.2607\n",
      "Epoch [6/10], Phase: train, Batch: [96/657], Loss: 0.2897\n",
      "Epoch [6/10], Phase: train, Batch: [97/657], Loss: 0.1918\n",
      "Epoch [6/10], Phase: train, Batch: [98/657], Loss: 0.1757\n",
      "Epoch [6/10], Phase: train, Batch: [99/657], Loss: 0.3524\n",
      "Epoch [6/10], Phase: train, Batch: [100/657], Loss: 0.1438\n",
      "Epoch [6/10], Phase: train, Batch: [101/657], Loss: 0.1447\n",
      "Epoch [6/10], Phase: train, Batch: [102/657], Loss: 0.2907\n",
      "Epoch [6/10], Phase: train, Batch: [103/657], Loss: 0.2976\n",
      "Epoch [6/10], Phase: train, Batch: [104/657], Loss: 0.2983\n",
      "Epoch [6/10], Phase: train, Batch: [105/657], Loss: 0.2245\n",
      "Epoch [6/10], Phase: train, Batch: [106/657], Loss: 0.2593\n",
      "Epoch [6/10], Phase: train, Batch: [107/657], Loss: 0.2605\n",
      "Epoch [6/10], Phase: train, Batch: [108/657], Loss: 0.2564\n",
      "Epoch [6/10], Phase: train, Batch: [109/657], Loss: 0.3307\n",
      "Epoch [6/10], Phase: train, Batch: [110/657], Loss: 0.1762\n",
      "Epoch [6/10], Phase: train, Batch: [111/657], Loss: 0.2756\n",
      "Epoch [6/10], Phase: train, Batch: [112/657], Loss: 0.4155\n",
      "Epoch [6/10], Phase: train, Batch: [113/657], Loss: 0.2460\n",
      "Epoch [6/10], Phase: train, Batch: [114/657], Loss: 0.2294\n",
      "Epoch [6/10], Phase: train, Batch: [115/657], Loss: 0.3378\n",
      "Epoch [6/10], Phase: train, Batch: [116/657], Loss: 0.2437\n",
      "Epoch [6/10], Phase: train, Batch: [117/657], Loss: 0.1606\n",
      "Epoch [6/10], Phase: train, Batch: [118/657], Loss: 0.4036\n",
      "Epoch [6/10], Phase: train, Batch: [119/657], Loss: 0.2825\n",
      "Epoch [6/10], Phase: train, Batch: [120/657], Loss: 0.2510\n",
      "Epoch [6/10], Phase: train, Batch: [121/657], Loss: 0.3400\n",
      "Epoch [6/10], Phase: train, Batch: [122/657], Loss: 0.3678\n",
      "Epoch [6/10], Phase: train, Batch: [123/657], Loss: 0.2882\n",
      "Epoch [6/10], Phase: train, Batch: [124/657], Loss: 0.3067\n",
      "Epoch [6/10], Phase: train, Batch: [125/657], Loss: 0.2207\n",
      "Epoch [6/10], Phase: train, Batch: [126/657], Loss: 0.3330\n",
      "Epoch [6/10], Phase: train, Batch: [127/657], Loss: 0.3133\n",
      "Epoch [6/10], Phase: train, Batch: [128/657], Loss: 0.2347\n",
      "Epoch [6/10], Phase: train, Batch: [129/657], Loss: 0.2619\n",
      "Epoch [6/10], Phase: train, Batch: [130/657], Loss: 0.2191\n",
      "Epoch [6/10], Phase: train, Batch: [131/657], Loss: 0.4426\n",
      "Epoch [6/10], Phase: train, Batch: [132/657], Loss: 0.2605\n",
      "Epoch [6/10], Phase: train, Batch: [133/657], Loss: 0.2248\n",
      "Epoch [6/10], Phase: train, Batch: [134/657], Loss: 0.1837\n",
      "Epoch [6/10], Phase: train, Batch: [135/657], Loss: 0.2878\n",
      "Epoch [6/10], Phase: train, Batch: [136/657], Loss: 0.2285\n",
      "Epoch [6/10], Phase: train, Batch: [137/657], Loss: 0.2675\n",
      "Epoch [6/10], Phase: train, Batch: [138/657], Loss: 0.3306\n",
      "Epoch [6/10], Phase: train, Batch: [139/657], Loss: 0.1824\n",
      "Epoch [6/10], Phase: train, Batch: [140/657], Loss: 0.2223\n",
      "Epoch [6/10], Phase: train, Batch: [141/657], Loss: 0.4349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Phase: train, Batch: [142/657], Loss: 0.1892\n",
      "Epoch [6/10], Phase: train, Batch: [143/657], Loss: 0.3564\n",
      "Epoch [6/10], Phase: train, Batch: [144/657], Loss: 0.2064\n",
      "Epoch [6/10], Phase: train, Batch: [145/657], Loss: 0.3151\n",
      "Epoch [6/10], Phase: train, Batch: [146/657], Loss: 0.1464\n",
      "Epoch [6/10], Phase: train, Batch: [147/657], Loss: 0.2628\n",
      "Epoch [6/10], Phase: train, Batch: [148/657], Loss: 0.1948\n",
      "Epoch [6/10], Phase: train, Batch: [149/657], Loss: 0.2635\n",
      "Epoch [6/10], Phase: train, Batch: [150/657], Loss: 0.2332\n",
      "Epoch [6/10], Phase: train, Batch: [151/657], Loss: 0.2506\n",
      "Epoch [6/10], Phase: train, Batch: [152/657], Loss: 0.4340\n",
      "Epoch [6/10], Phase: train, Batch: [153/657], Loss: 0.3382\n",
      "Epoch [6/10], Phase: train, Batch: [154/657], Loss: 0.3401\n",
      "Epoch [6/10], Phase: train, Batch: [155/657], Loss: 0.2151\n",
      "Epoch [6/10], Phase: train, Batch: [156/657], Loss: 0.3131\n",
      "Epoch [6/10], Phase: train, Batch: [157/657], Loss: 0.2879\n",
      "Epoch [6/10], Phase: train, Batch: [158/657], Loss: 0.2551\n",
      "Epoch [6/10], Phase: train, Batch: [159/657], Loss: 0.3026\n",
      "Epoch [6/10], Phase: train, Batch: [160/657], Loss: 0.1809\n",
      "Epoch [6/10], Phase: train, Batch: [161/657], Loss: 0.1956\n",
      "Epoch [6/10], Phase: train, Batch: [162/657], Loss: 0.2444\n",
      "Epoch [6/10], Phase: train, Batch: [163/657], Loss: 0.2977\n",
      "Epoch [6/10], Phase: train, Batch: [164/657], Loss: 0.1746\n",
      "Epoch [6/10], Phase: train, Batch: [165/657], Loss: 0.2759\n",
      "Epoch [6/10], Phase: train, Batch: [166/657], Loss: 0.2839\n",
      "Epoch [6/10], Phase: train, Batch: [167/657], Loss: 0.3207\n",
      "Epoch [6/10], Phase: train, Batch: [168/657], Loss: 0.1854\n",
      "Epoch [6/10], Phase: train, Batch: [169/657], Loss: 0.2837\n",
      "Epoch [6/10], Phase: train, Batch: [170/657], Loss: 0.4043\n",
      "Epoch [6/10], Phase: train, Batch: [171/657], Loss: 0.2574\n",
      "Epoch [6/10], Phase: train, Batch: [172/657], Loss: 0.2831\n",
      "Epoch [6/10], Phase: train, Batch: [173/657], Loss: 0.3408\n",
      "Epoch [6/10], Phase: train, Batch: [174/657], Loss: 0.2264\n",
      "Epoch [6/10], Phase: train, Batch: [175/657], Loss: 0.2734\n",
      "Epoch [6/10], Phase: train, Batch: [176/657], Loss: 0.3638\n",
      "Epoch [6/10], Phase: train, Batch: [177/657], Loss: 0.2851\n",
      "Epoch [6/10], Phase: train, Batch: [178/657], Loss: 0.3565\n",
      "Epoch [6/10], Phase: train, Batch: [179/657], Loss: 0.3386\n",
      "Epoch [6/10], Phase: train, Batch: [180/657], Loss: 0.1596\n",
      "Epoch [6/10], Phase: train, Batch: [181/657], Loss: 0.3850\n",
      "Epoch [6/10], Phase: train, Batch: [182/657], Loss: 0.3137\n",
      "Epoch [6/10], Phase: train, Batch: [183/657], Loss: 0.2330\n",
      "Epoch [6/10], Phase: train, Batch: [184/657], Loss: 0.2453\n",
      "Epoch [6/10], Phase: train, Batch: [185/657], Loss: 0.2373\n",
      "Epoch [6/10], Phase: train, Batch: [186/657], Loss: 0.2897\n",
      "Epoch [6/10], Phase: train, Batch: [187/657], Loss: 0.3139\n",
      "Epoch [6/10], Phase: train, Batch: [188/657], Loss: 0.2851\n",
      "Epoch [6/10], Phase: train, Batch: [189/657], Loss: 0.2791\n",
      "Epoch [6/10], Phase: train, Batch: [190/657], Loss: 0.2271\n",
      "Epoch [6/10], Phase: train, Batch: [191/657], Loss: 0.2822\n",
      "Epoch [6/10], Phase: train, Batch: [192/657], Loss: 0.2360\n",
      "Epoch [6/10], Phase: train, Batch: [193/657], Loss: 0.2719\n",
      "Epoch [6/10], Phase: train, Batch: [194/657], Loss: 0.2087\n",
      "Epoch [6/10], Phase: train, Batch: [195/657], Loss: 0.2288\n",
      "Epoch [6/10], Phase: train, Batch: [196/657], Loss: 0.3413\n",
      "Epoch [6/10], Phase: train, Batch: [197/657], Loss: 0.2984\n",
      "Epoch [6/10], Phase: train, Batch: [198/657], Loss: 0.3050\n",
      "Epoch [6/10], Phase: train, Batch: [199/657], Loss: 0.3410\n",
      "Epoch [6/10], Phase: train, Batch: [200/657], Loss: 0.1425\n",
      "Epoch [6/10], Phase: train, Batch: [201/657], Loss: 0.2977\n",
      "Epoch [6/10], Phase: train, Batch: [202/657], Loss: 0.4418\n",
      "Epoch [6/10], Phase: train, Batch: [203/657], Loss: 0.3654\n",
      "Epoch [6/10], Phase: train, Batch: [204/657], Loss: 0.3637\n",
      "Epoch [6/10], Phase: train, Batch: [205/657], Loss: 0.2371\n",
      "Epoch [6/10], Phase: train, Batch: [206/657], Loss: 0.3563\n",
      "Epoch [6/10], Phase: train, Batch: [207/657], Loss: 0.2956\n",
      "Epoch [6/10], Phase: train, Batch: [208/657], Loss: 0.3232\n",
      "Epoch [6/10], Phase: train, Batch: [209/657], Loss: 0.4095\n",
      "Epoch [6/10], Phase: train, Batch: [210/657], Loss: 0.3655\n",
      "Epoch [6/10], Phase: train, Batch: [211/657], Loss: 0.2491\n",
      "Epoch [6/10], Phase: train, Batch: [212/657], Loss: 0.2723\n",
      "Epoch [6/10], Phase: train, Batch: [213/657], Loss: 0.3433\n",
      "Epoch [6/10], Phase: train, Batch: [214/657], Loss: 0.2674\n",
      "Epoch [6/10], Phase: train, Batch: [215/657], Loss: 0.3576\n",
      "Epoch [6/10], Phase: train, Batch: [216/657], Loss: 0.3024\n",
      "Epoch [6/10], Phase: train, Batch: [217/657], Loss: 0.3077\n",
      "Epoch [6/10], Phase: train, Batch: [218/657], Loss: 0.1739\n",
      "Epoch [6/10], Phase: train, Batch: [219/657], Loss: 0.4197\n",
      "Epoch [6/10], Phase: train, Batch: [220/657], Loss: 0.3256\n",
      "Epoch [6/10], Phase: train, Batch: [221/657], Loss: 0.2233\n",
      "Epoch [6/10], Phase: train, Batch: [222/657], Loss: 0.2730\n",
      "Epoch [6/10], Phase: train, Batch: [223/657], Loss: 0.2283\n",
      "Epoch [6/10], Phase: train, Batch: [224/657], Loss: 0.1621\n",
      "Epoch [6/10], Phase: train, Batch: [225/657], Loss: 0.2907\n",
      "Epoch [6/10], Phase: train, Batch: [226/657], Loss: 0.2712\n",
      "Epoch [6/10], Phase: train, Batch: [227/657], Loss: 0.2288\n",
      "Epoch [6/10], Phase: train, Batch: [228/657], Loss: 0.2368\n",
      "Epoch [6/10], Phase: train, Batch: [229/657], Loss: 0.3565\n",
      "Epoch [6/10], Phase: train, Batch: [230/657], Loss: 0.2502\n",
      "Epoch [6/10], Phase: train, Batch: [231/657], Loss: 0.2917\n",
      "Epoch [6/10], Phase: train, Batch: [232/657], Loss: 0.3445\n",
      "Epoch [6/10], Phase: train, Batch: [233/657], Loss: 0.2137\n",
      "Epoch [6/10], Phase: train, Batch: [234/657], Loss: 0.2349\n",
      "Epoch [6/10], Phase: train, Batch: [235/657], Loss: 0.2421\n",
      "Epoch [6/10], Phase: train, Batch: [236/657], Loss: 0.4583\n",
      "Epoch [6/10], Phase: train, Batch: [237/657], Loss: 0.1848\n",
      "Epoch [6/10], Phase: train, Batch: [238/657], Loss: 0.2954\n",
      "Epoch [6/10], Phase: train, Batch: [239/657], Loss: 0.2573\n",
      "Epoch [6/10], Phase: train, Batch: [240/657], Loss: 0.3696\n",
      "Epoch [6/10], Phase: train, Batch: [241/657], Loss: 0.3807\n",
      "Epoch [6/10], Phase: train, Batch: [242/657], Loss: 0.2569\n",
      "Epoch [6/10], Phase: train, Batch: [243/657], Loss: 0.2188\n",
      "Epoch [6/10], Phase: train, Batch: [244/657], Loss: 0.1789\n",
      "Epoch [6/10], Phase: train, Batch: [245/657], Loss: 0.2446\n",
      "Epoch [6/10], Phase: train, Batch: [246/657], Loss: 0.3945\n",
      "Epoch [6/10], Phase: train, Batch: [247/657], Loss: 0.2491\n",
      "Epoch [6/10], Phase: train, Batch: [248/657], Loss: 0.2224\n",
      "Epoch [6/10], Phase: train, Batch: [249/657], Loss: 0.2651\n",
      "Epoch [6/10], Phase: train, Batch: [250/657], Loss: 0.3421\n",
      "Epoch [6/10], Phase: train, Batch: [251/657], Loss: 0.2866\n",
      "Epoch [6/10], Phase: train, Batch: [252/657], Loss: 0.3710\n",
      "Epoch [6/10], Phase: train, Batch: [253/657], Loss: 0.3798\n",
      "Epoch [6/10], Phase: train, Batch: [254/657], Loss: 0.3793\n",
      "Epoch [6/10], Phase: train, Batch: [255/657], Loss: 0.4127\n",
      "Epoch [6/10], Phase: train, Batch: [256/657], Loss: 0.3090\n",
      "Epoch [6/10], Phase: train, Batch: [257/657], Loss: 0.3361\n",
      "Epoch [6/10], Phase: train, Batch: [258/657], Loss: 0.2648\n",
      "Epoch [6/10], Phase: train, Batch: [259/657], Loss: 0.3470\n",
      "Epoch [6/10], Phase: train, Batch: [260/657], Loss: 0.2728\n",
      "Epoch [6/10], Phase: train, Batch: [261/657], Loss: 0.3452\n",
      "Epoch [6/10], Phase: train, Batch: [262/657], Loss: 0.2606\n",
      "Epoch [6/10], Phase: train, Batch: [263/657], Loss: 0.3367\n",
      "Epoch [6/10], Phase: train, Batch: [264/657], Loss: 0.4209\n",
      "Epoch [6/10], Phase: train, Batch: [265/657], Loss: 0.3292\n",
      "Epoch [6/10], Phase: train, Batch: [266/657], Loss: 0.2295\n",
      "Epoch [6/10], Phase: train, Batch: [267/657], Loss: 0.2859\n",
      "Epoch [6/10], Phase: train, Batch: [268/657], Loss: 0.2093\n",
      "Epoch [6/10], Phase: train, Batch: [269/657], Loss: 0.2717\n",
      "Epoch [6/10], Phase: train, Batch: [270/657], Loss: 0.2453\n",
      "Epoch [6/10], Phase: train, Batch: [271/657], Loss: 0.2608\n",
      "Epoch [6/10], Phase: train, Batch: [272/657], Loss: 0.3145\n",
      "Epoch [6/10], Phase: train, Batch: [273/657], Loss: 0.3009\n",
      "Epoch [6/10], Phase: train, Batch: [274/657], Loss: 0.3082\n",
      "Epoch [6/10], Phase: train, Batch: [275/657], Loss: 0.1971\n",
      "Epoch [6/10], Phase: train, Batch: [276/657], Loss: 0.4338\n",
      "Epoch [6/10], Phase: train, Batch: [277/657], Loss: 0.3991\n",
      "Epoch [6/10], Phase: train, Batch: [278/657], Loss: 0.0866\n",
      "Epoch [6/10], Phase: train, Batch: [279/657], Loss: 0.1861\n",
      "Epoch [6/10], Phase: train, Batch: [280/657], Loss: 0.3360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Phase: train, Batch: [281/657], Loss: 0.2889\n",
      "Epoch [6/10], Phase: train, Batch: [282/657], Loss: 0.3843\n",
      "Epoch [6/10], Phase: train, Batch: [283/657], Loss: 0.2680\n",
      "Epoch [6/10], Phase: train, Batch: [284/657], Loss: 0.2994\n",
      "Epoch [6/10], Phase: train, Batch: [285/657], Loss: 0.2530\n",
      "Epoch [6/10], Phase: train, Batch: [286/657], Loss: 0.3827\n",
      "Epoch [6/10], Phase: train, Batch: [287/657], Loss: 0.2422\n",
      "Epoch [6/10], Phase: train, Batch: [288/657], Loss: 0.3048\n",
      "Epoch [6/10], Phase: train, Batch: [289/657], Loss: 0.2544\n",
      "Epoch [6/10], Phase: train, Batch: [290/657], Loss: 0.3540\n",
      "Epoch [6/10], Phase: train, Batch: [291/657], Loss: 0.2134\n",
      "Epoch [6/10], Phase: train, Batch: [292/657], Loss: 0.2424\n",
      "Epoch [6/10], Phase: train, Batch: [293/657], Loss: 0.1585\n",
      "Epoch [6/10], Phase: train, Batch: [294/657], Loss: 0.2258\n",
      "Epoch [6/10], Phase: train, Batch: [295/657], Loss: 0.2414\n",
      "Epoch [6/10], Phase: train, Batch: [296/657], Loss: 0.2025\n",
      "Epoch [6/10], Phase: train, Batch: [297/657], Loss: 0.2650\n",
      "Epoch [6/10], Phase: train, Batch: [298/657], Loss: 0.4213\n",
      "Epoch [6/10], Phase: train, Batch: [299/657], Loss: 0.3392\n",
      "Epoch [6/10], Phase: train, Batch: [300/657], Loss: 0.3420\n",
      "Epoch [6/10], Phase: train, Batch: [301/657], Loss: 0.3386\n",
      "Epoch [6/10], Phase: train, Batch: [302/657], Loss: 0.1964\n",
      "Epoch [6/10], Phase: train, Batch: [303/657], Loss: 0.2161\n",
      "Epoch [6/10], Phase: train, Batch: [304/657], Loss: 0.3112\n",
      "Epoch [6/10], Phase: train, Batch: [305/657], Loss: 0.3581\n",
      "Epoch [6/10], Phase: train, Batch: [306/657], Loss: 0.2270\n",
      "Epoch [6/10], Phase: train, Batch: [307/657], Loss: 0.4239\n",
      "Epoch [6/10], Phase: train, Batch: [308/657], Loss: 0.2391\n",
      "Epoch [6/10], Phase: train, Batch: [309/657], Loss: 0.2300\n",
      "Epoch [6/10], Phase: train, Batch: [310/657], Loss: 0.2234\n",
      "Epoch [6/10], Phase: train, Batch: [311/657], Loss: 0.3665\n",
      "Epoch [6/10], Phase: train, Batch: [312/657], Loss: 0.2619\n",
      "Epoch [6/10], Phase: train, Batch: [313/657], Loss: 0.3103\n",
      "Epoch [6/10], Phase: train, Batch: [314/657], Loss: 0.2910\n",
      "Epoch [6/10], Phase: train, Batch: [315/657], Loss: 0.2637\n",
      "Epoch [6/10], Phase: train, Batch: [316/657], Loss: 0.2052\n",
      "Epoch [6/10], Phase: train, Batch: [317/657], Loss: 0.2786\n",
      "Epoch [6/10], Phase: train, Batch: [318/657], Loss: 0.3645\n",
      "Epoch [6/10], Phase: train, Batch: [319/657], Loss: 0.2457\n",
      "Epoch [6/10], Phase: train, Batch: [320/657], Loss: 0.1859\n",
      "Epoch [6/10], Phase: train, Batch: [321/657], Loss: 0.2565\n",
      "Epoch [6/10], Phase: train, Batch: [322/657], Loss: 0.3917\n",
      "Epoch [6/10], Phase: train, Batch: [323/657], Loss: 0.2269\n",
      "Epoch [6/10], Phase: train, Batch: [324/657], Loss: 0.4006\n",
      "Epoch [6/10], Phase: train, Batch: [325/657], Loss: 0.2212\n",
      "Epoch [6/10], Phase: train, Batch: [326/657], Loss: 0.1819\n",
      "Epoch [6/10], Phase: train, Batch: [327/657], Loss: 0.1815\n",
      "Epoch [6/10], Phase: train, Batch: [328/657], Loss: 0.2157\n",
      "Epoch [6/10], Phase: train, Batch: [329/657], Loss: 0.1794\n",
      "Epoch [6/10], Phase: train, Batch: [330/657], Loss: 0.1544\n",
      "Epoch [6/10], Phase: train, Batch: [331/657], Loss: 0.3542\n",
      "Epoch [6/10], Phase: train, Batch: [332/657], Loss: 0.2897\n",
      "Epoch [6/10], Phase: train, Batch: [333/657], Loss: 0.2717\n",
      "Epoch [6/10], Phase: train, Batch: [334/657], Loss: 0.4377\n",
      "Epoch [6/10], Phase: train, Batch: [335/657], Loss: 0.2471\n",
      "Epoch [6/10], Phase: train, Batch: [336/657], Loss: 0.2066\n",
      "Epoch [6/10], Phase: train, Batch: [337/657], Loss: 0.2250\n",
      "Epoch [6/10], Phase: train, Batch: [338/657], Loss: 0.2016\n",
      "Epoch [6/10], Phase: train, Batch: [339/657], Loss: 0.2704\n",
      "Epoch [6/10], Phase: train, Batch: [340/657], Loss: 0.3149\n",
      "Epoch [6/10], Phase: train, Batch: [341/657], Loss: 0.2261\n",
      "Epoch [6/10], Phase: train, Batch: [342/657], Loss: 0.3524\n",
      "Epoch [6/10], Phase: train, Batch: [343/657], Loss: 0.1478\n",
      "Epoch [6/10], Phase: train, Batch: [344/657], Loss: 0.1981\n",
      "Epoch [6/10], Phase: train, Batch: [345/657], Loss: 0.2240\n",
      "Epoch [6/10], Phase: train, Batch: [346/657], Loss: 0.3400\n",
      "Epoch [6/10], Phase: train, Batch: [347/657], Loss: 0.2761\n",
      "Epoch [6/10], Phase: train, Batch: [348/657], Loss: 0.2338\n",
      "Epoch [6/10], Phase: train, Batch: [349/657], Loss: 0.3225\n",
      "Epoch [6/10], Phase: train, Batch: [350/657], Loss: 0.2369\n",
      "Epoch [6/10], Phase: train, Batch: [351/657], Loss: 0.2666\n",
      "Epoch [6/10], Phase: train, Batch: [352/657], Loss: 0.2623\n",
      "Epoch [6/10], Phase: train, Batch: [353/657], Loss: 0.2014\n",
      "Epoch [6/10], Phase: train, Batch: [354/657], Loss: 0.3382\n",
      "Epoch [6/10], Phase: train, Batch: [355/657], Loss: 0.1873\n",
      "Epoch [6/10], Phase: train, Batch: [356/657], Loss: 0.3071\n",
      "Epoch [6/10], Phase: train, Batch: [357/657], Loss: 0.2754\n",
      "Epoch [6/10], Phase: train, Batch: [358/657], Loss: 0.1841\n",
      "Epoch [6/10], Phase: train, Batch: [359/657], Loss: 0.2126\n",
      "Epoch [6/10], Phase: train, Batch: [360/657], Loss: 0.2440\n",
      "Epoch [6/10], Phase: train, Batch: [361/657], Loss: 0.2962\n",
      "Epoch [6/10], Phase: train, Batch: [362/657], Loss: 0.4293\n",
      "Epoch [6/10], Phase: train, Batch: [363/657], Loss: 0.3447\n",
      "Epoch [6/10], Phase: train, Batch: [364/657], Loss: 0.3228\n",
      "Epoch [6/10], Phase: train, Batch: [365/657], Loss: 0.3521\n",
      "Epoch [6/10], Phase: train, Batch: [366/657], Loss: 0.3144\n",
      "Epoch [6/10], Phase: train, Batch: [367/657], Loss: 0.2843\n",
      "Epoch [6/10], Phase: train, Batch: [368/657], Loss: 0.3091\n",
      "Epoch [6/10], Phase: train, Batch: [369/657], Loss: 0.2428\n",
      "Epoch [6/10], Phase: train, Batch: [370/657], Loss: 0.3930\n",
      "Epoch [6/10], Phase: train, Batch: [371/657], Loss: 0.2576\n",
      "Epoch [6/10], Phase: train, Batch: [372/657], Loss: 0.3088\n",
      "Epoch [6/10], Phase: train, Batch: [373/657], Loss: 0.3377\n",
      "Epoch [6/10], Phase: train, Batch: [374/657], Loss: 0.2034\n",
      "Epoch [6/10], Phase: train, Batch: [375/657], Loss: 0.3052\n",
      "Epoch [6/10], Phase: train, Batch: [376/657], Loss: 0.2487\n",
      "Epoch [6/10], Phase: train, Batch: [377/657], Loss: 0.4332\n",
      "Epoch [6/10], Phase: train, Batch: [378/657], Loss: 0.3182\n",
      "Epoch [6/10], Phase: train, Batch: [379/657], Loss: 0.2369\n",
      "Epoch [6/10], Phase: train, Batch: [380/657], Loss: 0.2893\n",
      "Epoch [6/10], Phase: train, Batch: [381/657], Loss: 0.3593\n",
      "Epoch [6/10], Phase: train, Batch: [382/657], Loss: 0.3429\n",
      "Epoch [6/10], Phase: train, Batch: [383/657], Loss: 0.2502\n",
      "Epoch [6/10], Phase: train, Batch: [384/657], Loss: 0.2075\n",
      "Epoch [6/10], Phase: train, Batch: [385/657], Loss: 0.1965\n",
      "Epoch [6/10], Phase: train, Batch: [386/657], Loss: 0.2899\n",
      "Epoch [6/10], Phase: train, Batch: [387/657], Loss: 0.3332\n",
      "Epoch [6/10], Phase: train, Batch: [388/657], Loss: 0.3824\n",
      "Epoch [6/10], Phase: train, Batch: [389/657], Loss: 0.2220\n",
      "Epoch [6/10], Phase: train, Batch: [390/657], Loss: 0.2849\n",
      "Epoch [6/10], Phase: train, Batch: [391/657], Loss: 0.1781\n",
      "Epoch [6/10], Phase: train, Batch: [392/657], Loss: 0.1908\n",
      "Epoch [6/10], Phase: train, Batch: [393/657], Loss: 0.2748\n",
      "Epoch [6/10], Phase: train, Batch: [394/657], Loss: 0.3421\n",
      "Epoch [6/10], Phase: train, Batch: [395/657], Loss: 0.3856\n",
      "Epoch [6/10], Phase: train, Batch: [396/657], Loss: 0.3561\n",
      "Epoch [6/10], Phase: train, Batch: [397/657], Loss: 0.3978\n",
      "Epoch [6/10], Phase: train, Batch: [398/657], Loss: 0.1291\n",
      "Epoch [6/10], Phase: train, Batch: [399/657], Loss: 0.3551\n",
      "Epoch [6/10], Phase: train, Batch: [400/657], Loss: 0.2173\n",
      "Epoch [6/10], Phase: train, Batch: [401/657], Loss: 0.2342\n",
      "Epoch [6/10], Phase: train, Batch: [402/657], Loss: 0.2696\n",
      "Epoch [6/10], Phase: train, Batch: [403/657], Loss: 0.2646\n",
      "Epoch [6/10], Phase: train, Batch: [404/657], Loss: 0.1538\n",
      "Epoch [6/10], Phase: train, Batch: [405/657], Loss: 0.3025\n",
      "Epoch [6/10], Phase: train, Batch: [406/657], Loss: 0.2367\n",
      "Epoch [6/10], Phase: train, Batch: [407/657], Loss: 0.3006\n",
      "Epoch [6/10], Phase: train, Batch: [408/657], Loss: 0.2807\n",
      "Epoch [6/10], Phase: train, Batch: [409/657], Loss: 0.2478\n",
      "Epoch [6/10], Phase: train, Batch: [410/657], Loss: 0.3803\n",
      "Epoch [6/10], Phase: train, Batch: [411/657], Loss: 0.2264\n",
      "Epoch [6/10], Phase: train, Batch: [412/657], Loss: 0.2658\n",
      "Epoch [6/10], Phase: train, Batch: [413/657], Loss: 0.2966\n",
      "Epoch [6/10], Phase: train, Batch: [414/657], Loss: 0.2460\n",
      "Epoch [6/10], Phase: train, Batch: [415/657], Loss: 0.1819\n",
      "Epoch [6/10], Phase: train, Batch: [416/657], Loss: 0.1953\n",
      "Epoch [6/10], Phase: train, Batch: [417/657], Loss: 0.2510\n",
      "Epoch [6/10], Phase: train, Batch: [418/657], Loss: 0.3000\n",
      "Epoch [6/10], Phase: train, Batch: [419/657], Loss: 0.3219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Phase: train, Batch: [420/657], Loss: 0.1565\n",
      "Epoch [6/10], Phase: train, Batch: [421/657], Loss: 0.2756\n",
      "Epoch [6/10], Phase: train, Batch: [422/657], Loss: 0.2985\n",
      "Epoch [6/10], Phase: train, Batch: [423/657], Loss: 0.2330\n",
      "Epoch [6/10], Phase: train, Batch: [424/657], Loss: 0.1479\n",
      "Epoch [6/10], Phase: train, Batch: [425/657], Loss: 0.1835\n",
      "Epoch [6/10], Phase: train, Batch: [426/657], Loss: 0.2958\n",
      "Epoch [6/10], Phase: train, Batch: [427/657], Loss: 0.1546\n",
      "Epoch [6/10], Phase: train, Batch: [428/657], Loss: 0.3611\n",
      "Epoch [6/10], Phase: train, Batch: [429/657], Loss: 0.3111\n",
      "Epoch [6/10], Phase: train, Batch: [430/657], Loss: 0.3571\n",
      "Epoch [6/10], Phase: train, Batch: [431/657], Loss: 0.2280\n",
      "Epoch [6/10], Phase: train, Batch: [432/657], Loss: 0.3956\n",
      "Epoch [6/10], Phase: train, Batch: [433/657], Loss: 0.2466\n",
      "Epoch [6/10], Phase: train, Batch: [434/657], Loss: 0.2530\n",
      "Epoch [6/10], Phase: train, Batch: [435/657], Loss: 0.2333\n",
      "Epoch [6/10], Phase: train, Batch: [436/657], Loss: 0.1909\n",
      "Epoch [6/10], Phase: train, Batch: [437/657], Loss: 0.2324\n",
      "Epoch [6/10], Phase: train, Batch: [438/657], Loss: 0.3125\n",
      "Epoch [6/10], Phase: train, Batch: [439/657], Loss: 0.3825\n",
      "Epoch [6/10], Phase: train, Batch: [440/657], Loss: 0.2332\n",
      "Epoch [6/10], Phase: train, Batch: [441/657], Loss: 0.2530\n",
      "Epoch [6/10], Phase: train, Batch: [442/657], Loss: 0.1665\n",
      "Epoch [6/10], Phase: train, Batch: [443/657], Loss: 0.2389\n",
      "Epoch [6/10], Phase: train, Batch: [444/657], Loss: 0.3410\n",
      "Epoch [6/10], Phase: train, Batch: [445/657], Loss: 0.1742\n",
      "Epoch [6/10], Phase: train, Batch: [446/657], Loss: 0.3471\n",
      "Epoch [6/10], Phase: train, Batch: [447/657], Loss: 0.2371\n",
      "Epoch [6/10], Phase: train, Batch: [448/657], Loss: 0.4101\n",
      "Epoch [6/10], Phase: train, Batch: [449/657], Loss: 0.2255\n",
      "Epoch [6/10], Phase: train, Batch: [450/657], Loss: 0.2061\n",
      "Epoch [6/10], Phase: train, Batch: [451/657], Loss: 0.3048\n",
      "Epoch [6/10], Phase: train, Batch: [452/657], Loss: 0.1838\n",
      "Epoch [6/10], Phase: train, Batch: [453/657], Loss: 0.3339\n",
      "Epoch [6/10], Phase: train, Batch: [454/657], Loss: 0.1905\n",
      "Epoch [6/10], Phase: train, Batch: [455/657], Loss: 0.2522\n",
      "Epoch [6/10], Phase: train, Batch: [456/657], Loss: 0.2503\n",
      "Epoch [6/10], Phase: train, Batch: [457/657], Loss: 0.1913\n",
      "Epoch [6/10], Phase: train, Batch: [458/657], Loss: 0.3267\n",
      "Epoch [6/10], Phase: train, Batch: [459/657], Loss: 0.1552\n",
      "Epoch [6/10], Phase: train, Batch: [460/657], Loss: 0.2926\n",
      "Epoch [6/10], Phase: train, Batch: [461/657], Loss: 0.3138\n",
      "Epoch [6/10], Phase: train, Batch: [462/657], Loss: 0.2066\n",
      "Epoch [6/10], Phase: train, Batch: [463/657], Loss: 0.2631\n",
      "Epoch [6/10], Phase: train, Batch: [464/657], Loss: 0.2908\n",
      "Epoch [6/10], Phase: train, Batch: [465/657], Loss: 0.2403\n",
      "Epoch [6/10], Phase: train, Batch: [466/657], Loss: 0.3778\n",
      "Epoch [6/10], Phase: train, Batch: [467/657], Loss: 0.2214\n",
      "Epoch [6/10], Phase: train, Batch: [468/657], Loss: 0.1667\n",
      "Epoch [6/10], Phase: train, Batch: [469/657], Loss: 0.2124\n",
      "Epoch [6/10], Phase: train, Batch: [470/657], Loss: 0.2324\n",
      "Epoch [6/10], Phase: train, Batch: [471/657], Loss: 0.2426\n",
      "Epoch [6/10], Phase: train, Batch: [472/657], Loss: 0.3376\n",
      "Epoch [6/10], Phase: train, Batch: [473/657], Loss: 0.3720\n",
      "Epoch [6/10], Phase: train, Batch: [474/657], Loss: 0.3288\n",
      "Epoch [6/10], Phase: train, Batch: [475/657], Loss: 0.3565\n",
      "Epoch [6/10], Phase: train, Batch: [476/657], Loss: 0.1650\n",
      "Epoch [6/10], Phase: train, Batch: [477/657], Loss: 0.1748\n",
      "Epoch [6/10], Phase: train, Batch: [478/657], Loss: 0.2790\n",
      "Epoch [6/10], Phase: train, Batch: [479/657], Loss: 0.2736\n",
      "Epoch [6/10], Phase: train, Batch: [480/657], Loss: 0.4173\n",
      "Epoch [6/10], Phase: train, Batch: [481/657], Loss: 0.2981\n",
      "Epoch [6/10], Phase: train, Batch: [482/657], Loss: 0.1907\n",
      "Epoch [6/10], Phase: train, Batch: [483/657], Loss: 0.2177\n",
      "Epoch [6/10], Phase: train, Batch: [484/657], Loss: 0.2667\n",
      "Epoch [6/10], Phase: train, Batch: [485/657], Loss: 0.2825\n",
      "Epoch [6/10], Phase: train, Batch: [486/657], Loss: 0.2654\n",
      "Epoch [6/10], Phase: train, Batch: [487/657], Loss: 0.2835\n",
      "Epoch [6/10], Phase: train, Batch: [488/657], Loss: 0.1551\n",
      "Epoch [6/10], Phase: train, Batch: [489/657], Loss: 0.1405\n",
      "Epoch [6/10], Phase: train, Batch: [490/657], Loss: 0.2300\n",
      "Epoch [6/10], Phase: train, Batch: [491/657], Loss: 0.1639\n",
      "Epoch [6/10], Phase: train, Batch: [492/657], Loss: 0.2228\n",
      "Epoch [6/10], Phase: train, Batch: [493/657], Loss: 0.2350\n",
      "Epoch [6/10], Phase: train, Batch: [494/657], Loss: 0.2578\n",
      "Epoch [6/10], Phase: train, Batch: [495/657], Loss: 0.2075\n",
      "Epoch [6/10], Phase: train, Batch: [496/657], Loss: 0.2059\n",
      "Epoch [6/10], Phase: train, Batch: [497/657], Loss: 0.3295\n",
      "Epoch [6/10], Phase: train, Batch: [498/657], Loss: 0.1971\n",
      "Epoch [6/10], Phase: train, Batch: [499/657], Loss: 0.3650\n",
      "Epoch [6/10], Phase: train, Batch: [500/657], Loss: 0.2442\n",
      "Epoch [6/10], Phase: train, Batch: [501/657], Loss: 0.2375\n",
      "Epoch [6/10], Phase: train, Batch: [502/657], Loss: 0.2493\n",
      "Epoch [6/10], Phase: train, Batch: [503/657], Loss: 0.4297\n",
      "Epoch [6/10], Phase: train, Batch: [504/657], Loss: 0.3738\n",
      "Epoch [6/10], Phase: train, Batch: [505/657], Loss: 0.2865\n",
      "Epoch [6/10], Phase: train, Batch: [506/657], Loss: 0.2506\n",
      "Epoch [6/10], Phase: train, Batch: [507/657], Loss: 0.1646\n",
      "Epoch [6/10], Phase: train, Batch: [508/657], Loss: 0.3687\n",
      "Epoch [6/10], Phase: train, Batch: [509/657], Loss: 0.3156\n",
      "Epoch [6/10], Phase: train, Batch: [510/657], Loss: 0.3167\n",
      "Epoch [6/10], Phase: train, Batch: [511/657], Loss: 0.3612\n",
      "Epoch [6/10], Phase: train, Batch: [512/657], Loss: 0.2963\n",
      "Epoch [6/10], Phase: train, Batch: [513/657], Loss: 0.2078\n",
      "Epoch [6/10], Phase: train, Batch: [514/657], Loss: 0.1691\n",
      "Epoch [6/10], Phase: train, Batch: [515/657], Loss: 0.2036\n",
      "Epoch [6/10], Phase: train, Batch: [516/657], Loss: 0.2190\n",
      "Epoch [6/10], Phase: train, Batch: [517/657], Loss: 0.3356\n",
      "Epoch [6/10], Phase: train, Batch: [518/657], Loss: 0.2060\n",
      "Epoch [6/10], Phase: train, Batch: [519/657], Loss: 0.3553\n",
      "Epoch [6/10], Phase: train, Batch: [520/657], Loss: 0.3609\n",
      "Epoch [6/10], Phase: train, Batch: [521/657], Loss: 0.3091\n",
      "Epoch [6/10], Phase: train, Batch: [522/657], Loss: 0.2261\n",
      "Epoch [6/10], Phase: train, Batch: [523/657], Loss: 0.1982\n",
      "Epoch [6/10], Phase: train, Batch: [524/657], Loss: 0.3004\n",
      "Epoch [6/10], Phase: train, Batch: [525/657], Loss: 0.2081\n",
      "Epoch [6/10], Phase: train, Batch: [526/657], Loss: 0.2237\n",
      "Epoch [6/10], Phase: train, Batch: [527/657], Loss: 0.4632\n",
      "Epoch [6/10], Phase: train, Batch: [528/657], Loss: 0.2587\n",
      "Epoch [6/10], Phase: train, Batch: [529/657], Loss: 0.1944\n",
      "Epoch [6/10], Phase: train, Batch: [530/657], Loss: 0.3656\n",
      "Epoch [6/10], Phase: train, Batch: [531/657], Loss: 0.3171\n",
      "Epoch [6/10], Phase: train, Batch: [532/657], Loss: 0.3813\n",
      "Epoch [6/10], Phase: train, Batch: [533/657], Loss: 0.2956\n",
      "Epoch [6/10], Phase: train, Batch: [534/657], Loss: 0.2704\n",
      "Epoch [6/10], Phase: train, Batch: [535/657], Loss: 0.2763\n",
      "Epoch [6/10], Phase: train, Batch: [536/657], Loss: 0.3388\n",
      "Epoch [6/10], Phase: train, Batch: [537/657], Loss: 0.4013\n",
      "Epoch [6/10], Phase: train, Batch: [538/657], Loss: 0.3010\n",
      "Epoch [6/10], Phase: train, Batch: [539/657], Loss: 0.2549\n",
      "Epoch [6/10], Phase: train, Batch: [540/657], Loss: 0.3138\n",
      "Epoch [6/10], Phase: train, Batch: [541/657], Loss: 0.3219\n",
      "Epoch [6/10], Phase: train, Batch: [542/657], Loss: 0.3269\n",
      "Epoch [6/10], Phase: train, Batch: [543/657], Loss: 0.2579\n",
      "Epoch [6/10], Phase: train, Batch: [544/657], Loss: 0.1793\n",
      "Epoch [6/10], Phase: train, Batch: [545/657], Loss: 0.2982\n",
      "Epoch [6/10], Phase: train, Batch: [546/657], Loss: 0.2754\n",
      "Epoch [6/10], Phase: train, Batch: [547/657], Loss: 0.2427\n",
      "Epoch [6/10], Phase: train, Batch: [548/657], Loss: 0.2630\n",
      "Epoch [6/10], Phase: train, Batch: [549/657], Loss: 0.1802\n",
      "Epoch [6/10], Phase: train, Batch: [550/657], Loss: 0.2551\n",
      "Epoch [6/10], Phase: train, Batch: [551/657], Loss: 0.3485\n",
      "Epoch [6/10], Phase: train, Batch: [552/657], Loss: 0.3421\n",
      "Epoch [6/10], Phase: train, Batch: [553/657], Loss: 0.2658\n",
      "Epoch [6/10], Phase: train, Batch: [554/657], Loss: 0.1978\n",
      "Epoch [6/10], Phase: train, Batch: [555/657], Loss: 0.2488\n",
      "Epoch [6/10], Phase: train, Batch: [556/657], Loss: 0.2190\n",
      "Epoch [6/10], Phase: train, Batch: [557/657], Loss: 0.4358\n",
      "Epoch [6/10], Phase: train, Batch: [558/657], Loss: 0.4004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Phase: train, Batch: [559/657], Loss: 0.2513\n",
      "Epoch [6/10], Phase: train, Batch: [560/657], Loss: 0.1124\n",
      "Epoch [6/10], Phase: train, Batch: [561/657], Loss: 0.2794\n",
      "Epoch [6/10], Phase: train, Batch: [562/657], Loss: 0.2128\n",
      "Epoch [6/10], Phase: train, Batch: [563/657], Loss: 0.3351\n",
      "Epoch [6/10], Phase: train, Batch: [564/657], Loss: 0.2707\n",
      "Epoch [6/10], Phase: train, Batch: [565/657], Loss: 0.2696\n",
      "Epoch [6/10], Phase: train, Batch: [566/657], Loss: 0.2474\n",
      "Epoch [6/10], Phase: train, Batch: [567/657], Loss: 0.2463\n",
      "Epoch [6/10], Phase: train, Batch: [568/657], Loss: 0.1498\n",
      "Epoch [6/10], Phase: train, Batch: [569/657], Loss: 0.2803\n",
      "Epoch [6/10], Phase: train, Batch: [570/657], Loss: 0.3476\n",
      "Epoch [6/10], Phase: train, Batch: [571/657], Loss: 0.2513\n",
      "Epoch [6/10], Phase: train, Batch: [572/657], Loss: 0.3615\n",
      "Epoch [6/10], Phase: train, Batch: [573/657], Loss: 0.3091\n",
      "Epoch [6/10], Phase: train, Batch: [574/657], Loss: 0.3236\n",
      "Epoch [6/10], Phase: train, Batch: [575/657], Loss: 0.3719\n",
      "Epoch [6/10], Phase: train, Batch: [576/657], Loss: 0.2756\n",
      "Epoch [6/10], Phase: train, Batch: [577/657], Loss: 0.3257\n",
      "Epoch [6/10], Phase: train, Batch: [578/657], Loss: 0.3715\n",
      "Epoch [6/10], Phase: train, Batch: [579/657], Loss: 0.2170\n",
      "Epoch [6/10], Phase: train, Batch: [580/657], Loss: 0.2491\n",
      "Epoch [6/10], Phase: train, Batch: [581/657], Loss: 0.2467\n",
      "Epoch [6/10], Phase: train, Batch: [582/657], Loss: 0.3001\n",
      "Epoch [6/10], Phase: train, Batch: [583/657], Loss: 0.3094\n",
      "Epoch [6/10], Phase: train, Batch: [584/657], Loss: 0.4165\n",
      "Epoch [6/10], Phase: train, Batch: [585/657], Loss: 0.2158\n",
      "Epoch [6/10], Phase: train, Batch: [586/657], Loss: 0.1805\n",
      "Epoch [6/10], Phase: train, Batch: [587/657], Loss: 0.3415\n",
      "Epoch [6/10], Phase: train, Batch: [588/657], Loss: 0.2761\n",
      "Epoch [6/10], Phase: train, Batch: [589/657], Loss: 0.3384\n",
      "Epoch [6/10], Phase: train, Batch: [590/657], Loss: 0.3758\n",
      "Epoch [6/10], Phase: train, Batch: [591/657], Loss: 0.4714\n",
      "Epoch [6/10], Phase: train, Batch: [592/657], Loss: 0.1870\n",
      "Epoch [6/10], Phase: train, Batch: [593/657], Loss: 0.1793\n",
      "Epoch [6/10], Phase: train, Batch: [594/657], Loss: 0.4558\n",
      "Epoch [6/10], Phase: train, Batch: [595/657], Loss: 0.2820\n",
      "Epoch [6/10], Phase: train, Batch: [596/657], Loss: 0.3188\n",
      "Epoch [6/10], Phase: train, Batch: [597/657], Loss: 0.3495\n",
      "Epoch [6/10], Phase: train, Batch: [598/657], Loss: 0.1858\n",
      "Epoch [6/10], Phase: train, Batch: [599/657], Loss: 0.2543\n",
      "Epoch [6/10], Phase: train, Batch: [600/657], Loss: 0.5317\n",
      "Epoch [6/10], Phase: train, Batch: [601/657], Loss: 0.2271\n",
      "Epoch [6/10], Phase: train, Batch: [602/657], Loss: 0.1585\n",
      "Epoch [6/10], Phase: train, Batch: [603/657], Loss: 0.2991\n",
      "Epoch [6/10], Phase: train, Batch: [604/657], Loss: 0.1594\n",
      "Epoch [6/10], Phase: train, Batch: [605/657], Loss: 0.2914\n",
      "Epoch [6/10], Phase: train, Batch: [606/657], Loss: 0.2944\n",
      "Epoch [6/10], Phase: train, Batch: [607/657], Loss: 0.3212\n",
      "Epoch [6/10], Phase: train, Batch: [608/657], Loss: 0.1846\n",
      "Epoch [6/10], Phase: train, Batch: [609/657], Loss: 0.2537\n",
      "Epoch [6/10], Phase: train, Batch: [610/657], Loss: 0.3362\n",
      "Epoch [6/10], Phase: train, Batch: [611/657], Loss: 0.2557\n",
      "Epoch [6/10], Phase: train, Batch: [612/657], Loss: 0.2143\n",
      "Epoch [6/10], Phase: train, Batch: [613/657], Loss: 0.2013\n",
      "Epoch [6/10], Phase: train, Batch: [614/657], Loss: 0.2581\n",
      "Epoch [6/10], Phase: train, Batch: [615/657], Loss: 0.2084\n",
      "Epoch [6/10], Phase: train, Batch: [616/657], Loss: 0.2520\n",
      "Epoch [6/10], Phase: train, Batch: [617/657], Loss: 0.3051\n",
      "Epoch [6/10], Phase: train, Batch: [618/657], Loss: 0.2727\n",
      "Epoch [6/10], Phase: train, Batch: [619/657], Loss: 0.2016\n",
      "Epoch [6/10], Phase: train, Batch: [620/657], Loss: 0.3978\n",
      "Epoch [6/10], Phase: train, Batch: [621/657], Loss: 0.1524\n",
      "Epoch [6/10], Phase: train, Batch: [622/657], Loss: 0.1817\n",
      "Epoch [6/10], Phase: train, Batch: [623/657], Loss: 0.2342\n",
      "Epoch [6/10], Phase: train, Batch: [624/657], Loss: 0.2667\n",
      "Epoch [6/10], Phase: train, Batch: [625/657], Loss: 0.3525\n",
      "Epoch [6/10], Phase: train, Batch: [626/657], Loss: 0.3649\n",
      "Epoch [6/10], Phase: train, Batch: [627/657], Loss: 0.2653\n",
      "Epoch [6/10], Phase: train, Batch: [628/657], Loss: 0.3199\n",
      "Epoch [6/10], Phase: train, Batch: [629/657], Loss: 0.2487\n",
      "Epoch [6/10], Phase: train, Batch: [630/657], Loss: 0.2543\n",
      "Epoch [6/10], Phase: train, Batch: [631/657], Loss: 0.2339\n",
      "Epoch [6/10], Phase: train, Batch: [632/657], Loss: 0.2342\n",
      "Epoch [6/10], Phase: train, Batch: [633/657], Loss: 0.2976\n",
      "Epoch [6/10], Phase: train, Batch: [634/657], Loss: 0.3207\n",
      "Epoch [6/10], Phase: train, Batch: [635/657], Loss: 0.2747\n",
      "Epoch [6/10], Phase: train, Batch: [636/657], Loss: 0.2161\n",
      "Epoch [6/10], Phase: train, Batch: [637/657], Loss: 0.4028\n",
      "Epoch [6/10], Phase: train, Batch: [638/657], Loss: 0.3709\n",
      "Epoch [6/10], Phase: train, Batch: [639/657], Loss: 0.2174\n",
      "Epoch [6/10], Phase: train, Batch: [640/657], Loss: 0.3229\n",
      "Epoch [6/10], Phase: train, Batch: [641/657], Loss: 0.2567\n",
      "Epoch [6/10], Phase: train, Batch: [642/657], Loss: 0.3320\n",
      "Epoch [6/10], Phase: train, Batch: [643/657], Loss: 0.2099\n",
      "Epoch [6/10], Phase: train, Batch: [644/657], Loss: 0.2460\n",
      "Epoch [6/10], Phase: train, Batch: [645/657], Loss: 0.2347\n",
      "Epoch [6/10], Phase: train, Batch: [646/657], Loss: 0.3719\n",
      "Epoch [6/10], Phase: train, Batch: [647/657], Loss: 0.3044\n",
      "Epoch [6/10], Phase: train, Batch: [648/657], Loss: 0.4652\n",
      "Epoch [6/10], Phase: train, Batch: [649/657], Loss: 0.2501\n",
      "Epoch [6/10], Phase: train, Batch: [650/657], Loss: 0.2477\n",
      "Epoch [6/10], Phase: train, Batch: [651/657], Loss: 0.3260\n",
      "Epoch [6/10], Phase: train, Batch: [652/657], Loss: 0.1824\n",
      "Epoch [6/10], Phase: train, Batch: [653/657], Loss: 0.3955\n",
      "Epoch [6/10], Phase: train, Batch: [654/657], Loss: 0.3010\n",
      "Epoch [6/10], Phase: train, Batch: [655/657], Loss: 0.2451\n",
      "Epoch [6/10], Phase: train, Batch: [656/657], Loss: 0.3452\n",
      "Epoch [6/10], Phase: train, Batch: [657/657], Loss: 0.1332\n",
      "train Loss: 0.2779 Acc: 0.8869\n",
      "Epoch [6/10], Phase: val, Batch: [1/73], Loss: 0.3182\n",
      "Epoch [6/10], Phase: val, Batch: [2/73], Loss: 0.2970\n",
      "Epoch [6/10], Phase: val, Batch: [3/73], Loss: 0.1571\n",
      "Epoch [6/10], Phase: val, Batch: [4/73], Loss: 0.3598\n",
      "Epoch [6/10], Phase: val, Batch: [5/73], Loss: 0.2165\n",
      "Epoch [6/10], Phase: val, Batch: [6/73], Loss: 0.2756\n",
      "Epoch [6/10], Phase: val, Batch: [7/73], Loss: 0.1952\n",
      "Epoch [6/10], Phase: val, Batch: [8/73], Loss: 0.2219\n",
      "Epoch [6/10], Phase: val, Batch: [9/73], Loss: 0.0845\n",
      "Epoch [6/10], Phase: val, Batch: [10/73], Loss: 0.1942\n",
      "Epoch [6/10], Phase: val, Batch: [11/73], Loss: 0.1800\n",
      "Epoch [6/10], Phase: val, Batch: [12/73], Loss: 0.2462\n",
      "Epoch [6/10], Phase: val, Batch: [13/73], Loss: 0.1366\n",
      "Epoch [6/10], Phase: val, Batch: [14/73], Loss: 0.2913\n",
      "Epoch [6/10], Phase: val, Batch: [15/73], Loss: 0.2065\n",
      "Epoch [6/10], Phase: val, Batch: [16/73], Loss: 0.3099\n",
      "Epoch [6/10], Phase: val, Batch: [17/73], Loss: 0.1130\n",
      "Epoch [6/10], Phase: val, Batch: [18/73], Loss: 0.2499\n",
      "Epoch [6/10], Phase: val, Batch: [19/73], Loss: 0.3245\n",
      "Epoch [6/10], Phase: val, Batch: [20/73], Loss: 0.1716\n",
      "Epoch [6/10], Phase: val, Batch: [21/73], Loss: 0.3350\n",
      "Epoch [6/10], Phase: val, Batch: [22/73], Loss: 0.2078\n",
      "Epoch [6/10], Phase: val, Batch: [23/73], Loss: 0.2621\n",
      "Epoch [6/10], Phase: val, Batch: [24/73], Loss: 0.2879\n",
      "Epoch [6/10], Phase: val, Batch: [25/73], Loss: 0.1858\n",
      "Epoch [6/10], Phase: val, Batch: [26/73], Loss: 0.1814\n",
      "Epoch [6/10], Phase: val, Batch: [27/73], Loss: 0.2568\n",
      "Epoch [6/10], Phase: val, Batch: [28/73], Loss: 0.2420\n",
      "Epoch [6/10], Phase: val, Batch: [29/73], Loss: 0.3414\n",
      "Epoch [6/10], Phase: val, Batch: [30/73], Loss: 0.3400\n",
      "Epoch [6/10], Phase: val, Batch: [31/73], Loss: 0.1820\n",
      "Epoch [6/10], Phase: val, Batch: [32/73], Loss: 0.2774\n",
      "Epoch [6/10], Phase: val, Batch: [33/73], Loss: 0.3872\n",
      "Epoch [6/10], Phase: val, Batch: [34/73], Loss: 0.2096\n",
      "Epoch [6/10], Phase: val, Batch: [35/73], Loss: 0.1782\n",
      "Epoch [6/10], Phase: val, Batch: [36/73], Loss: 0.3403\n",
      "Epoch [6/10], Phase: val, Batch: [37/73], Loss: 0.2177\n",
      "Epoch [6/10], Phase: val, Batch: [38/73], Loss: 0.1685\n",
      "Epoch [6/10], Phase: val, Batch: [39/73], Loss: 0.2167\n",
      "Epoch [6/10], Phase: val, Batch: [40/73], Loss: 0.1955\n",
      "Epoch [6/10], Phase: val, Batch: [41/73], Loss: 0.2219\n",
      "Epoch [6/10], Phase: val, Batch: [42/73], Loss: 0.2684\n",
      "Epoch [6/10], Phase: val, Batch: [43/73], Loss: 0.2194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Phase: val, Batch: [44/73], Loss: 0.2374\n",
      "Epoch [6/10], Phase: val, Batch: [45/73], Loss: 0.1896\n",
      "Epoch [6/10], Phase: val, Batch: [46/73], Loss: 0.3061\n",
      "Epoch [6/10], Phase: val, Batch: [47/73], Loss: 0.2866\n",
      "Epoch [6/10], Phase: val, Batch: [48/73], Loss: 0.1430\n",
      "Epoch [6/10], Phase: val, Batch: [49/73], Loss: 0.2988\n",
      "Epoch [6/10], Phase: val, Batch: [50/73], Loss: 0.1824\n",
      "Epoch [6/10], Phase: val, Batch: [51/73], Loss: 0.3091\n",
      "Epoch [6/10], Phase: val, Batch: [52/73], Loss: 0.1903\n",
      "Epoch [6/10], Phase: val, Batch: [53/73], Loss: 0.2165\n",
      "Epoch [6/10], Phase: val, Batch: [54/73], Loss: 0.2091\n",
      "Epoch [6/10], Phase: val, Batch: [55/73], Loss: 0.2380\n",
      "Epoch [6/10], Phase: val, Batch: [56/73], Loss: 0.3029\n",
      "Epoch [6/10], Phase: val, Batch: [57/73], Loss: 0.1397\n",
      "Epoch [6/10], Phase: val, Batch: [58/73], Loss: 0.2553\n",
      "Epoch [6/10], Phase: val, Batch: [59/73], Loss: 0.2450\n",
      "Epoch [6/10], Phase: val, Batch: [60/73], Loss: 0.1727\n",
      "Epoch [6/10], Phase: val, Batch: [61/73], Loss: 0.3315\n",
      "Epoch [6/10], Phase: val, Batch: [62/73], Loss: 0.2352\n",
      "Epoch [6/10], Phase: val, Batch: [63/73], Loss: 0.2312\n",
      "Epoch [6/10], Phase: val, Batch: [64/73], Loss: 0.2810\n",
      "Epoch [6/10], Phase: val, Batch: [65/73], Loss: 0.2431\n",
      "Epoch [6/10], Phase: val, Batch: [66/73], Loss: 0.1809\n",
      "Epoch [6/10], Phase: val, Batch: [67/73], Loss: 0.2186\n",
      "Epoch [6/10], Phase: val, Batch: [68/73], Loss: 0.2176\n",
      "Epoch [6/10], Phase: val, Batch: [69/73], Loss: 0.2979\n",
      "Epoch [6/10], Phase: val, Batch: [70/73], Loss: 0.2450\n",
      "Epoch [6/10], Phase: val, Batch: [71/73], Loss: 0.3127\n",
      "Epoch [6/10], Phase: val, Batch: [72/73], Loss: 0.4061\n",
      "Epoch [6/10], Phase: val, Batch: [73/73], Loss: 0.1146\n",
      "val Loss: 0.2400 Acc: 0.9023\n",
      "Epoch [7/10], Phase: train, Batch: [1/657], Loss: 0.1535\n",
      "Epoch [7/10], Phase: train, Batch: [2/657], Loss: 0.2159\n",
      "Epoch [7/10], Phase: train, Batch: [3/657], Loss: 0.2765\n",
      "Epoch [7/10], Phase: train, Batch: [4/657], Loss: 0.2555\n",
      "Epoch [7/10], Phase: train, Batch: [5/657], Loss: 0.2226\n",
      "Epoch [7/10], Phase: train, Batch: [6/657], Loss: 0.3553\n",
      "Epoch [7/10], Phase: train, Batch: [7/657], Loss: 0.2494\n",
      "Epoch [7/10], Phase: train, Batch: [8/657], Loss: 0.4623\n",
      "Epoch [7/10], Phase: train, Batch: [9/657], Loss: 0.1661\n",
      "Epoch [7/10], Phase: train, Batch: [10/657], Loss: 0.2599\n",
      "Epoch [7/10], Phase: train, Batch: [11/657], Loss: 0.2459\n",
      "Epoch [7/10], Phase: train, Batch: [12/657], Loss: 0.3068\n",
      "Epoch [7/10], Phase: train, Batch: [13/657], Loss: 0.3312\n",
      "Epoch [7/10], Phase: train, Batch: [14/657], Loss: 0.2242\n",
      "Epoch [7/10], Phase: train, Batch: [15/657], Loss: 0.2050\n",
      "Epoch [7/10], Phase: train, Batch: [16/657], Loss: 0.2988\n",
      "Epoch [7/10], Phase: train, Batch: [17/657], Loss: 0.1680\n",
      "Epoch [7/10], Phase: train, Batch: [18/657], Loss: 0.2427\n",
      "Epoch [7/10], Phase: train, Batch: [19/657], Loss: 0.3732\n",
      "Epoch [7/10], Phase: train, Batch: [20/657], Loss: 0.4552\n",
      "Epoch [7/10], Phase: train, Batch: [21/657], Loss: 0.2046\n",
      "Epoch [7/10], Phase: train, Batch: [22/657], Loss: 0.3193\n",
      "Epoch [7/10], Phase: train, Batch: [23/657], Loss: 0.1983\n",
      "Epoch [7/10], Phase: train, Batch: [24/657], Loss: 0.2502\n",
      "Epoch [7/10], Phase: train, Batch: [25/657], Loss: 0.2728\n",
      "Epoch [7/10], Phase: train, Batch: [26/657], Loss: 0.3417\n",
      "Epoch [7/10], Phase: train, Batch: [27/657], Loss: 0.2258\n",
      "Epoch [7/10], Phase: train, Batch: [28/657], Loss: 0.2433\n",
      "Epoch [7/10], Phase: train, Batch: [29/657], Loss: 0.2444\n",
      "Epoch [7/10], Phase: train, Batch: [30/657], Loss: 0.3530\n",
      "Epoch [7/10], Phase: train, Batch: [31/657], Loss: 0.2835\n",
      "Epoch [7/10], Phase: train, Batch: [32/657], Loss: 0.2072\n",
      "Epoch [7/10], Phase: train, Batch: [33/657], Loss: 0.2246\n",
      "Epoch [7/10], Phase: train, Batch: [34/657], Loss: 0.3681\n",
      "Epoch [7/10], Phase: train, Batch: [35/657], Loss: 0.2739\n",
      "Epoch [7/10], Phase: train, Batch: [36/657], Loss: 0.2188\n",
      "Epoch [7/10], Phase: train, Batch: [37/657], Loss: 0.1782\n",
      "Epoch [7/10], Phase: train, Batch: [38/657], Loss: 0.2661\n",
      "Epoch [7/10], Phase: train, Batch: [39/657], Loss: 0.1954\n",
      "Epoch [7/10], Phase: train, Batch: [40/657], Loss: 0.3514\n",
      "Epoch [7/10], Phase: train, Batch: [41/657], Loss: 0.2518\n",
      "Epoch [7/10], Phase: train, Batch: [42/657], Loss: 0.1936\n",
      "Epoch [7/10], Phase: train, Batch: [43/657], Loss: 0.3272\n",
      "Epoch [7/10], Phase: train, Batch: [44/657], Loss: 0.2762\n",
      "Epoch [7/10], Phase: train, Batch: [45/657], Loss: 0.3397\n",
      "Epoch [7/10], Phase: train, Batch: [46/657], Loss: 0.1518\n",
      "Epoch [7/10], Phase: train, Batch: [47/657], Loss: 0.3453\n",
      "Epoch [7/10], Phase: train, Batch: [48/657], Loss: 0.1922\n",
      "Epoch [7/10], Phase: train, Batch: [49/657], Loss: 0.2403\n",
      "Epoch [7/10], Phase: train, Batch: [50/657], Loss: 0.3243\n",
      "Epoch [7/10], Phase: train, Batch: [51/657], Loss: 0.3835\n",
      "Epoch [7/10], Phase: train, Batch: [52/657], Loss: 0.2113\n",
      "Epoch [7/10], Phase: train, Batch: [53/657], Loss: 0.3910\n",
      "Epoch [7/10], Phase: train, Batch: [54/657], Loss: 0.3754\n",
      "Epoch [7/10], Phase: train, Batch: [55/657], Loss: 0.3711\n",
      "Epoch [7/10], Phase: train, Batch: [56/657], Loss: 0.3280\n",
      "Epoch [7/10], Phase: train, Batch: [57/657], Loss: 0.2997\n",
      "Epoch [7/10], Phase: train, Batch: [58/657], Loss: 0.2349\n",
      "Epoch [7/10], Phase: train, Batch: [59/657], Loss: 0.1959\n",
      "Epoch [7/10], Phase: train, Batch: [60/657], Loss: 0.1627\n",
      "Epoch [7/10], Phase: train, Batch: [61/657], Loss: 0.2685\n",
      "Epoch [7/10], Phase: train, Batch: [62/657], Loss: 0.2874\n",
      "Epoch [7/10], Phase: train, Batch: [63/657], Loss: 0.3413\n",
      "Epoch [7/10], Phase: train, Batch: [64/657], Loss: 0.1303\n",
      "Epoch [7/10], Phase: train, Batch: [65/657], Loss: 0.1911\n",
      "Epoch [7/10], Phase: train, Batch: [66/657], Loss: 0.2309\n",
      "Epoch [7/10], Phase: train, Batch: [67/657], Loss: 0.2723\n",
      "Epoch [7/10], Phase: train, Batch: [68/657], Loss: 0.2617\n",
      "Epoch [7/10], Phase: train, Batch: [69/657], Loss: 0.1384\n",
      "Epoch [7/10], Phase: train, Batch: [70/657], Loss: 0.1933\n",
      "Epoch [7/10], Phase: train, Batch: [71/657], Loss: 0.2085\n",
      "Epoch [7/10], Phase: train, Batch: [72/657], Loss: 0.2404\n",
      "Epoch [7/10], Phase: train, Batch: [73/657], Loss: 0.3919\n",
      "Epoch [7/10], Phase: train, Batch: [74/657], Loss: 0.2969\n",
      "Epoch [7/10], Phase: train, Batch: [75/657], Loss: 0.1949\n",
      "Epoch [7/10], Phase: train, Batch: [76/657], Loss: 0.4111\n",
      "Epoch [7/10], Phase: train, Batch: [77/657], Loss: 0.2515\n",
      "Epoch [7/10], Phase: train, Batch: [78/657], Loss: 0.3572\n",
      "Epoch [7/10], Phase: train, Batch: [79/657], Loss: 0.4044\n",
      "Epoch [7/10], Phase: train, Batch: [80/657], Loss: 0.2201\n",
      "Epoch [7/10], Phase: train, Batch: [81/657], Loss: 0.4130\n",
      "Epoch [7/10], Phase: train, Batch: [82/657], Loss: 0.3120\n",
      "Epoch [7/10], Phase: train, Batch: [83/657], Loss: 0.3346\n",
      "Epoch [7/10], Phase: train, Batch: [84/657], Loss: 0.2324\n",
      "Epoch [7/10], Phase: train, Batch: [85/657], Loss: 0.1717\n",
      "Epoch [7/10], Phase: train, Batch: [86/657], Loss: 0.1840\n",
      "Epoch [7/10], Phase: train, Batch: [87/657], Loss: 0.2070\n",
      "Epoch [7/10], Phase: train, Batch: [88/657], Loss: 0.2219\n",
      "Epoch [7/10], Phase: train, Batch: [89/657], Loss: 0.2556\n",
      "Epoch [7/10], Phase: train, Batch: [90/657], Loss: 0.3422\n",
      "Epoch [7/10], Phase: train, Batch: [91/657], Loss: 0.2305\n",
      "Epoch [7/10], Phase: train, Batch: [92/657], Loss: 0.2266\n",
      "Epoch [7/10], Phase: train, Batch: [93/657], Loss: 0.2759\n",
      "Epoch [7/10], Phase: train, Batch: [94/657], Loss: 0.1592\n",
      "Epoch [7/10], Phase: train, Batch: [95/657], Loss: 0.4397\n",
      "Epoch [7/10], Phase: train, Batch: [96/657], Loss: 0.1158\n",
      "Epoch [7/10], Phase: train, Batch: [97/657], Loss: 0.3575\n",
      "Epoch [7/10], Phase: train, Batch: [98/657], Loss: 0.1558\n",
      "Epoch [7/10], Phase: train, Batch: [99/657], Loss: 0.2074\n",
      "Epoch [7/10], Phase: train, Batch: [100/657], Loss: 0.1872\n",
      "Epoch [7/10], Phase: train, Batch: [101/657], Loss: 0.3371\n",
      "Epoch [7/10], Phase: train, Batch: [102/657], Loss: 0.1857\n",
      "Epoch [7/10], Phase: train, Batch: [103/657], Loss: 0.3230\n",
      "Epoch [7/10], Phase: train, Batch: [104/657], Loss: 0.2977\n",
      "Epoch [7/10], Phase: train, Batch: [105/657], Loss: 0.3624\n",
      "Epoch [7/10], Phase: train, Batch: [106/657], Loss: 0.1645\n",
      "Epoch [7/10], Phase: train, Batch: [107/657], Loss: 0.2296\n",
      "Epoch [7/10], Phase: train, Batch: [108/657], Loss: 0.2881\n",
      "Epoch [7/10], Phase: train, Batch: [109/657], Loss: 0.2334\n",
      "Epoch [7/10], Phase: train, Batch: [110/657], Loss: 0.3449\n",
      "Epoch [7/10], Phase: train, Batch: [111/657], Loss: 0.1642\n",
      "Epoch [7/10], Phase: train, Batch: [112/657], Loss: 0.1351\n",
      "Epoch [7/10], Phase: train, Batch: [113/657], Loss: 0.3208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Phase: train, Batch: [114/657], Loss: 0.1286\n",
      "Epoch [7/10], Phase: train, Batch: [115/657], Loss: 0.2287\n",
      "Epoch [7/10], Phase: train, Batch: [116/657], Loss: 0.5324\n",
      "Epoch [7/10], Phase: train, Batch: [117/657], Loss: 0.2714\n",
      "Epoch [7/10], Phase: train, Batch: [118/657], Loss: 0.3838\n",
      "Epoch [7/10], Phase: train, Batch: [119/657], Loss: 0.2710\n",
      "Epoch [7/10], Phase: train, Batch: [120/657], Loss: 0.4497\n",
      "Epoch [7/10], Phase: train, Batch: [121/657], Loss: 0.4115\n",
      "Epoch [7/10], Phase: train, Batch: [122/657], Loss: 0.2793\n",
      "Epoch [7/10], Phase: train, Batch: [123/657], Loss: 0.2508\n",
      "Epoch [7/10], Phase: train, Batch: [124/657], Loss: 0.2123\n",
      "Epoch [7/10], Phase: train, Batch: [125/657], Loss: 0.3329\n",
      "Epoch [7/10], Phase: train, Batch: [126/657], Loss: 0.2180\n",
      "Epoch [7/10], Phase: train, Batch: [127/657], Loss: 0.1864\n",
      "Epoch [7/10], Phase: train, Batch: [128/657], Loss: 0.2195\n",
      "Epoch [7/10], Phase: train, Batch: [129/657], Loss: 0.2987\n",
      "Epoch [7/10], Phase: train, Batch: [130/657], Loss: 0.2165\n",
      "Epoch [7/10], Phase: train, Batch: [131/657], Loss: 0.2416\n",
      "Epoch [7/10], Phase: train, Batch: [132/657], Loss: 0.2877\n",
      "Epoch [7/10], Phase: train, Batch: [133/657], Loss: 0.2061\n",
      "Epoch [7/10], Phase: train, Batch: [134/657], Loss: 0.2843\n",
      "Epoch [7/10], Phase: train, Batch: [135/657], Loss: 0.1770\n",
      "Epoch [7/10], Phase: train, Batch: [136/657], Loss: 0.2654\n",
      "Epoch [7/10], Phase: train, Batch: [137/657], Loss: 0.2866\n",
      "Epoch [7/10], Phase: train, Batch: [138/657], Loss: 0.2276\n",
      "Epoch [7/10], Phase: train, Batch: [139/657], Loss: 0.2599\n",
      "Epoch [7/10], Phase: train, Batch: [140/657], Loss: 0.2712\n",
      "Epoch [7/10], Phase: train, Batch: [141/657], Loss: 0.3532\n",
      "Epoch [7/10], Phase: train, Batch: [142/657], Loss: 0.4747\n",
      "Epoch [7/10], Phase: train, Batch: [143/657], Loss: 0.3374\n",
      "Epoch [7/10], Phase: train, Batch: [144/657], Loss: 0.2217\n",
      "Epoch [7/10], Phase: train, Batch: [145/657], Loss: 0.2383\n",
      "Epoch [7/10], Phase: train, Batch: [146/657], Loss: 0.1983\n",
      "Epoch [7/10], Phase: train, Batch: [147/657], Loss: 0.2860\n",
      "Epoch [7/10], Phase: train, Batch: [148/657], Loss: 0.2521\n",
      "Epoch [7/10], Phase: train, Batch: [149/657], Loss: 0.2270\n",
      "Epoch [7/10], Phase: train, Batch: [150/657], Loss: 0.4825\n",
      "Epoch [7/10], Phase: train, Batch: [151/657], Loss: 0.2978\n",
      "Epoch [7/10], Phase: train, Batch: [152/657], Loss: 0.1823\n",
      "Epoch [7/10], Phase: train, Batch: [153/657], Loss: 0.2291\n",
      "Epoch [7/10], Phase: train, Batch: [154/657], Loss: 0.3962\n",
      "Epoch [7/10], Phase: train, Batch: [155/657], Loss: 0.3081\n",
      "Epoch [7/10], Phase: train, Batch: [156/657], Loss: 0.2286\n",
      "Epoch [7/10], Phase: train, Batch: [157/657], Loss: 0.3480\n",
      "Epoch [7/10], Phase: train, Batch: [158/657], Loss: 0.1957\n",
      "Epoch [7/10], Phase: train, Batch: [159/657], Loss: 0.3025\n",
      "Epoch [7/10], Phase: train, Batch: [160/657], Loss: 0.1988\n",
      "Epoch [7/10], Phase: train, Batch: [161/657], Loss: 0.2135\n",
      "Epoch [7/10], Phase: train, Batch: [162/657], Loss: 0.4807\n",
      "Epoch [7/10], Phase: train, Batch: [163/657], Loss: 0.3711\n",
      "Epoch [7/10], Phase: train, Batch: [164/657], Loss: 0.2274\n",
      "Epoch [7/10], Phase: train, Batch: [165/657], Loss: 0.3006\n",
      "Epoch [7/10], Phase: train, Batch: [166/657], Loss: 0.1755\n",
      "Epoch [7/10], Phase: train, Batch: [167/657], Loss: 0.2555\n",
      "Epoch [7/10], Phase: train, Batch: [168/657], Loss: 0.3381\n",
      "Epoch [7/10], Phase: train, Batch: [169/657], Loss: 0.3855\n",
      "Epoch [7/10], Phase: train, Batch: [170/657], Loss: 0.1918\n",
      "Epoch [7/10], Phase: train, Batch: [171/657], Loss: 0.1865\n",
      "Epoch [7/10], Phase: train, Batch: [172/657], Loss: 0.2864\n",
      "Epoch [7/10], Phase: train, Batch: [173/657], Loss: 0.3100\n",
      "Epoch [7/10], Phase: train, Batch: [174/657], Loss: 0.2374\n",
      "Epoch [7/10], Phase: train, Batch: [175/657], Loss: 0.4549\n",
      "Epoch [7/10], Phase: train, Batch: [176/657], Loss: 0.3250\n",
      "Epoch [7/10], Phase: train, Batch: [177/657], Loss: 0.3756\n",
      "Epoch [7/10], Phase: train, Batch: [178/657], Loss: 0.2818\n",
      "Epoch [7/10], Phase: train, Batch: [179/657], Loss: 0.2006\n",
      "Epoch [7/10], Phase: train, Batch: [180/657], Loss: 0.2401\n",
      "Epoch [7/10], Phase: train, Batch: [181/657], Loss: 0.2453\n",
      "Epoch [7/10], Phase: train, Batch: [182/657], Loss: 0.2133\n",
      "Epoch [7/10], Phase: train, Batch: [183/657], Loss: 0.1733\n",
      "Epoch [7/10], Phase: train, Batch: [184/657], Loss: 0.2201\n",
      "Epoch [7/10], Phase: train, Batch: [185/657], Loss: 0.2713\n",
      "Epoch [7/10], Phase: train, Batch: [186/657], Loss: 0.2127\n",
      "Epoch [7/10], Phase: train, Batch: [187/657], Loss: 0.2995\n",
      "Epoch [7/10], Phase: train, Batch: [188/657], Loss: 0.4369\n",
      "Epoch [7/10], Phase: train, Batch: [189/657], Loss: 0.3142\n",
      "Epoch [7/10], Phase: train, Batch: [190/657], Loss: 0.1927\n",
      "Epoch [7/10], Phase: train, Batch: [191/657], Loss: 0.2629\n",
      "Epoch [7/10], Phase: train, Batch: [192/657], Loss: 0.2467\n",
      "Epoch [7/10], Phase: train, Batch: [193/657], Loss: 0.2545\n",
      "Epoch [7/10], Phase: train, Batch: [194/657], Loss: 0.2646\n",
      "Epoch [7/10], Phase: train, Batch: [195/657], Loss: 0.5485\n",
      "Epoch [7/10], Phase: train, Batch: [196/657], Loss: 0.4318\n",
      "Epoch [7/10], Phase: train, Batch: [197/657], Loss: 0.5227\n",
      "Epoch [7/10], Phase: train, Batch: [198/657], Loss: 0.2207\n",
      "Epoch [7/10], Phase: train, Batch: [199/657], Loss: 0.3759\n",
      "Epoch [7/10], Phase: train, Batch: [200/657], Loss: 0.2185\n",
      "Epoch [7/10], Phase: train, Batch: [201/657], Loss: 0.2675\n",
      "Epoch [7/10], Phase: train, Batch: [202/657], Loss: 0.2169\n",
      "Epoch [7/10], Phase: train, Batch: [203/657], Loss: 0.2300\n",
      "Epoch [7/10], Phase: train, Batch: [204/657], Loss: 0.2846\n",
      "Epoch [7/10], Phase: train, Batch: [205/657], Loss: 0.2161\n",
      "Epoch [7/10], Phase: train, Batch: [206/657], Loss: 0.2758\n",
      "Epoch [7/10], Phase: train, Batch: [207/657], Loss: 0.2039\n",
      "Epoch [7/10], Phase: train, Batch: [208/657], Loss: 0.2309\n",
      "Epoch [7/10], Phase: train, Batch: [209/657], Loss: 0.3398\n",
      "Epoch [7/10], Phase: train, Batch: [210/657], Loss: 0.2777\n",
      "Epoch [7/10], Phase: train, Batch: [211/657], Loss: 0.2764\n",
      "Epoch [7/10], Phase: train, Batch: [212/657], Loss: 0.2364\n",
      "Epoch [7/10], Phase: train, Batch: [213/657], Loss: 0.3334\n",
      "Epoch [7/10], Phase: train, Batch: [214/657], Loss: 0.2782\n",
      "Epoch [7/10], Phase: train, Batch: [215/657], Loss: 0.1594\n",
      "Epoch [7/10], Phase: train, Batch: [216/657], Loss: 0.3358\n",
      "Epoch [7/10], Phase: train, Batch: [217/657], Loss: 0.2710\n",
      "Epoch [7/10], Phase: train, Batch: [218/657], Loss: 0.2315\n",
      "Epoch [7/10], Phase: train, Batch: [219/657], Loss: 0.3531\n",
      "Epoch [7/10], Phase: train, Batch: [220/657], Loss: 0.3285\n",
      "Epoch [7/10], Phase: train, Batch: [221/657], Loss: 0.2880\n",
      "Epoch [7/10], Phase: train, Batch: [222/657], Loss: 0.3349\n",
      "Epoch [7/10], Phase: train, Batch: [223/657], Loss: 0.2269\n",
      "Epoch [7/10], Phase: train, Batch: [224/657], Loss: 0.3451\n",
      "Epoch [7/10], Phase: train, Batch: [225/657], Loss: 0.2388\n",
      "Epoch [7/10], Phase: train, Batch: [226/657], Loss: 0.2073\n",
      "Epoch [7/10], Phase: train, Batch: [227/657], Loss: 0.1752\n",
      "Epoch [7/10], Phase: train, Batch: [228/657], Loss: 0.2115\n",
      "Epoch [7/10], Phase: train, Batch: [229/657], Loss: 0.3089\n",
      "Epoch [7/10], Phase: train, Batch: [230/657], Loss: 0.2501\n",
      "Epoch [7/10], Phase: train, Batch: [231/657], Loss: 0.2983\n",
      "Epoch [7/10], Phase: train, Batch: [232/657], Loss: 0.2647\n",
      "Epoch [7/10], Phase: train, Batch: [233/657], Loss: 0.2827\n",
      "Epoch [7/10], Phase: train, Batch: [234/657], Loss: 0.2136\n",
      "Epoch [7/10], Phase: train, Batch: [235/657], Loss: 0.1680\n",
      "Epoch [7/10], Phase: train, Batch: [236/657], Loss: 0.3716\n",
      "Epoch [7/10], Phase: train, Batch: [237/657], Loss: 0.2507\n",
      "Epoch [7/10], Phase: train, Batch: [238/657], Loss: 0.2043\n",
      "Epoch [7/10], Phase: train, Batch: [239/657], Loss: 0.1767\n",
      "Epoch [7/10], Phase: train, Batch: [240/657], Loss: 0.3384\n",
      "Epoch [7/10], Phase: train, Batch: [241/657], Loss: 0.2530\n",
      "Epoch [7/10], Phase: train, Batch: [242/657], Loss: 0.1692\n",
      "Epoch [7/10], Phase: train, Batch: [243/657], Loss: 0.2846\n",
      "Epoch [7/10], Phase: train, Batch: [244/657], Loss: 0.2880\n",
      "Epoch [7/10], Phase: train, Batch: [245/657], Loss: 0.2112\n",
      "Epoch [7/10], Phase: train, Batch: [246/657], Loss: 0.1566\n",
      "Epoch [7/10], Phase: train, Batch: [247/657], Loss: 0.2930\n",
      "Epoch [7/10], Phase: train, Batch: [248/657], Loss: 0.3574\n",
      "Epoch [7/10], Phase: train, Batch: [249/657], Loss: 0.2573\n",
      "Epoch [7/10], Phase: train, Batch: [250/657], Loss: 0.3688\n",
      "Epoch [7/10], Phase: train, Batch: [251/657], Loss: 0.2360\n",
      "Epoch [7/10], Phase: train, Batch: [252/657], Loss: 0.4371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Phase: train, Batch: [253/657], Loss: 0.2448\n",
      "Epoch [7/10], Phase: train, Batch: [254/657], Loss: 0.2368\n",
      "Epoch [7/10], Phase: train, Batch: [255/657], Loss: 0.2422\n",
      "Epoch [7/10], Phase: train, Batch: [256/657], Loss: 0.2355\n",
      "Epoch [7/10], Phase: train, Batch: [257/657], Loss: 0.3046\n",
      "Epoch [7/10], Phase: train, Batch: [258/657], Loss: 0.2988\n",
      "Epoch [7/10], Phase: train, Batch: [259/657], Loss: 0.3537\n",
      "Epoch [7/10], Phase: train, Batch: [260/657], Loss: 0.2264\n",
      "Epoch [7/10], Phase: train, Batch: [261/657], Loss: 0.2252\n",
      "Epoch [7/10], Phase: train, Batch: [262/657], Loss: 0.2402\n",
      "Epoch [7/10], Phase: train, Batch: [263/657], Loss: 0.3207\n",
      "Epoch [7/10], Phase: train, Batch: [264/657], Loss: 0.1853\n",
      "Epoch [7/10], Phase: train, Batch: [265/657], Loss: 0.3704\n",
      "Epoch [7/10], Phase: train, Batch: [266/657], Loss: 0.1943\n",
      "Epoch [7/10], Phase: train, Batch: [267/657], Loss: 0.2532\n",
      "Epoch [7/10], Phase: train, Batch: [268/657], Loss: 0.3059\n",
      "Epoch [7/10], Phase: train, Batch: [269/657], Loss: 0.1809\n",
      "Epoch [7/10], Phase: train, Batch: [270/657], Loss: 0.2517\n",
      "Epoch [7/10], Phase: train, Batch: [271/657], Loss: 0.2721\n",
      "Epoch [7/10], Phase: train, Batch: [272/657], Loss: 0.1812\n",
      "Epoch [7/10], Phase: train, Batch: [273/657], Loss: 0.2242\n",
      "Epoch [7/10], Phase: train, Batch: [274/657], Loss: 0.2977\n",
      "Epoch [7/10], Phase: train, Batch: [275/657], Loss: 0.2669\n",
      "Epoch [7/10], Phase: train, Batch: [276/657], Loss: 0.3048\n",
      "Epoch [7/10], Phase: train, Batch: [277/657], Loss: 0.2751\n",
      "Epoch [7/10], Phase: train, Batch: [278/657], Loss: 0.2083\n",
      "Epoch [7/10], Phase: train, Batch: [279/657], Loss: 0.2490\n",
      "Epoch [7/10], Phase: train, Batch: [280/657], Loss: 0.1072\n",
      "Epoch [7/10], Phase: train, Batch: [281/657], Loss: 0.3081\n",
      "Epoch [7/10], Phase: train, Batch: [282/657], Loss: 0.2589\n",
      "Epoch [7/10], Phase: train, Batch: [283/657], Loss: 0.2743\n",
      "Epoch [7/10], Phase: train, Batch: [284/657], Loss: 0.3065\n",
      "Epoch [7/10], Phase: train, Batch: [285/657], Loss: 0.2091\n",
      "Epoch [7/10], Phase: train, Batch: [286/657], Loss: 0.3025\n",
      "Epoch [7/10], Phase: train, Batch: [287/657], Loss: 0.2835\n",
      "Epoch [7/10], Phase: train, Batch: [288/657], Loss: 0.2915\n",
      "Epoch [7/10], Phase: train, Batch: [289/657], Loss: 0.4014\n",
      "Epoch [7/10], Phase: train, Batch: [290/657], Loss: 0.1833\n",
      "Epoch [7/10], Phase: train, Batch: [291/657], Loss: 0.3668\n",
      "Epoch [7/10], Phase: train, Batch: [292/657], Loss: 0.2823\n",
      "Epoch [7/10], Phase: train, Batch: [293/657], Loss: 0.3166\n",
      "Epoch [7/10], Phase: train, Batch: [294/657], Loss: 0.2763\n",
      "Epoch [7/10], Phase: train, Batch: [295/657], Loss: 0.5317\n",
      "Epoch [7/10], Phase: train, Batch: [296/657], Loss: 0.3181\n",
      "Epoch [7/10], Phase: train, Batch: [297/657], Loss: 0.3279\n",
      "Epoch [7/10], Phase: train, Batch: [298/657], Loss: 0.3324\n",
      "Epoch [7/10], Phase: train, Batch: [299/657], Loss: 0.3134\n",
      "Epoch [7/10], Phase: train, Batch: [300/657], Loss: 0.3568\n",
      "Epoch [7/10], Phase: train, Batch: [301/657], Loss: 0.3189\n",
      "Epoch [7/10], Phase: train, Batch: [302/657], Loss: 0.4147\n",
      "Epoch [7/10], Phase: train, Batch: [303/657], Loss: 0.1908\n",
      "Epoch [7/10], Phase: train, Batch: [304/657], Loss: 0.4420\n",
      "Epoch [7/10], Phase: train, Batch: [305/657], Loss: 0.3303\n",
      "Epoch [7/10], Phase: train, Batch: [306/657], Loss: 0.3419\n",
      "Epoch [7/10], Phase: train, Batch: [307/657], Loss: 0.2953\n",
      "Epoch [7/10], Phase: train, Batch: [308/657], Loss: 0.2494\n",
      "Epoch [7/10], Phase: train, Batch: [309/657], Loss: 0.2455\n",
      "Epoch [7/10], Phase: train, Batch: [310/657], Loss: 0.2392\n",
      "Epoch [7/10], Phase: train, Batch: [311/657], Loss: 0.3218\n",
      "Epoch [7/10], Phase: train, Batch: [312/657], Loss: 0.2150\n",
      "Epoch [7/10], Phase: train, Batch: [313/657], Loss: 0.2033\n",
      "Epoch [7/10], Phase: train, Batch: [314/657], Loss: 0.2337\n",
      "Epoch [7/10], Phase: train, Batch: [315/657], Loss: 0.2541\n",
      "Epoch [7/10], Phase: train, Batch: [316/657], Loss: 0.2671\n",
      "Epoch [7/10], Phase: train, Batch: [317/657], Loss: 0.1727\n",
      "Epoch [7/10], Phase: train, Batch: [318/657], Loss: 0.2650\n",
      "Epoch [7/10], Phase: train, Batch: [319/657], Loss: 0.3112\n",
      "Epoch [7/10], Phase: train, Batch: [320/657], Loss: 0.2347\n",
      "Epoch [7/10], Phase: train, Batch: [321/657], Loss: 0.3012\n",
      "Epoch [7/10], Phase: train, Batch: [322/657], Loss: 0.2245\n",
      "Epoch [7/10], Phase: train, Batch: [323/657], Loss: 0.2028\n",
      "Epoch [7/10], Phase: train, Batch: [324/657], Loss: 0.2108\n",
      "Epoch [7/10], Phase: train, Batch: [325/657], Loss: 0.1544\n",
      "Epoch [7/10], Phase: train, Batch: [326/657], Loss: 0.2790\n",
      "Epoch [7/10], Phase: train, Batch: [327/657], Loss: 0.2959\n",
      "Epoch [7/10], Phase: train, Batch: [328/657], Loss: 0.1778\n",
      "Epoch [7/10], Phase: train, Batch: [329/657], Loss: 0.2888\n",
      "Epoch [7/10], Phase: train, Batch: [330/657], Loss: 0.2097\n",
      "Epoch [7/10], Phase: train, Batch: [331/657], Loss: 0.2968\n",
      "Epoch [7/10], Phase: train, Batch: [332/657], Loss: 0.2207\n",
      "Epoch [7/10], Phase: train, Batch: [333/657], Loss: 0.2597\n",
      "Epoch [7/10], Phase: train, Batch: [334/657], Loss: 0.2906\n",
      "Epoch [7/10], Phase: train, Batch: [335/657], Loss: 0.4047\n",
      "Epoch [7/10], Phase: train, Batch: [336/657], Loss: 0.1712\n",
      "Epoch [7/10], Phase: train, Batch: [337/657], Loss: 0.2848\n",
      "Epoch [7/10], Phase: train, Batch: [338/657], Loss: 0.3445\n",
      "Epoch [7/10], Phase: train, Batch: [339/657], Loss: 0.3864\n",
      "Epoch [7/10], Phase: train, Batch: [340/657], Loss: 0.3005\n",
      "Epoch [7/10], Phase: train, Batch: [341/657], Loss: 0.3016\n",
      "Epoch [7/10], Phase: train, Batch: [342/657], Loss: 0.2624\n",
      "Epoch [7/10], Phase: train, Batch: [343/657], Loss: 0.1620\n",
      "Epoch [7/10], Phase: train, Batch: [344/657], Loss: 0.2703\n",
      "Epoch [7/10], Phase: train, Batch: [345/657], Loss: 0.1992\n",
      "Epoch [7/10], Phase: train, Batch: [346/657], Loss: 0.1949\n",
      "Epoch [7/10], Phase: train, Batch: [347/657], Loss: 0.3256\n",
      "Epoch [7/10], Phase: train, Batch: [348/657], Loss: 0.2399\n",
      "Epoch [7/10], Phase: train, Batch: [349/657], Loss: 0.2330\n",
      "Epoch [7/10], Phase: train, Batch: [350/657], Loss: 0.3488\n",
      "Epoch [7/10], Phase: train, Batch: [351/657], Loss: 0.2073\n",
      "Epoch [7/10], Phase: train, Batch: [352/657], Loss: 0.1950\n",
      "Epoch [7/10], Phase: train, Batch: [353/657], Loss: 0.1563\n",
      "Epoch [7/10], Phase: train, Batch: [354/657], Loss: 0.2613\n",
      "Epoch [7/10], Phase: train, Batch: [355/657], Loss: 0.1929\n",
      "Epoch [7/10], Phase: train, Batch: [356/657], Loss: 0.2366\n",
      "Epoch [7/10], Phase: train, Batch: [357/657], Loss: 0.2552\n",
      "Epoch [7/10], Phase: train, Batch: [358/657], Loss: 0.2434\n",
      "Epoch [7/10], Phase: train, Batch: [359/657], Loss: 0.3429\n",
      "Epoch [7/10], Phase: train, Batch: [360/657], Loss: 0.3735\n",
      "Epoch [7/10], Phase: train, Batch: [361/657], Loss: 0.3656\n",
      "Epoch [7/10], Phase: train, Batch: [362/657], Loss: 0.3698\n",
      "Epoch [7/10], Phase: train, Batch: [363/657], Loss: 0.3563\n",
      "Epoch [7/10], Phase: train, Batch: [364/657], Loss: 0.2990\n",
      "Epoch [7/10], Phase: train, Batch: [365/657], Loss: 0.2344\n",
      "Epoch [7/10], Phase: train, Batch: [366/657], Loss: 0.2383\n",
      "Epoch [7/10], Phase: train, Batch: [367/657], Loss: 0.2508\n",
      "Epoch [7/10], Phase: train, Batch: [368/657], Loss: 0.4122\n",
      "Epoch [7/10], Phase: train, Batch: [369/657], Loss: 0.2305\n",
      "Epoch [7/10], Phase: train, Batch: [370/657], Loss: 0.2346\n",
      "Epoch [7/10], Phase: train, Batch: [371/657], Loss: 0.2447\n",
      "Epoch [7/10], Phase: train, Batch: [372/657], Loss: 0.2919\n",
      "Epoch [7/10], Phase: train, Batch: [373/657], Loss: 0.1711\n",
      "Epoch [7/10], Phase: train, Batch: [374/657], Loss: 0.3237\n",
      "Epoch [7/10], Phase: train, Batch: [375/657], Loss: 0.2862\n",
      "Epoch [7/10], Phase: train, Batch: [376/657], Loss: 0.2781\n",
      "Epoch [7/10], Phase: train, Batch: [377/657], Loss: 0.2880\n",
      "Epoch [7/10], Phase: train, Batch: [378/657], Loss: 0.2612\n",
      "Epoch [7/10], Phase: train, Batch: [379/657], Loss: 0.3438\n",
      "Epoch [7/10], Phase: train, Batch: [380/657], Loss: 0.1822\n",
      "Epoch [7/10], Phase: train, Batch: [381/657], Loss: 0.2362\n",
      "Epoch [7/10], Phase: train, Batch: [382/657], Loss: 0.2341\n",
      "Epoch [7/10], Phase: train, Batch: [383/657], Loss: 0.2677\n",
      "Epoch [7/10], Phase: train, Batch: [384/657], Loss: 0.3136\n",
      "Epoch [7/10], Phase: train, Batch: [385/657], Loss: 0.2297\n",
      "Epoch [7/10], Phase: train, Batch: [386/657], Loss: 0.2567\n",
      "Epoch [7/10], Phase: train, Batch: [387/657], Loss: 0.3752\n",
      "Epoch [7/10], Phase: train, Batch: [388/657], Loss: 0.3217\n",
      "Epoch [7/10], Phase: train, Batch: [389/657], Loss: 0.3534\n",
      "Epoch [7/10], Phase: train, Batch: [390/657], Loss: 0.2195\n",
      "Epoch [7/10], Phase: train, Batch: [391/657], Loss: 0.2421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Phase: train, Batch: [392/657], Loss: 0.2872\n",
      "Epoch [7/10], Phase: train, Batch: [393/657], Loss: 0.2877\n",
      "Epoch [7/10], Phase: train, Batch: [394/657], Loss: 0.3572\n",
      "Epoch [7/10], Phase: train, Batch: [395/657], Loss: 0.3183\n",
      "Epoch [7/10], Phase: train, Batch: [396/657], Loss: 0.2578\n",
      "Epoch [7/10], Phase: train, Batch: [397/657], Loss: 0.2729\n",
      "Epoch [7/10], Phase: train, Batch: [398/657], Loss: 0.2543\n",
      "Epoch [7/10], Phase: train, Batch: [399/657], Loss: 0.1810\n",
      "Epoch [7/10], Phase: train, Batch: [400/657], Loss: 0.2154\n",
      "Epoch [7/10], Phase: train, Batch: [401/657], Loss: 0.3127\n",
      "Epoch [7/10], Phase: train, Batch: [402/657], Loss: 0.3628\n",
      "Epoch [7/10], Phase: train, Batch: [403/657], Loss: 0.2207\n",
      "Epoch [7/10], Phase: train, Batch: [404/657], Loss: 0.3882\n",
      "Epoch [7/10], Phase: train, Batch: [405/657], Loss: 0.2143\n",
      "Epoch [7/10], Phase: train, Batch: [406/657], Loss: 0.2506\n",
      "Epoch [7/10], Phase: train, Batch: [407/657], Loss: 0.2352\n",
      "Epoch [7/10], Phase: train, Batch: [408/657], Loss: 0.1704\n",
      "Epoch [7/10], Phase: train, Batch: [409/657], Loss: 0.4223\n",
      "Epoch [7/10], Phase: train, Batch: [410/657], Loss: 0.2386\n",
      "Epoch [7/10], Phase: train, Batch: [411/657], Loss: 0.1694\n",
      "Epoch [7/10], Phase: train, Batch: [412/657], Loss: 0.2066\n",
      "Epoch [7/10], Phase: train, Batch: [413/657], Loss: 0.2658\n",
      "Epoch [7/10], Phase: train, Batch: [414/657], Loss: 0.3335\n",
      "Epoch [7/10], Phase: train, Batch: [415/657], Loss: 0.2633\n",
      "Epoch [7/10], Phase: train, Batch: [416/657], Loss: 0.2632\n",
      "Epoch [7/10], Phase: train, Batch: [417/657], Loss: 0.2521\n",
      "Epoch [7/10], Phase: train, Batch: [418/657], Loss: 0.3356\n",
      "Epoch [7/10], Phase: train, Batch: [419/657], Loss: 0.4357\n",
      "Epoch [7/10], Phase: train, Batch: [420/657], Loss: 0.3471\n",
      "Epoch [7/10], Phase: train, Batch: [421/657], Loss: 0.3289\n",
      "Epoch [7/10], Phase: train, Batch: [422/657], Loss: 0.1987\n",
      "Epoch [7/10], Phase: train, Batch: [423/657], Loss: 0.4239\n",
      "Epoch [7/10], Phase: train, Batch: [424/657], Loss: 0.2658\n",
      "Epoch [7/10], Phase: train, Batch: [425/657], Loss: 0.3026\n",
      "Epoch [7/10], Phase: train, Batch: [426/657], Loss: 0.1569\n",
      "Epoch [7/10], Phase: train, Batch: [427/657], Loss: 0.1838\n",
      "Epoch [7/10], Phase: train, Batch: [428/657], Loss: 0.4346\n",
      "Epoch [7/10], Phase: train, Batch: [429/657], Loss: 0.2289\n",
      "Epoch [7/10], Phase: train, Batch: [430/657], Loss: 0.3759\n",
      "Epoch [7/10], Phase: train, Batch: [431/657], Loss: 0.4183\n",
      "Epoch [7/10], Phase: train, Batch: [432/657], Loss: 0.2133\n",
      "Epoch [7/10], Phase: train, Batch: [433/657], Loss: 0.2001\n",
      "Epoch [7/10], Phase: train, Batch: [434/657], Loss: 0.3237\n",
      "Epoch [7/10], Phase: train, Batch: [435/657], Loss: 0.2853\n",
      "Epoch [7/10], Phase: train, Batch: [436/657], Loss: 0.2350\n",
      "Epoch [7/10], Phase: train, Batch: [437/657], Loss: 0.3913\n",
      "Epoch [7/10], Phase: train, Batch: [438/657], Loss: 0.3657\n",
      "Epoch [7/10], Phase: train, Batch: [439/657], Loss: 0.4009\n",
      "Epoch [7/10], Phase: train, Batch: [440/657], Loss: 0.3916\n",
      "Epoch [7/10], Phase: train, Batch: [441/657], Loss: 0.2151\n",
      "Epoch [7/10], Phase: train, Batch: [442/657], Loss: 0.3869\n",
      "Epoch [7/10], Phase: train, Batch: [443/657], Loss: 0.1969\n",
      "Epoch [7/10], Phase: train, Batch: [444/657], Loss: 0.3756\n",
      "Epoch [7/10], Phase: train, Batch: [445/657], Loss: 0.3284\n",
      "Epoch [7/10], Phase: train, Batch: [446/657], Loss: 0.2533\n",
      "Epoch [7/10], Phase: train, Batch: [447/657], Loss: 0.3477\n",
      "Epoch [7/10], Phase: train, Batch: [448/657], Loss: 0.2930\n",
      "Epoch [7/10], Phase: train, Batch: [449/657], Loss: 0.2261\n",
      "Epoch [7/10], Phase: train, Batch: [450/657], Loss: 0.4055\n",
      "Epoch [7/10], Phase: train, Batch: [451/657], Loss: 0.2140\n",
      "Epoch [7/10], Phase: train, Batch: [452/657], Loss: 0.2331\n",
      "Epoch [7/10], Phase: train, Batch: [453/657], Loss: 0.2965\n",
      "Epoch [7/10], Phase: train, Batch: [454/657], Loss: 0.3366\n",
      "Epoch [7/10], Phase: train, Batch: [455/657], Loss: 0.2779\n",
      "Epoch [7/10], Phase: train, Batch: [456/657], Loss: 0.3853\n",
      "Epoch [7/10], Phase: train, Batch: [457/657], Loss: 0.2560\n",
      "Epoch [7/10], Phase: train, Batch: [458/657], Loss: 0.3763\n",
      "Epoch [7/10], Phase: train, Batch: [459/657], Loss: 0.4589\n",
      "Epoch [7/10], Phase: train, Batch: [460/657], Loss: 0.2970\n",
      "Epoch [7/10], Phase: train, Batch: [461/657], Loss: 0.3572\n",
      "Epoch [7/10], Phase: train, Batch: [462/657], Loss: 0.2108\n",
      "Epoch [7/10], Phase: train, Batch: [463/657], Loss: 0.1757\n",
      "Epoch [7/10], Phase: train, Batch: [464/657], Loss: 0.3366\n",
      "Epoch [7/10], Phase: train, Batch: [465/657], Loss: 0.2314\n",
      "Epoch [7/10], Phase: train, Batch: [466/657], Loss: 0.3430\n",
      "Epoch [7/10], Phase: train, Batch: [467/657], Loss: 0.2505\n",
      "Epoch [7/10], Phase: train, Batch: [468/657], Loss: 0.2753\n",
      "Epoch [7/10], Phase: train, Batch: [469/657], Loss: 0.3399\n",
      "Epoch [7/10], Phase: train, Batch: [470/657], Loss: 0.1705\n",
      "Epoch [7/10], Phase: train, Batch: [471/657], Loss: 0.3140\n",
      "Epoch [7/10], Phase: train, Batch: [472/657], Loss: 0.4490\n",
      "Epoch [7/10], Phase: train, Batch: [473/657], Loss: 0.4390\n",
      "Epoch [7/10], Phase: train, Batch: [474/657], Loss: 0.2721\n",
      "Epoch [7/10], Phase: train, Batch: [475/657], Loss: 0.2100\n",
      "Epoch [7/10], Phase: train, Batch: [476/657], Loss: 0.2999\n",
      "Epoch [7/10], Phase: train, Batch: [477/657], Loss: 0.1764\n",
      "Epoch [7/10], Phase: train, Batch: [478/657], Loss: 0.2184\n",
      "Epoch [7/10], Phase: train, Batch: [479/657], Loss: 0.2673\n",
      "Epoch [7/10], Phase: train, Batch: [480/657], Loss: 0.3321\n",
      "Epoch [7/10], Phase: train, Batch: [481/657], Loss: 0.2628\n",
      "Epoch [7/10], Phase: train, Batch: [482/657], Loss: 0.3272\n",
      "Epoch [7/10], Phase: train, Batch: [483/657], Loss: 0.4070\n",
      "Epoch [7/10], Phase: train, Batch: [484/657], Loss: 0.1976\n",
      "Epoch [7/10], Phase: train, Batch: [485/657], Loss: 0.2352\n",
      "Epoch [7/10], Phase: train, Batch: [486/657], Loss: 0.3111\n",
      "Epoch [7/10], Phase: train, Batch: [487/657], Loss: 0.3183\n",
      "Epoch [7/10], Phase: train, Batch: [488/657], Loss: 0.2192\n",
      "Epoch [7/10], Phase: train, Batch: [489/657], Loss: 0.1745\n",
      "Epoch [7/10], Phase: train, Batch: [490/657], Loss: 0.1568\n",
      "Epoch [7/10], Phase: train, Batch: [491/657], Loss: 0.1711\n",
      "Epoch [7/10], Phase: train, Batch: [492/657], Loss: 0.1716\n",
      "Epoch [7/10], Phase: train, Batch: [493/657], Loss: 0.2529\n",
      "Epoch [7/10], Phase: train, Batch: [494/657], Loss: 0.3512\n",
      "Epoch [7/10], Phase: train, Batch: [495/657], Loss: 0.2783\n",
      "Epoch [7/10], Phase: train, Batch: [496/657], Loss: 0.1928\n",
      "Epoch [7/10], Phase: train, Batch: [497/657], Loss: 0.2242\n",
      "Epoch [7/10], Phase: train, Batch: [498/657], Loss: 0.1959\n",
      "Epoch [7/10], Phase: train, Batch: [499/657], Loss: 0.1359\n",
      "Epoch [7/10], Phase: train, Batch: [500/657], Loss: 0.2828\n",
      "Epoch [7/10], Phase: train, Batch: [501/657], Loss: 0.2991\n",
      "Epoch [7/10], Phase: train, Batch: [502/657], Loss: 0.2143\n",
      "Epoch [7/10], Phase: train, Batch: [503/657], Loss: 0.3669\n",
      "Epoch [7/10], Phase: train, Batch: [504/657], Loss: 0.3113\n",
      "Epoch [7/10], Phase: train, Batch: [505/657], Loss: 0.1996\n",
      "Epoch [7/10], Phase: train, Batch: [506/657], Loss: 0.2759\n",
      "Epoch [7/10], Phase: train, Batch: [507/657], Loss: 0.4043\n",
      "Epoch [7/10], Phase: train, Batch: [508/657], Loss: 0.1975\n",
      "Epoch [7/10], Phase: train, Batch: [509/657], Loss: 0.3160\n",
      "Epoch [7/10], Phase: train, Batch: [510/657], Loss: 0.2082\n",
      "Epoch [7/10], Phase: train, Batch: [511/657], Loss: 0.1845\n",
      "Epoch [7/10], Phase: train, Batch: [512/657], Loss: 0.2171\n",
      "Epoch [7/10], Phase: train, Batch: [513/657], Loss: 0.3542\n",
      "Epoch [7/10], Phase: train, Batch: [514/657], Loss: 0.2914\n",
      "Epoch [7/10], Phase: train, Batch: [515/657], Loss: 0.1906\n",
      "Epoch [7/10], Phase: train, Batch: [516/657], Loss: 0.4943\n",
      "Epoch [7/10], Phase: train, Batch: [517/657], Loss: 0.1884\n",
      "Epoch [7/10], Phase: train, Batch: [518/657], Loss: 0.1922\n",
      "Epoch [7/10], Phase: train, Batch: [519/657], Loss: 0.2836\n",
      "Epoch [7/10], Phase: train, Batch: [520/657], Loss: 0.3509\n",
      "Epoch [7/10], Phase: train, Batch: [521/657], Loss: 0.4773\n",
      "Epoch [7/10], Phase: train, Batch: [522/657], Loss: 0.3555\n",
      "Epoch [7/10], Phase: train, Batch: [523/657], Loss: 0.3107\n",
      "Epoch [7/10], Phase: train, Batch: [524/657], Loss: 0.3726\n",
      "Epoch [7/10], Phase: train, Batch: [525/657], Loss: 0.2234\n",
      "Epoch [7/10], Phase: train, Batch: [526/657], Loss: 0.3175\n",
      "Epoch [7/10], Phase: train, Batch: [527/657], Loss: 0.3218\n",
      "Epoch [7/10], Phase: train, Batch: [528/657], Loss: 0.2899\n",
      "Epoch [7/10], Phase: train, Batch: [529/657], Loss: 0.4191\n",
      "Epoch [7/10], Phase: train, Batch: [530/657], Loss: 0.2280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Phase: train, Batch: [531/657], Loss: 0.2524\n",
      "Epoch [7/10], Phase: train, Batch: [532/657], Loss: 0.1907\n",
      "Epoch [7/10], Phase: train, Batch: [533/657], Loss: 0.2877\n",
      "Epoch [7/10], Phase: train, Batch: [534/657], Loss: 0.1797\n",
      "Epoch [7/10], Phase: train, Batch: [535/657], Loss: 0.3716\n",
      "Epoch [7/10], Phase: train, Batch: [536/657], Loss: 0.1864\n",
      "Epoch [7/10], Phase: train, Batch: [537/657], Loss: 0.3973\n",
      "Epoch [7/10], Phase: train, Batch: [538/657], Loss: 0.2706\n",
      "Epoch [7/10], Phase: train, Batch: [539/657], Loss: 0.3256\n",
      "Epoch [7/10], Phase: train, Batch: [540/657], Loss: 0.2420\n",
      "Epoch [7/10], Phase: train, Batch: [541/657], Loss: 0.2599\n",
      "Epoch [7/10], Phase: train, Batch: [542/657], Loss: 0.3391\n",
      "Epoch [7/10], Phase: train, Batch: [543/657], Loss: 0.2869\n",
      "Epoch [7/10], Phase: train, Batch: [544/657], Loss: 0.1818\n",
      "Epoch [7/10], Phase: train, Batch: [545/657], Loss: 0.2232\n",
      "Epoch [7/10], Phase: train, Batch: [546/657], Loss: 0.4277\n",
      "Epoch [7/10], Phase: train, Batch: [547/657], Loss: 0.4041\n",
      "Epoch [7/10], Phase: train, Batch: [548/657], Loss: 0.3283\n",
      "Epoch [7/10], Phase: train, Batch: [549/657], Loss: 0.2401\n",
      "Epoch [7/10], Phase: train, Batch: [550/657], Loss: 0.1276\n",
      "Epoch [7/10], Phase: train, Batch: [551/657], Loss: 0.2710\n",
      "Epoch [7/10], Phase: train, Batch: [552/657], Loss: 0.2661\n",
      "Epoch [7/10], Phase: train, Batch: [553/657], Loss: 0.4253\n",
      "Epoch [7/10], Phase: train, Batch: [554/657], Loss: 0.2648\n",
      "Epoch [7/10], Phase: train, Batch: [555/657], Loss: 0.1556\n",
      "Epoch [7/10], Phase: train, Batch: [556/657], Loss: 0.2920\n",
      "Epoch [7/10], Phase: train, Batch: [557/657], Loss: 0.3140\n",
      "Epoch [7/10], Phase: train, Batch: [558/657], Loss: 0.2283\n",
      "Epoch [7/10], Phase: train, Batch: [559/657], Loss: 0.2601\n",
      "Epoch [7/10], Phase: train, Batch: [560/657], Loss: 0.2504\n",
      "Epoch [7/10], Phase: train, Batch: [561/657], Loss: 0.2563\n",
      "Epoch [7/10], Phase: train, Batch: [562/657], Loss: 0.3423\n",
      "Epoch [7/10], Phase: train, Batch: [563/657], Loss: 0.4686\n",
      "Epoch [7/10], Phase: train, Batch: [564/657], Loss: 0.2582\n",
      "Epoch [7/10], Phase: train, Batch: [565/657], Loss: 0.3817\n",
      "Epoch [7/10], Phase: train, Batch: [566/657], Loss: 0.3061\n",
      "Epoch [7/10], Phase: train, Batch: [567/657], Loss: 0.2900\n",
      "Epoch [7/10], Phase: train, Batch: [568/657], Loss: 0.3045\n",
      "Epoch [7/10], Phase: train, Batch: [569/657], Loss: 0.2781\n",
      "Epoch [7/10], Phase: train, Batch: [570/657], Loss: 0.4176\n",
      "Epoch [7/10], Phase: train, Batch: [571/657], Loss: 0.2387\n",
      "Epoch [7/10], Phase: train, Batch: [572/657], Loss: 0.2460\n",
      "Epoch [7/10], Phase: train, Batch: [573/657], Loss: 0.2943\n",
      "Epoch [7/10], Phase: train, Batch: [574/657], Loss: 0.2480\n",
      "Epoch [7/10], Phase: train, Batch: [575/657], Loss: 0.2398\n",
      "Epoch [7/10], Phase: train, Batch: [576/657], Loss: 0.1863\n",
      "Epoch [7/10], Phase: train, Batch: [577/657], Loss: 0.2642\n",
      "Epoch [7/10], Phase: train, Batch: [578/657], Loss: 0.2855\n",
      "Epoch [7/10], Phase: train, Batch: [579/657], Loss: 0.2071\n",
      "Epoch [7/10], Phase: train, Batch: [580/657], Loss: 0.4027\n",
      "Epoch [7/10], Phase: train, Batch: [581/657], Loss: 0.2719\n",
      "Epoch [7/10], Phase: train, Batch: [582/657], Loss: 0.2277\n",
      "Epoch [7/10], Phase: train, Batch: [583/657], Loss: 0.1941\n",
      "Epoch [7/10], Phase: train, Batch: [584/657], Loss: 0.2767\n",
      "Epoch [7/10], Phase: train, Batch: [585/657], Loss: 0.3900\n",
      "Epoch [7/10], Phase: train, Batch: [586/657], Loss: 0.3578\n",
      "Epoch [7/10], Phase: train, Batch: [587/657], Loss: 0.1615\n",
      "Epoch [7/10], Phase: train, Batch: [588/657], Loss: 0.3785\n",
      "Epoch [7/10], Phase: train, Batch: [589/657], Loss: 0.1446\n",
      "Epoch [7/10], Phase: train, Batch: [590/657], Loss: 0.2562\n",
      "Epoch [7/10], Phase: train, Batch: [591/657], Loss: 0.3458\n",
      "Epoch [7/10], Phase: train, Batch: [592/657], Loss: 0.3327\n",
      "Epoch [7/10], Phase: train, Batch: [593/657], Loss: 0.3267\n",
      "Epoch [7/10], Phase: train, Batch: [594/657], Loss: 0.3471\n",
      "Epoch [7/10], Phase: train, Batch: [595/657], Loss: 0.2779\n",
      "Epoch [7/10], Phase: train, Batch: [596/657], Loss: 0.3230\n",
      "Epoch [7/10], Phase: train, Batch: [597/657], Loss: 0.1603\n",
      "Epoch [7/10], Phase: train, Batch: [598/657], Loss: 0.3004\n",
      "Epoch [7/10], Phase: train, Batch: [599/657], Loss: 0.2117\n",
      "Epoch [7/10], Phase: train, Batch: [600/657], Loss: 0.4493\n",
      "Epoch [7/10], Phase: train, Batch: [601/657], Loss: 0.2753\n",
      "Epoch [7/10], Phase: train, Batch: [602/657], Loss: 0.2541\n",
      "Epoch [7/10], Phase: train, Batch: [603/657], Loss: 0.3011\n",
      "Epoch [7/10], Phase: train, Batch: [604/657], Loss: 0.2461\n",
      "Epoch [7/10], Phase: train, Batch: [605/657], Loss: 0.1921\n",
      "Epoch [7/10], Phase: train, Batch: [606/657], Loss: 0.2937\n",
      "Epoch [7/10], Phase: train, Batch: [607/657], Loss: 0.2965\n",
      "Epoch [7/10], Phase: train, Batch: [608/657], Loss: 0.1803\n",
      "Epoch [7/10], Phase: train, Batch: [609/657], Loss: 0.2863\n",
      "Epoch [7/10], Phase: train, Batch: [610/657], Loss: 0.4107\n",
      "Epoch [7/10], Phase: train, Batch: [611/657], Loss: 0.2958\n",
      "Epoch [7/10], Phase: train, Batch: [612/657], Loss: 0.3445\n",
      "Epoch [7/10], Phase: train, Batch: [613/657], Loss: 0.2411\n",
      "Epoch [7/10], Phase: train, Batch: [614/657], Loss: 0.3161\n",
      "Epoch [7/10], Phase: train, Batch: [615/657], Loss: 0.1627\n",
      "Epoch [7/10], Phase: train, Batch: [616/657], Loss: 0.2093\n",
      "Epoch [7/10], Phase: train, Batch: [617/657], Loss: 0.3590\n",
      "Epoch [7/10], Phase: train, Batch: [618/657], Loss: 0.2717\n",
      "Epoch [7/10], Phase: train, Batch: [619/657], Loss: 0.1969\n",
      "Epoch [7/10], Phase: train, Batch: [620/657], Loss: 0.3292\n",
      "Epoch [7/10], Phase: train, Batch: [621/657], Loss: 0.3910\n",
      "Epoch [7/10], Phase: train, Batch: [622/657], Loss: 0.1998\n",
      "Epoch [7/10], Phase: train, Batch: [623/657], Loss: 0.2064\n",
      "Epoch [7/10], Phase: train, Batch: [624/657], Loss: 0.3296\n",
      "Epoch [7/10], Phase: train, Batch: [625/657], Loss: 0.2270\n",
      "Epoch [7/10], Phase: train, Batch: [626/657], Loss: 0.2503\n",
      "Epoch [7/10], Phase: train, Batch: [627/657], Loss: 0.2980\n",
      "Epoch [7/10], Phase: train, Batch: [628/657], Loss: 0.3885\n",
      "Epoch [7/10], Phase: train, Batch: [629/657], Loss: 0.4254\n",
      "Epoch [7/10], Phase: train, Batch: [630/657], Loss: 0.1951\n",
      "Epoch [7/10], Phase: train, Batch: [631/657], Loss: 0.2306\n",
      "Epoch [7/10], Phase: train, Batch: [632/657], Loss: 0.3100\n",
      "Epoch [7/10], Phase: train, Batch: [633/657], Loss: 0.2173\n",
      "Epoch [7/10], Phase: train, Batch: [634/657], Loss: 0.3082\n",
      "Epoch [7/10], Phase: train, Batch: [635/657], Loss: 0.2271\n",
      "Epoch [7/10], Phase: train, Batch: [636/657], Loss: 0.2555\n",
      "Epoch [7/10], Phase: train, Batch: [637/657], Loss: 0.2940\n",
      "Epoch [7/10], Phase: train, Batch: [638/657], Loss: 0.3342\n",
      "Epoch [7/10], Phase: train, Batch: [639/657], Loss: 0.2483\n",
      "Epoch [7/10], Phase: train, Batch: [640/657], Loss: 0.2060\n",
      "Epoch [7/10], Phase: train, Batch: [641/657], Loss: 0.2270\n",
      "Epoch [7/10], Phase: train, Batch: [642/657], Loss: 0.2664\n",
      "Epoch [7/10], Phase: train, Batch: [643/657], Loss: 0.2244\n",
      "Epoch [7/10], Phase: train, Batch: [644/657], Loss: 0.1872\n",
      "Epoch [7/10], Phase: train, Batch: [645/657], Loss: 0.2396\n",
      "Epoch [7/10], Phase: train, Batch: [646/657], Loss: 0.2799\n",
      "Epoch [7/10], Phase: train, Batch: [647/657], Loss: 0.4066\n",
      "Epoch [7/10], Phase: train, Batch: [648/657], Loss: 0.2840\n",
      "Epoch [7/10], Phase: train, Batch: [649/657], Loss: 0.2574\n",
      "Epoch [7/10], Phase: train, Batch: [650/657], Loss: 0.1912\n",
      "Epoch [7/10], Phase: train, Batch: [651/657], Loss: 0.2612\n",
      "Epoch [7/10], Phase: train, Batch: [652/657], Loss: 0.2958\n",
      "Epoch [7/10], Phase: train, Batch: [653/657], Loss: 0.2390\n",
      "Epoch [7/10], Phase: train, Batch: [654/657], Loss: 0.2743\n",
      "Epoch [7/10], Phase: train, Batch: [655/657], Loss: 0.2706\n",
      "Epoch [7/10], Phase: train, Batch: [656/657], Loss: 0.3102\n",
      "Epoch [7/10], Phase: train, Batch: [657/657], Loss: 0.1043\n",
      "train Loss: 0.2766 Acc: 0.8892\n",
      "Epoch [7/10], Phase: val, Batch: [1/73], Loss: 0.3182\n",
      "Epoch [7/10], Phase: val, Batch: [2/73], Loss: 0.2970\n",
      "Epoch [7/10], Phase: val, Batch: [3/73], Loss: 0.1571\n",
      "Epoch [7/10], Phase: val, Batch: [4/73], Loss: 0.3598\n",
      "Epoch [7/10], Phase: val, Batch: [5/73], Loss: 0.2165\n",
      "Epoch [7/10], Phase: val, Batch: [6/73], Loss: 0.2756\n",
      "Epoch [7/10], Phase: val, Batch: [7/73], Loss: 0.1952\n",
      "Epoch [7/10], Phase: val, Batch: [8/73], Loss: 0.2219\n",
      "Epoch [7/10], Phase: val, Batch: [9/73], Loss: 0.0845\n",
      "Epoch [7/10], Phase: val, Batch: [10/73], Loss: 0.1942\n",
      "Epoch [7/10], Phase: val, Batch: [11/73], Loss: 0.1800\n",
      "Epoch [7/10], Phase: val, Batch: [12/73], Loss: 0.2462\n",
      "Epoch [7/10], Phase: val, Batch: [13/73], Loss: 0.1366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Phase: val, Batch: [14/73], Loss: 0.2913\n",
      "Epoch [7/10], Phase: val, Batch: [15/73], Loss: 0.2065\n",
      "Epoch [7/10], Phase: val, Batch: [16/73], Loss: 0.3099\n",
      "Epoch [7/10], Phase: val, Batch: [17/73], Loss: 0.1130\n",
      "Epoch [7/10], Phase: val, Batch: [18/73], Loss: 0.2499\n",
      "Epoch [7/10], Phase: val, Batch: [19/73], Loss: 0.3245\n",
      "Epoch [7/10], Phase: val, Batch: [20/73], Loss: 0.1716\n",
      "Epoch [7/10], Phase: val, Batch: [21/73], Loss: 0.3350\n",
      "Epoch [7/10], Phase: val, Batch: [22/73], Loss: 0.2078\n",
      "Epoch [7/10], Phase: val, Batch: [23/73], Loss: 0.2621\n",
      "Epoch [7/10], Phase: val, Batch: [24/73], Loss: 0.2879\n",
      "Epoch [7/10], Phase: val, Batch: [25/73], Loss: 0.1858\n",
      "Epoch [7/10], Phase: val, Batch: [26/73], Loss: 0.1814\n",
      "Epoch [7/10], Phase: val, Batch: [27/73], Loss: 0.2568\n",
      "Epoch [7/10], Phase: val, Batch: [28/73], Loss: 0.2420\n",
      "Epoch [7/10], Phase: val, Batch: [29/73], Loss: 0.3414\n",
      "Epoch [7/10], Phase: val, Batch: [30/73], Loss: 0.3400\n",
      "Epoch [7/10], Phase: val, Batch: [31/73], Loss: 0.1820\n",
      "Epoch [7/10], Phase: val, Batch: [32/73], Loss: 0.2774\n",
      "Epoch [7/10], Phase: val, Batch: [33/73], Loss: 0.3872\n",
      "Epoch [7/10], Phase: val, Batch: [34/73], Loss: 0.2096\n",
      "Epoch [7/10], Phase: val, Batch: [35/73], Loss: 0.1782\n",
      "Epoch [7/10], Phase: val, Batch: [36/73], Loss: 0.3403\n",
      "Epoch [7/10], Phase: val, Batch: [37/73], Loss: 0.2177\n",
      "Epoch [7/10], Phase: val, Batch: [38/73], Loss: 0.1685\n",
      "Epoch [7/10], Phase: val, Batch: [39/73], Loss: 0.2167\n",
      "Epoch [7/10], Phase: val, Batch: [40/73], Loss: 0.1955\n",
      "Epoch [7/10], Phase: val, Batch: [41/73], Loss: 0.2219\n",
      "Epoch [7/10], Phase: val, Batch: [42/73], Loss: 0.2684\n",
      "Epoch [7/10], Phase: val, Batch: [43/73], Loss: 0.2194\n",
      "Epoch [7/10], Phase: val, Batch: [44/73], Loss: 0.2374\n",
      "Epoch [7/10], Phase: val, Batch: [45/73], Loss: 0.1896\n",
      "Epoch [7/10], Phase: val, Batch: [46/73], Loss: 0.3061\n",
      "Epoch [7/10], Phase: val, Batch: [47/73], Loss: 0.2866\n",
      "Epoch [7/10], Phase: val, Batch: [48/73], Loss: 0.1430\n",
      "Epoch [7/10], Phase: val, Batch: [49/73], Loss: 0.2988\n",
      "Epoch [7/10], Phase: val, Batch: [50/73], Loss: 0.1824\n",
      "Epoch [7/10], Phase: val, Batch: [51/73], Loss: 0.3091\n",
      "Epoch [7/10], Phase: val, Batch: [52/73], Loss: 0.1903\n",
      "Epoch [7/10], Phase: val, Batch: [53/73], Loss: 0.2165\n",
      "Epoch [7/10], Phase: val, Batch: [54/73], Loss: 0.2091\n",
      "Epoch [7/10], Phase: val, Batch: [55/73], Loss: 0.2380\n",
      "Epoch [7/10], Phase: val, Batch: [56/73], Loss: 0.3029\n",
      "Epoch [7/10], Phase: val, Batch: [57/73], Loss: 0.1397\n",
      "Epoch [7/10], Phase: val, Batch: [58/73], Loss: 0.2553\n",
      "Epoch [7/10], Phase: val, Batch: [59/73], Loss: 0.2450\n",
      "Epoch [7/10], Phase: val, Batch: [60/73], Loss: 0.1727\n",
      "Epoch [7/10], Phase: val, Batch: [61/73], Loss: 0.3315\n",
      "Epoch [7/10], Phase: val, Batch: [62/73], Loss: 0.2352\n",
      "Epoch [7/10], Phase: val, Batch: [63/73], Loss: 0.2312\n",
      "Epoch [7/10], Phase: val, Batch: [64/73], Loss: 0.2810\n",
      "Epoch [7/10], Phase: val, Batch: [65/73], Loss: 0.2431\n",
      "Epoch [7/10], Phase: val, Batch: [66/73], Loss: 0.1809\n",
      "Epoch [7/10], Phase: val, Batch: [67/73], Loss: 0.2186\n",
      "Epoch [7/10], Phase: val, Batch: [68/73], Loss: 0.2176\n",
      "Epoch [7/10], Phase: val, Batch: [69/73], Loss: 0.2979\n",
      "Epoch [7/10], Phase: val, Batch: [70/73], Loss: 0.2450\n",
      "Epoch [7/10], Phase: val, Batch: [71/73], Loss: 0.3127\n",
      "Epoch [7/10], Phase: val, Batch: [72/73], Loss: 0.4061\n",
      "Epoch [7/10], Phase: val, Batch: [73/73], Loss: 0.1146\n",
      "val Loss: 0.2400 Acc: 0.9023\n",
      "Early stopping in iteration 3 -->> no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    if counter >= patience:\n",
    "        print(f\"Early stopping in iteration {counter} -->> no improvement in validation loss.\")\n",
    "        break\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_batches = len(dataloaders[phase])\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            #all_preds.extend(preds.cpu().numpy())\n",
    "            #all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            batch_loss = loss.item()\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Phase: {phase}, Batch: [{batch_idx+1}/{total_batches}], Loss: {batch_loss:.4f}')\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        scheduler.step()\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "        \n",
    "        if phase == 'val' and epoch_loss < best_val_loss:\n",
    "            best_val_loss = epoch_loss\n",
    "            counter = 0\n",
    "        elif phase == 'val':\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a44ba06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 7 early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3782aa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9097\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for inputs, labels in dataloaders['test']:\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = np.mean(all_preds == all_labels)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98fd2a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Test Set:\n",
      "[[5353  488]\n",
      " [ 564 5242]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "classification_rep = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "print(\"Confusion Matrix Test Set:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a70cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.90      0.92      0.91      5841\n",
      "        male       0.91      0.90      0.91      5806\n",
      "\n",
      "    accuracy                           0.91     11647\n",
      "   macro avg       0.91      0.91      0.91     11647\n",
      "weighted avg       0.91      0.91      0.91     11647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report Test Set:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b222c30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = ['Male', 'Female'])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92d6ee9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Eski Kod! Stop Here! Look at VGGTransferLearning.ipynb",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEski Kod! Stop Here! Look at VGGTransferLearning.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Eski Kod! Stop Here! Look at VGGTransferLearning.ipynb"
     ]
    }
   ],
   "source": [
    "raise Exception(\"Eski Kod! Stop Here! Look at VGGTransferLearning.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'vgg_19_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d2d1e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = models.vgg16(pretrained=False)  # Load a new instance of VGG16\n",
    "num_features = loaded_model.classifier[6].in_features\n",
    "loaded_model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 2)\n",
    ")\n",
    "loaded_model.load_state_dict(torch.load('vgg_model.pth'))\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image.to(device)  # Move the image to GPU if available\n",
    "\n",
    "image_paths = ['harun.jpg', 'arda.jpg', 'fatmanur.jpg']  # Provide paths to the images\n",
    "for image_path in image_paths:\n",
    "    input_image = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(input_image)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        predicted_label = class_names[predicted_class]\n",
    "        print(f\"Image: {image_path}, Predicted Gender: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
